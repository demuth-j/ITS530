{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## FoodGAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Jacob DeMuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import imageio\n",
    "\n",
    "import time\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "from mlxtend.plotting import heatmap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch_device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## diff learning rates supported by various sources\n",
    "d_learning_rate    = 0.0004\n",
    "g_learning_rate    = 0.0002\n",
    "## Batch size supported by this paper\n",
    "## https://arxiv.org/abs/1809.11096\n",
    "batch_size       = 2048\n",
    "N_Epochs         = 11000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"C:/Users/Jacob DeMuth/Documents/fast_food/Fast Food Classification V2/Train\"\n",
    "test_data_path = \"C:/Users/Jacob DeMuth/Documents/fast_food/Fast Food Classification V2/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = []\n",
    "labels_train  = []\n",
    "targets_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob DeMuth\\AppData\\Local\\Temp\\ipykernel_13484\\1353408582.py:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(  os.path.join(train_data_path, folder, image), pilmode=\"RGB\"  )\n",
      "C:\\Users\\Jacob DeMuth\\anaconda3\\envs\\py38_ITS530\\lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir( train_data_path ):\n",
    "    for image in os.listdir( os.path.join(train_data_path, folder) ):\n",
    "        if folder not in labels_train:\n",
    "            labels_train.append( folder )\n",
    "        targets_train.append(  labels_train.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(train_data_path, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img_pil = Image.fromarray(img_arr)\n",
    "        img_pil = img_pil.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        img = torch.from_numpy(np.array(img_pil)).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_train.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Image(s) info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( targets_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train    = torch.stack( dataset_train )\n",
    "targets_train = torch.Tensor(  targets_train  ).type(   torch.LongTensor   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15000, 3, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train[1500:1600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7255, 0.6980, 0.7882,  ..., 0.7804, 0.7804, 0.7725],\n",
       "         [0.6980, 0.6078, 0.6078,  ..., 0.7843, 0.7804, 0.7765],\n",
       "         [0.7176, 0.8118, 0.5765,  ..., 0.7725, 0.7804, 0.7804],\n",
       "         ...,\n",
       "         [0.7569, 0.6392, 0.8627,  ..., 0.2353, 0.1843, 0.0392],\n",
       "         [0.7255, 0.6706, 0.5373,  ..., 0.2902, 0.0471, 0.2118],\n",
       "         [0.6471, 0.5373, 0.4039,  ..., 0.0706, 0.2157, 0.7490]],\n",
       "\n",
       "        [[0.4863, 0.2902, 0.6118,  ..., 0.8941, 0.8941, 0.8902],\n",
       "         [0.4510, 0.2824, 0.3882,  ..., 0.8980, 0.8941, 0.8941],\n",
       "         [0.4510, 0.6196, 0.3412,  ..., 0.8941, 0.8980, 0.8941],\n",
       "         ...,\n",
       "         [0.5373, 0.3647, 0.5882,  ..., 0.1686, 0.1373, 0.0902],\n",
       "         [0.4980, 0.4039, 0.2235,  ..., 0.2353, 0.1137, 0.2431],\n",
       "         [0.4353, 0.3020, 0.1922,  ..., 0.1216, 0.2353, 0.6471]],\n",
       "\n",
       "        [[0.4039, 0.1020, 0.3490,  ..., 0.9255, 0.9255, 0.9216],\n",
       "         [0.2431, 0.0941, 0.2039,  ..., 0.9216, 0.9255, 0.9255],\n",
       "         [0.1569, 0.2471, 0.1490,  ..., 0.9333, 0.9216, 0.9176],\n",
       "         ...,\n",
       "         [0.1647, 0.1608, 0.2275,  ..., 0.1569, 0.1529, 0.1569],\n",
       "         [0.2078, 0.1490, 0.0941,  ..., 0.2471, 0.1725, 0.2588],\n",
       "         [0.3176, 0.1647, 0.0784,  ..., 0.2078, 0.2588, 0.5804]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tr = data_train[1001]\n",
    "img_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transform(  img_tr  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCXw/A3iLQL2a9W5ttNgnD5gf8AeIwHzMC345471Joug2emX93qq3Mt3bwANEJuN0Z/iHsM+lR3GpQReHbf7fDdW8Fzbp/pCAgMwP8AF2yeuO+etZfhbX5n1y5aNhNp1vE3mSKpIAPReeSeP84rxLt3i9Euv+R60r3ve6fQ6eXxRJbul3Y6dNC7KN5eTeZlDNjoSB1yT1xiu80u6/tLSrS+2eX58SuUPO0nqPzrzCaTQLnSvJsoClwkzKTbt5YVWyc7s88HAGBWvoGo61Y6TFbQxLfRJwkxBQ7ewI9vWtsLXlTfLc58TSpyipcljKu777TpcNqZHmlw6MqndHtVt6g7ugA4x3BFVYIYD4Xmm0y3gie4Yme2VNxkAGMxrgnGT09/bNYN/q1299N5jK4gc+WGGcZ659fxrQ0a9nignmR8T3LEPL/EBj+H0/CsqUHP4ux0On7O3K+pky6tN/ZsWkmO4MijYI5ECttHYjr2q1a+KINNgFtcagySr95IwzBfY44zUOvxj+0LG0RmjF65M0qcOecde1O8NeC9K1uxuLi5NwjR3LwqsUmAFGMdQeea76WHhFX7nNWryeiP/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = []\n",
    "labels_test = []\n",
    "targets_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob DeMuth\\AppData\\Local\\Temp\\ipykernel_13484\\730514307.py:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(  os.path.join(test_data_path, folder, image), pilmode=\"RGB\"  )\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir( test_data_path ):\n",
    "    for image in os.listdir( os.path.join(test_data_path, folder) ):\n",
    "        if folder not in labels_test:\n",
    "            labels_test.append( folder )\n",
    "        targets_test.append(  labels_test.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(test_data_path, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img_pil = Image.fromarray(img_arr)\n",
    "        img_pil = img_pil.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        img = torch.from_numpy(np.array(img_pil)).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.stack(dataset_test)\n",
    "targets_test = torch.tensor(targets_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 3, 28, 28])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Datasetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train  \n",
    "y_train = targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test  \n",
    "y_test = targets_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.numpy()\n",
    "X_test  = X_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(  np.float32  )\n",
    "X_test  = X_test.astype(   np.float32  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train )\n",
    "X_test = torch.from_numpy( X_test  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm_mean = (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm_std = (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_normalization = transforms.Compose([\n",
    "                            transforms.Normalize( img_norm_mean, img_norm_std )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = other_normalization( X_train )  \n",
    "\n",
    "X_test  = other_normalization( X_test ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[300].item()\n",
    "type(y_train[300].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[300].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1137,  0.2627, -0.0902,  ..., -0.7098, -0.7255, -0.7255],\n",
       "         [-0.0745,  0.0510, -0.0431,  ...,  0.0275,  0.6078,  0.1137],\n",
       "         [-0.1843, -0.0902, -0.3412,  ..., -0.3725,  0.4431, -0.4510],\n",
       "         ...,\n",
       "         [-0.0588,  0.0275,  0.0980,  ..., -0.5843,  0.4196,  0.2392],\n",
       "         [-0.2000, -0.1765, -0.1373,  ..., -0.0431,  0.3725,  0.2392],\n",
       "         [-0.2235, -0.1843, -0.1686,  ...,  0.3804,  0.2706,  0.2784]],\n",
       "\n",
       "        [[-0.4667, -0.3333, -0.5137,  ..., -0.7176, -0.7098, -0.7098],\n",
       "         [-0.6157, -0.4980, -0.5137,  ..., -0.0039,  0.5922,  0.0824],\n",
       "         [-0.6235, -0.5216, -0.7255,  ..., -0.4275,  0.4353, -0.4745],\n",
       "         ...,\n",
       "         [-0.0667, -0.0118,  0.0275,  ..., -0.5451,  0.0588, -0.7020],\n",
       "         [-0.2314, -0.2235, -0.2157,  ..., -0.0588, -0.2941, -0.7176],\n",
       "         [-0.2471, -0.2235, -0.2314,  ...,  0.0980, -0.6549, -0.6549]],\n",
       "\n",
       "        [[-0.8980, -0.8824, -0.8039,  ..., -0.6627, -0.6627, -0.6784],\n",
       "         [-0.9843, -0.9137, -0.7412,  ..., -0.0353,  0.6000,  0.0824],\n",
       "         [-0.9216, -0.8824, -0.9529,  ..., -0.4196,  0.4353, -0.4980],\n",
       "         ...,\n",
       "         [-0.1451, -0.0745, -0.0353,  ..., -0.4510, -0.0196, -0.8039],\n",
       "         [-0.3255, -0.3098, -0.2784,  ..., -0.0510, -0.3961, -0.8196],\n",
       "         [-0.3255, -0.3020, -0.3020,  ...,  0.0510, -0.7647, -0.7333]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15000, 3, 28, 28])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [  ( X_train[i],  y_train[i].item() )  for i in range( X_train.shape[0]   )  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [  ( X_test[i],  y_test[i].item() )  for i in range( X_test.shape[0]   )  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl  = torch.utils.data.DataLoader(train_list, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dl   = torch.utils.data.DataLoader(test_list,  batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GAN_losses(list_losses_real, list_losses_fake, list_losses_tricked):\n",
    "    \n",
    "    the_epochs = [i for i in range(len(list_losses_real))]  \n",
    "\n",
    "    plt.plot(the_epochs, list_losses_real,    label = \"real\") \n",
    "    plt.plot(the_epochs, list_losses_fake,    label = \"fake\") \n",
    "    plt.plot(the_epochs, list_losses_tricked, label = \"tricked\")\n",
    "    plt.legend() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    f1_measure = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    print('F1-mesure: %.3f' % f1_measure)\n",
    "    return f1_measure, confmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_per_epoch(the_scores_list):\n",
    "    x_epochs = []\n",
    "    y_epochs = [] \n",
    "    for i, val in enumerate(the_scores_list):\n",
    "        x_epochs.append(i)\n",
    "        y_epochs.append(val)\n",
    "    \n",
    "    plt.scatter(x_epochs, y_epochs,s=50,c='lightgreen', marker='s', label='score')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('score')\n",
    "    plt.title('Score per epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_G_vector_input():\n",
    "    rand_vec = torch.randn( 100 )\n",
    "    return rand_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_G_batch_vector_input():\n",
    "    rand_vec = torch.randn( (batch_size, 100 ) )\n",
    "    return rand_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch_one_hot_rc(batch_size, size):\n",
    "    rand_vec = torch.zeros( (batch_size, 10 ) )\n",
    "    for i in range(batch_size):\n",
    "        random_idx = random.randint(0,size-1)\n",
    "        rand_vec[i, random_idx] = 1.0\n",
    "    return rand_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## NN Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## References: https://www.reddit.com/r/MachineLearning/comments/i085a8/d_best_gan_tricks/\n",
    "##             https://www.mathworks.com/help/deeplearning/ug/train-conditional-generative-adversarial-network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.linear1 = nn.Linear(100+10, 256)\n",
    "        self.norm1   = nn.BatchNorm1d(256)\n",
    "        self.act1    = nn.LeakyReLU(0.02)\n",
    "\n",
    "        self.linear2 = nn.Linear(256, 512)\n",
    "        self.norm2   = nn.BatchNorm1d(512)\n",
    "        self.act2    = nn.LeakyReLU(0.02)\n",
    "\n",
    "        self.linear3 = nn.Linear(512, 1024)\n",
    "        self.norm3   = nn.BatchNorm1d(1024)\n",
    "        self.act3    = nn.LeakyReLU(0.02)\n",
    "\n",
    "        self.linear4 = nn.Linear(1024, 2048)\n",
    "        self.norm4   = nn.BatchNorm1d(2048)\n",
    "        self.act4    = nn.LeakyReLU(0.02)\n",
    "\n",
    "        self.linear5 = nn.Linear(2048, 2352)\n",
    "        self.norm5   = nn.BatchNorm1d(2352)\n",
    "        self.act5    = nn.Tanh()\n",
    "        \n",
    "\n",
    "    def forward(self, rand_input, label_tensor ):\n",
    "        \n",
    "        #print(rand_input.shape)\n",
    "        #print(label_tensor.shape)\n",
    "\n",
    "        inputs = torch.cat( ( rand_input , label_tensor) , dim=1)\n",
    "\n",
    "        x      = self.linear1( inputs )\n",
    "        x      = self.norm1(x)\n",
    "        x      = self.act1(x)\n",
    "        \n",
    "        x      = self.linear2(x)\n",
    "        x      = self.norm2(x)\n",
    "        x      = self.act2(x)\n",
    "\n",
    "        x      = self.linear3(x)\n",
    "        x      = self.norm3(x)\n",
    "        x      = self.act3(x)\n",
    "\n",
    "        x      = self.linear4(x)\n",
    "        x      = self.norm4(x)\n",
    "        x      = self.act4(x)\n",
    "        \n",
    "        x      = self.linear5(x)\n",
    "        x      = self.norm5(x)\n",
    "        y_pred = self.act5(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(2352+10, 1080)\n",
    "        self.act1    = nn.LeakyReLU(0.02)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear2 = nn.Linear(1080, 512)\n",
    "        self.act2    = nn.LeakyReLU(0.02)\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "\n",
    "        self.linear3 = nn.Linear(512, 128)\n",
    "        self.act3    = nn.LeakyReLU(0.02)\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "\n",
    "        self.linear4 = nn.Linear(128, 1)\n",
    "        self.act4   = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, label_tensor):\n",
    "        \n",
    "        inputs = torch.cat( (x, label_tensor) , dim=1)\n",
    "        \n",
    "        x      = self.linear1( inputs )\n",
    "        x      = self.act1(x)\n",
    "        x      = self.dropout(x)\n",
    "        x      = self.linear2(x)\n",
    "        x      = self.act2(x)\n",
    "        x      = self.dropout(x)\n",
    "        x      = self.linear3(x)\n",
    "        x      = self.act3(x)\n",
    "        x      = self.dropout(x)\n",
    "        x      = self.linear4(x)\n",
    "        y_pred = self.act4(x)\n",
    "        \n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_losses_real    = []\n",
    "list_losses_fake    = []\n",
    "list_losses_tricked = []\n",
    "    \n",
    "\n",
    "def training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt   ):\n",
    "    \n",
    "\n",
    "    for epoch in range(N_Epochs):\n",
    "        for xb, yb in train_dl:              ## xb = [batch, 3, 28, 28]\n",
    "            \n",
    "            xb = torch.squeeze(xb, dim=3)\n",
    "            xb = xb.reshape((2048, 2352))\n",
    "\n",
    "            yb = F.one_hot(yb, num_classes=10)\n",
    "            ## input()\n",
    "       \n",
    "            #################################################\n",
    "            \n",
    "            ## G_model.eval()     ## No G training\n",
    "            \n",
    "            rand_vector = random_batch_one_hot_rc(batch_size, 10)\n",
    "            \n",
    "            gen_img = G_model( random_G_batch_vector_input(),  rand_vector ).detach()\n",
    "            \n",
    "            \n",
    "            ## Train D with real data\n",
    "            D_real_y_pred = D_model(  xb, yb )\n",
    "            D_real_loss   = D_loss_fn( D_real_y_pred, torch.ones((batch_size, 1)) )\n",
    "            D_opt.zero_grad()\n",
    "            D_real_loss.backward()\n",
    "            D_opt.step()\n",
    "            \n",
    "            ## Train D with fake data\n",
    "            D_fake_y_pred = D_model(  gen_img,  rand_vector  )\n",
    "            D_fake_loss   = D_loss_fn( D_fake_y_pred, torch.zeros((batch_size, 1)))\n",
    "            D_opt.zero_grad()\n",
    "            D_fake_loss.backward()\n",
    "            D_opt.step()\n",
    "            \n",
    "            ## G_model.train()    ## yes G training\n",
    "            \n",
    "            #################################################\n",
    "            \n",
    "            ## D_model.eval()     ## No D training\n",
    "            \n",
    "            \n",
    "            rand_vector = random_batch_one_hot_rc(batch_size, 10)\n",
    "            \n",
    "            gen_img = G_model( random_G_batch_vector_input(), rand_vector )\n",
    "            \n",
    "            ## Train G with D_loss (need to trick D)\n",
    "            D_tricked_y_pred = D_model(  gen_img, rand_vector  )\n",
    "            D_tricked_loss   = D_loss_fn( D_tricked_y_pred, torch.ones((batch_size, 1)) )\n",
    "            G_opt.zero_grad()\n",
    "            D_tricked_loss.backward()\n",
    "            G_opt.step()\n",
    "            \n",
    "            ## D_model.train()    ## yes D training\n",
    "                        \n",
    "       \n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            print(\"******************************\")\n",
    "            print(epoch, \"D_real_loss=\", D_real_loss)\n",
    "            print(epoch, \"D_fake_loss=\", D_fake_loss)\n",
    "            print(epoch, \"D_tricked_loss=\", D_tricked_loss)\n",
    "            list_losses_real.append(        D_real_loss.detach().numpy()  )\n",
    "            list_losses_fake.append(        D_fake_loss.detach().numpy()  )\n",
    "            list_losses_tricked.append(  D_tricked_loss.detach().numpy()  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Call the core functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "0 D_real_loss= tensor(0.1487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "0 D_fake_loss= tensor(0.7782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "0 D_tricked_loss= tensor(0.6565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1 D_real_loss= tensor(0.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1 D_tricked_loss= tensor(1.3841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2 D_real_loss= tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2 D_tricked_loss= tensor(2.0690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3 D_fake_loss= tensor(0.2194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3 D_tricked_loss= tensor(4.0099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4 D_real_loss= tensor(0.2060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4 D_fake_loss= tensor(0.2404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4 D_tricked_loss= tensor(5.1143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5 D_real_loss= tensor(0.1734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5 D_fake_loss= tensor(0.2923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5 D_tricked_loss= tensor(4.8309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6 D_real_loss= tensor(0.1829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6 D_fake_loss= tensor(0.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6 D_tricked_loss= tensor(4.9526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7 D_real_loss= tensor(0.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7 D_fake_loss= tensor(0.2132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7 D_tricked_loss= tensor(5.8268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8 D_real_loss= tensor(0.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8 D_fake_loss= tensor(0.1716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8 D_tricked_loss= tensor(5.3792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9 D_real_loss= tensor(0.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9 D_fake_loss= tensor(0.2061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9 D_tricked_loss= tensor(5.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10 D_real_loss= tensor(0.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10 D_fake_loss= tensor(0.1925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10 D_tricked_loss= tensor(5.3424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "11 D_real_loss= tensor(0.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "11 D_fake_loss= tensor(0.1370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "11 D_tricked_loss= tensor(6.1554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "12 D_real_loss= tensor(0.1123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "12 D_fake_loss= tensor(0.0664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "12 D_tricked_loss= tensor(6.6693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "13 D_real_loss= tensor(0.0629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "13 D_fake_loss= tensor(0.0821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "13 D_tricked_loss= tensor(6.9243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "14 D_real_loss= tensor(0.1018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "14 D_fake_loss= tensor(0.1044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "14 D_tricked_loss= tensor(6.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "15 D_real_loss= tensor(0.1129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "15 D_fake_loss= tensor(0.1162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "15 D_tricked_loss= tensor(5.7981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "16 D_real_loss= tensor(0.1243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "16 D_fake_loss= tensor(0.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "16 D_tricked_loss= tensor(5.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "17 D_real_loss= tensor(0.1364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "17 D_fake_loss= tensor(0.1072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "17 D_tricked_loss= tensor(5.2128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "18 D_real_loss= tensor(0.1022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "18 D_fake_loss= tensor(0.1127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "18 D_tricked_loss= tensor(5.3203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "19 D_real_loss= tensor(0.1074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "19 D_fake_loss= tensor(0.0955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "19 D_tricked_loss= tensor(5.7619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "20 D_real_loss= tensor(0.2018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "20 D_fake_loss= tensor(0.0967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "20 D_tricked_loss= tensor(5.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "21 D_real_loss= tensor(0.1216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "21 D_fake_loss= tensor(0.1268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "21 D_tricked_loss= tensor(4.9196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "22 D_real_loss= tensor(0.1482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "22 D_fake_loss= tensor(0.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "22 D_tricked_loss= tensor(4.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "23 D_real_loss= tensor(0.1108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "23 D_fake_loss= tensor(0.1237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "23 D_tricked_loss= tensor(5.0769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "24 D_real_loss= tensor(0.1552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "24 D_fake_loss= tensor(0.1192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "24 D_tricked_loss= tensor(4.9713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "25 D_real_loss= tensor(0.2280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "25 D_fake_loss= tensor(0.2009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "25 D_tricked_loss= tensor(4.3833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "26 D_real_loss= tensor(0.1713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "26 D_fake_loss= tensor(0.1298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "26 D_tricked_loss= tensor(4.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "27 D_real_loss= tensor(0.1157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "27 D_fake_loss= tensor(0.1261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "27 D_tricked_loss= tensor(4.9512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "28 D_real_loss= tensor(0.1944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "28 D_fake_loss= tensor(0.1113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "28 D_tricked_loss= tensor(5.1306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "29 D_real_loss= tensor(0.1508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "29 D_fake_loss= tensor(0.1494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "29 D_tricked_loss= tensor(5.3530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "30 D_real_loss= tensor(0.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "30 D_fake_loss= tensor(0.1095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "30 D_tricked_loss= tensor(4.9771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "31 D_real_loss= tensor(0.0886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "31 D_fake_loss= tensor(0.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "31 D_tricked_loss= tensor(5.0034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "32 D_real_loss= tensor(0.0966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "32 D_fake_loss= tensor(0.0827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "32 D_tricked_loss= tensor(5.0937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "33 D_real_loss= tensor(0.1249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "33 D_fake_loss= tensor(0.0878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "33 D_tricked_loss= tensor(4.9550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "34 D_real_loss= tensor(0.0743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "34 D_fake_loss= tensor(0.0748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "34 D_tricked_loss= tensor(5.3729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "35 D_real_loss= tensor(0.0773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "35 D_fake_loss= tensor(0.0919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "35 D_tricked_loss= tensor(5.8209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "36 D_real_loss= tensor(0.0925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "36 D_fake_loss= tensor(0.1271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "36 D_tricked_loss= tensor(5.2582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "37 D_real_loss= tensor(0.0952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "37 D_fake_loss= tensor(0.1381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "37 D_tricked_loss= tensor(5.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "38 D_real_loss= tensor(0.3318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "38 D_fake_loss= tensor(0.2176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "38 D_tricked_loss= tensor(4.7941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "39 D_real_loss= tensor(0.2243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "39 D_fake_loss= tensor(0.1198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "39 D_tricked_loss= tensor(3.9807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "40 D_real_loss= tensor(0.1501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "40 D_fake_loss= tensor(0.1866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "40 D_tricked_loss= tensor(4.3130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "41 D_real_loss= tensor(0.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "41 D_fake_loss= tensor(0.1384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "41 D_tricked_loss= tensor(4.0662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "42 D_real_loss= tensor(0.1824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "42 D_fake_loss= tensor(0.1504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "42 D_tricked_loss= tensor(4.0814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "43 D_real_loss= tensor(0.1380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "43 D_fake_loss= tensor(0.1528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "43 D_tricked_loss= tensor(4.1916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "44 D_real_loss= tensor(0.1471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "44 D_fake_loss= tensor(0.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "44 D_tricked_loss= tensor(4.2916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "45 D_real_loss= tensor(0.1545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "45 D_fake_loss= tensor(0.1687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "45 D_tricked_loss= tensor(4.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "46 D_real_loss= tensor(0.1510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "46 D_fake_loss= tensor(0.1331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "46 D_tricked_loss= tensor(4.8598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "47 D_real_loss= tensor(0.3033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "47 D_fake_loss= tensor(0.0933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "47 D_tricked_loss= tensor(4.8218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "48 D_real_loss= tensor(0.1241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "48 D_fake_loss= tensor(0.0999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "48 D_tricked_loss= tensor(5.1121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "49 D_real_loss= tensor(0.1561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "49 D_fake_loss= tensor(0.1145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "49 D_tricked_loss= tensor(4.7669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "50 D_real_loss= tensor(0.1407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "50 D_fake_loss= tensor(0.1305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "50 D_tricked_loss= tensor(4.7187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "51 D_real_loss= tensor(0.1131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "51 D_fake_loss= tensor(0.1378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "51 D_tricked_loss= tensor(4.6468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "52 D_real_loss= tensor(0.1071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "52 D_fake_loss= tensor(0.0957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "52 D_tricked_loss= tensor(4.9106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "53 D_real_loss= tensor(0.0872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "53 D_fake_loss= tensor(0.0949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "53 D_tricked_loss= tensor(5.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "54 D_real_loss= tensor(0.1157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "54 D_fake_loss= tensor(0.1404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "54 D_tricked_loss= tensor(4.8122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "55 D_real_loss= tensor(0.1180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "55 D_fake_loss= tensor(0.0997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "55 D_tricked_loss= tensor(4.8605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "56 D_real_loss= tensor(0.0787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "56 D_fake_loss= tensor(0.0852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "56 D_tricked_loss= tensor(5.2114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "57 D_real_loss= tensor(0.1262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "57 D_fake_loss= tensor(0.0723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "57 D_tricked_loss= tensor(4.9002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "58 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "58 D_fake_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "58 D_tricked_loss= tensor(6.7212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "59 D_real_loss= tensor(0.1600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "59 D_fake_loss= tensor(0.1635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "59 D_tricked_loss= tensor(3.8727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "60 D_real_loss= tensor(0.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "60 D_fake_loss= tensor(0.1167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "60 D_tricked_loss= tensor(4.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "61 D_real_loss= tensor(0.0734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "61 D_fake_loss= tensor(0.1652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "61 D_tricked_loss= tensor(4.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "62 D_real_loss= tensor(0.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "62 D_fake_loss= tensor(0.1416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "62 D_tricked_loss= tensor(4.3378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "63 D_real_loss= tensor(0.1024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "63 D_fake_loss= tensor(0.1303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "63 D_tricked_loss= tensor(4.1137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "64 D_real_loss= tensor(0.1096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "64 D_fake_loss= tensor(0.1489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "64 D_tricked_loss= tensor(4.6450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "65 D_real_loss= tensor(0.1522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "65 D_fake_loss= tensor(0.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "65 D_tricked_loss= tensor(4.9023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "66 D_real_loss= tensor(0.1707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "66 D_fake_loss= tensor(0.1447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "66 D_tricked_loss= tensor(4.2787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "67 D_real_loss= tensor(0.1506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "67 D_fake_loss= tensor(0.1032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "67 D_tricked_loss= tensor(4.2721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "68 D_real_loss= tensor(0.1252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "68 D_fake_loss= tensor(0.0907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "68 D_tricked_loss= tensor(4.7364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "69 D_real_loss= tensor(0.1047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "69 D_fake_loss= tensor(0.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "69 D_tricked_loss= tensor(4.7539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "70 D_real_loss= tensor(0.1220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "70 D_fake_loss= tensor(0.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "70 D_tricked_loss= tensor(4.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "71 D_real_loss= tensor(0.1227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "71 D_fake_loss= tensor(0.0887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "71 D_tricked_loss= tensor(4.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "72 D_real_loss= tensor(0.1050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "72 D_fake_loss= tensor(0.1035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "72 D_tricked_loss= tensor(4.8207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "73 D_real_loss= tensor(0.1057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "73 D_fake_loss= tensor(0.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "73 D_tricked_loss= tensor(4.6574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "74 D_real_loss= tensor(0.1111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "74 D_fake_loss= tensor(0.0862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "74 D_tricked_loss= tensor(4.8561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "75 D_real_loss= tensor(0.1052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "75 D_fake_loss= tensor(0.0931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "75 D_tricked_loss= tensor(4.9487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "76 D_real_loss= tensor(0.1005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "76 D_fake_loss= tensor(0.0796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "76 D_tricked_loss= tensor(5.1091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "77 D_real_loss= tensor(0.1034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "77 D_fake_loss= tensor(0.0808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "77 D_tricked_loss= tensor(4.8855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "78 D_real_loss= tensor(0.1348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "78 D_fake_loss= tensor(0.0979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "78 D_tricked_loss= tensor(4.9549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "79 D_real_loss= tensor(0.1007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "79 D_fake_loss= tensor(0.1087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "79 D_tricked_loss= tensor(5.3792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "80 D_real_loss= tensor(0.0922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "80 D_fake_loss= tensor(0.0942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "80 D_tricked_loss= tensor(5.1903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "81 D_real_loss= tensor(0.1233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "81 D_fake_loss= tensor(0.1221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "81 D_tricked_loss= tensor(4.7518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "82 D_real_loss= tensor(0.0991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "82 D_fake_loss= tensor(0.1015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "82 D_tricked_loss= tensor(4.9206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "83 D_real_loss= tensor(0.0980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "83 D_fake_loss= tensor(0.0950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "83 D_tricked_loss= tensor(5.3348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "84 D_real_loss= tensor(0.1663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "84 D_fake_loss= tensor(0.1133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "84 D_tricked_loss= tensor(4.9446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "85 D_real_loss= tensor(0.0848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "85 D_fake_loss= tensor(0.1119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "85 D_tricked_loss= tensor(4.6852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "86 D_real_loss= tensor(0.1026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "86 D_fake_loss= tensor(0.0906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "86 D_tricked_loss= tensor(5.2728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "87 D_real_loss= tensor(0.1024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "87 D_fake_loss= tensor(0.0819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "87 D_tricked_loss= tensor(5.2197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "88 D_real_loss= tensor(0.1044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "88 D_fake_loss= tensor(0.0693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "88 D_tricked_loss= tensor(5.1126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "89 D_real_loss= tensor(0.1132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "89 D_fake_loss= tensor(0.0665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "89 D_tricked_loss= tensor(5.2984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "90 D_real_loss= tensor(0.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "90 D_fake_loss= tensor(0.0932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "90 D_tricked_loss= tensor(5.3894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "91 D_real_loss= tensor(0.1178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "91 D_fake_loss= tensor(0.0690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "91 D_tricked_loss= tensor(5.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "92 D_real_loss= tensor(0.1111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "92 D_fake_loss= tensor(0.0719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "92 D_tricked_loss= tensor(5.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "93 D_real_loss= tensor(0.0924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "93 D_fake_loss= tensor(0.0828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "93 D_tricked_loss= tensor(5.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "94 D_real_loss= tensor(0.1081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "94 D_fake_loss= tensor(0.0880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "94 D_tricked_loss= tensor(5.8398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "95 D_real_loss= tensor(0.0762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "95 D_fake_loss= tensor(0.0773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "95 D_tricked_loss= tensor(5.7775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "96 D_real_loss= tensor(0.1124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "96 D_fake_loss= tensor(0.0707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "96 D_tricked_loss= tensor(5.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "97 D_real_loss= tensor(0.1197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "97 D_fake_loss= tensor(0.0787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "97 D_tricked_loss= tensor(6.0298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "98 D_real_loss= tensor(0.1206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "98 D_fake_loss= tensor(0.0883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "98 D_tricked_loss= tensor(5.3196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "99 D_real_loss= tensor(0.1034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "99 D_fake_loss= tensor(0.0737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "99 D_tricked_loss= tensor(5.7116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "100 D_real_loss= tensor(0.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "100 D_fake_loss= tensor(0.0694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "100 D_tricked_loss= tensor(5.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "101 D_real_loss= tensor(0.0918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "101 D_fake_loss= tensor(0.0643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "101 D_tricked_loss= tensor(5.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "102 D_real_loss= tensor(0.0807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "102 D_fake_loss= tensor(0.0904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "102 D_tricked_loss= tensor(5.3856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "103 D_real_loss= tensor(0.1109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "103 D_fake_loss= tensor(0.0880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "103 D_tricked_loss= tensor(5.3744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "104 D_real_loss= tensor(0.1175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "104 D_fake_loss= tensor(0.1245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "104 D_tricked_loss= tensor(5.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "105 D_real_loss= tensor(0.1466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "105 D_fake_loss= tensor(0.0899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "105 D_tricked_loss= tensor(5.1061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "106 D_real_loss= tensor(0.1157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "106 D_fake_loss= tensor(0.0981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "106 D_tricked_loss= tensor(5.0745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "107 D_real_loss= tensor(0.1133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "107 D_fake_loss= tensor(0.0873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "107 D_tricked_loss= tensor(5.2421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "108 D_real_loss= tensor(0.1458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "108 D_fake_loss= tensor(0.0941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "108 D_tricked_loss= tensor(5.1323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "109 D_real_loss= tensor(0.1286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "109 D_fake_loss= tensor(0.1040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "109 D_tricked_loss= tensor(5.2253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "110 D_real_loss= tensor(0.1207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "110 D_fake_loss= tensor(0.0921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "110 D_tricked_loss= tensor(5.0282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "111 D_real_loss= tensor(0.1375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "111 D_fake_loss= tensor(0.0971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "111 D_tricked_loss= tensor(5.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "112 D_real_loss= tensor(0.1464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "112 D_fake_loss= tensor(0.1203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "112 D_tricked_loss= tensor(5.3547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "113 D_real_loss= tensor(0.1288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "113 D_fake_loss= tensor(0.0964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "113 D_tricked_loss= tensor(5.6284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "114 D_real_loss= tensor(0.1464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "114 D_fake_loss= tensor(0.1106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "114 D_tricked_loss= tensor(5.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "115 D_real_loss= tensor(0.1159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "115 D_fake_loss= tensor(0.0928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "115 D_tricked_loss= tensor(5.8359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "116 D_real_loss= tensor(0.1019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "116 D_fake_loss= tensor(0.0928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "116 D_tricked_loss= tensor(5.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "117 D_real_loss= tensor(0.1343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "117 D_fake_loss= tensor(0.0751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "117 D_tricked_loss= tensor(5.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "118 D_real_loss= tensor(0.1142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "118 D_fake_loss= tensor(0.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "118 D_tricked_loss= tensor(5.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "119 D_real_loss= tensor(0.1465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "119 D_fake_loss= tensor(0.0848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "119 D_tricked_loss= tensor(5.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "120 D_real_loss= tensor(0.1213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "120 D_fake_loss= tensor(0.1145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "120 D_tricked_loss= tensor(5.6209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "121 D_real_loss= tensor(0.1326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "121 D_fake_loss= tensor(0.0888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "121 D_tricked_loss= tensor(5.3280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "122 D_real_loss= tensor(0.1284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "122 D_fake_loss= tensor(0.0920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "122 D_tricked_loss= tensor(5.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "123 D_real_loss= tensor(0.1182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "123 D_fake_loss= tensor(0.0919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "123 D_tricked_loss= tensor(5.2180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "124 D_real_loss= tensor(0.1371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "124 D_fake_loss= tensor(0.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "124 D_tricked_loss= tensor(5.6304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "125 D_real_loss= tensor(0.1193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "125 D_fake_loss= tensor(0.1212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "125 D_tricked_loss= tensor(5.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "126 D_real_loss= tensor(0.1188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "126 D_fake_loss= tensor(0.0959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "126 D_tricked_loss= tensor(5.2103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "127 D_real_loss= tensor(0.1035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "127 D_fake_loss= tensor(0.0855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "127 D_tricked_loss= tensor(5.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "128 D_real_loss= tensor(0.1408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "128 D_fake_loss= tensor(0.0726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "128 D_tricked_loss= tensor(5.1805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "129 D_real_loss= tensor(0.1005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "129 D_fake_loss= tensor(0.0786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "129 D_tricked_loss= tensor(5.3280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "130 D_real_loss= tensor(0.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "130 D_fake_loss= tensor(0.0774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "130 D_tricked_loss= tensor(5.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "131 D_real_loss= tensor(0.1042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "131 D_fake_loss= tensor(0.0816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "131 D_tricked_loss= tensor(5.1773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "132 D_real_loss= tensor(0.0680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "132 D_fake_loss= tensor(0.1095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "132 D_tricked_loss= tensor(5.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "133 D_real_loss= tensor(0.1214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "133 D_fake_loss= tensor(0.0905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "133 D_tricked_loss= tensor(5.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "134 D_real_loss= tensor(0.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "134 D_fake_loss= tensor(0.0714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "134 D_tricked_loss= tensor(5.7054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "135 D_real_loss= tensor(0.1073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "135 D_fake_loss= tensor(0.1096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "135 D_tricked_loss= tensor(5.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "136 D_real_loss= tensor(0.1001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "136 D_fake_loss= tensor(0.0882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "136 D_tricked_loss= tensor(5.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "137 D_real_loss= tensor(0.1184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "137 D_fake_loss= tensor(0.0733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "137 D_tricked_loss= tensor(5.6860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "138 D_real_loss= tensor(0.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "138 D_fake_loss= tensor(0.0857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "138 D_tricked_loss= tensor(5.0299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "139 D_real_loss= tensor(0.1197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "139 D_fake_loss= tensor(0.1009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "139 D_tricked_loss= tensor(5.1144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "140 D_real_loss= tensor(0.1190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "140 D_fake_loss= tensor(0.1166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "140 D_tricked_loss= tensor(5.2170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "141 D_real_loss= tensor(0.1428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "141 D_fake_loss= tensor(0.0881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "141 D_tricked_loss= tensor(5.0246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "142 D_real_loss= tensor(0.1223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "142 D_fake_loss= tensor(0.0974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "142 D_tricked_loss= tensor(5.3583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "143 D_real_loss= tensor(0.1410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "143 D_fake_loss= tensor(0.1000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "143 D_tricked_loss= tensor(5.0469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "144 D_real_loss= tensor(0.1199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "144 D_fake_loss= tensor(0.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "144 D_tricked_loss= tensor(5.1980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "145 D_real_loss= tensor(0.0965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "145 D_fake_loss= tensor(0.0879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "145 D_tricked_loss= tensor(5.2442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "146 D_real_loss= tensor(0.1455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "146 D_fake_loss= tensor(0.1037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "146 D_tricked_loss= tensor(5.0610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "147 D_real_loss= tensor(0.1313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "147 D_fake_loss= tensor(0.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "147 D_tricked_loss= tensor(5.2204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "148 D_real_loss= tensor(0.1448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "148 D_fake_loss= tensor(0.0942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "148 D_tricked_loss= tensor(4.8875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "149 D_real_loss= tensor(0.1213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "149 D_fake_loss= tensor(0.1095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "149 D_tricked_loss= tensor(4.6559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "150 D_real_loss= tensor(0.1470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "150 D_fake_loss= tensor(0.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "150 D_tricked_loss= tensor(4.7306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "151 D_real_loss= tensor(0.1326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "151 D_fake_loss= tensor(0.0936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "151 D_tricked_loss= tensor(4.6973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "152 D_real_loss= tensor(0.1281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "152 D_fake_loss= tensor(0.1179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "152 D_tricked_loss= tensor(4.8393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "153 D_real_loss= tensor(0.1430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "153 D_fake_loss= tensor(0.0951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "153 D_tricked_loss= tensor(5.1395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "154 D_real_loss= tensor(0.1440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "154 D_fake_loss= tensor(0.1440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "154 D_tricked_loss= tensor(4.9080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "155 D_real_loss= tensor(0.1458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "155 D_fake_loss= tensor(0.0883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "155 D_tricked_loss= tensor(5.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "156 D_real_loss= tensor(0.1728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "156 D_fake_loss= tensor(0.0972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "156 D_tricked_loss= tensor(4.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "157 D_real_loss= tensor(0.1434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "157 D_fake_loss= tensor(0.1153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "157 D_tricked_loss= tensor(4.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "158 D_real_loss= tensor(0.1221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "158 D_fake_loss= tensor(0.1060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "158 D_tricked_loss= tensor(4.8432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "159 D_real_loss= tensor(0.1570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "159 D_fake_loss= tensor(0.1025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "159 D_tricked_loss= tensor(4.9163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "160 D_real_loss= tensor(0.1331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "160 D_fake_loss= tensor(0.1400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "160 D_tricked_loss= tensor(4.6421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "161 D_real_loss= tensor(0.1805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "161 D_fake_loss= tensor(0.0981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "161 D_tricked_loss= tensor(4.8863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "162 D_real_loss= tensor(0.1451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "162 D_fake_loss= tensor(0.1310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "162 D_tricked_loss= tensor(4.9416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "163 D_real_loss= tensor(0.1461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "163 D_fake_loss= tensor(0.1244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "163 D_tricked_loss= tensor(4.7888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "164 D_real_loss= tensor(0.1708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "164 D_fake_loss= tensor(0.1062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "164 D_tricked_loss= tensor(4.8844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "165 D_real_loss= tensor(0.1545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "165 D_fake_loss= tensor(0.1397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "165 D_tricked_loss= tensor(4.8841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "166 D_real_loss= tensor(0.1300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "166 D_fake_loss= tensor(0.1205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "166 D_tricked_loss= tensor(4.6415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "167 D_real_loss= tensor(0.1136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "167 D_fake_loss= tensor(0.1120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "167 D_tricked_loss= tensor(4.9505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "168 D_real_loss= tensor(0.1790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "168 D_fake_loss= tensor(0.1082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "168 D_tricked_loss= tensor(4.8680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "169 D_real_loss= tensor(0.1217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "169 D_fake_loss= tensor(0.1007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "169 D_tricked_loss= tensor(4.9504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "170 D_real_loss= tensor(0.1274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "170 D_fake_loss= tensor(0.1385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "170 D_tricked_loss= tensor(4.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "171 D_real_loss= tensor(0.1505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "171 D_fake_loss= tensor(0.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "171 D_tricked_loss= tensor(4.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "172 D_real_loss= tensor(0.1319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "172 D_fake_loss= tensor(0.0935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "172 D_tricked_loss= tensor(5.0454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "173 D_real_loss= tensor(0.1112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "173 D_fake_loss= tensor(0.1239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "173 D_tricked_loss= tensor(4.9811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "174 D_real_loss= tensor(0.1385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "174 D_fake_loss= tensor(0.1127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "174 D_tricked_loss= tensor(5.1749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "175 D_real_loss= tensor(0.1220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "175 D_fake_loss= tensor(0.0905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "175 D_tricked_loss= tensor(4.8293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "176 D_real_loss= tensor(0.1323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "176 D_fake_loss= tensor(0.1092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "176 D_tricked_loss= tensor(4.7745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "177 D_real_loss= tensor(0.1474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "177 D_fake_loss= tensor(0.1018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "177 D_tricked_loss= tensor(4.6479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "178 D_real_loss= tensor(0.1562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "178 D_fake_loss= tensor(0.2055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "178 D_tricked_loss= tensor(4.7084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "179 D_real_loss= tensor(0.1933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "179 D_fake_loss= tensor(0.0731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "179 D_tricked_loss= tensor(4.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "180 D_real_loss= tensor(0.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "180 D_fake_loss= tensor(0.1301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "180 D_tricked_loss= tensor(4.2282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "181 D_real_loss= tensor(0.1334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "181 D_fake_loss= tensor(0.1377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "181 D_tricked_loss= tensor(4.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "182 D_real_loss= tensor(0.1669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "182 D_fake_loss= tensor(0.1426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "182 D_tricked_loss= tensor(4.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "183 D_real_loss= tensor(0.1739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "183 D_fake_loss= tensor(0.1374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "183 D_tricked_loss= tensor(4.4101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "184 D_real_loss= tensor(0.1724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "184 D_fake_loss= tensor(0.1345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "184 D_tricked_loss= tensor(4.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "185 D_real_loss= tensor(0.1979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "185 D_fake_loss= tensor(0.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "185 D_tricked_loss= tensor(4.3282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "186 D_real_loss= tensor(0.1893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "186 D_fake_loss= tensor(0.1046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "186 D_tricked_loss= tensor(4.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "187 D_real_loss= tensor(0.1575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "187 D_fake_loss= tensor(0.1057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "187 D_tricked_loss= tensor(4.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "188 D_real_loss= tensor(0.2002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "188 D_fake_loss= tensor(0.1382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "188 D_tricked_loss= tensor(4.2935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "189 D_real_loss= tensor(0.1783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "189 D_fake_loss= tensor(0.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "189 D_tricked_loss= tensor(4.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "190 D_real_loss= tensor(0.1500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "190 D_fake_loss= tensor(0.1322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "190 D_tricked_loss= tensor(4.6394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "191 D_real_loss= tensor(0.1484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "191 D_fake_loss= tensor(0.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "191 D_tricked_loss= tensor(4.3713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "192 D_real_loss= tensor(0.1429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "192 D_fake_loss= tensor(0.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "192 D_tricked_loss= tensor(4.4285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "193 D_real_loss= tensor(0.1121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "193 D_fake_loss= tensor(0.1176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "193 D_tricked_loss= tensor(4.7313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "194 D_real_loss= tensor(0.1373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "194 D_fake_loss= tensor(0.0881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "194 D_tricked_loss= tensor(4.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "195 D_real_loss= tensor(0.1390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "195 D_fake_loss= tensor(0.1239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "195 D_tricked_loss= tensor(4.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "196 D_real_loss= tensor(0.0943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "196 D_fake_loss= tensor(0.1245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "196 D_tricked_loss= tensor(5.0260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "197 D_real_loss= tensor(0.2110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "197 D_fake_loss= tensor(0.1160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "197 D_tricked_loss= tensor(4.6786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "198 D_real_loss= tensor(0.1739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "198 D_fake_loss= tensor(0.2379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "198 D_tricked_loss= tensor(4.7057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "199 D_real_loss= tensor(0.1503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "199 D_fake_loss= tensor(0.1203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "199 D_tricked_loss= tensor(4.1023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "200 D_real_loss= tensor(0.1460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "200 D_fake_loss= tensor(0.1428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "200 D_tricked_loss= tensor(4.2484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "201 D_real_loss= tensor(0.1540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "201 D_fake_loss= tensor(0.1275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "201 D_tricked_loss= tensor(4.3139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "202 D_real_loss= tensor(0.1565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "202 D_fake_loss= tensor(0.1103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "202 D_tricked_loss= tensor(4.9116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "203 D_real_loss= tensor(0.1926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "203 D_fake_loss= tensor(0.1417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "203 D_tricked_loss= tensor(4.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "204 D_real_loss= tensor(0.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "204 D_fake_loss= tensor(0.1416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "204 D_tricked_loss= tensor(4.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "205 D_real_loss= tensor(0.1585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "205 D_fake_loss= tensor(0.1226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "205 D_tricked_loss= tensor(4.6420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "206 D_real_loss= tensor(0.1930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "206 D_fake_loss= tensor(0.1551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "206 D_tricked_loss= tensor(4.1925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "207 D_real_loss= tensor(0.1552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "207 D_fake_loss= tensor(0.1586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "207 D_tricked_loss= tensor(4.3060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "208 D_real_loss= tensor(0.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "208 D_fake_loss= tensor(0.1393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "208 D_tricked_loss= tensor(4.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "209 D_real_loss= tensor(0.1700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "209 D_fake_loss= tensor(0.1419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "209 D_tricked_loss= tensor(4.6457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "210 D_real_loss= tensor(0.1614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "210 D_fake_loss= tensor(0.1093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "210 D_tricked_loss= tensor(4.6387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "211 D_real_loss= tensor(0.1569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "211 D_fake_loss= tensor(0.1328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "211 D_tricked_loss= tensor(4.6629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "212 D_real_loss= tensor(0.1649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "212 D_fake_loss= tensor(0.1205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "212 D_tricked_loss= tensor(4.6414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "213 D_real_loss= tensor(0.1676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "213 D_fake_loss= tensor(0.1287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "213 D_tricked_loss= tensor(4.6332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "214 D_real_loss= tensor(0.1736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "214 D_fake_loss= tensor(0.1305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "214 D_tricked_loss= tensor(4.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "215 D_real_loss= tensor(0.1558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "215 D_fake_loss= tensor(0.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "215 D_tricked_loss= tensor(4.2717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "216 D_real_loss= tensor(0.1638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "216 D_fake_loss= tensor(0.1341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "216 D_tricked_loss= tensor(4.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "217 D_real_loss= tensor(0.1668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "217 D_fake_loss= tensor(0.1365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "217 D_tricked_loss= tensor(4.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "218 D_real_loss= tensor(0.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "218 D_fake_loss= tensor(0.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "218 D_tricked_loss= tensor(4.6647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "219 D_real_loss= tensor(0.1999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "219 D_fake_loss= tensor(0.1418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "219 D_tricked_loss= tensor(4.6046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "220 D_real_loss= tensor(0.1814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "220 D_fake_loss= tensor(0.1229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "220 D_tricked_loss= tensor(4.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "221 D_real_loss= tensor(0.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "221 D_fake_loss= tensor(0.1454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "221 D_tricked_loss= tensor(4.2787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "222 D_real_loss= tensor(0.2132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "222 D_fake_loss= tensor(0.1369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "222 D_tricked_loss= tensor(4.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "223 D_real_loss= tensor(0.1546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "223 D_fake_loss= tensor(0.1464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "223 D_tricked_loss= tensor(4.6529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "224 D_real_loss= tensor(0.2063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "224 D_fake_loss= tensor(0.1418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "224 D_tricked_loss= tensor(4.3442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "225 D_real_loss= tensor(0.1497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "225 D_fake_loss= tensor(0.1632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "225 D_tricked_loss= tensor(4.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "226 D_real_loss= tensor(0.1352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "226 D_fake_loss= tensor(0.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "226 D_tricked_loss= tensor(4.2137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "227 D_real_loss= tensor(0.1899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "227 D_fake_loss= tensor(0.1152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "227 D_tricked_loss= tensor(4.1702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "228 D_real_loss= tensor(0.1712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "228 D_fake_loss= tensor(0.1383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "228 D_tricked_loss= tensor(4.3376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "229 D_real_loss= tensor(0.1653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "229 D_fake_loss= tensor(0.1277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "229 D_tricked_loss= tensor(4.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "230 D_real_loss= tensor(0.1510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "230 D_fake_loss= tensor(0.1517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "230 D_tricked_loss= tensor(4.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "231 D_real_loss= tensor(0.1607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "231 D_fake_loss= tensor(0.1585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "231 D_tricked_loss= tensor(4.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "232 D_real_loss= tensor(0.1746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "232 D_fake_loss= tensor(0.1387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "232 D_tricked_loss= tensor(4.7878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "233 D_real_loss= tensor(0.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "233 D_fake_loss= tensor(0.1347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "233 D_tricked_loss= tensor(4.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "234 D_real_loss= tensor(0.1758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "234 D_fake_loss= tensor(0.1216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "234 D_tricked_loss= tensor(4.7053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "235 D_real_loss= tensor(0.1705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "235 D_fake_loss= tensor(0.1391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "235 D_tricked_loss= tensor(4.6878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "236 D_real_loss= tensor(0.1462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "236 D_fake_loss= tensor(0.1139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "236 D_tricked_loss= tensor(4.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "237 D_real_loss= tensor(0.1549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "237 D_fake_loss= tensor(0.1004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "237 D_tricked_loss= tensor(4.7944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "238 D_real_loss= tensor(0.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "238 D_fake_loss= tensor(0.1328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "238 D_tricked_loss= tensor(4.7946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "239 D_real_loss= tensor(0.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "239 D_fake_loss= tensor(0.1399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "239 D_tricked_loss= tensor(4.4404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "240 D_real_loss= tensor(0.1606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "240 D_fake_loss= tensor(0.1214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "240 D_tricked_loss= tensor(4.9065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "241 D_real_loss= tensor(0.1673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "241 D_fake_loss= tensor(0.1607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "241 D_tricked_loss= tensor(4.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "242 D_real_loss= tensor(0.1775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "242 D_fake_loss= tensor(0.1258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "242 D_tricked_loss= tensor(4.3814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "243 D_real_loss= tensor(0.1664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "243 D_fake_loss= tensor(0.1058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "243 D_tricked_loss= tensor(4.6121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "244 D_real_loss= tensor(0.2010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "244 D_fake_loss= tensor(0.1216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "244 D_tricked_loss= tensor(4.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "245 D_real_loss= tensor(0.2054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "245 D_fake_loss= tensor(0.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "245 D_tricked_loss= tensor(4.3349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "246 D_real_loss= tensor(0.1678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "246 D_fake_loss= tensor(0.1377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "246 D_tricked_loss= tensor(4.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "247 D_real_loss= tensor(0.1609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "247 D_fake_loss= tensor(0.1252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "247 D_tricked_loss= tensor(4.3707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "248 D_real_loss= tensor(0.1941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "248 D_fake_loss= tensor(0.1277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "248 D_tricked_loss= tensor(4.3015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "249 D_real_loss= tensor(0.1723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "249 D_fake_loss= tensor(0.1712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "249 D_tricked_loss= tensor(4.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "250 D_real_loss= tensor(0.1336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "250 D_fake_loss= tensor(0.1306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "250 D_tricked_loss= tensor(4.4004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "251 D_real_loss= tensor(0.1826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "251 D_fake_loss= tensor(0.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "251 D_tricked_loss= tensor(4.4080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "252 D_real_loss= tensor(0.1582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "252 D_fake_loss= tensor(0.1063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "252 D_tricked_loss= tensor(4.7368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "253 D_real_loss= tensor(0.1435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "253 D_fake_loss= tensor(0.1466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "253 D_tricked_loss= tensor(4.3549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "254 D_real_loss= tensor(0.1656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "254 D_fake_loss= tensor(0.1944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "254 D_tricked_loss= tensor(4.2044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "255 D_real_loss= tensor(0.1493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "255 D_fake_loss= tensor(0.1265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "255 D_tricked_loss= tensor(4.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "256 D_real_loss= tensor(0.1849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "256 D_fake_loss= tensor(0.1442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "256 D_tricked_loss= tensor(4.4166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "257 D_real_loss= tensor(0.2254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "257 D_fake_loss= tensor(0.1348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "257 D_tricked_loss= tensor(4.1663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "258 D_real_loss= tensor(0.1678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "258 D_fake_loss= tensor(0.1092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "258 D_tricked_loss= tensor(4.2175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "259 D_real_loss= tensor(0.1705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "259 D_fake_loss= tensor(0.1366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "259 D_tricked_loss= tensor(4.2384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "260 D_real_loss= tensor(0.1692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "260 D_fake_loss= tensor(0.1564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "260 D_tricked_loss= tensor(4.1787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "261 D_real_loss= tensor(0.2056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "261 D_fake_loss= tensor(0.1440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "261 D_tricked_loss= tensor(4.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "262 D_real_loss= tensor(0.1669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "262 D_fake_loss= tensor(0.1381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "262 D_tricked_loss= tensor(4.2152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "263 D_real_loss= tensor(0.2038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "263 D_fake_loss= tensor(0.1521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "263 D_tricked_loss= tensor(4.1509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "264 D_real_loss= tensor(0.1680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "264 D_fake_loss= tensor(0.1581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "264 D_tricked_loss= tensor(4.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "265 D_real_loss= tensor(0.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "265 D_fake_loss= tensor(0.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "265 D_tricked_loss= tensor(4.1093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "266 D_real_loss= tensor(0.1735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "266 D_fake_loss= tensor(0.1538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "266 D_tricked_loss= tensor(4.0757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "267 D_real_loss= tensor(0.1927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "267 D_fake_loss= tensor(0.1477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "267 D_tricked_loss= tensor(4.0748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "268 D_real_loss= tensor(0.1874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "268 D_fake_loss= tensor(0.1318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "268 D_tricked_loss= tensor(4.2963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "269 D_real_loss= tensor(0.1969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "269 D_fake_loss= tensor(0.1663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "269 D_tricked_loss= tensor(4.1194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "270 D_real_loss= tensor(0.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "270 D_fake_loss= tensor(0.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "270 D_tricked_loss= tensor(4.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "271 D_real_loss= tensor(0.1789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "271 D_fake_loss= tensor(0.1416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "271 D_tricked_loss= tensor(4.3264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "272 D_real_loss= tensor(0.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "272 D_fake_loss= tensor(0.1805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "272 D_tricked_loss= tensor(4.1128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "273 D_real_loss= tensor(0.1718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "273 D_fake_loss= tensor(0.1584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "273 D_tricked_loss= tensor(4.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "274 D_real_loss= tensor(0.1693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "274 D_fake_loss= tensor(0.1590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "274 D_tricked_loss= tensor(4.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "275 D_real_loss= tensor(0.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "275 D_fake_loss= tensor(0.1414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "275 D_tricked_loss= tensor(4.2490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "276 D_real_loss= tensor(0.2154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "276 D_fake_loss= tensor(0.1503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "276 D_tricked_loss= tensor(4.1999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "277 D_real_loss= tensor(0.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "277 D_fake_loss= tensor(0.1529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "277 D_tricked_loss= tensor(4.2009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "278 D_real_loss= tensor(0.2020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "278 D_fake_loss= tensor(0.1582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "278 D_tricked_loss= tensor(3.9495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "279 D_real_loss= tensor(0.2098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "279 D_fake_loss= tensor(0.1448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "279 D_tricked_loss= tensor(4.0483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "280 D_real_loss= tensor(0.2061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "280 D_fake_loss= tensor(0.1560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "280 D_tricked_loss= tensor(4.1254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "281 D_real_loss= tensor(0.2234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "281 D_fake_loss= tensor(0.1482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "281 D_tricked_loss= tensor(4.1184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "282 D_real_loss= tensor(0.2190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "282 D_fake_loss= tensor(0.1694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "282 D_tricked_loss= tensor(3.9995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "283 D_real_loss= tensor(0.1718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "283 D_fake_loss= tensor(0.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "283 D_tricked_loss= tensor(4.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "284 D_real_loss= tensor(0.1572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "284 D_fake_loss= tensor(0.1580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "284 D_tricked_loss= tensor(3.8466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "285 D_real_loss= tensor(0.1946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "285 D_fake_loss= tensor(0.1683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "285 D_tricked_loss= tensor(4.1951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "286 D_real_loss= tensor(0.1910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "286 D_fake_loss= tensor(0.1402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "286 D_tricked_loss= tensor(4.1977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "287 D_real_loss= tensor(0.1748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "287 D_fake_loss= tensor(0.1506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "287 D_tricked_loss= tensor(4.0647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "288 D_real_loss= tensor(0.2029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "288 D_fake_loss= tensor(0.1742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "288 D_tricked_loss= tensor(4.0485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "289 D_real_loss= tensor(0.1619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "289 D_fake_loss= tensor(0.1665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "289 D_tricked_loss= tensor(4.0886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "290 D_real_loss= tensor(0.1902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "290 D_fake_loss= tensor(0.1735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "290 D_tricked_loss= tensor(4.1723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "291 D_real_loss= tensor(0.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "291 D_fake_loss= tensor(0.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "291 D_tricked_loss= tensor(4.0052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "292 D_real_loss= tensor(0.1716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "292 D_fake_loss= tensor(0.1461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "292 D_tricked_loss= tensor(4.2803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "293 D_real_loss= tensor(0.1745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "293 D_fake_loss= tensor(0.1566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "293 D_tricked_loss= tensor(4.0379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "294 D_real_loss= tensor(0.1781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "294 D_fake_loss= tensor(0.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "294 D_tricked_loss= tensor(4.1542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "295 D_real_loss= tensor(0.1588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "295 D_fake_loss= tensor(0.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "295 D_tricked_loss= tensor(4.3711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "296 D_real_loss= tensor(0.1853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "296 D_fake_loss= tensor(0.1322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "296 D_tricked_loss= tensor(4.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "297 D_real_loss= tensor(0.1978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "297 D_fake_loss= tensor(0.1689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "297 D_tricked_loss= tensor(4.2927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "298 D_real_loss= tensor(0.2276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "298 D_fake_loss= tensor(0.1599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "298 D_tricked_loss= tensor(4.2741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "299 D_real_loss= tensor(0.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "299 D_fake_loss= tensor(0.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "299 D_tricked_loss= tensor(4.2557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "300 D_real_loss= tensor(0.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "300 D_fake_loss= tensor(0.1767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "300 D_tricked_loss= tensor(4.2549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "301 D_real_loss= tensor(0.1901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "301 D_fake_loss= tensor(0.1585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "301 D_tricked_loss= tensor(4.2510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "302 D_real_loss= tensor(0.2003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "302 D_fake_loss= tensor(0.1450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "302 D_tricked_loss= tensor(4.2474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "303 D_real_loss= tensor(0.1997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "303 D_fake_loss= tensor(0.1769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "303 D_tricked_loss= tensor(4.1480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "304 D_real_loss= tensor(0.1920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "304 D_fake_loss= tensor(0.1620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "304 D_tricked_loss= tensor(4.1522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "305 D_real_loss= tensor(0.1805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "305 D_fake_loss= tensor(0.1284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "305 D_tricked_loss= tensor(4.3304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "306 D_real_loss= tensor(0.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "306 D_fake_loss= tensor(0.1507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "306 D_tricked_loss= tensor(3.7817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "307 D_real_loss= tensor(0.1497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "307 D_fake_loss= tensor(0.1678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "307 D_tricked_loss= tensor(4.0928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "308 D_real_loss= tensor(0.2039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "308 D_fake_loss= tensor(0.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "308 D_tricked_loss= tensor(4.2781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "309 D_real_loss= tensor(0.2376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "309 D_fake_loss= tensor(0.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "309 D_tricked_loss= tensor(4.0756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "310 D_real_loss= tensor(0.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "310 D_fake_loss= tensor(0.1837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "310 D_tricked_loss= tensor(4.0341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "311 D_real_loss= tensor(0.1682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "311 D_fake_loss= tensor(0.1744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "311 D_tricked_loss= tensor(4.0003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "312 D_real_loss= tensor(0.2003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "312 D_fake_loss= tensor(0.1566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "312 D_tricked_loss= tensor(3.7390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "313 D_real_loss= tensor(0.2123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "313 D_fake_loss= tensor(0.1497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "313 D_tricked_loss= tensor(3.8632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "314 D_real_loss= tensor(0.1810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "314 D_fake_loss= tensor(0.1405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "314 D_tricked_loss= tensor(4.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "315 D_real_loss= tensor(0.1710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "315 D_fake_loss= tensor(0.1745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "315 D_tricked_loss= tensor(4.3679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "316 D_real_loss= tensor(0.2101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "316 D_fake_loss= tensor(0.1595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "316 D_tricked_loss= tensor(4.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "317 D_real_loss= tensor(0.1906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "317 D_fake_loss= tensor(0.1609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "317 D_tricked_loss= tensor(4.0719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "318 D_real_loss= tensor(0.1812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "318 D_fake_loss= tensor(0.1344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "318 D_tricked_loss= tensor(3.9740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "319 D_real_loss= tensor(0.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "319 D_fake_loss= tensor(0.1592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "319 D_tricked_loss= tensor(4.0125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "320 D_real_loss= tensor(0.1608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "320 D_fake_loss= tensor(0.1490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "320 D_tricked_loss= tensor(4.0946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "321 D_real_loss= tensor(0.1860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "321 D_fake_loss= tensor(0.1637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "321 D_tricked_loss= tensor(4.0555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "322 D_real_loss= tensor(0.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "322 D_fake_loss= tensor(0.1969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "322 D_tricked_loss= tensor(4.1319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "323 D_real_loss= tensor(0.1779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "323 D_fake_loss= tensor(0.1894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "323 D_tricked_loss= tensor(4.2723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "324 D_real_loss= tensor(0.2057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "324 D_fake_loss= tensor(0.1544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "324 D_tricked_loss= tensor(4.1597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "325 D_real_loss= tensor(0.1823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "325 D_fake_loss= tensor(0.1781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "325 D_tricked_loss= tensor(3.7603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "326 D_real_loss= tensor(0.1873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "326 D_fake_loss= tensor(0.1654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "326 D_tricked_loss= tensor(3.9020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "327 D_real_loss= tensor(0.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "327 D_fake_loss= tensor(0.1290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "327 D_tricked_loss= tensor(4.2499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "328 D_real_loss= tensor(0.2315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "328 D_fake_loss= tensor(0.1325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "328 D_tricked_loss= tensor(4.1652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "329 D_real_loss= tensor(0.2357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "329 D_fake_loss= tensor(0.1820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "329 D_tricked_loss= tensor(4.2896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "330 D_real_loss= tensor(0.2013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "330 D_fake_loss= tensor(0.1569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "330 D_tricked_loss= tensor(4.2640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "331 D_real_loss= tensor(0.2095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "331 D_fake_loss= tensor(0.1798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "331 D_tricked_loss= tensor(4.1174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "332 D_real_loss= tensor(0.2253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "332 D_fake_loss= tensor(0.1702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "332 D_tricked_loss= tensor(3.8006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "333 D_real_loss= tensor(0.1932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "333 D_fake_loss= tensor(0.1563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "333 D_tricked_loss= tensor(3.9168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "334 D_real_loss= tensor(0.1789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "334 D_fake_loss= tensor(0.1441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "334 D_tricked_loss= tensor(4.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "335 D_real_loss= tensor(0.2123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "335 D_fake_loss= tensor(0.1961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "335 D_tricked_loss= tensor(3.9097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "336 D_real_loss= tensor(0.2359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "336 D_fake_loss= tensor(0.1654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "336 D_tricked_loss= tensor(4.2032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "337 D_real_loss= tensor(0.2657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "337 D_fake_loss= tensor(0.1675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "337 D_tricked_loss= tensor(3.9826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "338 D_real_loss= tensor(0.2288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "338 D_fake_loss= tensor(0.1684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "338 D_tricked_loss= tensor(3.9485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "339 D_real_loss= tensor(0.2125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "339 D_fake_loss= tensor(0.1873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "339 D_tricked_loss= tensor(3.8502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "340 D_real_loss= tensor(0.1904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "340 D_fake_loss= tensor(0.1693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "340 D_tricked_loss= tensor(3.7927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "341 D_real_loss= tensor(0.1963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "341 D_fake_loss= tensor(0.1622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "341 D_tricked_loss= tensor(3.9768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "342 D_real_loss= tensor(0.2208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "342 D_fake_loss= tensor(0.1591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "342 D_tricked_loss= tensor(3.9705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "343 D_real_loss= tensor(0.1578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "343 D_fake_loss= tensor(0.1639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "343 D_tricked_loss= tensor(4.0214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "344 D_real_loss= tensor(0.1921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "344 D_fake_loss= tensor(0.1943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "344 D_tricked_loss= tensor(3.8879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "345 D_real_loss= tensor(0.2324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "345 D_fake_loss= tensor(0.1600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "345 D_tricked_loss= tensor(3.8765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "346 D_real_loss= tensor(0.1778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "346 D_fake_loss= tensor(0.1440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "346 D_tricked_loss= tensor(4.0204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "347 D_real_loss= tensor(0.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "347 D_fake_loss= tensor(0.1719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "347 D_tricked_loss= tensor(3.7921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "348 D_real_loss= tensor(0.2305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "348 D_fake_loss= tensor(0.1516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "348 D_tricked_loss= tensor(3.9488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "349 D_real_loss= tensor(0.1734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "349 D_fake_loss= tensor(0.1651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "349 D_tricked_loss= tensor(4.0573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "350 D_real_loss= tensor(0.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "350 D_fake_loss= tensor(0.2104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "350 D_tricked_loss= tensor(3.9038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "351 D_real_loss= tensor(0.2218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "351 D_fake_loss= tensor(0.1684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "351 D_tricked_loss= tensor(3.9198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "352 D_real_loss= tensor(0.1821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "352 D_fake_loss= tensor(0.1400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "352 D_tricked_loss= tensor(4.0937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "353 D_real_loss= tensor(0.1882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "353 D_fake_loss= tensor(0.1660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "353 D_tricked_loss= tensor(4.0174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "354 D_real_loss= tensor(0.2066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "354 D_fake_loss= tensor(0.1715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "354 D_tricked_loss= tensor(4.0038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "355 D_real_loss= tensor(0.1646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "355 D_fake_loss= tensor(0.1546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "355 D_tricked_loss= tensor(4.2013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "356 D_real_loss= tensor(0.2015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "356 D_fake_loss= tensor(0.1753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "356 D_tricked_loss= tensor(4.2231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "357 D_real_loss= tensor(0.2141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "357 D_fake_loss= tensor(0.1948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "357 D_tricked_loss= tensor(4.0442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "358 D_real_loss= tensor(0.1967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "358 D_fake_loss= tensor(0.1910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "358 D_tricked_loss= tensor(3.9847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "359 D_real_loss= tensor(0.2007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "359 D_fake_loss= tensor(0.1872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "359 D_tricked_loss= tensor(3.9648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "360 D_real_loss= tensor(0.2097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "360 D_fake_loss= tensor(0.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "360 D_tricked_loss= tensor(3.7347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "361 D_real_loss= tensor(0.2003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "361 D_fake_loss= tensor(0.1742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "361 D_tricked_loss= tensor(3.9245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "362 D_real_loss= tensor(0.2185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "362 D_fake_loss= tensor(0.1710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "362 D_tricked_loss= tensor(3.9555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "363 D_real_loss= tensor(0.2444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "363 D_fake_loss= tensor(0.1953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "363 D_tricked_loss= tensor(3.8850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "364 D_real_loss= tensor(0.2106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "364 D_fake_loss= tensor(0.1643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "364 D_tricked_loss= tensor(3.7855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "365 D_real_loss= tensor(0.2202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "365 D_fake_loss= tensor(0.1618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "365 D_tricked_loss= tensor(3.8760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "366 D_real_loss= tensor(0.2360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "366 D_fake_loss= tensor(0.1639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "366 D_tricked_loss= tensor(3.7106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "367 D_real_loss= tensor(0.2201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "367 D_fake_loss= tensor(0.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "367 D_tricked_loss= tensor(3.8934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "368 D_real_loss= tensor(0.1845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "368 D_fake_loss= tensor(0.1680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "368 D_tricked_loss= tensor(3.9338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "369 D_real_loss= tensor(0.2251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "369 D_fake_loss= tensor(0.1682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "369 D_tricked_loss= tensor(3.8372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "370 D_real_loss= tensor(0.2247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "370 D_fake_loss= tensor(0.2021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "370 D_tricked_loss= tensor(3.9958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "371 D_real_loss= tensor(0.2188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "371 D_fake_loss= tensor(0.1588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "371 D_tricked_loss= tensor(3.9473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "372 D_real_loss= tensor(0.2104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "372 D_fake_loss= tensor(0.1771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "372 D_tricked_loss= tensor(3.9248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "373 D_real_loss= tensor(0.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "373 D_fake_loss= tensor(0.1733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "373 D_tricked_loss= tensor(3.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "374 D_real_loss= tensor(0.2199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "374 D_fake_loss= tensor(0.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "374 D_tricked_loss= tensor(3.7251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "375 D_real_loss= tensor(0.2129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "375 D_fake_loss= tensor(0.1624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "375 D_tricked_loss= tensor(3.8362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "376 D_real_loss= tensor(0.2356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "376 D_fake_loss= tensor(0.1887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "376 D_tricked_loss= tensor(3.7498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "377 D_real_loss= tensor(0.2289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "377 D_fake_loss= tensor(0.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "377 D_tricked_loss= tensor(3.7817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "378 D_real_loss= tensor(0.2126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "378 D_fake_loss= tensor(0.1754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "378 D_tricked_loss= tensor(3.6423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "379 D_real_loss= tensor(0.2521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "379 D_fake_loss= tensor(0.1900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "379 D_tricked_loss= tensor(3.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "380 D_real_loss= tensor(0.2085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "380 D_fake_loss= tensor(0.1700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "380 D_tricked_loss= tensor(3.7070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "381 D_real_loss= tensor(0.1880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "381 D_fake_loss= tensor(0.1831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "381 D_tricked_loss= tensor(3.7221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "382 D_real_loss= tensor(0.2201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "382 D_fake_loss= tensor(0.1772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "382 D_tricked_loss= tensor(3.8060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "383 D_real_loss= tensor(0.1922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "383 D_fake_loss= tensor(0.2140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "383 D_tricked_loss= tensor(3.7416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "384 D_real_loss= tensor(0.2522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "384 D_fake_loss= tensor(0.2178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "384 D_tricked_loss= tensor(3.7841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "385 D_real_loss= tensor(0.2315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "385 D_fake_loss= tensor(0.1968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "385 D_tricked_loss= tensor(3.8588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "386 D_real_loss= tensor(0.2319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "386 D_fake_loss= tensor(0.1974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "386 D_tricked_loss= tensor(3.6297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "387 D_real_loss= tensor(0.2318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "387 D_fake_loss= tensor(0.2013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "387 D_tricked_loss= tensor(3.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "388 D_real_loss= tensor(0.2444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "388 D_fake_loss= tensor(0.1918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "388 D_tricked_loss= tensor(3.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "389 D_real_loss= tensor(0.1712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "389 D_fake_loss= tensor(0.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "389 D_tricked_loss= tensor(3.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "390 D_real_loss= tensor(0.2420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "390 D_fake_loss= tensor(0.1919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "390 D_tricked_loss= tensor(3.8082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "391 D_real_loss= tensor(0.2337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "391 D_fake_loss= tensor(0.2138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "391 D_tricked_loss= tensor(3.7695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "392 D_real_loss= tensor(0.1992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "392 D_fake_loss= tensor(0.1890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "392 D_tricked_loss= tensor(3.9990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "393 D_real_loss= tensor(0.2189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "393 D_fake_loss= tensor(0.1921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "393 D_tricked_loss= tensor(3.9180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "394 D_real_loss= tensor(0.2408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "394 D_fake_loss= tensor(0.1834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "394 D_tricked_loss= tensor(3.6270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "395 D_real_loss= tensor(0.2126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "395 D_fake_loss= tensor(0.1581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "395 D_tricked_loss= tensor(3.7258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "396 D_real_loss= tensor(0.1863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "396 D_fake_loss= tensor(0.1821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "396 D_tricked_loss= tensor(3.7534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "397 D_real_loss= tensor(0.2289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "397 D_fake_loss= tensor(0.2041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "397 D_tricked_loss= tensor(3.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "398 D_real_loss= tensor(0.2088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "398 D_fake_loss= tensor(0.2107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "398 D_tricked_loss= tensor(3.7960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "399 D_real_loss= tensor(0.2298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "399 D_fake_loss= tensor(0.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "399 D_tricked_loss= tensor(3.6987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "400 D_real_loss= tensor(0.2202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "400 D_fake_loss= tensor(0.1941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "400 D_tricked_loss= tensor(3.9008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "401 D_real_loss= tensor(0.1956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "401 D_fake_loss= tensor(0.1859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "401 D_tricked_loss= tensor(3.6613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "402 D_real_loss= tensor(0.2215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "402 D_fake_loss= tensor(0.1967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "402 D_tricked_loss= tensor(3.7700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "403 D_real_loss= tensor(0.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "403 D_fake_loss= tensor(0.1759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "403 D_tricked_loss= tensor(3.7243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "404 D_real_loss= tensor(0.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "404 D_fake_loss= tensor(0.1854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "404 D_tricked_loss= tensor(3.6465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "405 D_real_loss= tensor(0.1953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "405 D_fake_loss= tensor(0.1819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "405 D_tricked_loss= tensor(3.8436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "406 D_real_loss= tensor(0.2229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "406 D_fake_loss= tensor(0.1864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "406 D_tricked_loss= tensor(4.0128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "407 D_real_loss= tensor(0.2102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "407 D_fake_loss= tensor(0.1906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "407 D_tricked_loss= tensor(3.7353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "408 D_real_loss= tensor(0.2095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "408 D_fake_loss= tensor(0.2011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "408 D_tricked_loss= tensor(3.8086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "409 D_real_loss= tensor(0.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "409 D_fake_loss= tensor(0.1970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "409 D_tricked_loss= tensor(3.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "410 D_real_loss= tensor(0.2375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "410 D_fake_loss= tensor(0.1888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "410 D_tricked_loss= tensor(3.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "411 D_real_loss= tensor(0.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "411 D_fake_loss= tensor(0.1770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "411 D_tricked_loss= tensor(3.7946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "412 D_real_loss= tensor(0.1993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "412 D_fake_loss= tensor(0.1776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "412 D_tricked_loss= tensor(3.8459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "413 D_real_loss= tensor(0.2104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "413 D_fake_loss= tensor(0.1840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "413 D_tricked_loss= tensor(3.8453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "414 D_real_loss= tensor(0.2696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "414 D_fake_loss= tensor(0.1747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "414 D_tricked_loss= tensor(3.9455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "415 D_real_loss= tensor(0.2199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "415 D_fake_loss= tensor(0.1946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "415 D_tricked_loss= tensor(3.7804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "416 D_real_loss= tensor(0.2232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "416 D_fake_loss= tensor(0.1777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "416 D_tricked_loss= tensor(3.7005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "417 D_real_loss= tensor(0.2127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "417 D_fake_loss= tensor(0.1838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "417 D_tricked_loss= tensor(3.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "418 D_real_loss= tensor(0.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "418 D_fake_loss= tensor(0.1770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "418 D_tricked_loss= tensor(3.6771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "419 D_real_loss= tensor(0.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "419 D_fake_loss= tensor(0.2040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "419 D_tricked_loss= tensor(3.6274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "420 D_real_loss= tensor(0.2179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "420 D_fake_loss= tensor(0.1909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "420 D_tricked_loss= tensor(3.6904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "421 D_real_loss= tensor(0.2128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "421 D_fake_loss= tensor(0.2115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "421 D_tricked_loss= tensor(3.6422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "422 D_real_loss= tensor(0.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "422 D_fake_loss= tensor(0.2117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "422 D_tricked_loss= tensor(3.7753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "423 D_real_loss= tensor(0.2351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "423 D_fake_loss= tensor(0.2175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "423 D_tricked_loss= tensor(3.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "424 D_real_loss= tensor(0.2202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "424 D_fake_loss= tensor(0.1929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "424 D_tricked_loss= tensor(3.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "425 D_real_loss= tensor(0.2409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "425 D_fake_loss= tensor(0.1769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "425 D_tricked_loss= tensor(3.8574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "426 D_real_loss= tensor(0.2445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "426 D_fake_loss= tensor(0.2159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "426 D_tricked_loss= tensor(3.3464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "427 D_real_loss= tensor(0.2132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "427 D_fake_loss= tensor(0.2107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "427 D_tricked_loss= tensor(3.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "428 D_real_loss= tensor(0.2428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "428 D_fake_loss= tensor(0.1896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "428 D_tricked_loss= tensor(3.6522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "429 D_real_loss= tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "429 D_fake_loss= tensor(0.1799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "429 D_tricked_loss= tensor(3.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "430 D_real_loss= tensor(0.2297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "430 D_fake_loss= tensor(0.1755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "430 D_tricked_loss= tensor(3.6500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "431 D_real_loss= tensor(0.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "431 D_fake_loss= tensor(0.1538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "431 D_tricked_loss= tensor(3.9323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "432 D_real_loss= tensor(0.2363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "432 D_fake_loss= tensor(0.2140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "432 D_tricked_loss= tensor(3.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "433 D_real_loss= tensor(0.2153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "433 D_fake_loss= tensor(0.1897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "433 D_tricked_loss= tensor(3.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "434 D_real_loss= tensor(0.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "434 D_fake_loss= tensor(0.1846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "434 D_tricked_loss= tensor(3.7710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "435 D_real_loss= tensor(0.2225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "435 D_fake_loss= tensor(0.2267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "435 D_tricked_loss= tensor(3.7424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "436 D_real_loss= tensor(0.2127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "436 D_fake_loss= tensor(0.2094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "436 D_tricked_loss= tensor(3.6443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "437 D_real_loss= tensor(0.2102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "437 D_fake_loss= tensor(0.1669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "437 D_tricked_loss= tensor(3.7768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "438 D_real_loss= tensor(0.2109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "438 D_fake_loss= tensor(0.1839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "438 D_tricked_loss= tensor(3.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "439 D_real_loss= tensor(0.2230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "439 D_fake_loss= tensor(0.1728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "439 D_tricked_loss= tensor(3.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "440 D_real_loss= tensor(0.2282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "440 D_fake_loss= tensor(0.1949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "440 D_tricked_loss= tensor(3.6362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "441 D_real_loss= tensor(0.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "441 D_fake_loss= tensor(0.2016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "441 D_tricked_loss= tensor(3.7115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "442 D_real_loss= tensor(0.2337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "442 D_fake_loss= tensor(0.2300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "442 D_tricked_loss= tensor(3.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "443 D_real_loss= tensor(0.2361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "443 D_fake_loss= tensor(0.1915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "443 D_tricked_loss= tensor(3.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "444 D_real_loss= tensor(0.2431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "444 D_fake_loss= tensor(0.1743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "444 D_tricked_loss= tensor(3.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "445 D_real_loss= tensor(0.2355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "445 D_fake_loss= tensor(0.1840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "445 D_tricked_loss= tensor(3.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "446 D_real_loss= tensor(0.2684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "446 D_fake_loss= tensor(0.1974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "446 D_tricked_loss= tensor(3.3522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "447 D_real_loss= tensor(0.2420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "447 D_fake_loss= tensor(0.2197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "447 D_tricked_loss= tensor(3.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "448 D_real_loss= tensor(0.2618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "448 D_fake_loss= tensor(0.2052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "448 D_tricked_loss= tensor(3.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "449 D_real_loss= tensor(0.2335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "449 D_fake_loss= tensor(0.1971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "449 D_tricked_loss= tensor(3.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "450 D_real_loss= tensor(0.2646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "450 D_fake_loss= tensor(0.1590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "450 D_tricked_loss= tensor(3.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "451 D_real_loss= tensor(0.2373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "451 D_fake_loss= tensor(0.1731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "451 D_tricked_loss= tensor(3.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "452 D_real_loss= tensor(0.2259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "452 D_fake_loss= tensor(0.2174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "452 D_tricked_loss= tensor(3.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "453 D_real_loss= tensor(0.2541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "453 D_fake_loss= tensor(0.2185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "453 D_tricked_loss= tensor(3.6746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "454 D_real_loss= tensor(0.2876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "454 D_fake_loss= tensor(0.2186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "454 D_tricked_loss= tensor(3.6105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "455 D_real_loss= tensor(0.2180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "455 D_fake_loss= tensor(0.2314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "455 D_tricked_loss= tensor(3.3476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "456 D_real_loss= tensor(0.2269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "456 D_fake_loss= tensor(0.1926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "456 D_tricked_loss= tensor(3.2898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "457 D_real_loss= tensor(0.2459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "457 D_fake_loss= tensor(0.1956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "457 D_tricked_loss= tensor(3.4123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "458 D_real_loss= tensor(0.2153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "458 D_fake_loss= tensor(0.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "458 D_tricked_loss= tensor(3.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "459 D_real_loss= tensor(0.2436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "459 D_fake_loss= tensor(0.2037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "459 D_tricked_loss= tensor(3.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "460 D_real_loss= tensor(0.2132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "460 D_fake_loss= tensor(0.1962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "460 D_tricked_loss= tensor(3.7250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "461 D_real_loss= tensor(0.2275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "461 D_fake_loss= tensor(0.2212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "461 D_tricked_loss= tensor(3.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "462 D_real_loss= tensor(0.2782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "462 D_fake_loss= tensor(0.2041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "462 D_tricked_loss= tensor(3.3311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "463 D_real_loss= tensor(0.2512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "463 D_fake_loss= tensor(0.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "463 D_tricked_loss= tensor(3.3711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "464 D_real_loss= tensor(0.2405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "464 D_fake_loss= tensor(0.1730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "464 D_tricked_loss= tensor(3.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "465 D_real_loss= tensor(0.2243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "465 D_fake_loss= tensor(0.1827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "465 D_tricked_loss= tensor(3.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "466 D_real_loss= tensor(0.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "466 D_fake_loss= tensor(0.1969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "466 D_tricked_loss= tensor(3.6634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "467 D_real_loss= tensor(0.2352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "467 D_fake_loss= tensor(0.2194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "467 D_tricked_loss= tensor(3.8225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "468 D_real_loss= tensor(0.2634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "468 D_fake_loss= tensor(0.2469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "468 D_tricked_loss= tensor(3.6746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "469 D_real_loss= tensor(0.2594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "469 D_fake_loss= tensor(0.2147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "469 D_tricked_loss= tensor(3.6191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "470 D_real_loss= tensor(0.2346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "470 D_fake_loss= tensor(0.2401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "470 D_tricked_loss= tensor(3.3435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "471 D_real_loss= tensor(0.2753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "471 D_fake_loss= tensor(0.2303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "471 D_tricked_loss= tensor(3.0693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "472 D_real_loss= tensor(0.2241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "472 D_fake_loss= tensor(0.1923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "472 D_tricked_loss= tensor(3.2992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "473 D_real_loss= tensor(0.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "473 D_fake_loss= tensor(0.1745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "473 D_tricked_loss= tensor(3.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "474 D_real_loss= tensor(0.2296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "474 D_fake_loss= tensor(0.2516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "474 D_tricked_loss= tensor(3.3878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "475 D_real_loss= tensor(0.2076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "475 D_fake_loss= tensor(0.2059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "475 D_tricked_loss= tensor(3.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "476 D_real_loss= tensor(0.2146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "476 D_fake_loss= tensor(0.2010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "476 D_tricked_loss= tensor(3.7189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "477 D_real_loss= tensor(0.2697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "477 D_fake_loss= tensor(0.2294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "477 D_tricked_loss= tensor(3.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "478 D_real_loss= tensor(0.2755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "478 D_fake_loss= tensor(0.1883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "478 D_tricked_loss= tensor(3.3862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "479 D_real_loss= tensor(0.2271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "479 D_fake_loss= tensor(0.2147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "479 D_tricked_loss= tensor(3.3610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "480 D_real_loss= tensor(0.2375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "480 D_fake_loss= tensor(0.1741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "480 D_tricked_loss= tensor(3.4042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "481 D_real_loss= tensor(0.2256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "481 D_fake_loss= tensor(0.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "481 D_tricked_loss= tensor(3.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "482 D_real_loss= tensor(0.2178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "482 D_fake_loss= tensor(0.2128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "482 D_tricked_loss= tensor(3.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "483 D_real_loss= tensor(0.2051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "483 D_fake_loss= tensor(0.2097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "483 D_tricked_loss= tensor(3.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "484 D_real_loss= tensor(0.2596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "484 D_fake_loss= tensor(0.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "484 D_tricked_loss= tensor(3.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "485 D_real_loss= tensor(0.2661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "485 D_fake_loss= tensor(0.2262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "485 D_tricked_loss= tensor(3.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "486 D_real_loss= tensor(0.2279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "486 D_fake_loss= tensor(0.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "486 D_tricked_loss= tensor(3.3964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "487 D_real_loss= tensor(0.2483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "487 D_fake_loss= tensor(0.2236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "487 D_tricked_loss= tensor(3.2821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "488 D_real_loss= tensor(0.2490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "488 D_fake_loss= tensor(0.1969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "488 D_tricked_loss= tensor(3.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "489 D_real_loss= tensor(0.2505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "489 D_fake_loss= tensor(0.2051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "489 D_tricked_loss= tensor(3.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "490 D_real_loss= tensor(0.2377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "490 D_fake_loss= tensor(0.2277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "490 D_tricked_loss= tensor(3.3663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "491 D_real_loss= tensor(0.2618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "491 D_fake_loss= tensor(0.2062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "491 D_tricked_loss= tensor(3.3648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "492 D_real_loss= tensor(0.2354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "492 D_fake_loss= tensor(0.1843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "492 D_tricked_loss= tensor(3.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "493 D_real_loss= tensor(0.2453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "493 D_fake_loss= tensor(0.2243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "493 D_tricked_loss= tensor(3.2662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "494 D_real_loss= tensor(0.2568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "494 D_fake_loss= tensor(0.2071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "494 D_tricked_loss= tensor(3.3290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "495 D_real_loss= tensor(0.2373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "495 D_fake_loss= tensor(0.2055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "495 D_tricked_loss= tensor(3.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "496 D_real_loss= tensor(0.2015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "496 D_fake_loss= tensor(0.2105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "496 D_tricked_loss= tensor(3.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "497 D_real_loss= tensor(0.2453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "497 D_fake_loss= tensor(0.2168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "497 D_tricked_loss= tensor(3.4039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "498 D_real_loss= tensor(0.2458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "498 D_fake_loss= tensor(0.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "498 D_tricked_loss= tensor(3.7424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "499 D_real_loss= tensor(0.2528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "499 D_fake_loss= tensor(0.1983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "499 D_tricked_loss= tensor(3.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "500 D_real_loss= tensor(0.2701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "500 D_fake_loss= tensor(0.2291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "500 D_tricked_loss= tensor(3.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "501 D_real_loss= tensor(0.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "501 D_fake_loss= tensor(0.1835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "501 D_tricked_loss= tensor(3.2231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "502 D_real_loss= tensor(0.2396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "502 D_fake_loss= tensor(0.1940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "502 D_tricked_loss= tensor(3.3433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "503 D_real_loss= tensor(0.2600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "503 D_fake_loss= tensor(0.2127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "503 D_tricked_loss= tensor(3.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "504 D_real_loss= tensor(0.2492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "504 D_fake_loss= tensor(0.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "504 D_tricked_loss= tensor(3.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "505 D_real_loss= tensor(0.2378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "505 D_fake_loss= tensor(0.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "505 D_tricked_loss= tensor(3.3666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "506 D_real_loss= tensor(0.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "506 D_fake_loss= tensor(0.2136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "506 D_tricked_loss= tensor(3.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "507 D_real_loss= tensor(0.2537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "507 D_fake_loss= tensor(0.2123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "507 D_tricked_loss= tensor(3.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "508 D_real_loss= tensor(0.2527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "508 D_fake_loss= tensor(0.1989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "508 D_tricked_loss= tensor(3.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "509 D_real_loss= tensor(0.2302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "509 D_fake_loss= tensor(0.2217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "509 D_tricked_loss= tensor(3.3322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "510 D_real_loss= tensor(0.2772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "510 D_fake_loss= tensor(0.2203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "510 D_tricked_loss= tensor(3.2910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "511 D_real_loss= tensor(0.2392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "511 D_fake_loss= tensor(0.2050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "511 D_tricked_loss= tensor(3.3794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "512 D_real_loss= tensor(0.2320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "512 D_fake_loss= tensor(0.2150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "512 D_tricked_loss= tensor(3.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "513 D_real_loss= tensor(0.2349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "513 D_fake_loss= tensor(0.2394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "513 D_tricked_loss= tensor(3.3281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "514 D_real_loss= tensor(0.2632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "514 D_fake_loss= tensor(0.2465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "514 D_tricked_loss= tensor(3.3049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "515 D_real_loss= tensor(0.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "515 D_fake_loss= tensor(0.2367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "515 D_tricked_loss= tensor(3.3335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "516 D_real_loss= tensor(0.2504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "516 D_fake_loss= tensor(0.2356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "516 D_tricked_loss= tensor(3.1500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "517 D_real_loss= tensor(0.2237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "517 D_fake_loss= tensor(0.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "517 D_tricked_loss= tensor(3.3156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "518 D_real_loss= tensor(0.2112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "518 D_fake_loss= tensor(0.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "518 D_tricked_loss= tensor(3.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "519 D_real_loss= tensor(0.2404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "519 D_fake_loss= tensor(0.2136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "519 D_tricked_loss= tensor(3.3444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "520 D_real_loss= tensor(0.2353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "520 D_fake_loss= tensor(0.1874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "520 D_tricked_loss= tensor(3.6439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "521 D_real_loss= tensor(0.2334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "521 D_fake_loss= tensor(0.2073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "521 D_tricked_loss= tensor(3.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "522 D_real_loss= tensor(0.2516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "522 D_fake_loss= tensor(0.2207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "522 D_tricked_loss= tensor(3.2573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "523 D_real_loss= tensor(0.2400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "523 D_fake_loss= tensor(0.2097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "523 D_tricked_loss= tensor(3.3791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "524 D_real_loss= tensor(0.2550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "524 D_fake_loss= tensor(0.2127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "524 D_tricked_loss= tensor(3.2426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "525 D_real_loss= tensor(0.2776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "525 D_fake_loss= tensor(0.2353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "525 D_tricked_loss= tensor(3.2346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "526 D_real_loss= tensor(0.2778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "526 D_fake_loss= tensor(0.2244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "526 D_tricked_loss= tensor(3.0872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "527 D_real_loss= tensor(0.2488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "527 D_fake_loss= tensor(0.2183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "527 D_tricked_loss= tensor(3.3178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "528 D_real_loss= tensor(0.2436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "528 D_fake_loss= tensor(0.2142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "528 D_tricked_loss= tensor(3.2989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "529 D_real_loss= tensor(0.2574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "529 D_fake_loss= tensor(0.2044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "529 D_tricked_loss= tensor(3.3927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "530 D_real_loss= tensor(0.2372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "530 D_fake_loss= tensor(0.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "530 D_tricked_loss= tensor(3.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "531 D_real_loss= tensor(0.2467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "531 D_fake_loss= tensor(0.2007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "531 D_tricked_loss= tensor(3.3599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "532 D_real_loss= tensor(0.2491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "532 D_fake_loss= tensor(0.2229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "532 D_tricked_loss= tensor(3.2798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "533 D_real_loss= tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "533 D_fake_loss= tensor(0.2064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "533 D_tricked_loss= tensor(3.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "534 D_real_loss= tensor(0.2583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "534 D_fake_loss= tensor(0.2381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "534 D_tricked_loss= tensor(3.3783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "535 D_real_loss= tensor(0.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "535 D_fake_loss= tensor(0.2222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "535 D_tricked_loss= tensor(3.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "536 D_real_loss= tensor(0.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "536 D_fake_loss= tensor(0.2086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "536 D_tricked_loss= tensor(3.3718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "537 D_real_loss= tensor(0.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "537 D_fake_loss= tensor(0.2098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "537 D_tricked_loss= tensor(3.2646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "538 D_real_loss= tensor(0.2839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "538 D_fake_loss= tensor(0.2245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "538 D_tricked_loss= tensor(3.3169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "539 D_real_loss= tensor(0.2375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "539 D_fake_loss= tensor(0.2161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "539 D_tricked_loss= tensor(3.4272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "540 D_real_loss= tensor(0.2589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "540 D_fake_loss= tensor(0.1959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "540 D_tricked_loss= tensor(3.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "541 D_real_loss= tensor(0.2627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "541 D_fake_loss= tensor(0.2203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "541 D_tricked_loss= tensor(3.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "542 D_real_loss= tensor(0.2550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "542 D_fake_loss= tensor(0.2503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "542 D_tricked_loss= tensor(3.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "543 D_real_loss= tensor(0.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "543 D_fake_loss= tensor(0.2111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "543 D_tricked_loss= tensor(3.3721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "544 D_real_loss= tensor(0.2557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "544 D_fake_loss= tensor(0.2568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "544 D_tricked_loss= tensor(3.1367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "545 D_real_loss= tensor(0.2530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "545 D_fake_loss= tensor(0.2191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "545 D_tricked_loss= tensor(3.2277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "546 D_real_loss= tensor(0.2586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "546 D_fake_loss= tensor(0.2161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "546 D_tricked_loss= tensor(3.2405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "547 D_real_loss= tensor(0.2581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "547 D_fake_loss= tensor(0.2557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "547 D_tricked_loss= tensor(3.1833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "548 D_real_loss= tensor(0.2621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "548 D_fake_loss= tensor(0.2265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "548 D_tricked_loss= tensor(3.0522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "549 D_real_loss= tensor(0.2592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "549 D_fake_loss= tensor(0.2119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "549 D_tricked_loss= tensor(3.2881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "550 D_real_loss= tensor(0.2688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "550 D_fake_loss= tensor(0.2287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "550 D_tricked_loss= tensor(3.3135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "551 D_real_loss= tensor(0.2662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "551 D_fake_loss= tensor(0.2561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "551 D_tricked_loss= tensor(3.2008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "552 D_real_loss= tensor(0.2518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "552 D_fake_loss= tensor(0.2410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "552 D_tricked_loss= tensor(3.2994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "553 D_real_loss= tensor(0.2697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "553 D_fake_loss= tensor(0.2124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "553 D_tricked_loss= tensor(3.3202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "554 D_real_loss= tensor(0.2885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "554 D_fake_loss= tensor(0.2005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "554 D_tricked_loss= tensor(3.2576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "555 D_real_loss= tensor(0.2201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "555 D_fake_loss= tensor(0.2077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "555 D_tricked_loss= tensor(3.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "556 D_real_loss= tensor(0.2664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "556 D_fake_loss= tensor(0.2070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "556 D_tricked_loss= tensor(3.2677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "557 D_real_loss= tensor(0.2358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "557 D_fake_loss= tensor(0.2423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "557 D_tricked_loss= tensor(3.2913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "558 D_real_loss= tensor(0.2483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "558 D_fake_loss= tensor(0.2198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "558 D_tricked_loss= tensor(3.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "559 D_real_loss= tensor(0.2513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "559 D_fake_loss= tensor(0.2794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "559 D_tricked_loss= tensor(2.9778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "560 D_real_loss= tensor(0.2592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "560 D_fake_loss= tensor(0.2471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "560 D_tricked_loss= tensor(3.1257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "561 D_real_loss= tensor(0.2512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "561 D_fake_loss= tensor(0.2305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "561 D_tricked_loss= tensor(3.0300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "562 D_real_loss= tensor(0.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "562 D_fake_loss= tensor(0.2194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "562 D_tricked_loss= tensor(3.1821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "563 D_real_loss= tensor(0.2521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "563 D_fake_loss= tensor(0.2421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "563 D_tricked_loss= tensor(3.0445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "564 D_real_loss= tensor(0.2417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "564 D_fake_loss= tensor(0.2068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "564 D_tricked_loss= tensor(3.2720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "565 D_real_loss= tensor(0.2567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "565 D_fake_loss= tensor(0.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "565 D_tricked_loss= tensor(3.1682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "566 D_real_loss= tensor(0.2596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "566 D_fake_loss= tensor(0.2449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "566 D_tricked_loss= tensor(3.1492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "567 D_real_loss= tensor(0.2890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "567 D_fake_loss= tensor(0.2165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "567 D_tricked_loss= tensor(3.3687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "568 D_real_loss= tensor(0.2901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "568 D_fake_loss= tensor(0.1932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "568 D_tricked_loss= tensor(3.1980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "569 D_real_loss= tensor(0.2773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "569 D_fake_loss= tensor(0.2180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "569 D_tricked_loss= tensor(3.1709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "570 D_real_loss= tensor(0.2209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "570 D_fake_loss= tensor(0.2352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "570 D_tricked_loss= tensor(3.2211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "571 D_real_loss= tensor(0.2482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "571 D_fake_loss= tensor(0.2179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "571 D_tricked_loss= tensor(3.3388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "572 D_real_loss= tensor(0.2543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "572 D_fake_loss= tensor(0.2229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "572 D_tricked_loss= tensor(3.4167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "573 D_real_loss= tensor(0.2422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "573 D_fake_loss= tensor(0.2671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "573 D_tricked_loss= tensor(3.2634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "574 D_real_loss= tensor(0.2596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "574 D_fake_loss= tensor(0.2353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "574 D_tricked_loss= tensor(3.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "575 D_real_loss= tensor(0.2694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "575 D_fake_loss= tensor(0.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "575 D_tricked_loss= tensor(3.3500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "576 D_real_loss= tensor(0.2653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "576 D_fake_loss= tensor(0.2437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "576 D_tricked_loss= tensor(3.1705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "577 D_real_loss= tensor(0.2614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "577 D_fake_loss= tensor(0.2289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "577 D_tricked_loss= tensor(3.2988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "578 D_real_loss= tensor(0.2474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "578 D_fake_loss= tensor(0.2503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "578 D_tricked_loss= tensor(3.1277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "579 D_real_loss= tensor(0.2297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "579 D_fake_loss= tensor(0.2361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "579 D_tricked_loss= tensor(3.0519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "580 D_real_loss= tensor(0.2867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "580 D_fake_loss= tensor(0.2488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "580 D_tricked_loss= tensor(3.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "581 D_real_loss= tensor(0.2770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "581 D_fake_loss= tensor(0.2321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "581 D_tricked_loss= tensor(3.3218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "582 D_real_loss= tensor(0.2536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "582 D_fake_loss= tensor(0.2210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "582 D_tricked_loss= tensor(3.3607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "583 D_real_loss= tensor(0.2416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "583 D_fake_loss= tensor(0.2382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "583 D_tricked_loss= tensor(3.3073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "584 D_real_loss= tensor(0.2435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "584 D_fake_loss= tensor(0.2201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "584 D_tricked_loss= tensor(3.0199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "585 D_real_loss= tensor(0.2356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "585 D_fake_loss= tensor(0.2012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "585 D_tricked_loss= tensor(3.1377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "586 D_real_loss= tensor(0.2107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "586 D_fake_loss= tensor(0.2026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "586 D_tricked_loss= tensor(3.2960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "587 D_real_loss= tensor(0.2490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "587 D_fake_loss= tensor(0.2709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "587 D_tricked_loss= tensor(3.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "588 D_real_loss= tensor(0.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "588 D_fake_loss= tensor(0.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "588 D_tricked_loss= tensor(3.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "589 D_real_loss= tensor(0.2159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "589 D_fake_loss= tensor(0.2302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "589 D_tricked_loss= tensor(3.3168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "590 D_real_loss= tensor(0.2961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "590 D_fake_loss= tensor(0.2594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "590 D_tricked_loss= tensor(3.3084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "591 D_real_loss= tensor(0.2765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "591 D_fake_loss= tensor(0.2001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "591 D_tricked_loss= tensor(3.3248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "592 D_real_loss= tensor(0.2332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "592 D_fake_loss= tensor(0.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "592 D_tricked_loss= tensor(3.2486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "593 D_real_loss= tensor(0.2518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "593 D_fake_loss= tensor(0.2669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "593 D_tricked_loss= tensor(3.1931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "594 D_real_loss= tensor(0.2496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "594 D_fake_loss= tensor(0.2194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "594 D_tricked_loss= tensor(3.2902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "595 D_real_loss= tensor(0.2558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "595 D_fake_loss= tensor(0.2042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "595 D_tricked_loss= tensor(3.3487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "596 D_real_loss= tensor(0.2944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "596 D_fake_loss= tensor(0.2304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "596 D_tricked_loss= tensor(3.4117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "597 D_real_loss= tensor(0.2650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "597 D_fake_loss= tensor(0.2260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "597 D_tricked_loss= tensor(3.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "598 D_real_loss= tensor(0.2619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "598 D_fake_loss= tensor(0.2738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "598 D_tricked_loss= tensor(3.2457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "599 D_real_loss= tensor(0.2990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "599 D_fake_loss= tensor(0.2510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "599 D_tricked_loss= tensor(3.1239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "600 D_real_loss= tensor(0.2531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "600 D_fake_loss= tensor(0.2138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "600 D_tricked_loss= tensor(3.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "601 D_real_loss= tensor(0.2490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "601 D_fake_loss= tensor(0.2435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "601 D_tricked_loss= tensor(3.0899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "602 D_real_loss= tensor(0.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "602 D_fake_loss= tensor(0.2561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "602 D_tricked_loss= tensor(3.0259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "603 D_real_loss= tensor(0.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "603 D_fake_loss= tensor(0.2439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "603 D_tricked_loss= tensor(3.1923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "604 D_real_loss= tensor(0.2946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "604 D_fake_loss= tensor(0.2643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "604 D_tricked_loss= tensor(3.0313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "605 D_real_loss= tensor(0.2768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "605 D_fake_loss= tensor(0.2464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "605 D_tricked_loss= tensor(2.9983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "606 D_real_loss= tensor(0.2955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "606 D_fake_loss= tensor(0.2291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "606 D_tricked_loss= tensor(3.0702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "607 D_real_loss= tensor(0.2368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "607 D_fake_loss= tensor(0.2405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "607 D_tricked_loss= tensor(3.0962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "608 D_real_loss= tensor(0.2405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "608 D_fake_loss= tensor(0.2657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "608 D_tricked_loss= tensor(2.9212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "609 D_real_loss= tensor(0.2540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "609 D_fake_loss= tensor(0.2361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "609 D_tricked_loss= tensor(3.1480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "610 D_real_loss= tensor(0.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "610 D_fake_loss= tensor(0.2473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "610 D_tricked_loss= tensor(3.0048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "611 D_real_loss= tensor(0.2801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "611 D_fake_loss= tensor(0.2692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "611 D_tricked_loss= tensor(3.1043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "612 D_real_loss= tensor(0.3175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "612 D_fake_loss= tensor(0.2316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "612 D_tricked_loss= tensor(3.1482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "613 D_real_loss= tensor(0.2498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "613 D_fake_loss= tensor(0.2783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "613 D_tricked_loss= tensor(2.9425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "614 D_real_loss= tensor(0.2933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "614 D_fake_loss= tensor(0.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "614 D_tricked_loss= tensor(2.7793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "615 D_real_loss= tensor(0.3076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "615 D_fake_loss= tensor(0.2263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "615 D_tricked_loss= tensor(2.9798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "616 D_real_loss= tensor(0.2838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "616 D_fake_loss= tensor(0.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "616 D_tricked_loss= tensor(3.1302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "617 D_real_loss= tensor(0.2888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "617 D_fake_loss= tensor(0.2511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "617 D_tricked_loss= tensor(3.0861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "618 D_real_loss= tensor(0.2757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "618 D_fake_loss= tensor(0.2391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "618 D_tricked_loss= tensor(3.2041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "619 D_real_loss= tensor(0.2588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "619 D_fake_loss= tensor(0.2451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "619 D_tricked_loss= tensor(3.2676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "620 D_real_loss= tensor(0.2645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "620 D_fake_loss= tensor(0.2667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "620 D_tricked_loss= tensor(3.0486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "621 D_real_loss= tensor(0.2784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "621 D_fake_loss= tensor(0.2726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "621 D_tricked_loss= tensor(2.9673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "622 D_real_loss= tensor(0.2806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "622 D_fake_loss= tensor(0.2498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "622 D_tricked_loss= tensor(3.0274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "623 D_real_loss= tensor(0.2561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "623 D_fake_loss= tensor(0.2687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "623 D_tricked_loss= tensor(2.8727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "624 D_real_loss= tensor(0.2880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "624 D_fake_loss= tensor(0.2155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "624 D_tricked_loss= tensor(3.0915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "625 D_real_loss= tensor(0.2713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "625 D_fake_loss= tensor(0.2376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "625 D_tricked_loss= tensor(3.1486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "626 D_real_loss= tensor(0.2866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "626 D_fake_loss= tensor(0.2223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "626 D_tricked_loss= tensor(3.2865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "627 D_real_loss= tensor(0.2863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "627 D_fake_loss= tensor(0.2539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "627 D_tricked_loss= tensor(3.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "628 D_real_loss= tensor(0.2801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "628 D_fake_loss= tensor(0.2328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "628 D_tricked_loss= tensor(3.1753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "629 D_real_loss= tensor(0.2928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "629 D_fake_loss= tensor(0.2620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "629 D_tricked_loss= tensor(2.9792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "630 D_real_loss= tensor(0.2702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "630 D_fake_loss= tensor(0.2794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "630 D_tricked_loss= tensor(2.9296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "631 D_real_loss= tensor(0.2849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "631 D_fake_loss= tensor(0.2619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "631 D_tricked_loss= tensor(3.1037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "632 D_real_loss= tensor(0.3108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "632 D_fake_loss= tensor(0.2381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "632 D_tricked_loss= tensor(2.9655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "633 D_real_loss= tensor(0.2624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "633 D_fake_loss= tensor(0.2540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "633 D_tricked_loss= tensor(3.0163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "634 D_real_loss= tensor(0.2855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "634 D_fake_loss= tensor(0.2290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "634 D_tricked_loss= tensor(3.2989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "635 D_real_loss= tensor(0.2872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "635 D_fake_loss= tensor(0.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "635 D_tricked_loss= tensor(3.0827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "636 D_real_loss= tensor(0.2588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "636 D_fake_loss= tensor(0.2527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "636 D_tricked_loss= tensor(3.0062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "637 D_real_loss= tensor(0.2759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "637 D_fake_loss= tensor(0.2307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "637 D_tricked_loss= tensor(3.0923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "638 D_real_loss= tensor(0.2571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "638 D_fake_loss= tensor(0.2494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "638 D_tricked_loss= tensor(3.1261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "639 D_real_loss= tensor(0.2869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "639 D_fake_loss= tensor(0.2486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "639 D_tricked_loss= tensor(3.1342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "640 D_real_loss= tensor(0.2524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "640 D_fake_loss= tensor(0.2531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "640 D_tricked_loss= tensor(3.1519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "641 D_real_loss= tensor(0.2888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "641 D_fake_loss= tensor(0.2174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "641 D_tricked_loss= tensor(3.3396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "642 D_real_loss= tensor(0.2804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "642 D_fake_loss= tensor(0.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "642 D_tricked_loss= tensor(3.1845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "643 D_real_loss= tensor(0.2757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "643 D_fake_loss= tensor(0.2454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "643 D_tricked_loss= tensor(3.0212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "644 D_real_loss= tensor(0.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "644 D_fake_loss= tensor(0.2511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "644 D_tricked_loss= tensor(3.0652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "645 D_real_loss= tensor(0.3106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "645 D_fake_loss= tensor(0.2470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "645 D_tricked_loss= tensor(2.9701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "646 D_real_loss= tensor(0.2995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "646 D_fake_loss= tensor(0.2498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "646 D_tricked_loss= tensor(3.0409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "647 D_real_loss= tensor(0.2741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "647 D_fake_loss= tensor(0.2801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "647 D_tricked_loss= tensor(2.9648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "648 D_real_loss= tensor(0.3062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "648 D_fake_loss= tensor(0.2447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "648 D_tricked_loss= tensor(3.0215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "649 D_real_loss= tensor(0.2723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "649 D_fake_loss= tensor(0.2690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "649 D_tricked_loss= tensor(3.0281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "650 D_real_loss= tensor(0.2827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "650 D_fake_loss= tensor(0.2673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "650 D_tricked_loss= tensor(2.9499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "651 D_real_loss= tensor(0.2821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "651 D_fake_loss= tensor(0.2350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "651 D_tricked_loss= tensor(2.9387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "652 D_real_loss= tensor(0.2731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "652 D_fake_loss= tensor(0.2475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "652 D_tricked_loss= tensor(2.9213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "653 D_real_loss= tensor(0.2739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "653 D_fake_loss= tensor(0.2593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "653 D_tricked_loss= tensor(2.8826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "654 D_real_loss= tensor(0.2903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "654 D_fake_loss= tensor(0.2897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "654 D_tricked_loss= tensor(2.8953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "655 D_real_loss= tensor(0.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "655 D_fake_loss= tensor(0.2395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "655 D_tricked_loss= tensor(3.0706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "656 D_real_loss= tensor(0.2706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "656 D_fake_loss= tensor(0.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "656 D_tricked_loss= tensor(3.1349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "657 D_real_loss= tensor(0.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "657 D_fake_loss= tensor(0.2725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "657 D_tricked_loss= tensor(2.9153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "658 D_real_loss= tensor(0.2771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "658 D_fake_loss= tensor(0.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "658 D_tricked_loss= tensor(2.8816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "659 D_real_loss= tensor(0.3073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "659 D_fake_loss= tensor(0.2383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "659 D_tricked_loss= tensor(2.8401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "660 D_real_loss= tensor(0.2813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "660 D_fake_loss= tensor(0.2227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "660 D_tricked_loss= tensor(3.0085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "661 D_real_loss= tensor(0.2540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "661 D_fake_loss= tensor(0.2581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "661 D_tricked_loss= tensor(2.9428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "662 D_real_loss= tensor(0.3298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "662 D_fake_loss= tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "662 D_tricked_loss= tensor(3.0047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "663 D_real_loss= tensor(0.2763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "663 D_fake_loss= tensor(0.2495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "663 D_tricked_loss= tensor(3.2128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "664 D_real_loss= tensor(0.2781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "664 D_fake_loss= tensor(0.2662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "664 D_tricked_loss= tensor(3.2563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "665 D_real_loss= tensor(0.2968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "665 D_fake_loss= tensor(0.2805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "665 D_tricked_loss= tensor(2.9986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "666 D_real_loss= tensor(0.3048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "666 D_fake_loss= tensor(0.2512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "666 D_tricked_loss= tensor(2.9061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "667 D_real_loss= tensor(0.3173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "667 D_fake_loss= tensor(0.2576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "667 D_tricked_loss= tensor(2.8313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "668 D_real_loss= tensor(0.2782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "668 D_fake_loss= tensor(0.2446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "668 D_tricked_loss= tensor(2.7788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "669 D_real_loss= tensor(0.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "669 D_fake_loss= tensor(0.2225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "669 D_tricked_loss= tensor(3.0582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "670 D_real_loss= tensor(0.2431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "670 D_fake_loss= tensor(0.2618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "670 D_tricked_loss= tensor(3.0448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "671 D_real_loss= tensor(0.2729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "671 D_fake_loss= tensor(0.2858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "671 D_tricked_loss= tensor(2.9274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "672 D_real_loss= tensor(0.2670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "672 D_fake_loss= tensor(0.2503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "672 D_tricked_loss= tensor(3.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "673 D_real_loss= tensor(0.2477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "673 D_fake_loss= tensor(0.2535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "673 D_tricked_loss= tensor(3.0184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "674 D_real_loss= tensor(0.2760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "674 D_fake_loss= tensor(0.2644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "674 D_tricked_loss= tensor(2.8969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "675 D_real_loss= tensor(0.2858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "675 D_fake_loss= tensor(0.2300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "675 D_tricked_loss= tensor(2.8300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "676 D_real_loss= tensor(0.2493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "676 D_fake_loss= tensor(0.2149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "676 D_tricked_loss= tensor(2.9690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "677 D_real_loss= tensor(0.2842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "677 D_fake_loss= tensor(0.2583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "677 D_tricked_loss= tensor(2.8001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "678 D_real_loss= tensor(0.2999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "678 D_fake_loss= tensor(0.2517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "678 D_tricked_loss= tensor(3.1455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "679 D_real_loss= tensor(0.2609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "679 D_fake_loss= tensor(0.2588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "679 D_tricked_loss= tensor(3.0353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "680 D_real_loss= tensor(0.3042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "680 D_fake_loss= tensor(0.2826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "680 D_tricked_loss= tensor(2.9869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "681 D_real_loss= tensor(0.3019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "681 D_fake_loss= tensor(0.2345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "681 D_tricked_loss= tensor(2.9970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "682 D_real_loss= tensor(0.2700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "682 D_fake_loss= tensor(0.2540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "682 D_tricked_loss= tensor(3.0131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "683 D_real_loss= tensor(0.2874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "683 D_fake_loss= tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "683 D_tricked_loss= tensor(2.9193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "684 D_real_loss= tensor(0.2837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "684 D_fake_loss= tensor(0.2321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "684 D_tricked_loss= tensor(3.0273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "685 D_real_loss= tensor(0.2853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "685 D_fake_loss= tensor(0.2488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "685 D_tricked_loss= tensor(3.0232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "686 D_real_loss= tensor(0.3034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "686 D_fake_loss= tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "686 D_tricked_loss= tensor(2.9150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "687 D_real_loss= tensor(0.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "687 D_fake_loss= tensor(0.2286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "687 D_tricked_loss= tensor(2.9214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "688 D_real_loss= tensor(0.2934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "688 D_fake_loss= tensor(0.2511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "688 D_tricked_loss= tensor(3.0810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "689 D_real_loss= tensor(0.2900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "689 D_fake_loss= tensor(0.2515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "689 D_tricked_loss= tensor(2.9565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "690 D_real_loss= tensor(0.2790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "690 D_fake_loss= tensor(0.2482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "690 D_tricked_loss= tensor(2.9257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "691 D_real_loss= tensor(0.2745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "691 D_fake_loss= tensor(0.2615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "691 D_tricked_loss= tensor(2.8317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "692 D_real_loss= tensor(0.2969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "692 D_fake_loss= tensor(0.2625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "692 D_tricked_loss= tensor(2.8527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "693 D_real_loss= tensor(0.2598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "693 D_fake_loss= tensor(0.2070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "693 D_tricked_loss= tensor(3.3661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "694 D_real_loss= tensor(0.2840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "694 D_fake_loss= tensor(0.2650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "694 D_tricked_loss= tensor(2.9661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "695 D_real_loss= tensor(0.2734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "695 D_fake_loss= tensor(0.2511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "695 D_tricked_loss= tensor(3.0347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "696 D_real_loss= tensor(0.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "696 D_fake_loss= tensor(0.2282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "696 D_tricked_loss= tensor(3.1256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "697 D_real_loss= tensor(0.2904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "697 D_fake_loss= tensor(0.2419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "697 D_tricked_loss= tensor(3.1445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "698 D_real_loss= tensor(0.2788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "698 D_fake_loss= tensor(0.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "698 D_tricked_loss= tensor(3.0631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "699 D_real_loss= tensor(0.2718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "699 D_fake_loss= tensor(0.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "699 D_tricked_loss= tensor(3.0453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "700 D_real_loss= tensor(0.2922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "700 D_fake_loss= tensor(0.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "700 D_tricked_loss= tensor(2.8877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "701 D_real_loss= tensor(0.2805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "701 D_fake_loss= tensor(0.2640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "701 D_tricked_loss= tensor(2.8307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "702 D_real_loss= tensor(0.2904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "702 D_fake_loss= tensor(0.2608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "702 D_tricked_loss= tensor(2.8493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "703 D_real_loss= tensor(0.3065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "703 D_fake_loss= tensor(0.2582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "703 D_tricked_loss= tensor(2.9875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "704 D_real_loss= tensor(0.3067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "704 D_fake_loss= tensor(0.2715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "704 D_tricked_loss= tensor(3.0371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "705 D_real_loss= tensor(0.2787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "705 D_fake_loss= tensor(0.2407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "705 D_tricked_loss= tensor(3.2170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "706 D_real_loss= tensor(0.2812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "706 D_fake_loss= tensor(0.2230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "706 D_tricked_loss= tensor(2.9184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "707 D_real_loss= tensor(0.3033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "707 D_fake_loss= tensor(0.2437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "707 D_tricked_loss= tensor(2.8914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "708 D_real_loss= tensor(0.2672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "708 D_fake_loss= tensor(0.2668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "708 D_tricked_loss= tensor(2.7829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "709 D_real_loss= tensor(0.2943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "709 D_fake_loss= tensor(0.2557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "709 D_tricked_loss= tensor(2.8670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "710 D_real_loss= tensor(0.2900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "710 D_fake_loss= tensor(0.2887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "710 D_tricked_loss= tensor(2.9280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "711 D_real_loss= tensor(0.2882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "711 D_fake_loss= tensor(0.2560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "711 D_tricked_loss= tensor(3.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "712 D_real_loss= tensor(0.2694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "712 D_fake_loss= tensor(0.2699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "712 D_tricked_loss= tensor(2.8854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "713 D_real_loss= tensor(0.3207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "713 D_fake_loss= tensor(0.2496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "713 D_tricked_loss= tensor(2.8961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "714 D_real_loss= tensor(0.3050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "714 D_fake_loss= tensor(0.2459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "714 D_tricked_loss= tensor(2.8638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "715 D_real_loss= tensor(0.3222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "715 D_fake_loss= tensor(0.2656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "715 D_tricked_loss= tensor(2.8368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "716 D_real_loss= tensor(0.2678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "716 D_fake_loss= tensor(0.2525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "716 D_tricked_loss= tensor(2.7618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "717 D_real_loss= tensor(0.2786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "717 D_fake_loss= tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "717 D_tricked_loss= tensor(3.0337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "718 D_real_loss= tensor(0.3020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "718 D_fake_loss= tensor(0.2244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "718 D_tricked_loss= tensor(3.0207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "719 D_real_loss= tensor(0.2911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "719 D_fake_loss= tensor(0.2732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "719 D_tricked_loss= tensor(3.0200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "720 D_real_loss= tensor(0.3024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "720 D_fake_loss= tensor(0.2313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "720 D_tricked_loss= tensor(3.0797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "721 D_real_loss= tensor(0.2845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "721 D_fake_loss= tensor(0.2565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "721 D_tricked_loss= tensor(3.0084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "722 D_real_loss= tensor(0.2958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "722 D_fake_loss= tensor(0.2545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "722 D_tricked_loss= tensor(2.9308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "723 D_real_loss= tensor(0.2908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "723 D_fake_loss= tensor(0.2795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "723 D_tricked_loss= tensor(2.8221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "724 D_real_loss= tensor(0.2851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "724 D_fake_loss= tensor(0.2607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "724 D_tricked_loss= tensor(2.7932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "725 D_real_loss= tensor(0.2831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "725 D_fake_loss= tensor(0.2464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "725 D_tricked_loss= tensor(2.8344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "726 D_real_loss= tensor(0.2728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "726 D_fake_loss= tensor(0.2827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "726 D_tricked_loss= tensor(2.8852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "727 D_real_loss= tensor(0.3118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "727 D_fake_loss= tensor(0.2458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "727 D_tricked_loss= tensor(3.0281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "728 D_real_loss= tensor(0.2689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "728 D_fake_loss= tensor(0.2624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "728 D_tricked_loss= tensor(3.0656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "729 D_real_loss= tensor(0.3022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "729 D_fake_loss= tensor(0.3143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "729 D_tricked_loss= tensor(2.9652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "730 D_real_loss= tensor(0.2936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "730 D_fake_loss= tensor(0.2372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "730 D_tricked_loss= tensor(2.9159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "731 D_real_loss= tensor(0.2896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "731 D_fake_loss= tensor(0.2648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "731 D_tricked_loss= tensor(2.7604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "732 D_real_loss= tensor(0.3086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "732 D_fake_loss= tensor(0.2677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "732 D_tricked_loss= tensor(2.7940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "733 D_real_loss= tensor(0.2672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "733 D_fake_loss= tensor(0.2600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "733 D_tricked_loss= tensor(2.9295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "734 D_real_loss= tensor(0.2591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "734 D_fake_loss= tensor(0.2831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "734 D_tricked_loss= tensor(3.0184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "735 D_real_loss= tensor(0.3064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "735 D_fake_loss= tensor(0.2890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "735 D_tricked_loss= tensor(2.9034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "736 D_real_loss= tensor(0.2984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "736 D_fake_loss= tensor(0.2580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "736 D_tricked_loss= tensor(3.0761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "737 D_real_loss= tensor(0.2975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "737 D_fake_loss= tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "737 D_tricked_loss= tensor(2.9991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "738 D_real_loss= tensor(0.3252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "738 D_fake_loss= tensor(0.2566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "738 D_tricked_loss= tensor(2.8730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "739 D_real_loss= tensor(0.2962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "739 D_fake_loss= tensor(0.2604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "739 D_tricked_loss= tensor(2.9386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "740 D_real_loss= tensor(0.3168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "740 D_fake_loss= tensor(0.2507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "740 D_tricked_loss= tensor(2.9060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "741 D_real_loss= tensor(0.3182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "741 D_fake_loss= tensor(0.2446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "741 D_tricked_loss= tensor(2.9223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "742 D_real_loss= tensor(0.2807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "742 D_fake_loss= tensor(0.2466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "742 D_tricked_loss= tensor(3.0169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "743 D_real_loss= tensor(0.2962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "743 D_fake_loss= tensor(0.2806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "743 D_tricked_loss= tensor(2.9266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "744 D_real_loss= tensor(0.3330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "744 D_fake_loss= tensor(0.2638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "744 D_tricked_loss= tensor(2.9981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "745 D_real_loss= tensor(0.2930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "745 D_fake_loss= tensor(0.2799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "745 D_tricked_loss= tensor(3.0352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "746 D_real_loss= tensor(0.3449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "746 D_fake_loss= tensor(0.2742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "746 D_tricked_loss= tensor(2.8723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "747 D_real_loss= tensor(0.3066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "747 D_fake_loss= tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "747 D_tricked_loss= tensor(2.7945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "748 D_real_loss= tensor(0.3413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "748 D_fake_loss= tensor(0.2407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "748 D_tricked_loss= tensor(2.7721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "749 D_real_loss= tensor(0.2784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "749 D_fake_loss= tensor(0.2577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "749 D_tricked_loss= tensor(2.9239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "750 D_real_loss= tensor(0.3026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "750 D_fake_loss= tensor(0.2445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "750 D_tricked_loss= tensor(2.9109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "751 D_real_loss= tensor(0.3040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "751 D_fake_loss= tensor(0.2328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "751 D_tricked_loss= tensor(2.9077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "752 D_real_loss= tensor(0.2759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "752 D_fake_loss= tensor(0.2760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "752 D_tricked_loss= tensor(3.0309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "753 D_real_loss= tensor(0.3073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "753 D_fake_loss= tensor(0.2448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "753 D_tricked_loss= tensor(2.8738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "754 D_real_loss= tensor(0.3098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "754 D_fake_loss= tensor(0.2600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "754 D_tricked_loss= tensor(2.9104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "755 D_real_loss= tensor(0.2566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "755 D_fake_loss= tensor(0.2772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "755 D_tricked_loss= tensor(2.8194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "756 D_real_loss= tensor(0.2737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "756 D_fake_loss= tensor(0.2636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "756 D_tricked_loss= tensor(2.8287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "757 D_real_loss= tensor(0.2644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "757 D_fake_loss= tensor(0.2586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "757 D_tricked_loss= tensor(2.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "758 D_real_loss= tensor(0.3075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "758 D_fake_loss= tensor(0.2473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "758 D_tricked_loss= tensor(2.9253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "759 D_real_loss= tensor(0.2786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "759 D_fake_loss= tensor(0.2697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "759 D_tricked_loss= tensor(2.8545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "760 D_real_loss= tensor(0.3012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "760 D_fake_loss= tensor(0.2785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "760 D_tricked_loss= tensor(2.9494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "761 D_real_loss= tensor(0.2619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "761 D_fake_loss= tensor(0.2684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "761 D_tricked_loss= tensor(2.9226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "762 D_real_loss= tensor(0.3157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "762 D_fake_loss= tensor(0.2895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "762 D_tricked_loss= tensor(2.9215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "763 D_real_loss= tensor(0.2940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "763 D_fake_loss= tensor(0.2482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "763 D_tricked_loss= tensor(2.8545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "764 D_real_loss= tensor(0.3271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "764 D_fake_loss= tensor(0.2223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "764 D_tricked_loss= tensor(2.8465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "765 D_real_loss= tensor(0.3243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "765 D_fake_loss= tensor(0.2713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "765 D_tricked_loss= tensor(2.7904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "766 D_real_loss= tensor(0.2738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "766 D_fake_loss= tensor(0.2260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "766 D_tricked_loss= tensor(2.9096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "767 D_real_loss= tensor(0.2882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "767 D_fake_loss= tensor(0.2935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "767 D_tricked_loss= tensor(2.7466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "768 D_real_loss= tensor(0.3169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "768 D_fake_loss= tensor(0.2769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "768 D_tricked_loss= tensor(2.8735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "769 D_real_loss= tensor(0.3152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "769 D_fake_loss= tensor(0.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "769 D_tricked_loss= tensor(2.8232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "770 D_real_loss= tensor(0.2942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "770 D_fake_loss= tensor(0.3026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "770 D_tricked_loss= tensor(2.8838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "771 D_real_loss= tensor(0.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "771 D_fake_loss= tensor(0.2595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "771 D_tricked_loss= tensor(2.8898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "772 D_real_loss= tensor(0.2974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "772 D_fake_loss= tensor(0.2823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "772 D_tricked_loss= tensor(2.6773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "773 D_real_loss= tensor(0.3046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "773 D_fake_loss= tensor(0.2535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "773 D_tricked_loss= tensor(2.7049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "774 D_real_loss= tensor(0.2725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "774 D_fake_loss= tensor(0.2368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "774 D_tricked_loss= tensor(2.9260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "775 D_real_loss= tensor(0.3032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "775 D_fake_loss= tensor(0.3010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "775 D_tricked_loss= tensor(2.8360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "776 D_real_loss= tensor(0.3100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "776 D_fake_loss= tensor(0.2580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "776 D_tricked_loss= tensor(2.8785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "777 D_real_loss= tensor(0.3114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "777 D_fake_loss= tensor(0.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "777 D_tricked_loss= tensor(2.9192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "778 D_real_loss= tensor(0.3019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "778 D_fake_loss= tensor(0.2776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "778 D_tricked_loss= tensor(2.8049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "779 D_real_loss= tensor(0.3113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "779 D_fake_loss= tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "779 D_tricked_loss= tensor(2.8085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "780 D_real_loss= tensor(0.3137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "780 D_fake_loss= tensor(0.3044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "780 D_tricked_loss= tensor(2.7372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "781 D_real_loss= tensor(0.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "781 D_fake_loss= tensor(0.2603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "781 D_tricked_loss= tensor(2.6478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "782 D_real_loss= tensor(0.3095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "782 D_fake_loss= tensor(0.2266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "782 D_tricked_loss= tensor(2.8223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "783 D_real_loss= tensor(0.3012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "783 D_fake_loss= tensor(0.2437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "783 D_tricked_loss= tensor(2.8460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "784 D_real_loss= tensor(0.3115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "784 D_fake_loss= tensor(0.2409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "784 D_tricked_loss= tensor(2.8808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "785 D_real_loss= tensor(0.2698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "785 D_fake_loss= tensor(0.2698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "785 D_tricked_loss= tensor(2.8274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "786 D_real_loss= tensor(0.3090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "786 D_fake_loss= tensor(0.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "786 D_tricked_loss= tensor(2.7502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "787 D_real_loss= tensor(0.2961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "787 D_fake_loss= tensor(0.2837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "787 D_tricked_loss= tensor(2.9552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "788 D_real_loss= tensor(0.3435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "788 D_fake_loss= tensor(0.2878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "788 D_tricked_loss= tensor(2.8737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "789 D_real_loss= tensor(0.3426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "789 D_fake_loss= tensor(0.3240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "789 D_tricked_loss= tensor(2.7018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "790 D_real_loss= tensor(0.3002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "790 D_fake_loss= tensor(0.2866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "790 D_tricked_loss= tensor(2.6698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "791 D_real_loss= tensor(0.3293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "791 D_fake_loss= tensor(0.2995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "791 D_tricked_loss= tensor(2.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "792 D_real_loss= tensor(0.2882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "792 D_fake_loss= tensor(0.2814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "792 D_tricked_loss= tensor(2.6421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "793 D_real_loss= tensor(0.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "793 D_fake_loss= tensor(0.2924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "793 D_tricked_loss= tensor(2.7591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "794 D_real_loss= tensor(0.2916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "794 D_fake_loss= tensor(0.2934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "794 D_tricked_loss= tensor(2.7016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "795 D_real_loss= tensor(0.3139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "795 D_fake_loss= tensor(0.3018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "795 D_tricked_loss= tensor(2.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "796 D_real_loss= tensor(0.3013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "796 D_fake_loss= tensor(0.2813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "796 D_tricked_loss= tensor(2.8633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "797 D_real_loss= tensor(0.3041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "797 D_fake_loss= tensor(0.2864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "797 D_tricked_loss= tensor(2.8217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "798 D_real_loss= tensor(0.3254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "798 D_fake_loss= tensor(0.2504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "798 D_tricked_loss= tensor(2.8644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "799 D_real_loss= tensor(0.2884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "799 D_fake_loss= tensor(0.2869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "799 D_tricked_loss= tensor(2.8124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "800 D_real_loss= tensor(0.3268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "800 D_fake_loss= tensor(0.2558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "800 D_tricked_loss= tensor(2.6131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "801 D_real_loss= tensor(0.3118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "801 D_fake_loss= tensor(0.2732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "801 D_tricked_loss= tensor(2.7804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "802 D_real_loss= tensor(0.2848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "802 D_fake_loss= tensor(0.2604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "802 D_tricked_loss= tensor(2.6692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "803 D_real_loss= tensor(0.3092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "803 D_fake_loss= tensor(0.3092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "803 D_tricked_loss= tensor(2.7934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "804 D_real_loss= tensor(0.2939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "804 D_fake_loss= tensor(0.2764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "804 D_tricked_loss= tensor(2.8265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "805 D_real_loss= tensor(0.3045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "805 D_fake_loss= tensor(0.2618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "805 D_tricked_loss= tensor(2.8942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "806 D_real_loss= tensor(0.3280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "806 D_fake_loss= tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "806 D_tricked_loss= tensor(2.9494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "807 D_real_loss= tensor(0.3532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "807 D_fake_loss= tensor(0.2629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "807 D_tricked_loss= tensor(2.8741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "808 D_real_loss= tensor(0.3282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "808 D_fake_loss= tensor(0.2780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "808 D_tricked_loss= tensor(2.6830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "809 D_real_loss= tensor(0.2993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "809 D_fake_loss= tensor(0.2533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "809 D_tricked_loss= tensor(2.8270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "810 D_real_loss= tensor(0.3361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "810 D_fake_loss= tensor(0.2635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "810 D_tricked_loss= tensor(2.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "811 D_real_loss= tensor(0.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "811 D_fake_loss= tensor(0.2650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "811 D_tricked_loss= tensor(2.6749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "812 D_real_loss= tensor(0.2837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "812 D_fake_loss= tensor(0.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "812 D_tricked_loss= tensor(2.8623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "813 D_real_loss= tensor(0.3144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "813 D_fake_loss= tensor(0.3369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "813 D_tricked_loss= tensor(2.8050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "814 D_real_loss= tensor(0.2982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "814 D_fake_loss= tensor(0.2766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "814 D_tricked_loss= tensor(2.9919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "815 D_real_loss= tensor(0.3145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "815 D_fake_loss= tensor(0.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "815 D_tricked_loss= tensor(2.9007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "816 D_real_loss= tensor(0.2963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "816 D_fake_loss= tensor(0.2872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "816 D_tricked_loss= tensor(2.8283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "817 D_real_loss= tensor(0.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "817 D_fake_loss= tensor(0.2998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "817 D_tricked_loss= tensor(2.7151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "818 D_real_loss= tensor(0.3231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "818 D_fake_loss= tensor(0.2816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "818 D_tricked_loss= tensor(2.6355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "819 D_real_loss= tensor(0.2930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "819 D_fake_loss= tensor(0.2645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "819 D_tricked_loss= tensor(2.7006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "820 D_real_loss= tensor(0.3146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "820 D_fake_loss= tensor(0.2505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "820 D_tricked_loss= tensor(2.8008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "821 D_real_loss= tensor(0.3039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "821 D_fake_loss= tensor(0.2880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "821 D_tricked_loss= tensor(2.8057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "822 D_real_loss= tensor(0.3057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "822 D_fake_loss= tensor(0.2797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "822 D_tricked_loss= tensor(2.7477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "823 D_real_loss= tensor(0.3048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "823 D_fake_loss= tensor(0.3050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "823 D_tricked_loss= tensor(2.8611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "824 D_real_loss= tensor(0.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "824 D_fake_loss= tensor(0.2809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "824 D_tricked_loss= tensor(2.8726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "825 D_real_loss= tensor(0.3052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "825 D_fake_loss= tensor(0.2600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "825 D_tricked_loss= tensor(2.8468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "826 D_real_loss= tensor(0.2802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "826 D_fake_loss= tensor(0.2598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "826 D_tricked_loss= tensor(2.6873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "827 D_real_loss= tensor(0.3073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "827 D_fake_loss= tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "827 D_tricked_loss= tensor(2.7689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "828 D_real_loss= tensor(0.2892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "828 D_fake_loss= tensor(0.2876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "828 D_tricked_loss= tensor(2.7724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "829 D_real_loss= tensor(0.2757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "829 D_fake_loss= tensor(0.2803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "829 D_tricked_loss= tensor(2.7274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "830 D_real_loss= tensor(0.2972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "830 D_fake_loss= tensor(0.2715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "830 D_tricked_loss= tensor(2.7337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "831 D_real_loss= tensor(0.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "831 D_fake_loss= tensor(0.2908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "831 D_tricked_loss= tensor(2.7355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "832 D_real_loss= tensor(0.3165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "832 D_fake_loss= tensor(0.2816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "832 D_tricked_loss= tensor(2.7390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "833 D_real_loss= tensor(0.3039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "833 D_fake_loss= tensor(0.2854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "833 D_tricked_loss= tensor(2.8028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "834 D_real_loss= tensor(0.3323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "834 D_fake_loss= tensor(0.2731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "834 D_tricked_loss= tensor(2.7302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "835 D_real_loss= tensor(0.3242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "835 D_fake_loss= tensor(0.2809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "835 D_tricked_loss= tensor(2.6919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "836 D_real_loss= tensor(0.2963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "836 D_fake_loss= tensor(0.2794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "836 D_tricked_loss= tensor(2.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "837 D_real_loss= tensor(0.3121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "837 D_fake_loss= tensor(0.2822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "837 D_tricked_loss= tensor(2.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "838 D_real_loss= tensor(0.2981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "838 D_fake_loss= tensor(0.2527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "838 D_tricked_loss= tensor(2.7553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "839 D_real_loss= tensor(0.3158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "839 D_fake_loss= tensor(0.2852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "839 D_tricked_loss= tensor(2.7909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "840 D_real_loss= tensor(0.3269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "840 D_fake_loss= tensor(0.2921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "840 D_tricked_loss= tensor(2.7572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "841 D_real_loss= tensor(0.3398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "841 D_fake_loss= tensor(0.2590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "841 D_tricked_loss= tensor(2.8267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "842 D_real_loss= tensor(0.3201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "842 D_fake_loss= tensor(0.2878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "842 D_tricked_loss= tensor(2.7550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "843 D_real_loss= tensor(0.3159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "843 D_fake_loss= tensor(0.3037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "843 D_tricked_loss= tensor(2.7995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "844 D_real_loss= tensor(0.3576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "844 D_fake_loss= tensor(0.2613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "844 D_tricked_loss= tensor(2.7771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "845 D_real_loss= tensor(0.3067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "845 D_fake_loss= tensor(0.2807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "845 D_tricked_loss= tensor(2.7162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "846 D_real_loss= tensor(0.3328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "846 D_fake_loss= tensor(0.2567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "846 D_tricked_loss= tensor(2.7367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "847 D_real_loss= tensor(0.2825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "847 D_fake_loss= tensor(0.2634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "847 D_tricked_loss= tensor(2.7953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "848 D_real_loss= tensor(0.3069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "848 D_fake_loss= tensor(0.2687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "848 D_tricked_loss= tensor(2.7900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "849 D_real_loss= tensor(0.2677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "849 D_fake_loss= tensor(0.2864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "849 D_tricked_loss= tensor(2.7623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "850 D_real_loss= tensor(0.3314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "850 D_fake_loss= tensor(0.3134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "850 D_tricked_loss= tensor(2.7613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "851 D_real_loss= tensor(0.3032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "851 D_fake_loss= tensor(0.2588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "851 D_tricked_loss= tensor(2.8113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "852 D_real_loss= tensor(0.2942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "852 D_fake_loss= tensor(0.2761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "852 D_tricked_loss= tensor(2.7862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "853 D_real_loss= tensor(0.3187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "853 D_fake_loss= tensor(0.2822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "853 D_tricked_loss= tensor(2.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "854 D_real_loss= tensor(0.3373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "854 D_fake_loss= tensor(0.2755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "854 D_tricked_loss= tensor(2.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "855 D_real_loss= tensor(0.3241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "855 D_fake_loss= tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "855 D_tricked_loss= tensor(2.6360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "856 D_real_loss= tensor(0.3166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "856 D_fake_loss= tensor(0.2574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "856 D_tricked_loss= tensor(2.6577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "857 D_real_loss= tensor(0.3127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "857 D_fake_loss= tensor(0.2569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "857 D_tricked_loss= tensor(2.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "858 D_real_loss= tensor(0.3075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "858 D_fake_loss= tensor(0.2717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "858 D_tricked_loss= tensor(2.6720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "859 D_real_loss= tensor(0.3111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "859 D_fake_loss= tensor(0.2516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "859 D_tricked_loss= tensor(2.7818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "860 D_real_loss= tensor(0.3250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "860 D_fake_loss= tensor(0.2696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "860 D_tricked_loss= tensor(2.7115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "861 D_real_loss= tensor(0.2976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "861 D_fake_loss= tensor(0.2877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "861 D_tricked_loss= tensor(2.6551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "862 D_real_loss= tensor(0.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "862 D_fake_loss= tensor(0.2870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "862 D_tricked_loss= tensor(2.6715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "863 D_real_loss= tensor(0.3226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "863 D_fake_loss= tensor(0.2987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "863 D_tricked_loss= tensor(2.6191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "864 D_real_loss= tensor(0.3222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "864 D_fake_loss= tensor(0.3054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "864 D_tricked_loss= tensor(2.6915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "865 D_real_loss= tensor(0.2973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "865 D_fake_loss= tensor(0.2922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "865 D_tricked_loss= tensor(2.7018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "866 D_real_loss= tensor(0.2966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "866 D_fake_loss= tensor(0.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "866 D_tricked_loss= tensor(2.6694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "867 D_real_loss= tensor(0.2915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "867 D_fake_loss= tensor(0.3014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "867 D_tricked_loss= tensor(2.7208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "868 D_real_loss= tensor(0.3023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "868 D_fake_loss= tensor(0.2864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "868 D_tricked_loss= tensor(2.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "869 D_real_loss= tensor(0.3449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "869 D_fake_loss= tensor(0.2783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "869 D_tricked_loss= tensor(2.6553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "870 D_real_loss= tensor(0.3182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "870 D_fake_loss= tensor(0.2994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "870 D_tricked_loss= tensor(2.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "871 D_real_loss= tensor(0.3169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "871 D_fake_loss= tensor(0.2984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "871 D_tricked_loss= tensor(2.6611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "872 D_real_loss= tensor(0.3183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "872 D_fake_loss= tensor(0.2873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "872 D_tricked_loss= tensor(2.6404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "873 D_real_loss= tensor(0.3368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "873 D_fake_loss= tensor(0.2743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "873 D_tricked_loss= tensor(2.7804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "874 D_real_loss= tensor(0.3409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "874 D_fake_loss= tensor(0.3047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "874 D_tricked_loss= tensor(2.7241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "875 D_real_loss= tensor(0.3006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "875 D_fake_loss= tensor(0.2716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "875 D_tricked_loss= tensor(2.6464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "876 D_real_loss= tensor(0.3315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "876 D_fake_loss= tensor(0.3001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "876 D_tricked_loss= tensor(2.6824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "877 D_real_loss= tensor(0.3497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "877 D_fake_loss= tensor(0.2916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "877 D_tricked_loss= tensor(2.7145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "878 D_real_loss= tensor(0.3211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "878 D_fake_loss= tensor(0.2847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "878 D_tricked_loss= tensor(2.6631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "879 D_real_loss= tensor(0.3346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "879 D_fake_loss= tensor(0.3021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "879 D_tricked_loss= tensor(2.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "880 D_real_loss= tensor(0.3307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "880 D_fake_loss= tensor(0.2745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "880 D_tricked_loss= tensor(2.6143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "881 D_real_loss= tensor(0.3436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "881 D_fake_loss= tensor(0.2903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "881 D_tricked_loss= tensor(2.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "882 D_real_loss= tensor(0.3623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "882 D_fake_loss= tensor(0.3024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "882 D_tricked_loss= tensor(2.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "883 D_real_loss= tensor(0.3429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "883 D_fake_loss= tensor(0.2920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "883 D_tricked_loss= tensor(2.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "884 D_real_loss= tensor(0.3042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "884 D_fake_loss= tensor(0.2974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "884 D_tricked_loss= tensor(2.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "885 D_real_loss= tensor(0.3273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "885 D_fake_loss= tensor(0.3053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "885 D_tricked_loss= tensor(2.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "886 D_real_loss= tensor(0.3181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "886 D_fake_loss= tensor(0.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "886 D_tricked_loss= tensor(2.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "887 D_real_loss= tensor(0.3263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "887 D_fake_loss= tensor(0.2980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "887 D_tricked_loss= tensor(2.6726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "888 D_real_loss= tensor(0.3032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "888 D_fake_loss= tensor(0.2697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "888 D_tricked_loss= tensor(2.7339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "889 D_real_loss= tensor(0.3143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "889 D_fake_loss= tensor(0.2679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "889 D_tricked_loss= tensor(2.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "890 D_real_loss= tensor(0.3241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "890 D_fake_loss= tensor(0.2998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "890 D_tricked_loss= tensor(2.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "891 D_real_loss= tensor(0.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "891 D_fake_loss= tensor(0.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "891 D_tricked_loss= tensor(2.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "892 D_real_loss= tensor(0.3787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "892 D_fake_loss= tensor(0.2745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "892 D_tricked_loss= tensor(2.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "893 D_real_loss= tensor(0.3312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "893 D_fake_loss= tensor(0.2768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "893 D_tricked_loss= tensor(2.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "894 D_real_loss= tensor(0.3004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "894 D_fake_loss= tensor(0.3063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "894 D_tricked_loss= tensor(2.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "895 D_real_loss= tensor(0.3232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "895 D_fake_loss= tensor(0.2967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "895 D_tricked_loss= tensor(2.7130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "896 D_real_loss= tensor(0.3266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "896 D_fake_loss= tensor(0.2836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "896 D_tricked_loss= tensor(2.7033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "897 D_real_loss= tensor(0.3301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "897 D_fake_loss= tensor(0.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "897 D_tricked_loss= tensor(2.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "898 D_real_loss= tensor(0.3651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "898 D_fake_loss= tensor(0.2719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "898 D_tricked_loss= tensor(2.6773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "899 D_real_loss= tensor(0.3383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "899 D_fake_loss= tensor(0.2565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "899 D_tricked_loss= tensor(2.6760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "900 D_real_loss= tensor(0.3304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "900 D_fake_loss= tensor(0.2763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "900 D_tricked_loss= tensor(2.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "901 D_real_loss= tensor(0.3139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "901 D_fake_loss= tensor(0.2674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "901 D_tricked_loss= tensor(2.6524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "902 D_real_loss= tensor(0.3191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "902 D_fake_loss= tensor(0.3112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "902 D_tricked_loss= tensor(2.6904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "903 D_real_loss= tensor(0.3269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "903 D_fake_loss= tensor(0.3021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "903 D_tricked_loss= tensor(2.6674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "904 D_real_loss= tensor(0.3192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "904 D_fake_loss= tensor(0.2944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "904 D_tricked_loss= tensor(2.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "905 D_real_loss= tensor(0.3352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "905 D_fake_loss= tensor(0.2993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "905 D_tricked_loss= tensor(2.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "906 D_real_loss= tensor(0.3482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "906 D_fake_loss= tensor(0.2927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "906 D_tricked_loss= tensor(2.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "907 D_real_loss= tensor(0.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "907 D_fake_loss= tensor(0.3066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "907 D_tricked_loss= tensor(2.6210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "908 D_real_loss= tensor(0.3610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "908 D_fake_loss= tensor(0.2991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "908 D_tricked_loss= tensor(2.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "909 D_real_loss= tensor(0.3412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "909 D_fake_loss= tensor(0.2806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "909 D_tricked_loss= tensor(2.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "910 D_real_loss= tensor(0.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "910 D_fake_loss= tensor(0.3081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "910 D_tricked_loss= tensor(2.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "911 D_real_loss= tensor(0.3166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "911 D_fake_loss= tensor(0.2853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "911 D_tricked_loss= tensor(2.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "912 D_real_loss= tensor(0.3439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "912 D_fake_loss= tensor(0.2727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "912 D_tricked_loss= tensor(2.7195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "913 D_real_loss= tensor(0.3018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "913 D_fake_loss= tensor(0.2940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "913 D_tricked_loss= tensor(2.7313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "914 D_real_loss= tensor(0.3162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "914 D_fake_loss= tensor(0.2788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "914 D_tricked_loss= tensor(2.7332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "915 D_real_loss= tensor(0.3342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "915 D_fake_loss= tensor(0.3017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "915 D_tricked_loss= tensor(2.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "916 D_real_loss= tensor(0.3332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "916 D_fake_loss= tensor(0.2947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "916 D_tricked_loss= tensor(2.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "917 D_real_loss= tensor(0.3140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "917 D_fake_loss= tensor(0.2871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "917 D_tricked_loss= tensor(2.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "918 D_real_loss= tensor(0.3573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "918 D_fake_loss= tensor(0.2753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "918 D_tricked_loss= tensor(2.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "919 D_real_loss= tensor(0.3262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "919 D_fake_loss= tensor(0.2642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "919 D_tricked_loss= tensor(2.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "920 D_real_loss= tensor(0.3251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "920 D_fake_loss= tensor(0.2838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "920 D_tricked_loss= tensor(2.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "921 D_real_loss= tensor(0.3199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "921 D_fake_loss= tensor(0.3064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "921 D_tricked_loss= tensor(2.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "922 D_real_loss= tensor(0.3301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "922 D_fake_loss= tensor(0.2880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "922 D_tricked_loss= tensor(2.6294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "923 D_real_loss= tensor(0.3414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "923 D_fake_loss= tensor(0.2864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "923 D_tricked_loss= tensor(2.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "924 D_real_loss= tensor(0.3206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "924 D_fake_loss= tensor(0.3055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "924 D_tricked_loss= tensor(2.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "925 D_real_loss= tensor(0.3212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "925 D_fake_loss= tensor(0.3475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "925 D_tricked_loss= tensor(2.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "926 D_real_loss= tensor(0.3238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "926 D_fake_loss= tensor(0.2974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "926 D_tricked_loss= tensor(2.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "927 D_real_loss= tensor(0.3012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "927 D_fake_loss= tensor(0.2847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "927 D_tricked_loss= tensor(2.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "928 D_real_loss= tensor(0.3109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "928 D_fake_loss= tensor(0.3345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "928 D_tricked_loss= tensor(2.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "929 D_real_loss= tensor(0.2755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "929 D_fake_loss= tensor(0.2997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "929 D_tricked_loss= tensor(2.6696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "930 D_real_loss= tensor(0.3497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "930 D_fake_loss= tensor(0.2758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "930 D_tricked_loss= tensor(2.6280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "931 D_real_loss= tensor(0.2967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "931 D_fake_loss= tensor(0.3104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "931 D_tricked_loss= tensor(2.6226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "932 D_real_loss= tensor(0.3604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "932 D_fake_loss= tensor(0.3056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "932 D_tricked_loss= tensor(2.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "933 D_real_loss= tensor(0.3040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "933 D_fake_loss= tensor(0.3076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "933 D_tricked_loss= tensor(2.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "934 D_real_loss= tensor(0.3225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "934 D_fake_loss= tensor(0.2945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "934 D_tricked_loss= tensor(2.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "935 D_real_loss= tensor(0.3388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "935 D_fake_loss= tensor(0.2922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "935 D_tricked_loss= tensor(2.6138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "936 D_real_loss= tensor(0.3084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "936 D_fake_loss= tensor(0.2709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "936 D_tricked_loss= tensor(2.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "937 D_real_loss= tensor(0.3381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "937 D_fake_loss= tensor(0.3247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "937 D_tricked_loss= tensor(2.6500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "938 D_real_loss= tensor(0.3751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "938 D_fake_loss= tensor(0.3189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "938 D_tricked_loss= tensor(2.6137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "939 D_real_loss= tensor(0.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "939 D_fake_loss= tensor(0.2767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "939 D_tricked_loss= tensor(2.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "940 D_real_loss= tensor(0.3478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "940 D_fake_loss= tensor(0.3069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "940 D_tricked_loss= tensor(2.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "941 D_real_loss= tensor(0.3523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "941 D_fake_loss= tensor(0.3069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "941 D_tricked_loss= tensor(2.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "942 D_real_loss= tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "942 D_fake_loss= tensor(0.3107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "942 D_tricked_loss= tensor(2.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "943 D_real_loss= tensor(0.3341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "943 D_fake_loss= tensor(0.3512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "943 D_tricked_loss= tensor(2.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "944 D_real_loss= tensor(0.3206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "944 D_fake_loss= tensor(0.3015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "944 D_tricked_loss= tensor(2.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "945 D_real_loss= tensor(0.3784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "945 D_fake_loss= tensor(0.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "945 D_tricked_loss= tensor(2.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "946 D_real_loss= tensor(0.3752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "946 D_fake_loss= tensor(0.2886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "946 D_tricked_loss= tensor(2.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "947 D_real_loss= tensor(0.3446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "947 D_fake_loss= tensor(0.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "947 D_tricked_loss= tensor(2.6874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "948 D_real_loss= tensor(0.3124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "948 D_fake_loss= tensor(0.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "948 D_tricked_loss= tensor(2.6312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "949 D_real_loss= tensor(0.3569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "949 D_fake_loss= tensor(0.3079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "949 D_tricked_loss= tensor(2.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "950 D_real_loss= tensor(0.3629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "950 D_fake_loss= tensor(0.2801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "950 D_tricked_loss= tensor(2.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "951 D_real_loss= tensor(0.3416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "951 D_fake_loss= tensor(0.3214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "951 D_tricked_loss= tensor(2.3761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "952 D_real_loss= tensor(0.3343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "952 D_fake_loss= tensor(0.3063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "952 D_tricked_loss= tensor(2.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "953 D_real_loss= tensor(0.3366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "953 D_fake_loss= tensor(0.3162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "953 D_tricked_loss= tensor(2.3762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "954 D_real_loss= tensor(0.3244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "954 D_fake_loss= tensor(0.3426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "954 D_tricked_loss= tensor(2.3711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "955 D_real_loss= tensor(0.3302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "955 D_fake_loss= tensor(0.2981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "955 D_tricked_loss= tensor(2.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "956 D_real_loss= tensor(0.3592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "956 D_fake_loss= tensor(0.3245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "956 D_tricked_loss= tensor(2.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "957 D_real_loss= tensor(0.3352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "957 D_fake_loss= tensor(0.3063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "957 D_tricked_loss= tensor(2.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "958 D_real_loss= tensor(0.3067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "958 D_fake_loss= tensor(0.3239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "958 D_tricked_loss= tensor(2.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "959 D_real_loss= tensor(0.3171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "959 D_fake_loss= tensor(0.3268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "959 D_tricked_loss= tensor(2.3908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "960 D_real_loss= tensor(0.3075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "960 D_fake_loss= tensor(0.3040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "960 D_tricked_loss= tensor(2.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "961 D_real_loss= tensor(0.3294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "961 D_fake_loss= tensor(0.3117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "961 D_tricked_loss= tensor(2.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "962 D_real_loss= tensor(0.3173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "962 D_fake_loss= tensor(0.2980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "962 D_tricked_loss= tensor(2.6277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "963 D_real_loss= tensor(0.2913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "963 D_fake_loss= tensor(0.3072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "963 D_tricked_loss= tensor(2.7414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "964 D_real_loss= tensor(0.3170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "964 D_fake_loss= tensor(0.3459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "964 D_tricked_loss= tensor(2.6179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "965 D_real_loss= tensor(0.3312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "965 D_fake_loss= tensor(0.3028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "965 D_tricked_loss= tensor(2.6883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "966 D_real_loss= tensor(0.3436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "966 D_fake_loss= tensor(0.3103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "966 D_tricked_loss= tensor(2.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "967 D_real_loss= tensor(0.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "967 D_fake_loss= tensor(0.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "967 D_tricked_loss= tensor(2.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "968 D_real_loss= tensor(0.3220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "968 D_fake_loss= tensor(0.2914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "968 D_tricked_loss= tensor(2.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "969 D_real_loss= tensor(0.3087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "969 D_fake_loss= tensor(0.3068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "969 D_tricked_loss= tensor(2.3587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "970 D_real_loss= tensor(0.3277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "970 D_fake_loss= tensor(0.3490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "970 D_tricked_loss= tensor(2.4057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "971 D_real_loss= tensor(0.3422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "971 D_fake_loss= tensor(0.3212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "971 D_tricked_loss= tensor(2.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "972 D_real_loss= tensor(0.3431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "972 D_fake_loss= tensor(0.3306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "972 D_tricked_loss= tensor(2.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "973 D_real_loss= tensor(0.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "973 D_fake_loss= tensor(0.3050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "973 D_tricked_loss= tensor(2.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "974 D_real_loss= tensor(0.3192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "974 D_fake_loss= tensor(0.2908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "974 D_tricked_loss= tensor(2.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "975 D_real_loss= tensor(0.3666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "975 D_fake_loss= tensor(0.3128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "975 D_tricked_loss= tensor(2.3937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "976 D_real_loss= tensor(0.3316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "976 D_fake_loss= tensor(0.3088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "976 D_tricked_loss= tensor(2.3710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "977 D_real_loss= tensor(0.3501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "977 D_fake_loss= tensor(0.3055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "977 D_tricked_loss= tensor(2.3459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "978 D_real_loss= tensor(0.3481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "978 D_fake_loss= tensor(0.3519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "978 D_tricked_loss= tensor(2.3111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "979 D_real_loss= tensor(0.3500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "979 D_fake_loss= tensor(0.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "979 D_tricked_loss= tensor(2.3622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "980 D_real_loss= tensor(0.3234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "980 D_fake_loss= tensor(0.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "980 D_tricked_loss= tensor(2.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "981 D_real_loss= tensor(0.3182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "981 D_fake_loss= tensor(0.3401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "981 D_tricked_loss= tensor(2.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "982 D_real_loss= tensor(0.3310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "982 D_fake_loss= tensor(0.3270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "982 D_tricked_loss= tensor(2.6239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "983 D_real_loss= tensor(0.3315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "983 D_fake_loss= tensor(0.3078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "983 D_tricked_loss= tensor(2.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "984 D_real_loss= tensor(0.3363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "984 D_fake_loss= tensor(0.3014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "984 D_tricked_loss= tensor(2.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "985 D_real_loss= tensor(0.3439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "985 D_fake_loss= tensor(0.2884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "985 D_tricked_loss= tensor(2.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "986 D_real_loss= tensor(0.3027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "986 D_fake_loss= tensor(0.2953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "986 D_tricked_loss= tensor(2.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "987 D_real_loss= tensor(0.3103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "987 D_fake_loss= tensor(0.3107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "987 D_tricked_loss= tensor(2.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "988 D_real_loss= tensor(0.3212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "988 D_fake_loss= tensor(0.3042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "988 D_tricked_loss= tensor(2.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "989 D_real_loss= tensor(0.3363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "989 D_fake_loss= tensor(0.3056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "989 D_tricked_loss= tensor(2.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "990 D_real_loss= tensor(0.3676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "990 D_fake_loss= tensor(0.2955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "990 D_tricked_loss= tensor(2.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "991 D_real_loss= tensor(0.3745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "991 D_fake_loss= tensor(0.3029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "991 D_tricked_loss= tensor(2.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "992 D_real_loss= tensor(0.3612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "992 D_fake_loss= tensor(0.3138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "992 D_tricked_loss= tensor(2.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "993 D_real_loss= tensor(0.3322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "993 D_fake_loss= tensor(0.3119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "993 D_tricked_loss= tensor(2.3520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "994 D_real_loss= tensor(0.3460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "994 D_fake_loss= tensor(0.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "994 D_tricked_loss= tensor(2.3826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "995 D_real_loss= tensor(0.3220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "995 D_fake_loss= tensor(0.3080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "995 D_tricked_loss= tensor(2.4095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "996 D_real_loss= tensor(0.3486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "996 D_fake_loss= tensor(0.3135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "996 D_tricked_loss= tensor(2.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "997 D_real_loss= tensor(0.3517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "997 D_fake_loss= tensor(0.3229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "997 D_tricked_loss= tensor(2.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "998 D_real_loss= tensor(0.3490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "998 D_fake_loss= tensor(0.3316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "998 D_tricked_loss= tensor(2.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "999 D_real_loss= tensor(0.3286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "999 D_fake_loss= tensor(0.3346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "999 D_tricked_loss= tensor(2.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1000 D_real_loss= tensor(0.3658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1000 D_fake_loss= tensor(0.3056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1000 D_tricked_loss= tensor(2.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1001 D_real_loss= tensor(0.3525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1001 D_fake_loss= tensor(0.3327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1001 D_tricked_loss= tensor(2.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1002 D_real_loss= tensor(0.3842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1002 D_fake_loss= tensor(0.2919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1002 D_tricked_loss= tensor(2.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1003 D_real_loss= tensor(0.3253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1003 D_fake_loss= tensor(0.3078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1003 D_tricked_loss= tensor(2.3655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1004 D_real_loss= tensor(0.3511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1004 D_fake_loss= tensor(0.3310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1004 D_tricked_loss= tensor(2.4068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1005 D_real_loss= tensor(0.3321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1005 D_fake_loss= tensor(0.3263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1005 D_tricked_loss= tensor(2.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1006 D_real_loss= tensor(0.3372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1006 D_fake_loss= tensor(0.3358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1006 D_tricked_loss= tensor(2.3624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1007 D_real_loss= tensor(0.3470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1007 D_fake_loss= tensor(0.3629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1007 D_tricked_loss= tensor(2.3295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1008 D_real_loss= tensor(0.3497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1008 D_fake_loss= tensor(0.3456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1008 D_tricked_loss= tensor(2.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1009 D_real_loss= tensor(0.3689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1009 D_fake_loss= tensor(0.3098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1009 D_tricked_loss= tensor(2.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1010 D_real_loss= tensor(0.3419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1010 D_fake_loss= tensor(0.3464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1010 D_tricked_loss= tensor(2.3825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1011 D_real_loss= tensor(0.3435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1011 D_fake_loss= tensor(0.3492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1011 D_tricked_loss= tensor(2.3143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1012 D_real_loss= tensor(0.3744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1012 D_fake_loss= tensor(0.2948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1012 D_tricked_loss= tensor(2.4031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1013 D_real_loss= tensor(0.3855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1013 D_fake_loss= tensor(0.2852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1013 D_tricked_loss= tensor(2.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1014 D_real_loss= tensor(0.3488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1014 D_fake_loss= tensor(0.3290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1014 D_tricked_loss= tensor(2.3253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1015 D_real_loss= tensor(0.3234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1015 D_fake_loss= tensor(0.2988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1015 D_tricked_loss= tensor(2.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1016 D_real_loss= tensor(0.3392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1016 D_fake_loss= tensor(0.3156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1016 D_tricked_loss= tensor(2.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1017 D_real_loss= tensor(0.3454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1017 D_fake_loss= tensor(0.3472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1017 D_tricked_loss= tensor(2.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1018 D_real_loss= tensor(0.3633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1018 D_fake_loss= tensor(0.3573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1018 D_tricked_loss= tensor(2.4002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1019 D_real_loss= tensor(0.3507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1019 D_fake_loss= tensor(0.3373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1019 D_tricked_loss= tensor(2.3797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1020 D_real_loss= tensor(0.3521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1020 D_fake_loss= tensor(0.3099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1020 D_tricked_loss= tensor(2.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1021 D_real_loss= tensor(0.3572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1021 D_fake_loss= tensor(0.3245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1021 D_tricked_loss= tensor(2.3425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1022 D_real_loss= tensor(0.3708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1022 D_fake_loss= tensor(0.3227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1022 D_tricked_loss= tensor(2.3016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1023 D_real_loss= tensor(0.3319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1023 D_fake_loss= tensor(0.2994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1023 D_tricked_loss= tensor(2.3459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1024 D_real_loss= tensor(0.3484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1024 D_fake_loss= tensor(0.3300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1024 D_tricked_loss= tensor(2.3970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1025 D_real_loss= tensor(0.3266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1025 D_fake_loss= tensor(0.3229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1025 D_tricked_loss= tensor(2.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1026 D_real_loss= tensor(0.3165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1026 D_fake_loss= tensor(0.3441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1026 D_tricked_loss= tensor(2.3647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1027 D_real_loss= tensor(0.3324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1027 D_fake_loss= tensor(0.3292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1027 D_tricked_loss= tensor(2.2964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1028 D_real_loss= tensor(0.3587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1028 D_fake_loss= tensor(0.3179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1028 D_tricked_loss= tensor(2.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1029 D_real_loss= tensor(0.3778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1029 D_fake_loss= tensor(0.3501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1029 D_tricked_loss= tensor(2.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1030 D_real_loss= tensor(0.3595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1030 D_fake_loss= tensor(0.3168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1030 D_tricked_loss= tensor(2.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1031 D_real_loss= tensor(0.3363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1031 D_fake_loss= tensor(0.2793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1031 D_tricked_loss= tensor(2.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1032 D_real_loss= tensor(0.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1032 D_fake_loss= tensor(0.3206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1032 D_tricked_loss= tensor(2.3304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1033 D_real_loss= tensor(0.3607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1033 D_fake_loss= tensor(0.2838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1033 D_tricked_loss= tensor(2.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1034 D_real_loss= tensor(0.3618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1034 D_fake_loss= tensor(0.2908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1034 D_tricked_loss= tensor(2.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1035 D_real_loss= tensor(0.3497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1035 D_fake_loss= tensor(0.2989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1035 D_tricked_loss= tensor(2.4140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1036 D_real_loss= tensor(0.3345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1036 D_fake_loss= tensor(0.3063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1036 D_tricked_loss= tensor(2.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1037 D_real_loss= tensor(0.3487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1037 D_fake_loss= tensor(0.2894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1037 D_tricked_loss= tensor(2.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1038 D_real_loss= tensor(0.3587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1038 D_fake_loss= tensor(0.3186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1038 D_tricked_loss= tensor(2.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1039 D_real_loss= tensor(0.3835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1039 D_fake_loss= tensor(0.3005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1039 D_tricked_loss= tensor(2.3593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1040 D_real_loss= tensor(0.3715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1040 D_fake_loss= tensor(0.2815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1040 D_tricked_loss= tensor(2.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1041 D_real_loss= tensor(0.3626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1041 D_fake_loss= tensor(0.2854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1041 D_tricked_loss= tensor(2.3834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1042 D_real_loss= tensor(0.3328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1042 D_fake_loss= tensor(0.2976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1042 D_tricked_loss= tensor(2.3522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1043 D_real_loss= tensor(0.3353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1043 D_fake_loss= tensor(0.3085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1043 D_tricked_loss= tensor(2.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1044 D_real_loss= tensor(0.3605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1044 D_fake_loss= tensor(0.3011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1044 D_tricked_loss= tensor(2.3380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1045 D_real_loss= tensor(0.3465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1045 D_fake_loss= tensor(0.3010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1045 D_tricked_loss= tensor(2.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1046 D_real_loss= tensor(0.3353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1046 D_fake_loss= tensor(0.3590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1046 D_tricked_loss= tensor(2.3339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1047 D_real_loss= tensor(0.3684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1047 D_fake_loss= tensor(0.2988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1047 D_tricked_loss= tensor(2.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1048 D_real_loss= tensor(0.3442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1048 D_fake_loss= tensor(0.3242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1048 D_tricked_loss= tensor(2.3438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1049 D_real_loss= tensor(0.3843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1049 D_fake_loss= tensor(0.3324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1049 D_tricked_loss= tensor(2.3117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1050 D_real_loss= tensor(0.3592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1050 D_fake_loss= tensor(0.3386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1050 D_tricked_loss= tensor(2.3829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1051 D_real_loss= tensor(0.3781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1051 D_fake_loss= tensor(0.3240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1051 D_tricked_loss= tensor(2.2847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1052 D_real_loss= tensor(0.3491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1052 D_fake_loss= tensor(0.3021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1052 D_tricked_loss= tensor(2.4068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1053 D_real_loss= tensor(0.3694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1053 D_fake_loss= tensor(0.3357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1053 D_tricked_loss= tensor(2.3460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1054 D_real_loss= tensor(0.3535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1054 D_fake_loss= tensor(0.3328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1054 D_tricked_loss= tensor(2.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1055 D_real_loss= tensor(0.3396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1055 D_fake_loss= tensor(0.3065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1055 D_tricked_loss= tensor(2.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1056 D_real_loss= tensor(0.3738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1056 D_fake_loss= tensor(0.3173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1056 D_tricked_loss= tensor(2.3937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1057 D_real_loss= tensor(0.3461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1057 D_fake_loss= tensor(0.3583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1057 D_tricked_loss= tensor(2.3932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1058 D_real_loss= tensor(0.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1058 D_fake_loss= tensor(0.3822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1058 D_tricked_loss= tensor(2.2070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1059 D_real_loss= tensor(0.3480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1059 D_fake_loss= tensor(0.3054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1059 D_tricked_loss= tensor(2.3937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1060 D_real_loss= tensor(0.3543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1060 D_fake_loss= tensor(0.3305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1060 D_tricked_loss= tensor(2.3969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1061 D_real_loss= tensor(0.3590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1061 D_fake_loss= tensor(0.3248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1061 D_tricked_loss= tensor(2.3269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1062 D_real_loss= tensor(0.3212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1062 D_fake_loss= tensor(0.3637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1062 D_tricked_loss= tensor(2.3437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1063 D_real_loss= tensor(0.3632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1063 D_fake_loss= tensor(0.3372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1063 D_tricked_loss= tensor(2.2911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1064 D_real_loss= tensor(0.3408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1064 D_fake_loss= tensor(0.3141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1064 D_tricked_loss= tensor(2.3496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1065 D_real_loss= tensor(0.3513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1065 D_fake_loss= tensor(0.3516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1065 D_tricked_loss= tensor(2.3723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1066 D_real_loss= tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1066 D_fake_loss= tensor(0.3229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1066 D_tricked_loss= tensor(2.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1067 D_real_loss= tensor(0.3572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1067 D_fake_loss= tensor(0.3618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1067 D_tricked_loss= tensor(2.3400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1068 D_real_loss= tensor(0.3652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1068 D_fake_loss= tensor(0.3255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1068 D_tricked_loss= tensor(2.2783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1069 D_real_loss= tensor(0.3542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1069 D_fake_loss= tensor(0.3487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1069 D_tricked_loss= tensor(2.2285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1070 D_real_loss= tensor(0.3415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1070 D_fake_loss= tensor(0.3409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1070 D_tricked_loss= tensor(2.3252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1071 D_real_loss= tensor(0.3548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1071 D_fake_loss= tensor(0.3429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1071 D_tricked_loss= tensor(2.2709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1072 D_real_loss= tensor(0.3566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1072 D_fake_loss= tensor(0.3455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1072 D_tricked_loss= tensor(2.2632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1073 D_real_loss= tensor(0.3346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1073 D_fake_loss= tensor(0.3214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1073 D_tricked_loss= tensor(2.2582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1074 D_real_loss= tensor(0.3792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1074 D_fake_loss= tensor(0.3209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1074 D_tricked_loss= tensor(2.3445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1075 D_real_loss= tensor(0.3777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1075 D_fake_loss= tensor(0.3421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1075 D_tricked_loss= tensor(2.2753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1076 D_real_loss= tensor(0.3674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1076 D_fake_loss= tensor(0.3283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1076 D_tricked_loss= tensor(2.3611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1077 D_real_loss= tensor(0.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1077 D_fake_loss= tensor(0.3437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1077 D_tricked_loss= tensor(2.2457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1078 D_real_loss= tensor(0.3471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1078 D_fake_loss= tensor(0.3233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1078 D_tricked_loss= tensor(2.4028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1079 D_real_loss= tensor(0.3318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1079 D_fake_loss= tensor(0.3074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1079 D_tricked_loss= tensor(2.4257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1080 D_real_loss= tensor(0.3337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1080 D_fake_loss= tensor(0.3176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1080 D_tricked_loss= tensor(2.4952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1081 D_real_loss= tensor(0.3494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1081 D_fake_loss= tensor(0.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1081 D_tricked_loss= tensor(2.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1082 D_real_loss= tensor(0.3470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1082 D_fake_loss= tensor(0.3190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1082 D_tricked_loss= tensor(2.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1083 D_real_loss= tensor(0.3513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1083 D_fake_loss= tensor(0.3310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1083 D_tricked_loss= tensor(2.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1084 D_real_loss= tensor(0.3851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1084 D_fake_loss= tensor(0.3148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1084 D_tricked_loss= tensor(2.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1085 D_real_loss= tensor(0.3763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1085 D_fake_loss= tensor(0.3330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1085 D_tricked_loss= tensor(2.2481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1086 D_real_loss= tensor(0.3328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1086 D_fake_loss= tensor(0.3108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1086 D_tricked_loss= tensor(2.2752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1087 D_real_loss= tensor(0.3546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1087 D_fake_loss= tensor(0.3630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1087 D_tricked_loss= tensor(2.2648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1088 D_real_loss= tensor(0.3706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1088 D_fake_loss= tensor(0.3659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1088 D_tricked_loss= tensor(2.3540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1089 D_real_loss= tensor(0.3582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1089 D_fake_loss= tensor(0.3513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1089 D_tricked_loss= tensor(2.2841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1090 D_real_loss= tensor(0.3709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1090 D_fake_loss= tensor(0.3277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1090 D_tricked_loss= tensor(2.3224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1091 D_real_loss= tensor(0.3445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1091 D_fake_loss= tensor(0.3557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1091 D_tricked_loss= tensor(2.2338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1092 D_real_loss= tensor(0.3794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1092 D_fake_loss= tensor(0.3503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1092 D_tricked_loss= tensor(2.4023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1093 D_real_loss= tensor(0.3686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1093 D_fake_loss= tensor(0.3441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1093 D_tricked_loss= tensor(2.2128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1094 D_real_loss= tensor(0.3861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1094 D_fake_loss= tensor(0.3398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1094 D_tricked_loss= tensor(2.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1095 D_real_loss= tensor(0.3502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1095 D_fake_loss= tensor(0.3124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1095 D_tricked_loss= tensor(2.2940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1096 D_real_loss= tensor(0.3544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1096 D_fake_loss= tensor(0.3759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1096 D_tricked_loss= tensor(2.3068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1097 D_real_loss= tensor(0.3664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1097 D_fake_loss= tensor(0.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1097 D_tricked_loss= tensor(2.3006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1098 D_real_loss= tensor(0.3706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1098 D_fake_loss= tensor(0.3260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1098 D_tricked_loss= tensor(2.2714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1099 D_real_loss= tensor(0.3712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1099 D_fake_loss= tensor(0.3302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1099 D_tricked_loss= tensor(2.2925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1100 D_real_loss= tensor(0.3543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1100 D_fake_loss= tensor(0.3393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1100 D_tricked_loss= tensor(2.3587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1101 D_real_loss= tensor(0.3565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1101 D_fake_loss= tensor(0.3348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1101 D_tricked_loss= tensor(2.1599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1102 D_real_loss= tensor(0.3532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1102 D_fake_loss= tensor(0.3049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1102 D_tricked_loss= tensor(2.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1103 D_real_loss= tensor(0.3411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1103 D_fake_loss= tensor(0.2973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1103 D_tricked_loss= tensor(2.2233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1104 D_real_loss= tensor(0.3429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1104 D_fake_loss= tensor(0.3178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1104 D_tricked_loss= tensor(2.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1105 D_real_loss= tensor(0.3313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1105 D_fake_loss= tensor(0.3685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1105 D_tricked_loss= tensor(2.3753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1106 D_real_loss= tensor(0.3685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1106 D_fake_loss= tensor(0.3506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1106 D_tricked_loss= tensor(2.2385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1107 D_real_loss= tensor(0.3906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1107 D_fake_loss= tensor(0.3126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1107 D_tricked_loss= tensor(2.3037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1108 D_real_loss= tensor(0.3717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1108 D_fake_loss= tensor(0.3547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1108 D_tricked_loss= tensor(2.3553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1109 D_real_loss= tensor(0.3793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1109 D_fake_loss= tensor(0.3148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1109 D_tricked_loss= tensor(2.3661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1110 D_real_loss= tensor(0.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1110 D_fake_loss= tensor(0.3314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1110 D_tricked_loss= tensor(2.2647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1111 D_real_loss= tensor(0.3577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1111 D_fake_loss= tensor(0.3245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1111 D_tricked_loss= tensor(2.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1112 D_real_loss= tensor(0.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1112 D_fake_loss= tensor(0.2931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1112 D_tricked_loss= tensor(2.3658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1113 D_real_loss= tensor(0.3454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1113 D_fake_loss= tensor(0.3653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1113 D_tricked_loss= tensor(2.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1114 D_real_loss= tensor(0.3441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1114 D_fake_loss= tensor(0.3098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1114 D_tricked_loss= tensor(2.3228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1115 D_real_loss= tensor(0.3213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1115 D_fake_loss= tensor(0.3578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1115 D_tricked_loss= tensor(2.3978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1116 D_real_loss= tensor(0.3548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1116 D_fake_loss= tensor(0.3460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1116 D_tricked_loss= tensor(2.3666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1117 D_real_loss= tensor(0.3530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1117 D_fake_loss= tensor(0.3272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1117 D_tricked_loss= tensor(2.3950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1118 D_real_loss= tensor(0.3820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1118 D_fake_loss= tensor(0.3406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1118 D_tricked_loss= tensor(2.3780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1119 D_real_loss= tensor(0.3911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1119 D_fake_loss= tensor(0.3108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1119 D_tricked_loss= tensor(2.2933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1120 D_real_loss= tensor(0.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1120 D_fake_loss= tensor(0.3264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1120 D_tricked_loss= tensor(2.2218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1121 D_real_loss= tensor(0.3567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1121 D_fake_loss= tensor(0.3232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1121 D_tricked_loss= tensor(2.2678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1122 D_real_loss= tensor(0.3896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1122 D_fake_loss= tensor(0.3488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1122 D_tricked_loss= tensor(2.2126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1123 D_real_loss= tensor(0.3692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1123 D_fake_loss= tensor(0.3482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1123 D_tricked_loss= tensor(2.1928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1124 D_real_loss= tensor(0.3561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1124 D_fake_loss= tensor(0.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1124 D_tricked_loss= tensor(2.2711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1125 D_real_loss= tensor(0.4011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1125 D_fake_loss= tensor(0.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1125 D_tricked_loss= tensor(2.2114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1126 D_real_loss= tensor(0.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1126 D_fake_loss= tensor(0.3400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1126 D_tricked_loss= tensor(2.2761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1127 D_real_loss= tensor(0.3690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1127 D_fake_loss= tensor(0.3458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1127 D_tricked_loss= tensor(2.1456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1128 D_real_loss= tensor(0.3749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1128 D_fake_loss= tensor(0.3228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1128 D_tricked_loss= tensor(2.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1129 D_real_loss= tensor(0.3749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1129 D_fake_loss= tensor(0.3350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1129 D_tricked_loss= tensor(2.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1130 D_real_loss= tensor(0.3498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1130 D_fake_loss= tensor(0.3665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1130 D_tricked_loss= tensor(2.1704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1131 D_real_loss= tensor(0.3480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1131 D_fake_loss= tensor(0.3070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1131 D_tricked_loss= tensor(2.2453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1132 D_real_loss= tensor(0.3665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1132 D_fake_loss= tensor(0.3556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1132 D_tricked_loss= tensor(2.3624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1133 D_real_loss= tensor(0.3634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1133 D_fake_loss= tensor(0.3465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1133 D_tricked_loss= tensor(2.2840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1134 D_real_loss= tensor(0.3871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1134 D_fake_loss= tensor(0.3240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1134 D_tricked_loss= tensor(2.2773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1135 D_real_loss= tensor(0.3867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1135 D_fake_loss= tensor(0.3463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1135 D_tricked_loss= tensor(2.2847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1136 D_real_loss= tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1136 D_fake_loss= tensor(0.3315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1136 D_tricked_loss= tensor(2.2330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1137 D_real_loss= tensor(0.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1137 D_fake_loss= tensor(0.3498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1137 D_tricked_loss= tensor(2.1659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1138 D_real_loss= tensor(0.3810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1138 D_fake_loss= tensor(0.3494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1138 D_tricked_loss= tensor(2.2260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1139 D_real_loss= tensor(0.3367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1139 D_fake_loss= tensor(0.3386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1139 D_tricked_loss= tensor(2.1698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1140 D_real_loss= tensor(0.3283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1140 D_fake_loss= tensor(0.3514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1140 D_tricked_loss= tensor(2.2197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1141 D_real_loss= tensor(0.3494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1141 D_fake_loss= tensor(0.3310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1141 D_tricked_loss= tensor(2.2560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1142 D_real_loss= tensor(0.3560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1142 D_fake_loss= tensor(0.3510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1142 D_tricked_loss= tensor(2.3146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1143 D_real_loss= tensor(0.3726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1143 D_fake_loss= tensor(0.3456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1143 D_tricked_loss= tensor(2.3799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1144 D_real_loss= tensor(0.3867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1144 D_fake_loss= tensor(0.3294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1144 D_tricked_loss= tensor(2.3697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1145 D_real_loss= tensor(0.3711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1145 D_fake_loss= tensor(0.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1145 D_tricked_loss= tensor(2.3231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1146 D_real_loss= tensor(0.3886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1146 D_fake_loss= tensor(0.3498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1146 D_tricked_loss= tensor(2.2182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1147 D_real_loss= tensor(0.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1147 D_fake_loss= tensor(0.3292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1147 D_tricked_loss= tensor(2.2043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1148 D_real_loss= tensor(0.3853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1148 D_fake_loss= tensor(0.3311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1148 D_tricked_loss= tensor(2.2194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1149 D_real_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1149 D_fake_loss= tensor(0.3316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1149 D_tricked_loss= tensor(2.2227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1150 D_real_loss= tensor(0.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1150 D_fake_loss= tensor(0.3574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1150 D_tricked_loss= tensor(2.2268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1151 D_real_loss= tensor(0.3720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1151 D_fake_loss= tensor(0.3419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1151 D_tricked_loss= tensor(2.3316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1152 D_real_loss= tensor(0.3638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1152 D_fake_loss= tensor(0.3483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1152 D_tricked_loss= tensor(2.1917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1153 D_real_loss= tensor(0.3778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1153 D_fake_loss= tensor(0.3473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1153 D_tricked_loss= tensor(2.1735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1154 D_real_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1154 D_fake_loss= tensor(0.3595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1154 D_tricked_loss= tensor(2.2623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1155 D_real_loss= tensor(0.3846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1155 D_fake_loss= tensor(0.3518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1155 D_tricked_loss= tensor(2.2088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1156 D_real_loss= tensor(0.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1156 D_fake_loss= tensor(0.3513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1156 D_tricked_loss= tensor(2.1152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1157 D_real_loss= tensor(0.3819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1157 D_fake_loss= tensor(0.3506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1157 D_tricked_loss= tensor(2.1019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1158 D_real_loss= tensor(0.3761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1158 D_fake_loss= tensor(0.3506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1158 D_tricked_loss= tensor(2.1744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1159 D_real_loss= tensor(0.3758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1159 D_fake_loss= tensor(0.3606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1159 D_tricked_loss= tensor(2.0363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1160 D_real_loss= tensor(0.3825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1160 D_fake_loss= tensor(0.3539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1160 D_tricked_loss= tensor(2.0589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1161 D_real_loss= tensor(0.3911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1161 D_fake_loss= tensor(0.3512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1161 D_tricked_loss= tensor(2.1553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1162 D_real_loss= tensor(0.3529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1162 D_fake_loss= tensor(0.3656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1162 D_tricked_loss= tensor(2.2563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1163 D_real_loss= tensor(0.3388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1163 D_fake_loss= tensor(0.3493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1163 D_tricked_loss= tensor(2.2631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1164 D_real_loss= tensor(0.3761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1164 D_fake_loss= tensor(0.3421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1164 D_tricked_loss= tensor(2.2787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1165 D_real_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1165 D_fake_loss= tensor(0.3527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1165 D_tricked_loss= tensor(2.1487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1166 D_real_loss= tensor(0.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1166 D_fake_loss= tensor(0.3322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1166 D_tricked_loss= tensor(2.2137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1167 D_real_loss= tensor(0.3820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1167 D_fake_loss= tensor(0.3751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1167 D_tricked_loss= tensor(2.1767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1168 D_real_loss= tensor(0.3422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1168 D_fake_loss= tensor(0.3328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1168 D_tricked_loss= tensor(2.1283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1169 D_real_loss= tensor(0.3884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1169 D_fake_loss= tensor(0.3489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1169 D_tricked_loss= tensor(2.2077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1170 D_real_loss= tensor(0.3726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1170 D_fake_loss= tensor(0.3268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1170 D_tricked_loss= tensor(2.2519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1171 D_real_loss= tensor(0.3868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1171 D_fake_loss= tensor(0.3527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1171 D_tricked_loss= tensor(2.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1172 D_real_loss= tensor(0.3799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1172 D_fake_loss= tensor(0.3684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1172 D_tricked_loss= tensor(2.1602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1173 D_real_loss= tensor(0.3912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1173 D_fake_loss= tensor(0.3558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1173 D_tricked_loss= tensor(2.1594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1174 D_real_loss= tensor(0.3688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1174 D_fake_loss= tensor(0.3429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1174 D_tricked_loss= tensor(2.1736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1175 D_real_loss= tensor(0.4067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1175 D_fake_loss= tensor(0.3392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1175 D_tricked_loss= tensor(2.1568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1176 D_real_loss= tensor(0.3858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1176 D_fake_loss= tensor(0.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1176 D_tricked_loss= tensor(2.2265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1177 D_real_loss= tensor(0.3759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1177 D_fake_loss= tensor(0.3666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1177 D_tricked_loss= tensor(2.1172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1178 D_real_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1178 D_fake_loss= tensor(0.3621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1178 D_tricked_loss= tensor(2.0729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1179 D_real_loss= tensor(0.3679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1179 D_fake_loss= tensor(0.3934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1179 D_tricked_loss= tensor(2.1069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1180 D_real_loss= tensor(0.3790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1180 D_fake_loss= tensor(0.3450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1180 D_tricked_loss= tensor(2.1782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1181 D_real_loss= tensor(0.4021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1181 D_fake_loss= tensor(0.3289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1181 D_tricked_loss= tensor(2.1944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1182 D_real_loss= tensor(0.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1182 D_fake_loss= tensor(0.3493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1182 D_tricked_loss= tensor(2.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1183 D_real_loss= tensor(0.3831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1183 D_fake_loss= tensor(0.3554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1183 D_tricked_loss= tensor(2.0959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1184 D_real_loss= tensor(0.4041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1184 D_fake_loss= tensor(0.3506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1184 D_tricked_loss= tensor(2.0973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1185 D_real_loss= tensor(0.3550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1185 D_fake_loss= tensor(0.3800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1185 D_tricked_loss= tensor(2.0807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1186 D_real_loss= tensor(0.3979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1186 D_fake_loss= tensor(0.3682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1186 D_tricked_loss= tensor(2.0293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1187 D_real_loss= tensor(0.3972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1187 D_fake_loss= tensor(0.3519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1187 D_tricked_loss= tensor(2.0313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1188 D_real_loss= tensor(0.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1188 D_fake_loss= tensor(0.3524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1188 D_tricked_loss= tensor(2.1316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1189 D_real_loss= tensor(0.3673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1189 D_fake_loss= tensor(0.3572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1189 D_tricked_loss= tensor(2.0976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1190 D_real_loss= tensor(0.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1190 D_fake_loss= tensor(0.3656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1190 D_tricked_loss= tensor(2.0692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1191 D_real_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1191 D_fake_loss= tensor(0.3455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1191 D_tricked_loss= tensor(2.1833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1192 D_real_loss= tensor(0.4026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1192 D_fake_loss= tensor(0.3748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1192 D_tricked_loss= tensor(2.1210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1193 D_real_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1193 D_fake_loss= tensor(0.3578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1193 D_tricked_loss= tensor(2.0758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1194 D_real_loss= tensor(0.3781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1194 D_fake_loss= tensor(0.3712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1194 D_tricked_loss= tensor(2.0296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1195 D_real_loss= tensor(0.3950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1195 D_fake_loss= tensor(0.3513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1195 D_tricked_loss= tensor(2.0591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1196 D_real_loss= tensor(0.3424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1196 D_fake_loss= tensor(0.3703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1196 D_tricked_loss= tensor(2.0258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1197 D_real_loss= tensor(0.3696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1197 D_fake_loss= tensor(0.3509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1197 D_tricked_loss= tensor(2.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1198 D_real_loss= tensor(0.3511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1198 D_fake_loss= tensor(0.3179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1198 D_tricked_loss= tensor(2.1563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1199 D_real_loss= tensor(0.3793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1199 D_fake_loss= tensor(0.3454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1199 D_tricked_loss= tensor(2.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1200 D_real_loss= tensor(0.3969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1200 D_fake_loss= tensor(0.3461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1200 D_tricked_loss= tensor(2.1427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1201 D_real_loss= tensor(0.3496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1201 D_fake_loss= tensor(0.3750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1201 D_tricked_loss= tensor(2.1154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1202 D_real_loss= tensor(0.3827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1202 D_fake_loss= tensor(0.3556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1202 D_tricked_loss= tensor(2.1229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1203 D_real_loss= tensor(0.3753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1203 D_fake_loss= tensor(0.3222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1203 D_tricked_loss= tensor(2.1681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1204 D_real_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1204 D_fake_loss= tensor(0.3442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1204 D_tricked_loss= tensor(2.1550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1205 D_real_loss= tensor(0.3891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1205 D_fake_loss= tensor(0.3312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1205 D_tricked_loss= tensor(2.1842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1206 D_real_loss= tensor(0.3788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1206 D_fake_loss= tensor(0.3703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1206 D_tricked_loss= tensor(2.1471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1207 D_real_loss= tensor(0.3728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1207 D_fake_loss= tensor(0.3717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1207 D_tricked_loss= tensor(2.1654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1208 D_real_loss= tensor(0.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1208 D_fake_loss= tensor(0.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1208 D_tricked_loss= tensor(2.1876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1209 D_real_loss= tensor(0.3881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1209 D_fake_loss= tensor(0.3424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1209 D_tricked_loss= tensor(2.1699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1210 D_real_loss= tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1210 D_fake_loss= tensor(0.3516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1210 D_tricked_loss= tensor(2.0666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1211 D_real_loss= tensor(0.3859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1211 D_fake_loss= tensor(0.3584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1211 D_tricked_loss= tensor(2.1260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1212 D_real_loss= tensor(0.3698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1212 D_fake_loss= tensor(0.3768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1212 D_tricked_loss= tensor(2.0552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1213 D_real_loss= tensor(0.3692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1213 D_fake_loss= tensor(0.3497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1213 D_tricked_loss= tensor(2.1556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1214 D_real_loss= tensor(0.3880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1214 D_fake_loss= tensor(0.3545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1214 D_tricked_loss= tensor(2.1410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1215 D_real_loss= tensor(0.3745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1215 D_fake_loss= tensor(0.3417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1215 D_tricked_loss= tensor(2.1892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1216 D_real_loss= tensor(0.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1216 D_fake_loss= tensor(0.3587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1216 D_tricked_loss= tensor(2.0570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1217 D_real_loss= tensor(0.3958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1217 D_fake_loss= tensor(0.3842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1217 D_tricked_loss= tensor(2.1241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1218 D_real_loss= tensor(0.3947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1218 D_fake_loss= tensor(0.3439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1218 D_tricked_loss= tensor(2.0385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1219 D_real_loss= tensor(0.4191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1219 D_fake_loss= tensor(0.3757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1219 D_tricked_loss= tensor(1.9925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1220 D_real_loss= tensor(0.3827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1220 D_fake_loss= tensor(0.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1220 D_tricked_loss= tensor(2.0535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1221 D_real_loss= tensor(0.3774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1221 D_fake_loss= tensor(0.3250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1221 D_tricked_loss= tensor(2.0176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1222 D_real_loss= tensor(0.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1222 D_fake_loss= tensor(0.4004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1222 D_tricked_loss= tensor(2.0495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1223 D_real_loss= tensor(0.3712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1223 D_fake_loss= tensor(0.3576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1223 D_tricked_loss= tensor(2.1045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1224 D_real_loss= tensor(0.3928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1224 D_fake_loss= tensor(0.3352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1224 D_tricked_loss= tensor(2.1579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1225 D_real_loss= tensor(0.3784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1225 D_fake_loss= tensor(0.3872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1225 D_tricked_loss= tensor(2.1347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1226 D_real_loss= tensor(0.3865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1226 D_fake_loss= tensor(0.3595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1226 D_tricked_loss= tensor(2.1938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1227 D_real_loss= tensor(0.4108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1227 D_fake_loss= tensor(0.3249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1227 D_tricked_loss= tensor(2.0679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1228 D_real_loss= tensor(0.3881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1228 D_fake_loss= tensor(0.3409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1228 D_tricked_loss= tensor(2.1633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1229 D_real_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1229 D_fake_loss= tensor(0.3570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1229 D_tricked_loss= tensor(2.1633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1230 D_real_loss= tensor(0.3521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1230 D_fake_loss= tensor(0.3412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1230 D_tricked_loss= tensor(2.1197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1231 D_real_loss= tensor(0.3702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1231 D_fake_loss= tensor(0.3648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1231 D_tricked_loss= tensor(2.1154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1232 D_real_loss= tensor(0.3799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1232 D_fake_loss= tensor(0.3904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1232 D_tricked_loss= tensor(2.0901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1233 D_real_loss= tensor(0.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1233 D_fake_loss= tensor(0.3620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1233 D_tricked_loss= tensor(2.1512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1234 D_real_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1234 D_fake_loss= tensor(0.3362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1234 D_tricked_loss= tensor(2.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1235 D_real_loss= tensor(0.3559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1235 D_fake_loss= tensor(0.3800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1235 D_tricked_loss= tensor(2.1857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1236 D_real_loss= tensor(0.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1236 D_fake_loss= tensor(0.3629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1236 D_tricked_loss= tensor(2.0566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1237 D_real_loss= tensor(0.4014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1237 D_fake_loss= tensor(0.3214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1237 D_tricked_loss= tensor(2.1360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1238 D_real_loss= tensor(0.3819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1238 D_fake_loss= tensor(0.3194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1238 D_tricked_loss= tensor(2.0782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1239 D_real_loss= tensor(0.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1239 D_fake_loss= tensor(0.3643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1239 D_tricked_loss= tensor(2.2635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1240 D_real_loss= tensor(0.3666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1240 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1240 D_tricked_loss= tensor(2.0649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1241 D_real_loss= tensor(0.3820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1241 D_fake_loss= tensor(0.4137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1241 D_tricked_loss= tensor(2.1348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1242 D_real_loss= tensor(0.3961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1242 D_fake_loss= tensor(0.3724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1242 D_tricked_loss= tensor(2.2174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1243 D_real_loss= tensor(0.3929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1243 D_fake_loss= tensor(0.3844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1243 D_tricked_loss= tensor(2.1708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1244 D_real_loss= tensor(0.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1244 D_fake_loss= tensor(0.3522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1244 D_tricked_loss= tensor(2.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1245 D_real_loss= tensor(0.4049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1245 D_fake_loss= tensor(0.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1245 D_tricked_loss= tensor(2.1296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1246 D_real_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1246 D_fake_loss= tensor(0.3136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1246 D_tricked_loss= tensor(2.0606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1247 D_real_loss= tensor(0.3975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1247 D_fake_loss= tensor(0.3683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1247 D_tricked_loss= tensor(2.0625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1248 D_real_loss= tensor(0.4168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1248 D_fake_loss= tensor(0.3516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1248 D_tricked_loss= tensor(2.0395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1249 D_real_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1249 D_fake_loss= tensor(0.3627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1249 D_tricked_loss= tensor(2.1776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1250 D_real_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1250 D_fake_loss= tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1250 D_tricked_loss= tensor(2.0621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1251 D_real_loss= tensor(0.3846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1251 D_fake_loss= tensor(0.3492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1251 D_tricked_loss= tensor(2.1940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1252 D_real_loss= tensor(0.3683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1252 D_fake_loss= tensor(0.3443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1252 D_tricked_loss= tensor(2.2295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1253 D_real_loss= tensor(0.3973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1253 D_fake_loss= tensor(0.3412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1253 D_tricked_loss= tensor(2.3064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1254 D_real_loss= tensor(0.4016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1254 D_fake_loss= tensor(0.3803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1254 D_tricked_loss= tensor(2.1269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1255 D_real_loss= tensor(0.3928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1255 D_fake_loss= tensor(0.3660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1255 D_tricked_loss= tensor(2.0292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1256 D_real_loss= tensor(0.3630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1256 D_fake_loss= tensor(0.3444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1256 D_tricked_loss= tensor(2.1034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1257 D_real_loss= tensor(0.3749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1257 D_fake_loss= tensor(0.3243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1257 D_tricked_loss= tensor(2.1777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1258 D_real_loss= tensor(0.3591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1258 D_fake_loss= tensor(0.3129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1258 D_tricked_loss= tensor(2.2198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1259 D_real_loss= tensor(0.3479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1259 D_fake_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1259 D_tricked_loss= tensor(2.1872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1260 D_real_loss= tensor(0.3647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1260 D_fake_loss= tensor(0.3909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1260 D_tricked_loss= tensor(2.1100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1261 D_real_loss= tensor(0.3744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1261 D_fake_loss= tensor(0.3572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1261 D_tricked_loss= tensor(2.1472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1262 D_real_loss= tensor(0.3758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1262 D_fake_loss= tensor(0.3467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1262 D_tricked_loss= tensor(2.2656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1263 D_real_loss= tensor(0.3656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1263 D_fake_loss= tensor(0.3568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1263 D_tricked_loss= tensor(2.2000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1264 D_real_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1264 D_fake_loss= tensor(0.3511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1264 D_tricked_loss= tensor(2.0814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1265 D_real_loss= tensor(0.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1265 D_fake_loss= tensor(0.3481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1265 D_tricked_loss= tensor(2.0687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1266 D_real_loss= tensor(0.4156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1266 D_fake_loss= tensor(0.3052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1266 D_tricked_loss= tensor(2.1110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1267 D_real_loss= tensor(0.3781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1267 D_fake_loss= tensor(0.3324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1267 D_tricked_loss= tensor(2.1448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1268 D_real_loss= tensor(0.3798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1268 D_fake_loss= tensor(0.3972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1268 D_tricked_loss= tensor(2.0440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1269 D_real_loss= tensor(0.3621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1269 D_fake_loss= tensor(0.4013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1269 D_tricked_loss= tensor(2.0312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1270 D_real_loss= tensor(0.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1270 D_fake_loss= tensor(0.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1270 D_tricked_loss= tensor(2.2484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1271 D_real_loss= tensor(0.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1271 D_fake_loss= tensor(0.3470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1271 D_tricked_loss= tensor(2.2900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1272 D_real_loss= tensor(0.3796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1272 D_fake_loss= tensor(0.3853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1272 D_tricked_loss= tensor(2.1626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1273 D_real_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1273 D_fake_loss= tensor(0.3837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1273 D_tricked_loss= tensor(1.9613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1274 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1274 D_fake_loss= tensor(0.3441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1274 D_tricked_loss= tensor(2.0099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1275 D_real_loss= tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1275 D_fake_loss= tensor(0.3541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1275 D_tricked_loss= tensor(2.0080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1276 D_real_loss= tensor(0.3931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1276 D_fake_loss= tensor(0.3712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1276 D_tricked_loss= tensor(2.0293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1277 D_real_loss= tensor(0.3622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1277 D_fake_loss= tensor(0.3618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1277 D_tricked_loss= tensor(2.0016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1278 D_real_loss= tensor(0.3801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1278 D_fake_loss= tensor(0.3580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1278 D_tricked_loss= tensor(2.0507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1279 D_real_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1279 D_fake_loss= tensor(0.3471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1279 D_tricked_loss= tensor(2.1803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1280 D_real_loss= tensor(0.4132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1280 D_fake_loss= tensor(0.3471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1280 D_tricked_loss= tensor(2.2480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1281 D_real_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1281 D_fake_loss= tensor(0.3466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1281 D_tricked_loss= tensor(2.2091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1282 D_real_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1282 D_fake_loss= tensor(0.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1282 D_tricked_loss= tensor(2.1324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1283 D_real_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1283 D_fake_loss= tensor(0.3867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1283 D_tricked_loss= tensor(1.9837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1284 D_real_loss= tensor(0.4109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1284 D_fake_loss= tensor(0.3707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1284 D_tricked_loss= tensor(1.8569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1285 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1285 D_fake_loss= tensor(0.3742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1285 D_tricked_loss= tensor(1.9512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1286 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1286 D_fake_loss= tensor(0.4012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1286 D_tricked_loss= tensor(1.9510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1287 D_real_loss= tensor(0.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1287 D_fake_loss= tensor(0.3700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1287 D_tricked_loss= tensor(1.9322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1288 D_real_loss= tensor(0.4057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1288 D_fake_loss= tensor(0.3693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1288 D_tricked_loss= tensor(1.9454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1289 D_real_loss= tensor(0.3859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1289 D_fake_loss= tensor(0.3805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1289 D_tricked_loss= tensor(1.9779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1290 D_real_loss= tensor(0.3999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1290 D_fake_loss= tensor(0.3954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1290 D_tricked_loss= tensor(2.0049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1291 D_real_loss= tensor(0.4211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1291 D_fake_loss= tensor(0.3617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1291 D_tricked_loss= tensor(2.0499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1292 D_real_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1292 D_fake_loss= tensor(0.3687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1292 D_tricked_loss= tensor(2.0548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1293 D_real_loss= tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1293 D_fake_loss= tensor(0.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1293 D_tricked_loss= tensor(2.0025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1294 D_real_loss= tensor(0.4057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1294 D_fake_loss= tensor(0.3689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1294 D_tricked_loss= tensor(1.9828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1295 D_real_loss= tensor(0.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1295 D_fake_loss= tensor(0.3734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1295 D_tricked_loss= tensor(2.0288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1296 D_real_loss= tensor(0.3912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1296 D_fake_loss= tensor(0.3656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1296 D_tricked_loss= tensor(1.9557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1297 D_real_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1297 D_fake_loss= tensor(0.3795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1297 D_tricked_loss= tensor(2.0640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1298 D_real_loss= tensor(0.3660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1298 D_fake_loss= tensor(0.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1298 D_tricked_loss= tensor(2.0465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1299 D_real_loss= tensor(0.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1299 D_fake_loss= tensor(0.3732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1299 D_tricked_loss= tensor(2.1253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1300 D_real_loss= tensor(0.3753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1300 D_fake_loss= tensor(0.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1300 D_tricked_loss= tensor(2.0623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1301 D_real_loss= tensor(0.3923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1301 D_fake_loss= tensor(0.3571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1301 D_tricked_loss= tensor(2.0596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1302 D_real_loss= tensor(0.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1302 D_fake_loss= tensor(0.3799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1302 D_tricked_loss= tensor(2.1284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1303 D_real_loss= tensor(0.4081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1303 D_fake_loss= tensor(0.3891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1303 D_tricked_loss= tensor(2.0403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1304 D_real_loss= tensor(0.4211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1304 D_fake_loss= tensor(0.3623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1304 D_tricked_loss= tensor(2.0391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1305 D_real_loss= tensor(0.3795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1305 D_fake_loss= tensor(0.3949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1305 D_tricked_loss= tensor(2.0151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1306 D_real_loss= tensor(0.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1306 D_fake_loss= tensor(0.3345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1306 D_tricked_loss= tensor(2.0269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1307 D_real_loss= tensor(0.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1307 D_fake_loss= tensor(0.3522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1307 D_tricked_loss= tensor(2.0441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1308 D_real_loss= tensor(0.3830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1308 D_fake_loss= tensor(0.3959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1308 D_tricked_loss= tensor(2.0987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1309 D_real_loss= tensor(0.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1309 D_fake_loss= tensor(0.3646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1309 D_tricked_loss= tensor(2.1122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1310 D_real_loss= tensor(0.3790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1310 D_fake_loss= tensor(0.3627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1310 D_tricked_loss= tensor(2.0013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1311 D_real_loss= tensor(0.3746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1311 D_fake_loss= tensor(0.3749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1311 D_tricked_loss= tensor(2.1204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1312 D_real_loss= tensor(0.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1312 D_fake_loss= tensor(0.3719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1312 D_tricked_loss= tensor(2.1473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1313 D_real_loss= tensor(0.3837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1313 D_fake_loss= tensor(0.3682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1313 D_tricked_loss= tensor(2.0290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1314 D_real_loss= tensor(0.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1314 D_fake_loss= tensor(0.3618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1314 D_tricked_loss= tensor(2.0110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1315 D_real_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1315 D_fake_loss= tensor(0.3674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1315 D_tricked_loss= tensor(1.9393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1316 D_real_loss= tensor(0.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1316 D_fake_loss= tensor(0.3912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1316 D_tricked_loss= tensor(1.9381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1317 D_real_loss= tensor(0.4039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1317 D_fake_loss= tensor(0.3805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1317 D_tricked_loss= tensor(2.0186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1318 D_real_loss= tensor(0.3815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1318 D_fake_loss= tensor(0.3995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1318 D_tricked_loss= tensor(1.9939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1319 D_real_loss= tensor(0.3915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1319 D_fake_loss= tensor(0.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1319 D_tricked_loss= tensor(2.1330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1320 D_real_loss= tensor(0.3777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1320 D_fake_loss= tensor(0.3359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1320 D_tricked_loss= tensor(2.1554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1321 D_real_loss= tensor(0.4133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1321 D_fake_loss= tensor(0.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1321 D_tricked_loss= tensor(2.1856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1322 D_real_loss= tensor(0.3650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1322 D_fake_loss= tensor(0.3768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1322 D_tricked_loss= tensor(2.1686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1323 D_real_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1323 D_fake_loss= tensor(0.3645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1323 D_tricked_loss= tensor(2.1250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1324 D_real_loss= tensor(0.3959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1324 D_fake_loss= tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1324 D_tricked_loss= tensor(2.0454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1325 D_real_loss= tensor(0.3682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1325 D_fake_loss= tensor(0.3649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1325 D_tricked_loss= tensor(1.9375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1326 D_real_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1326 D_fake_loss= tensor(0.3619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1326 D_tricked_loss= tensor(2.0942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1327 D_real_loss= tensor(0.3885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1327 D_fake_loss= tensor(0.3733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1327 D_tricked_loss= tensor(2.1438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1328 D_real_loss= tensor(0.3826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1328 D_fake_loss= tensor(0.3599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1328 D_tricked_loss= tensor(2.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1329 D_real_loss= tensor(0.3757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1329 D_fake_loss= tensor(0.3962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1329 D_tricked_loss= tensor(2.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1330 D_real_loss= tensor(0.3678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1330 D_fake_loss= tensor(0.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1330 D_tricked_loss= tensor(2.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1331 D_real_loss= tensor(0.3844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1331 D_fake_loss= tensor(0.3534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1331 D_tricked_loss= tensor(2.1479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1332 D_real_loss= tensor(0.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1332 D_fake_loss= tensor(0.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1332 D_tricked_loss= tensor(2.1244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1333 D_real_loss= tensor(0.3920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1333 D_fake_loss= tensor(0.3339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1333 D_tricked_loss= tensor(2.0940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1334 D_real_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1334 D_fake_loss= tensor(0.3746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1334 D_tricked_loss= tensor(2.0720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1335 D_real_loss= tensor(0.3813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1335 D_fake_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1335 D_tricked_loss= tensor(2.0792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1336 D_real_loss= tensor(0.4065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1336 D_fake_loss= tensor(0.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1336 D_tricked_loss= tensor(2.1315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1337 D_real_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1337 D_fake_loss= tensor(0.3540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1337 D_tricked_loss= tensor(2.0070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1338 D_real_loss= tensor(0.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1338 D_fake_loss= tensor(0.3560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1338 D_tricked_loss= tensor(2.1473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1339 D_real_loss= tensor(0.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1339 D_fake_loss= tensor(0.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1339 D_tricked_loss= tensor(2.1616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1340 D_real_loss= tensor(0.4115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1340 D_fake_loss= tensor(0.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1340 D_tricked_loss= tensor(2.0522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1341 D_real_loss= tensor(0.3921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1341 D_fake_loss= tensor(0.3638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1341 D_tricked_loss= tensor(2.0876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1342 D_real_loss= tensor(0.3896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1342 D_fake_loss= tensor(0.3888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1342 D_tricked_loss= tensor(2.0603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1343 D_real_loss= tensor(0.3713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1343 D_fake_loss= tensor(0.3445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1343 D_tricked_loss= tensor(2.0662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1344 D_real_loss= tensor(0.3573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1344 D_fake_loss= tensor(0.3579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1344 D_tricked_loss= tensor(2.1024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1345 D_real_loss= tensor(0.3712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1345 D_fake_loss= tensor(0.3418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1345 D_tricked_loss= tensor(2.1567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1346 D_real_loss= tensor(0.3752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1346 D_fake_loss= tensor(0.3557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1346 D_tricked_loss= tensor(2.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1347 D_real_loss= tensor(0.3756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1347 D_fake_loss= tensor(0.3502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1347 D_tricked_loss= tensor(2.1854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1348 D_real_loss= tensor(0.3976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1348 D_fake_loss= tensor(0.3793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1348 D_tricked_loss= tensor(2.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1349 D_real_loss= tensor(0.3859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1349 D_fake_loss= tensor(0.3782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1349 D_tricked_loss= tensor(2.1429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1350 D_real_loss= tensor(0.4117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1350 D_fake_loss= tensor(0.3655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1350 D_tricked_loss= tensor(2.0444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1351 D_real_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1351 D_fake_loss= tensor(0.3505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1351 D_tricked_loss= tensor(2.0892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1352 D_real_loss= tensor(0.3930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1352 D_fake_loss= tensor(0.3687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1352 D_tricked_loss= tensor(1.9761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1353 D_real_loss= tensor(0.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1353 D_fake_loss= tensor(0.3689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1353 D_tricked_loss= tensor(2.0999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1354 D_real_loss= tensor(0.3990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1354 D_fake_loss= tensor(0.3283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1354 D_tricked_loss= tensor(2.0511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1355 D_real_loss= tensor(0.3764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1355 D_fake_loss= tensor(0.3946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1355 D_tricked_loss= tensor(2.0523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1356 D_real_loss= tensor(0.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1356 D_fake_loss= tensor(0.3630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1356 D_tricked_loss= tensor(1.9785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1357 D_real_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1357 D_fake_loss= tensor(0.3595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1357 D_tricked_loss= tensor(2.1820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1358 D_real_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1358 D_fake_loss= tensor(0.3709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1358 D_tricked_loss= tensor(1.9545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1359 D_real_loss= tensor(0.4016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1359 D_fake_loss= tensor(0.3939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1359 D_tricked_loss= tensor(2.0174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1360 D_real_loss= tensor(0.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1360 D_fake_loss= tensor(0.3695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1360 D_tricked_loss= tensor(2.0351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1361 D_real_loss= tensor(0.3989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1361 D_fake_loss= tensor(0.3545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1361 D_tricked_loss= tensor(1.9723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1362 D_real_loss= tensor(0.4103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1362 D_fake_loss= tensor(0.3725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1362 D_tricked_loss= tensor(1.9685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1363 D_real_loss= tensor(0.4051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1363 D_fake_loss= tensor(0.3850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1363 D_tricked_loss= tensor(1.9685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1364 D_real_loss= tensor(0.4002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1364 D_fake_loss= tensor(0.3554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1364 D_tricked_loss= tensor(2.0340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1365 D_real_loss= tensor(0.3837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1365 D_fake_loss= tensor(0.3527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1365 D_tricked_loss= tensor(2.0071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1366 D_real_loss= tensor(0.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1366 D_fake_loss= tensor(0.3867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1366 D_tricked_loss= tensor(2.0413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1367 D_real_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1367 D_fake_loss= tensor(0.3747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1367 D_tricked_loss= tensor(1.9946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1368 D_real_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1368 D_fake_loss= tensor(0.3591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1368 D_tricked_loss= tensor(1.9930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1369 D_real_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1369 D_fake_loss= tensor(0.3729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1369 D_tricked_loss= tensor(2.0416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1370 D_real_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1370 D_fake_loss= tensor(0.3840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1370 D_tricked_loss= tensor(1.9508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1371 D_real_loss= tensor(0.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1371 D_fake_loss= tensor(0.3419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1371 D_tricked_loss= tensor(2.0780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1372 D_real_loss= tensor(0.4005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1372 D_fake_loss= tensor(0.3678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1372 D_tricked_loss= tensor(2.0242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1373 D_real_loss= tensor(0.4068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1373 D_fake_loss= tensor(0.3349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1373 D_tricked_loss= tensor(2.0250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1374 D_real_loss= tensor(0.3590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1374 D_fake_loss= tensor(0.3847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1374 D_tricked_loss= tensor(1.9638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1375 D_real_loss= tensor(0.4076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1375 D_fake_loss= tensor(0.3794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1375 D_tricked_loss= tensor(2.0147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1376 D_real_loss= tensor(0.3739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1376 D_fake_loss= tensor(0.3665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1376 D_tricked_loss= tensor(2.0729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1377 D_real_loss= tensor(0.3904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1377 D_fake_loss= tensor(0.3946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1377 D_tricked_loss= tensor(2.0170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1378 D_real_loss= tensor(0.4041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1378 D_fake_loss= tensor(0.3591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1378 D_tricked_loss= tensor(2.0921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1379 D_real_loss= tensor(0.4058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1379 D_fake_loss= tensor(0.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1379 D_tricked_loss= tensor(1.8952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1380 D_real_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1380 D_fake_loss= tensor(0.3681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1380 D_tricked_loss= tensor(1.8843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1381 D_real_loss= tensor(0.4123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1381 D_fake_loss= tensor(0.3486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1381 D_tricked_loss= tensor(1.9550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1382 D_real_loss= tensor(0.3995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1382 D_fake_loss= tensor(0.3944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1382 D_tricked_loss= tensor(1.9822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1383 D_real_loss= tensor(0.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1383 D_fake_loss= tensor(0.3649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1383 D_tricked_loss= tensor(1.9191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1384 D_real_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1384 D_fake_loss= tensor(0.3784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1384 D_tricked_loss= tensor(2.0019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1385 D_real_loss= tensor(0.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1385 D_fake_loss= tensor(0.3809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1385 D_tricked_loss= tensor(1.9931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1386 D_real_loss= tensor(0.4222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1386 D_fake_loss= tensor(0.3371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1386 D_tricked_loss= tensor(2.0780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1387 D_real_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1387 D_fake_loss= tensor(0.3472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1387 D_tricked_loss= tensor(1.9202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1388 D_real_loss= tensor(0.3932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1388 D_fake_loss= tensor(0.3648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1388 D_tricked_loss= tensor(2.0363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1389 D_real_loss= tensor(0.4148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1389 D_fake_loss= tensor(0.3561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1389 D_tricked_loss= tensor(1.9550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1390 D_real_loss= tensor(0.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1390 D_fake_loss= tensor(0.3902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1390 D_tricked_loss= tensor(1.9834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1391 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1391 D_fake_loss= tensor(0.3625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1391 D_tricked_loss= tensor(2.0584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1392 D_real_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1392 D_fake_loss= tensor(0.3697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1392 D_tricked_loss= tensor(2.0196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1393 D_real_loss= tensor(0.4336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1393 D_fake_loss= tensor(0.3723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1393 D_tricked_loss= tensor(2.0274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1394 D_real_loss= tensor(0.4050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1394 D_fake_loss= tensor(0.4070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1394 D_tricked_loss= tensor(1.9642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1395 D_real_loss= tensor(0.3908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1395 D_fake_loss= tensor(0.3863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1395 D_tricked_loss= tensor(1.8920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1396 D_real_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1396 D_fake_loss= tensor(0.3827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1396 D_tricked_loss= tensor(1.8719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1397 D_real_loss= tensor(0.4072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1397 D_fake_loss= tensor(0.3820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1397 D_tricked_loss= tensor(1.9877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1398 D_real_loss= tensor(0.4141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1398 D_fake_loss= tensor(0.3814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1398 D_tricked_loss= tensor(1.9068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1399 D_real_loss= tensor(0.4222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1399 D_fake_loss= tensor(0.3717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1399 D_tricked_loss= tensor(1.9490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1400 D_real_loss= tensor(0.4063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1400 D_fake_loss= tensor(0.3809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1400 D_tricked_loss= tensor(1.8490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1401 D_real_loss= tensor(0.4200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1401 D_fake_loss= tensor(0.4026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1401 D_tricked_loss= tensor(1.9908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1402 D_real_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1402 D_fake_loss= tensor(0.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1402 D_tricked_loss= tensor(1.9650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1403 D_real_loss= tensor(0.4075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1403 D_fake_loss= tensor(0.3645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1403 D_tricked_loss= tensor(2.0005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1404 D_real_loss= tensor(0.3846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1404 D_fake_loss= tensor(0.3652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1404 D_tricked_loss= tensor(2.0364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1405 D_real_loss= tensor(0.4004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1405 D_fake_loss= tensor(0.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1405 D_tricked_loss= tensor(2.0048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1406 D_real_loss= tensor(0.3908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1406 D_fake_loss= tensor(0.3786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1406 D_tricked_loss= tensor(2.0208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1407 D_real_loss= tensor(0.4081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1407 D_fake_loss= tensor(0.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1407 D_tricked_loss= tensor(1.9227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1408 D_real_loss= tensor(0.4133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1408 D_fake_loss= tensor(0.3786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1408 D_tricked_loss= tensor(1.9383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1409 D_real_loss= tensor(0.3921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1409 D_fake_loss= tensor(0.3843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1409 D_tricked_loss= tensor(1.9544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1410 D_real_loss= tensor(0.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1410 D_fake_loss= tensor(0.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1410 D_tricked_loss= tensor(1.9530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1411 D_real_loss= tensor(0.3966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1411 D_fake_loss= tensor(0.3887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1411 D_tricked_loss= tensor(1.9322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1412 D_real_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1412 D_fake_loss= tensor(0.4072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1412 D_tricked_loss= tensor(2.0466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1413 D_real_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1413 D_fake_loss= tensor(0.3547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1413 D_tricked_loss= tensor(1.9644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1414 D_real_loss= tensor(0.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1414 D_fake_loss= tensor(0.4014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1414 D_tricked_loss= tensor(1.8800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1415 D_real_loss= tensor(0.4051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1415 D_fake_loss= tensor(0.3700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1415 D_tricked_loss= tensor(1.9822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1416 D_real_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1416 D_fake_loss= tensor(0.3971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1416 D_tricked_loss= tensor(1.9226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1417 D_real_loss= tensor(0.4101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1417 D_fake_loss= tensor(0.3661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1417 D_tricked_loss= tensor(1.9943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1418 D_real_loss= tensor(0.4048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1418 D_fake_loss= tensor(0.3944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1418 D_tricked_loss= tensor(1.9643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1419 D_real_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1419 D_fake_loss= tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1419 D_tricked_loss= tensor(1.9345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1420 D_real_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1420 D_fake_loss= tensor(0.3710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1420 D_tricked_loss= tensor(2.0197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1421 D_real_loss= tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1421 D_fake_loss= tensor(0.3627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1421 D_tricked_loss= tensor(2.0115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1422 D_real_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1422 D_fake_loss= tensor(0.3805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1422 D_tricked_loss= tensor(2.0260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1423 D_real_loss= tensor(0.3916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1423 D_fake_loss= tensor(0.4044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1423 D_tricked_loss= tensor(1.9731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1424 D_real_loss= tensor(0.4012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1424 D_fake_loss= tensor(0.3846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1424 D_tricked_loss= tensor(2.0330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1425 D_real_loss= tensor(0.3938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1425 D_fake_loss= tensor(0.3834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1425 D_tricked_loss= tensor(1.9427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1426 D_real_loss= tensor(0.4134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1426 D_fake_loss= tensor(0.3836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1426 D_tricked_loss= tensor(1.8778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1427 D_real_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1427 D_fake_loss= tensor(0.3804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1427 D_tricked_loss= tensor(1.9304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1428 D_real_loss= tensor(0.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1428 D_fake_loss= tensor(0.3850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1428 D_tricked_loss= tensor(1.8878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1429 D_real_loss= tensor(0.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1429 D_fake_loss= tensor(0.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1429 D_tricked_loss= tensor(1.9518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1430 D_real_loss= tensor(0.4074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1430 D_fake_loss= tensor(0.3874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1430 D_tricked_loss= tensor(1.8585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1431 D_real_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1431 D_fake_loss= tensor(0.3657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1431 D_tricked_loss= tensor(1.9351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1432 D_real_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1432 D_fake_loss= tensor(0.3730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1432 D_tricked_loss= tensor(1.9211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1433 D_real_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1433 D_fake_loss= tensor(0.3728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1433 D_tricked_loss= tensor(1.9498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1434 D_real_loss= tensor(0.4012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1434 D_fake_loss= tensor(0.3969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1434 D_tricked_loss= tensor(1.9357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1435 D_real_loss= tensor(0.3729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1435 D_fake_loss= tensor(0.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1435 D_tricked_loss= tensor(1.8401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1436 D_real_loss= tensor(0.3956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1436 D_fake_loss= tensor(0.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1436 D_tricked_loss= tensor(1.9773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1437 D_real_loss= tensor(0.4200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1437 D_fake_loss= tensor(0.4114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1437 D_tricked_loss= tensor(1.9565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1438 D_real_loss= tensor(0.4094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1438 D_fake_loss= tensor(0.3759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1438 D_tricked_loss= tensor(1.9439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1439 D_real_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1439 D_fake_loss= tensor(0.3843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1439 D_tricked_loss= tensor(1.9927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1440 D_real_loss= tensor(0.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1440 D_fake_loss= tensor(0.3733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1440 D_tricked_loss= tensor(1.9441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1441 D_real_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1441 D_fake_loss= tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1441 D_tricked_loss= tensor(1.9945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1442 D_real_loss= tensor(0.4106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1442 D_fake_loss= tensor(0.3739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1442 D_tricked_loss= tensor(1.9100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1443 D_real_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1443 D_fake_loss= tensor(0.3626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1443 D_tricked_loss= tensor(2.0720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1444 D_real_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1444 D_fake_loss= tensor(0.3752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1444 D_tricked_loss= tensor(1.9242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1445 D_real_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1445 D_fake_loss= tensor(0.4083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1445 D_tricked_loss= tensor(1.9192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1446 D_real_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1446 D_fake_loss= tensor(0.3939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1446 D_tricked_loss= tensor(2.0115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1447 D_real_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1447 D_fake_loss= tensor(0.3764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1447 D_tricked_loss= tensor(1.9547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1448 D_real_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1448 D_fake_loss= tensor(0.3892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1448 D_tricked_loss= tensor(1.9161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1449 D_real_loss= tensor(0.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1449 D_fake_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1449 D_tricked_loss= tensor(2.0063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1450 D_real_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1450 D_fake_loss= tensor(0.3654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1450 D_tricked_loss= tensor(2.0023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1451 D_real_loss= tensor(0.4162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1451 D_fake_loss= tensor(0.3480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1451 D_tricked_loss= tensor(1.9337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1452 D_real_loss= tensor(0.4118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1452 D_fake_loss= tensor(0.4072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1452 D_tricked_loss= tensor(1.9393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1453 D_real_loss= tensor(0.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1453 D_fake_loss= tensor(0.3333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1453 D_tricked_loss= tensor(2.0331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1454 D_real_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1454 D_fake_loss= tensor(0.3944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1454 D_tricked_loss= tensor(2.0440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1455 D_real_loss= tensor(0.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1455 D_fake_loss= tensor(0.3700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1455 D_tricked_loss= tensor(2.0979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1456 D_real_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1456 D_fake_loss= tensor(0.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1456 D_tricked_loss= tensor(2.0437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1457 D_real_loss= tensor(0.3957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1457 D_fake_loss= tensor(0.3877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1457 D_tricked_loss= tensor(1.9879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1458 D_real_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1458 D_fake_loss= tensor(0.3637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1458 D_tricked_loss= tensor(1.9951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1459 D_real_loss= tensor(0.3908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1459 D_fake_loss= tensor(0.3522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1459 D_tricked_loss= tensor(1.9742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1460 D_real_loss= tensor(0.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1460 D_fake_loss= tensor(0.3974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1460 D_tricked_loss= tensor(1.9759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1461 D_real_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1461 D_fake_loss= tensor(0.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1461 D_tricked_loss= tensor(2.0383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1462 D_real_loss= tensor(0.4104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1462 D_fake_loss= tensor(0.3826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1462 D_tricked_loss= tensor(1.9146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1463 D_real_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1463 D_fake_loss= tensor(0.3829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1463 D_tricked_loss= tensor(1.9709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1464 D_real_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1464 D_fake_loss= tensor(0.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1464 D_tricked_loss= tensor(2.0604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1465 D_real_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1465 D_fake_loss= tensor(0.3818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1465 D_tricked_loss= tensor(1.9924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1466 D_real_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1466 D_fake_loss= tensor(0.3684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1466 D_tricked_loss= tensor(1.9748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1467 D_real_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1467 D_fake_loss= tensor(0.3926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1467 D_tricked_loss= tensor(1.8782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1468 D_real_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1468 D_fake_loss= tensor(0.3560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1468 D_tricked_loss= tensor(1.8865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1469 D_real_loss= tensor(0.4050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1469 D_fake_loss= tensor(0.3767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1469 D_tricked_loss= tensor(1.9688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1470 D_real_loss= tensor(0.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1470 D_fake_loss= tensor(0.3813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1470 D_tricked_loss= tensor(1.9442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1471 D_real_loss= tensor(0.3996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1471 D_fake_loss= tensor(0.3892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1471 D_tricked_loss= tensor(1.9655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1472 D_real_loss= tensor(0.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1472 D_fake_loss= tensor(0.3941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1472 D_tricked_loss= tensor(1.9927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1473 D_real_loss= tensor(0.4180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1473 D_fake_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1473 D_tricked_loss= tensor(1.9679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1474 D_real_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1474 D_fake_loss= tensor(0.3794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1474 D_tricked_loss= tensor(1.9851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1475 D_real_loss= tensor(0.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1475 D_fake_loss= tensor(0.3487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1475 D_tricked_loss= tensor(2.0629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1476 D_real_loss= tensor(0.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1476 D_fake_loss= tensor(0.3605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1476 D_tricked_loss= tensor(1.9232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1477 D_real_loss= tensor(0.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1477 D_fake_loss= tensor(0.3439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1477 D_tricked_loss= tensor(1.9375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1478 D_real_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1478 D_fake_loss= tensor(0.3659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1478 D_tricked_loss= tensor(2.1154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1479 D_real_loss= tensor(0.3972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1479 D_fake_loss= tensor(0.3827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1479 D_tricked_loss= tensor(1.9575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1480 D_real_loss= tensor(0.3930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1480 D_fake_loss= tensor(0.3974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1480 D_tricked_loss= tensor(1.9706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1481 D_real_loss= tensor(0.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1481 D_fake_loss= tensor(0.3877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1481 D_tricked_loss= tensor(1.9409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1482 D_real_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1482 D_fake_loss= tensor(0.3936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1482 D_tricked_loss= tensor(2.0090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1483 D_real_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1483 D_fake_loss= tensor(0.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1483 D_tricked_loss= tensor(1.9061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1484 D_real_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1484 D_fake_loss= tensor(0.3671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1484 D_tricked_loss= tensor(1.9804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1485 D_real_loss= tensor(0.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1485 D_fake_loss= tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1485 D_tricked_loss= tensor(1.9637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1486 D_real_loss= tensor(0.4075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1486 D_fake_loss= tensor(0.3914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1486 D_tricked_loss= tensor(1.9151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1487 D_real_loss= tensor(0.4135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1487 D_fake_loss= tensor(0.3534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1487 D_tricked_loss= tensor(2.0117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1488 D_real_loss= tensor(0.3841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1488 D_fake_loss= tensor(0.3842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1488 D_tricked_loss= tensor(2.0521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1489 D_real_loss= tensor(0.3935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1489 D_fake_loss= tensor(0.3838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1489 D_tricked_loss= tensor(1.9487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1490 D_real_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1490 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1490 D_tricked_loss= tensor(2.0092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1491 D_real_loss= tensor(0.4011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1491 D_fake_loss= tensor(0.4102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1491 D_tricked_loss= tensor(2.0124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1492 D_real_loss= tensor(0.4263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1492 D_fake_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1492 D_tricked_loss= tensor(2.0403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1493 D_real_loss= tensor(0.3926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1493 D_fake_loss= tensor(0.3696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1493 D_tricked_loss= tensor(2.0790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1494 D_real_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1494 D_fake_loss= tensor(0.3891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1494 D_tricked_loss= tensor(1.9490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1495 D_real_loss= tensor(0.4358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1495 D_fake_loss= tensor(0.3830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1495 D_tricked_loss= tensor(1.8845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1496 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1496 D_fake_loss= tensor(0.3888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1496 D_tricked_loss= tensor(1.8201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1497 D_real_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1497 D_fake_loss= tensor(0.3673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1497 D_tricked_loss= tensor(1.9008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1498 D_real_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1498 D_fake_loss= tensor(0.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1498 D_tricked_loss= tensor(1.8957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1499 D_real_loss= tensor(0.4009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1499 D_fake_loss= tensor(0.3808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1499 D_tricked_loss= tensor(1.8525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1500 D_real_loss= tensor(0.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1500 D_fake_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1500 D_tricked_loss= tensor(1.9759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1501 D_real_loss= tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1501 D_fake_loss= tensor(0.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1501 D_tricked_loss= tensor(1.9435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1502 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1502 D_fake_loss= tensor(0.4139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1502 D_tricked_loss= tensor(1.9836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1503 D_real_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1503 D_fake_loss= tensor(0.4150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1503 D_tricked_loss= tensor(1.8361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1504 D_real_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1504 D_fake_loss= tensor(0.4078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1504 D_tricked_loss= tensor(1.7806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1505 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1505 D_fake_loss= tensor(0.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1505 D_tricked_loss= tensor(1.8944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1506 D_real_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1506 D_fake_loss= tensor(0.3600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1506 D_tricked_loss= tensor(1.9332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1507 D_real_loss= tensor(0.3923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1507 D_fake_loss= tensor(0.3977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1507 D_tricked_loss= tensor(2.0059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1508 D_real_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1508 D_fake_loss= tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1508 D_tricked_loss= tensor(1.9275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1509 D_real_loss= tensor(0.3988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1509 D_fake_loss= tensor(0.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1509 D_tricked_loss= tensor(1.9071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1510 D_real_loss= tensor(0.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1510 D_fake_loss= tensor(0.3772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1510 D_tricked_loss= tensor(1.9298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1511 D_real_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1511 D_fake_loss= tensor(0.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1511 D_tricked_loss= tensor(1.8852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1512 D_real_loss= tensor(0.4183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1512 D_fake_loss= tensor(0.3862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1512 D_tricked_loss= tensor(1.8583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1513 D_real_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1513 D_fake_loss= tensor(0.3610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1513 D_tricked_loss= tensor(1.9821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1514 D_real_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1514 D_fake_loss= tensor(0.3662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1514 D_tricked_loss= tensor(1.9219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1515 D_real_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1515 D_fake_loss= tensor(0.3659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1515 D_tricked_loss= tensor(1.9249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1516 D_real_loss= tensor(0.4352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1516 D_fake_loss= tensor(0.3514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1516 D_tricked_loss= tensor(1.8770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1517 D_real_loss= tensor(0.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1517 D_fake_loss= tensor(0.3726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1517 D_tricked_loss= tensor(2.0186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1518 D_real_loss= tensor(0.3833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1518 D_fake_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1518 D_tricked_loss= tensor(1.9888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1519 D_real_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1519 D_fake_loss= tensor(0.3884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1519 D_tricked_loss= tensor(1.9300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1520 D_real_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1520 D_fake_loss= tensor(0.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1520 D_tricked_loss= tensor(1.8917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1521 D_real_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1521 D_fake_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1521 D_tricked_loss= tensor(1.9585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1522 D_real_loss= tensor(0.4124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1522 D_fake_loss= tensor(0.4017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1522 D_tricked_loss= tensor(2.0507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1523 D_real_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1523 D_fake_loss= tensor(0.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1523 D_tricked_loss= tensor(1.9652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1524 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1524 D_fake_loss= tensor(0.3818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1524 D_tricked_loss= tensor(1.9192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1525 D_real_loss= tensor(0.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1525 D_fake_loss= tensor(0.3945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1525 D_tricked_loss= tensor(1.7618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1526 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1526 D_fake_loss= tensor(0.3569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1526 D_tricked_loss= tensor(1.8077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1527 D_real_loss= tensor(0.4013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1527 D_fake_loss= tensor(0.3706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1527 D_tricked_loss= tensor(1.9341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1528 D_real_loss= tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1528 D_fake_loss= tensor(0.3326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1528 D_tricked_loss= tensor(1.9695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1529 D_real_loss= tensor(0.3699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1529 D_fake_loss= tensor(0.3642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1529 D_tricked_loss= tensor(2.0384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1530 D_real_loss= tensor(0.3682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1530 D_fake_loss= tensor(0.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1530 D_tricked_loss= tensor(1.8776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1531 D_real_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1531 D_fake_loss= tensor(0.3623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1531 D_tricked_loss= tensor(1.9744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1532 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1532 D_fake_loss= tensor(0.3846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1532 D_tricked_loss= tensor(2.0417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1533 D_real_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1533 D_fake_loss= tensor(0.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1533 D_tricked_loss= tensor(1.8958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1534 D_real_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1534 D_fake_loss= tensor(0.3815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1534 D_tricked_loss= tensor(2.0621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1535 D_real_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1535 D_fake_loss= tensor(0.4095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1535 D_tricked_loss= tensor(1.8361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1536 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1536 D_fake_loss= tensor(0.3733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1536 D_tricked_loss= tensor(1.8214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1537 D_real_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1537 D_fake_loss= tensor(0.3862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1537 D_tricked_loss= tensor(1.8417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1538 D_real_loss= tensor(0.3950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1538 D_fake_loss= tensor(0.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1538 D_tricked_loss= tensor(1.8176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1539 D_real_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1539 D_fake_loss= tensor(0.3835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1539 D_tricked_loss= tensor(1.9272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1540 D_real_loss= tensor(0.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1540 D_fake_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1540 D_tricked_loss= tensor(1.8554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1541 D_real_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1541 D_fake_loss= tensor(0.3919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1541 D_tricked_loss= tensor(1.8735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1542 D_real_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1542 D_fake_loss= tensor(0.3863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1542 D_tricked_loss= tensor(1.8751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1543 D_real_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1543 D_fake_loss= tensor(0.4003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1543 D_tricked_loss= tensor(1.8746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1544 D_real_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1544 D_fake_loss= tensor(0.3965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1544 D_tricked_loss= tensor(1.9297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1545 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1545 D_fake_loss= tensor(0.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1545 D_tricked_loss= tensor(1.8324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1546 D_real_loss= tensor(0.4481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1546 D_fake_loss= tensor(0.4088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1546 D_tricked_loss= tensor(1.8351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1547 D_real_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1547 D_fake_loss= tensor(0.3869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1547 D_tricked_loss= tensor(1.8345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1548 D_real_loss= tensor(0.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1548 D_fake_loss= tensor(0.3651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1548 D_tricked_loss= tensor(1.9408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1549 D_real_loss= tensor(0.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1549 D_fake_loss= tensor(0.3649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1549 D_tricked_loss= tensor(1.9152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1550 D_real_loss= tensor(0.4046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1550 D_fake_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1550 D_tricked_loss= tensor(1.9692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1551 D_real_loss= tensor(0.4015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1551 D_fake_loss= tensor(0.3957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1551 D_tricked_loss= tensor(1.9415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1552 D_real_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1552 D_fake_loss= tensor(0.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1552 D_tricked_loss= tensor(1.8771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1553 D_real_loss= tensor(0.4391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1553 D_fake_loss= tensor(0.3882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1553 D_tricked_loss= tensor(1.9772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1554 D_real_loss= tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1554 D_fake_loss= tensor(0.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1554 D_tricked_loss= tensor(1.8101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1555 D_real_loss= tensor(0.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1555 D_fake_loss= tensor(0.3813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1555 D_tricked_loss= tensor(1.8341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1556 D_real_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1556 D_fake_loss= tensor(0.3701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1556 D_tricked_loss= tensor(1.8598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1557 D_real_loss= tensor(0.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1557 D_fake_loss= tensor(0.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1557 D_tricked_loss= tensor(1.8510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1558 D_real_loss= tensor(0.3782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1558 D_fake_loss= tensor(0.3374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1558 D_tricked_loss= tensor(1.8972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1559 D_real_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1559 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1559 D_tricked_loss= tensor(1.8966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1560 D_real_loss= tensor(0.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1560 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1560 D_tricked_loss= tensor(1.9327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1561 D_real_loss= tensor(0.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1561 D_fake_loss= tensor(0.4082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1561 D_tricked_loss= tensor(1.8595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1562 D_real_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1562 D_fake_loss= tensor(0.3671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1562 D_tricked_loss= tensor(1.9013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1563 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1563 D_fake_loss= tensor(0.3708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1563 D_tricked_loss= tensor(1.8707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1564 D_real_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1564 D_fake_loss= tensor(0.4023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1564 D_tricked_loss= tensor(1.8849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1565 D_real_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1565 D_fake_loss= tensor(0.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1565 D_tricked_loss= tensor(1.9278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1566 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1566 D_fake_loss= tensor(0.4210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1566 D_tricked_loss= tensor(1.7724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1567 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1567 D_fake_loss= tensor(0.3963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1567 D_tricked_loss= tensor(1.8233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1568 D_real_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1568 D_fake_loss= tensor(0.4067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1568 D_tricked_loss= tensor(1.8109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1569 D_real_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1569 D_fake_loss= tensor(0.3912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1569 D_tricked_loss= tensor(1.8920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1570 D_real_loss= tensor(0.3946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1570 D_fake_loss= tensor(0.3884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1570 D_tricked_loss= tensor(1.8266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1571 D_real_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1571 D_fake_loss= tensor(0.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1571 D_tricked_loss= tensor(1.9151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1572 D_real_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1572 D_fake_loss= tensor(0.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1572 D_tricked_loss= tensor(1.9528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1573 D_real_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1573 D_fake_loss= tensor(0.3833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1573 D_tricked_loss= tensor(2.0450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1574 D_real_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1574 D_fake_loss= tensor(0.3904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1574 D_tricked_loss= tensor(2.0296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1575 D_real_loss= tensor(0.4495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1575 D_fake_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1575 D_tricked_loss= tensor(1.9539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1576 D_real_loss= tensor(0.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1576 D_fake_loss= tensor(0.3633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1576 D_tricked_loss= tensor(1.8647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1577 D_real_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1577 D_fake_loss= tensor(0.3983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1577 D_tricked_loss= tensor(1.8674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1578 D_real_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1578 D_fake_loss= tensor(0.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1578 D_tricked_loss= tensor(1.8701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1579 D_real_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1579 D_fake_loss= tensor(0.4042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1579 D_tricked_loss= tensor(1.8649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1580 D_real_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1580 D_fake_loss= tensor(0.3747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1580 D_tricked_loss= tensor(1.9244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1581 D_real_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1581 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1581 D_tricked_loss= tensor(1.8586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1582 D_real_loss= tensor(0.4033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1582 D_fake_loss= tensor(0.4223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1582 D_tricked_loss= tensor(1.8043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1583 D_real_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1583 D_fake_loss= tensor(0.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1583 D_tricked_loss= tensor(1.8628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1584 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1584 D_fake_loss= tensor(0.3826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1584 D_tricked_loss= tensor(1.8933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1585 D_real_loss= tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1585 D_fake_loss= tensor(0.4027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1585 D_tricked_loss= tensor(1.8659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1586 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1586 D_fake_loss= tensor(0.4014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1586 D_tricked_loss= tensor(1.8094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1587 D_real_loss= tensor(0.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1587 D_fake_loss= tensor(0.3739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1587 D_tricked_loss= tensor(1.8132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1588 D_real_loss= tensor(0.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1588 D_fake_loss= tensor(0.4195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1588 D_tricked_loss= tensor(1.8984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1589 D_real_loss= tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1589 D_fake_loss= tensor(0.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1589 D_tricked_loss= tensor(1.8911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1590 D_real_loss= tensor(0.4036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1590 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1590 D_tricked_loss= tensor(1.9168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1591 D_real_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1591 D_fake_loss= tensor(0.3934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1591 D_tricked_loss= tensor(1.9270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1592 D_real_loss= tensor(0.4225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1592 D_fake_loss= tensor(0.4166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1592 D_tricked_loss= tensor(1.8609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1593 D_real_loss= tensor(0.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1593 D_fake_loss= tensor(0.4108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1593 D_tricked_loss= tensor(1.9017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1594 D_real_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1594 D_fake_loss= tensor(0.3789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1594 D_tricked_loss= tensor(1.8456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1595 D_real_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1595 D_fake_loss= tensor(0.3827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1595 D_tricked_loss= tensor(1.9112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1596 D_real_loss= tensor(0.4108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1596 D_fake_loss= tensor(0.3969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1596 D_tricked_loss= tensor(1.8124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1597 D_real_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1597 D_fake_loss= tensor(0.3752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1597 D_tricked_loss= tensor(1.8863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1598 D_real_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1598 D_fake_loss= tensor(0.3962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1598 D_tricked_loss= tensor(1.8950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1599 D_real_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1599 D_fake_loss= tensor(0.3809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1599 D_tricked_loss= tensor(1.8302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1600 D_real_loss= tensor(0.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1600 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1600 D_tricked_loss= tensor(1.8967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1601 D_real_loss= tensor(0.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1601 D_fake_loss= tensor(0.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1601 D_tricked_loss= tensor(1.8877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1602 D_real_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1602 D_fake_loss= tensor(0.3989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1602 D_tricked_loss= tensor(1.8837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1603 D_real_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1603 D_fake_loss= tensor(0.4062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1603 D_tricked_loss= tensor(1.8318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1604 D_real_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1604 D_fake_loss= tensor(0.4007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1604 D_tricked_loss= tensor(1.8287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1605 D_real_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1605 D_fake_loss= tensor(0.4122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1605 D_tricked_loss= tensor(1.8438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1606 D_real_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1606 D_fake_loss= tensor(0.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1606 D_tricked_loss= tensor(1.7643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1607 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1607 D_fake_loss= tensor(0.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1607 D_tricked_loss= tensor(1.7210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1608 D_real_loss= tensor(0.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1608 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1608 D_tricked_loss= tensor(1.7748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1609 D_real_loss= tensor(0.4044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1609 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1609 D_tricked_loss= tensor(1.7959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1610 D_real_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1610 D_fake_loss= tensor(0.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1610 D_tricked_loss= tensor(1.8572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1611 D_real_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1611 D_fake_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1611 D_tricked_loss= tensor(1.8118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1612 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1612 D_fake_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1612 D_tricked_loss= tensor(1.8661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1613 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1613 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1613 D_tricked_loss= tensor(1.8444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1614 D_real_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1614 D_fake_loss= tensor(0.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1614 D_tricked_loss= tensor(1.7889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1615 D_real_loss= tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1615 D_fake_loss= tensor(0.3841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1615 D_tricked_loss= tensor(1.8796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1616 D_real_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1616 D_fake_loss= tensor(0.3574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1616 D_tricked_loss= tensor(1.7906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1617 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1617 D_fake_loss= tensor(0.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1617 D_tricked_loss= tensor(1.8290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1618 D_real_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1618 D_fake_loss= tensor(0.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1618 D_tricked_loss= tensor(1.7771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1619 D_real_loss= tensor(0.4223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1619 D_fake_loss= tensor(0.3926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1619 D_tricked_loss= tensor(1.9087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1620 D_real_loss= tensor(0.4148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1620 D_fake_loss= tensor(0.4130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1620 D_tricked_loss= tensor(1.8473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1621 D_real_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1621 D_fake_loss= tensor(0.3947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1621 D_tricked_loss= tensor(1.8049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1622 D_real_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1622 D_fake_loss= tensor(0.4262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1622 D_tricked_loss= tensor(1.8235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1623 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1623 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1623 D_tricked_loss= tensor(1.7982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1624 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1624 D_fake_loss= tensor(0.3736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1624 D_tricked_loss= tensor(1.8288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1625 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1625 D_fake_loss= tensor(0.3945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1625 D_tricked_loss= tensor(1.8328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1626 D_real_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1626 D_fake_loss= tensor(0.4012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1626 D_tricked_loss= tensor(1.8641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1627 D_real_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1627 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1627 D_tricked_loss= tensor(1.7638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1628 D_real_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1628 D_fake_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1628 D_tricked_loss= tensor(1.7915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1629 D_real_loss= tensor(0.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1629 D_fake_loss= tensor(0.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1629 D_tricked_loss= tensor(1.8291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1630 D_real_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1630 D_fake_loss= tensor(0.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1630 D_tricked_loss= tensor(1.8325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1631 D_real_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1631 D_fake_loss= tensor(0.4134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1631 D_tricked_loss= tensor(1.9023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1632 D_real_loss= tensor(0.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1632 D_fake_loss= tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1632 D_tricked_loss= tensor(1.8585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1633 D_real_loss= tensor(0.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1633 D_fake_loss= tensor(0.4008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1633 D_tricked_loss= tensor(1.8310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1634 D_real_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1634 D_fake_loss= tensor(0.3888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1634 D_tricked_loss= tensor(1.7624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1635 D_real_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1635 D_fake_loss= tensor(0.3839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1635 D_tricked_loss= tensor(1.7618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1636 D_real_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1636 D_fake_loss= tensor(0.4022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1636 D_tricked_loss= tensor(1.8281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1637 D_real_loss= tensor(0.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1637 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1637 D_tricked_loss= tensor(1.8329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1638 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1638 D_fake_loss= tensor(0.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1638 D_tricked_loss= tensor(1.8016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1639 D_real_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1639 D_fake_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1639 D_tricked_loss= tensor(1.8643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1640 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1640 D_fake_loss= tensor(0.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1640 D_tricked_loss= tensor(1.8438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1641 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1641 D_fake_loss= tensor(0.3990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1641 D_tricked_loss= tensor(1.8481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1642 D_real_loss= tensor(0.4328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1642 D_fake_loss= tensor(0.3823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1642 D_tricked_loss= tensor(1.8479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1643 D_real_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1643 D_fake_loss= tensor(0.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1643 D_tricked_loss= tensor(1.8985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1644 D_real_loss= tensor(0.4032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1644 D_fake_loss= tensor(0.3844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1644 D_tricked_loss= tensor(1.8475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1645 D_real_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1645 D_fake_loss= tensor(0.3890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1645 D_tricked_loss= tensor(1.9275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1646 D_real_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1646 D_fake_loss= tensor(0.3919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1646 D_tricked_loss= tensor(2.0112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1647 D_real_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1647 D_fake_loss= tensor(0.3901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1647 D_tricked_loss= tensor(1.9823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1648 D_real_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1648 D_fake_loss= tensor(0.3772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1648 D_tricked_loss= tensor(1.9029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1649 D_real_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1649 D_fake_loss= tensor(0.3769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1649 D_tricked_loss= tensor(1.9176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1650 D_real_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1650 D_fake_loss= tensor(0.3879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1650 D_tricked_loss= tensor(1.8802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1651 D_real_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1651 D_fake_loss= tensor(0.3789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1651 D_tricked_loss= tensor(1.8485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1652 D_real_loss= tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1652 D_fake_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1652 D_tricked_loss= tensor(1.7869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1653 D_real_loss= tensor(0.3973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1653 D_fake_loss= tensor(0.4128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1653 D_tricked_loss= tensor(1.8145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1654 D_real_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1654 D_fake_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1654 D_tricked_loss= tensor(1.7892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1655 D_real_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1655 D_fake_loss= tensor(0.4086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1655 D_tricked_loss= tensor(1.8663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1656 D_real_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1656 D_fake_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1656 D_tricked_loss= tensor(1.9090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1657 D_real_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1657 D_fake_loss= tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1657 D_tricked_loss= tensor(1.8964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1658 D_real_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1658 D_fake_loss= tensor(0.4200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1658 D_tricked_loss= tensor(1.8173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1659 D_real_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1659 D_fake_loss= tensor(0.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1659 D_tricked_loss= tensor(1.7470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1660 D_real_loss= tensor(0.4413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1660 D_fake_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1660 D_tricked_loss= tensor(1.7863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1661 D_real_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1661 D_fake_loss= tensor(0.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1661 D_tricked_loss= tensor(1.8320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1662 D_real_loss= tensor(0.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1662 D_fake_loss= tensor(0.3939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1662 D_tricked_loss= tensor(1.7751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1663 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1663 D_fake_loss= tensor(0.3840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1663 D_tricked_loss= tensor(1.9013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1664 D_real_loss= tensor(0.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1664 D_fake_loss= tensor(0.3869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1664 D_tricked_loss= tensor(1.8873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1665 D_real_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1665 D_fake_loss= tensor(0.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1665 D_tricked_loss= tensor(1.8833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1666 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1666 D_fake_loss= tensor(0.3853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1666 D_tricked_loss= tensor(1.9065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1667 D_real_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1667 D_fake_loss= tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1667 D_tricked_loss= tensor(1.8167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1668 D_real_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1668 D_fake_loss= tensor(0.3920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1668 D_tricked_loss= tensor(1.8451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1669 D_real_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1669 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1669 D_tricked_loss= tensor(1.7887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1670 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1670 D_fake_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1670 D_tricked_loss= tensor(1.7779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1671 D_real_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1671 D_fake_loss= tensor(0.3934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1671 D_tricked_loss= tensor(1.8038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1672 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1672 D_fake_loss= tensor(0.4128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1672 D_tricked_loss= tensor(1.7692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1673 D_real_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1673 D_fake_loss= tensor(0.4189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1673 D_tricked_loss= tensor(1.7804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1674 D_real_loss= tensor(0.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1674 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1674 D_tricked_loss= tensor(1.7349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1675 D_real_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1675 D_fake_loss= tensor(0.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1675 D_tricked_loss= tensor(1.7964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1676 D_real_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1676 D_fake_loss= tensor(0.4250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1676 D_tricked_loss= tensor(1.8209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1677 D_real_loss= tensor(0.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1677 D_fake_loss= tensor(0.3901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1677 D_tricked_loss= tensor(1.8121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1678 D_real_loss= tensor(0.4249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1678 D_fake_loss= tensor(0.3826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1678 D_tricked_loss= tensor(1.8640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1679 D_real_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1679 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1679 D_tricked_loss= tensor(1.7622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1680 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1680 D_fake_loss= tensor(0.4033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1680 D_tricked_loss= tensor(1.7995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1681 D_real_loss= tensor(0.4129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1681 D_fake_loss= tensor(0.3817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1681 D_tricked_loss= tensor(1.8478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1682 D_real_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1682 D_fake_loss= tensor(0.3830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1682 D_tricked_loss= tensor(1.9085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1683 D_real_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1683 D_fake_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1683 D_tricked_loss= tensor(1.8465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1684 D_real_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1684 D_fake_loss= tensor(0.4052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1684 D_tricked_loss= tensor(1.8243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1685 D_real_loss= tensor(0.3978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1685 D_fake_loss= tensor(0.3981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1685 D_tricked_loss= tensor(1.8624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1686 D_real_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1686 D_fake_loss= tensor(0.4037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1686 D_tricked_loss= tensor(1.8491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1687 D_real_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1687 D_fake_loss= tensor(0.3668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1687 D_tricked_loss= tensor(1.9010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1688 D_real_loss= tensor(0.3990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1688 D_fake_loss= tensor(0.3836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1688 D_tricked_loss= tensor(1.9602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1689 D_real_loss= tensor(0.3997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1689 D_fake_loss= tensor(0.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1689 D_tricked_loss= tensor(1.9049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1690 D_real_loss= tensor(0.4257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1690 D_fake_loss= tensor(0.4272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1690 D_tricked_loss= tensor(1.9303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1691 D_real_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1691 D_fake_loss= tensor(0.4033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1691 D_tricked_loss= tensor(1.9033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1692 D_real_loss= tensor(0.4352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1692 D_fake_loss= tensor(0.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1692 D_tricked_loss= tensor(1.9528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1693 D_real_loss= tensor(0.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1693 D_fake_loss= tensor(0.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1693 D_tricked_loss= tensor(1.9550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1694 D_real_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1694 D_fake_loss= tensor(0.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1694 D_tricked_loss= tensor(1.8512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1695 D_real_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1695 D_fake_loss= tensor(0.3915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1695 D_tricked_loss= tensor(1.7964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1696 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1696 D_fake_loss= tensor(0.3748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1696 D_tricked_loss= tensor(1.8106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1697 D_real_loss= tensor(0.4045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1697 D_fake_loss= tensor(0.3794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1697 D_tricked_loss= tensor(1.8752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1698 D_real_loss= tensor(0.3999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1698 D_fake_loss= tensor(0.4073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1698 D_tricked_loss= tensor(1.8763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1699 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1699 D_fake_loss= tensor(0.3621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1699 D_tricked_loss= tensor(1.8951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1700 D_real_loss= tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1700 D_fake_loss= tensor(0.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1700 D_tricked_loss= tensor(1.8643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1701 D_real_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1701 D_fake_loss= tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1701 D_tricked_loss= tensor(1.8197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1702 D_real_loss= tensor(0.4237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1702 D_fake_loss= tensor(0.3770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1702 D_tricked_loss= tensor(1.9642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1703 D_real_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1703 D_fake_loss= tensor(0.3891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1703 D_tricked_loss= tensor(1.9388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1704 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1704 D_fake_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1704 D_tricked_loss= tensor(1.8529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1705 D_real_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1705 D_fake_loss= tensor(0.4263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1705 D_tricked_loss= tensor(1.7885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1706 D_real_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1706 D_fake_loss= tensor(0.3913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1706 D_tricked_loss= tensor(1.8486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1707 D_real_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1707 D_fake_loss= tensor(0.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1707 D_tricked_loss= tensor(1.8401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1708 D_real_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1708 D_fake_loss= tensor(0.4050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1708 D_tricked_loss= tensor(1.7814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1709 D_real_loss= tensor(0.4133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1709 D_fake_loss= tensor(0.4022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1709 D_tricked_loss= tensor(1.8586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1710 D_real_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1710 D_fake_loss= tensor(0.4257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1710 D_tricked_loss= tensor(1.8500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1711 D_real_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1711 D_fake_loss= tensor(0.4148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1711 D_tricked_loss= tensor(1.8187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1712 D_real_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1712 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1712 D_tricked_loss= tensor(1.8369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1713 D_real_loss= tensor(0.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1713 D_fake_loss= tensor(0.3816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1713 D_tricked_loss= tensor(1.8906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1714 D_real_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1714 D_fake_loss= tensor(0.3981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1714 D_tricked_loss= tensor(1.7995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1715 D_real_loss= tensor(0.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1715 D_fake_loss= tensor(0.4129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1715 D_tricked_loss= tensor(1.8091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1716 D_real_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1716 D_fake_loss= tensor(0.4129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1716 D_tricked_loss= tensor(1.8722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1717 D_real_loss= tensor(0.4062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1717 D_fake_loss= tensor(0.3936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1717 D_tricked_loss= tensor(1.8586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1718 D_real_loss= tensor(0.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1718 D_fake_loss= tensor(0.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1718 D_tricked_loss= tensor(1.8236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1719 D_real_loss= tensor(0.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1719 D_fake_loss= tensor(0.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1719 D_tricked_loss= tensor(1.8199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1720 D_real_loss= tensor(0.4083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1720 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1720 D_tricked_loss= tensor(1.8027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1721 D_real_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1721 D_fake_loss= tensor(0.3964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1721 D_tricked_loss= tensor(1.8284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1722 D_real_loss= tensor(0.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1722 D_fake_loss= tensor(0.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1722 D_tricked_loss= tensor(1.8431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1723 D_real_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1723 D_fake_loss= tensor(0.3764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1723 D_tricked_loss= tensor(1.8809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1724 D_real_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1724 D_fake_loss= tensor(0.4027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1724 D_tricked_loss= tensor(1.8491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1725 D_real_loss= tensor(0.4134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1725 D_fake_loss= tensor(0.3787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1725 D_tricked_loss= tensor(1.8238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1726 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1726 D_fake_loss= tensor(0.3400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1726 D_tricked_loss= tensor(1.9603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1727 D_real_loss= tensor(0.3873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1727 D_fake_loss= tensor(0.4189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1727 D_tricked_loss= tensor(1.9425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1728 D_real_loss= tensor(0.4101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1728 D_fake_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1728 D_tricked_loss= tensor(1.8181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1729 D_real_loss= tensor(0.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1729 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1729 D_tricked_loss= tensor(1.8362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1730 D_real_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1730 D_fake_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1730 D_tricked_loss= tensor(1.8006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1731 D_real_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1731 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1731 D_tricked_loss= tensor(1.9104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1732 D_real_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1732 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1732 D_tricked_loss= tensor(1.8067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1733 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1733 D_fake_loss= tensor(0.4045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1733 D_tricked_loss= tensor(1.6849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1734 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1734 D_fake_loss= tensor(0.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1734 D_tricked_loss= tensor(1.7980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1735 D_real_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1735 D_fake_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1735 D_tricked_loss= tensor(1.7125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1736 D_real_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1736 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1736 D_tricked_loss= tensor(1.7884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1737 D_real_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1737 D_fake_loss= tensor(0.3901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1737 D_tricked_loss= tensor(1.7389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1738 D_real_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1738 D_fake_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1738 D_tricked_loss= tensor(1.7445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1739 D_real_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1739 D_fake_loss= tensor(0.4033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1739 D_tricked_loss= tensor(1.8241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1740 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1740 D_fake_loss= tensor(0.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1740 D_tricked_loss= tensor(1.7619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1741 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1741 D_fake_loss= tensor(0.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1741 D_tricked_loss= tensor(1.7770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1742 D_real_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1742 D_fake_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1742 D_tricked_loss= tensor(1.7788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1743 D_real_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1743 D_fake_loss= tensor(0.4104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1743 D_tricked_loss= tensor(1.7439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1744 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1744 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1744 D_tricked_loss= tensor(1.7157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1745 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1745 D_fake_loss= tensor(0.3869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1745 D_tricked_loss= tensor(1.7496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1746 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1746 D_fake_loss= tensor(0.4121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1746 D_tricked_loss= tensor(1.7852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1747 D_real_loss= tensor(0.4358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1747 D_fake_loss= tensor(0.3748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1747 D_tricked_loss= tensor(1.8989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1748 D_real_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1748 D_fake_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1748 D_tricked_loss= tensor(1.8297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1749 D_real_loss= tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1749 D_fake_loss= tensor(0.4018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1749 D_tricked_loss= tensor(1.8770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1750 D_real_loss= tensor(0.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1750 D_fake_loss= tensor(0.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1750 D_tricked_loss= tensor(1.9326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1751 D_real_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1751 D_fake_loss= tensor(0.3928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1751 D_tricked_loss= tensor(1.9203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1752 D_real_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1752 D_fake_loss= tensor(0.3937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1752 D_tricked_loss= tensor(1.8859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1753 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1753 D_fake_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1753 D_tricked_loss= tensor(1.8413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1754 D_real_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1754 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1754 D_tricked_loss= tensor(1.7827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1755 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1755 D_fake_loss= tensor(0.3909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1755 D_tricked_loss= tensor(1.7416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1756 D_real_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1756 D_fake_loss= tensor(0.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1756 D_tricked_loss= tensor(1.7642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1757 D_real_loss= tensor(0.4075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1757 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1757 D_tricked_loss= tensor(1.7471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1758 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1758 D_fake_loss= tensor(0.4287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1758 D_tricked_loss= tensor(1.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1759 D_real_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1759 D_fake_loss= tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1759 D_tricked_loss= tensor(1.8084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1760 D_real_loss= tensor(0.4740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1760 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1760 D_tricked_loss= tensor(1.8370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1761 D_real_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1761 D_fake_loss= tensor(0.4404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1761 D_tricked_loss= tensor(1.7344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1762 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1762 D_fake_loss= tensor(0.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1762 D_tricked_loss= tensor(1.7870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1763 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1763 D_fake_loss= tensor(0.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1763 D_tricked_loss= tensor(1.7669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1764 D_real_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1764 D_fake_loss= tensor(0.4137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1764 D_tricked_loss= tensor(1.7632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1765 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1765 D_fake_loss= tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1765 D_tricked_loss= tensor(1.7282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1766 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1766 D_fake_loss= tensor(0.4018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1766 D_tricked_loss= tensor(1.7638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1767 D_real_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1767 D_fake_loss= tensor(0.4037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1767 D_tricked_loss= tensor(1.7357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1768 D_real_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1768 D_fake_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1768 D_tricked_loss= tensor(1.7860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1769 D_real_loss= tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1769 D_fake_loss= tensor(0.3939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1769 D_tricked_loss= tensor(1.7591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1770 D_real_loss= tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1770 D_fake_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1770 D_tricked_loss= tensor(1.7568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1771 D_real_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1771 D_fake_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1771 D_tricked_loss= tensor(1.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1772 D_real_loss= tensor(0.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1772 D_fake_loss= tensor(0.4167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1772 D_tricked_loss= tensor(1.7981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1773 D_real_loss= tensor(0.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1773 D_fake_loss= tensor(0.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1773 D_tricked_loss= tensor(1.7498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1774 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1774 D_fake_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1774 D_tricked_loss= tensor(1.7692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1775 D_real_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1775 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1775 D_tricked_loss= tensor(1.6791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1776 D_real_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1776 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1776 D_tricked_loss= tensor(1.6509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1777 D_real_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1777 D_fake_loss= tensor(0.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1777 D_tricked_loss= tensor(1.7860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1778 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1778 D_fake_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1778 D_tricked_loss= tensor(1.6997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1779 D_real_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1779 D_fake_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1779 D_tricked_loss= tensor(1.7682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1780 D_real_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1780 D_fake_loss= tensor(0.4132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1780 D_tricked_loss= tensor(1.7194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1781 D_real_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1781 D_fake_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1781 D_tricked_loss= tensor(1.7417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1782 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1782 D_fake_loss= tensor(0.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1782 D_tricked_loss= tensor(1.7157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1783 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1783 D_fake_loss= tensor(0.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1783 D_tricked_loss= tensor(1.7921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1784 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1784 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1784 D_tricked_loss= tensor(1.8160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1785 D_real_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1785 D_fake_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1785 D_tricked_loss= tensor(1.7357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1786 D_real_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1786 D_fake_loss= tensor(0.4083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1786 D_tricked_loss= tensor(1.7305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1787 D_real_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1787 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1787 D_tricked_loss= tensor(1.7504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1788 D_real_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1788 D_fake_loss= tensor(0.3894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1788 D_tricked_loss= tensor(1.8127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1789 D_real_loss= tensor(0.4014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1789 D_fake_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1789 D_tricked_loss= tensor(1.9557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1790 D_real_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1790 D_fake_loss= tensor(0.4048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1790 D_tricked_loss= tensor(1.9136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1791 D_real_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1791 D_fake_loss= tensor(0.3804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1791 D_tricked_loss= tensor(1.9059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1792 D_real_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1792 D_fake_loss= tensor(0.4081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1792 D_tricked_loss= tensor(1.8463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1793 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1793 D_fake_loss= tensor(0.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1793 D_tricked_loss= tensor(1.9560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1794 D_real_loss= tensor(0.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1794 D_fake_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1794 D_tricked_loss= tensor(1.8684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1795 D_real_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1795 D_fake_loss= tensor(0.4101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1795 D_tricked_loss= tensor(1.8758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1796 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1796 D_fake_loss= tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1796 D_tricked_loss= tensor(1.7630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1797 D_real_loss= tensor(0.4200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1797 D_fake_loss= tensor(0.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1797 D_tricked_loss= tensor(1.7001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1798 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1798 D_fake_loss= tensor(0.4191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1798 D_tricked_loss= tensor(1.7097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1799 D_real_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1799 D_fake_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1799 D_tricked_loss= tensor(1.7122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1800 D_real_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1800 D_fake_loss= tensor(0.3735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1800 D_tricked_loss= tensor(1.7591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1801 D_real_loss= tensor(0.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1801 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1801 D_tricked_loss= tensor(1.8213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1802 D_real_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1802 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1802 D_tricked_loss= tensor(1.7458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1803 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1803 D_fake_loss= tensor(0.3998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1803 D_tricked_loss= tensor(1.8888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1804 D_real_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1804 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1804 D_tricked_loss= tensor(1.8949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1805 D_real_loss= tensor(0.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1805 D_fake_loss= tensor(0.4039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1805 D_tricked_loss= tensor(1.7624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1806 D_real_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1806 D_fake_loss= tensor(0.4162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1806 D_tricked_loss= tensor(1.7311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1807 D_real_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1807 D_fake_loss= tensor(0.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1807 D_tricked_loss= tensor(1.7356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1808 D_real_loss= tensor(0.4109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1808 D_fake_loss= tensor(0.3805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1808 D_tricked_loss= tensor(1.8275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1809 D_real_loss= tensor(0.3893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1809 D_fake_loss= tensor(0.4026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1809 D_tricked_loss= tensor(1.8128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1810 D_real_loss= tensor(0.4135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1810 D_fake_loss= tensor(0.3890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1810 D_tricked_loss= tensor(1.9166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1811 D_real_loss= tensor(0.3959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1811 D_fake_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1811 D_tricked_loss= tensor(1.8465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1812 D_real_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1812 D_fake_loss= tensor(0.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1812 D_tricked_loss= tensor(1.8436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1813 D_real_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1813 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1813 D_tricked_loss= tensor(1.8016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1814 D_real_loss= tensor(0.4365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1814 D_fake_loss= tensor(0.4031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1814 D_tricked_loss= tensor(1.7984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1815 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1815 D_fake_loss= tensor(0.3937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1815 D_tricked_loss= tensor(1.8434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1816 D_real_loss= tensor(0.4536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1816 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1816 D_tricked_loss= tensor(1.6723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1817 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1817 D_fake_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1817 D_tricked_loss= tensor(1.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1818 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1818 D_fake_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1818 D_tricked_loss= tensor(1.6474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1819 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1819 D_fake_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1819 D_tricked_loss= tensor(1.6773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1820 D_real_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1820 D_fake_loss= tensor(0.3949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1820 D_tricked_loss= tensor(1.8358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1821 D_real_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1821 D_fake_loss= tensor(0.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1821 D_tricked_loss= tensor(1.7397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1822 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1822 D_fake_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1822 D_tricked_loss= tensor(1.8126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1823 D_real_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1823 D_fake_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1823 D_tricked_loss= tensor(1.7380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1824 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1824 D_fake_loss= tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1824 D_tricked_loss= tensor(1.7501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1825 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1825 D_fake_loss= tensor(0.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1825 D_tricked_loss= tensor(1.8156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1826 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1826 D_fake_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1826 D_tricked_loss= tensor(1.7067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1827 D_real_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1827 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1827 D_tricked_loss= tensor(1.7140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1828 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1828 D_fake_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1828 D_tricked_loss= tensor(1.7303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1829 D_real_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1829 D_fake_loss= tensor(0.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1829 D_tricked_loss= tensor(1.7622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1830 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1830 D_fake_loss= tensor(0.4052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1830 D_tricked_loss= tensor(1.7411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1831 D_real_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1831 D_fake_loss= tensor(0.3948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1831 D_tricked_loss= tensor(1.7084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1832 D_real_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1832 D_fake_loss= tensor(0.4115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1832 D_tricked_loss= tensor(1.7822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1833 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1833 D_fake_loss= tensor(0.4003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1833 D_tricked_loss= tensor(1.7811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1834 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1834 D_fake_loss= tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1834 D_tricked_loss= tensor(1.7570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1835 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1835 D_fake_loss= tensor(0.4047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1835 D_tricked_loss= tensor(1.8037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1836 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1836 D_fake_loss= tensor(0.3984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1836 D_tricked_loss= tensor(1.7117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1837 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1837 D_fake_loss= tensor(0.3928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1837 D_tricked_loss= tensor(1.7651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1838 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1838 D_fake_loss= tensor(0.4336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1838 D_tricked_loss= tensor(1.6380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1839 D_real_loss= tensor(0.4482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1839 D_fake_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1839 D_tricked_loss= tensor(1.6870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1840 D_real_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1840 D_fake_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1840 D_tricked_loss= tensor(1.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1841 D_real_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1841 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1841 D_tricked_loss= tensor(1.7209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1842 D_real_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1842 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1842 D_tricked_loss= tensor(1.7572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1843 D_real_loss= tensor(0.4527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1843 D_fake_loss= tensor(0.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1843 D_tricked_loss= tensor(1.7766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1844 D_real_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1844 D_fake_loss= tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1844 D_tricked_loss= tensor(1.7368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1845 D_real_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1845 D_fake_loss= tensor(0.4183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1845 D_tricked_loss= tensor(1.8145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1846 D_real_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1846 D_fake_loss= tensor(0.4117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1846 D_tricked_loss= tensor(1.7207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1847 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1847 D_fake_loss= tensor(0.4249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1847 D_tricked_loss= tensor(1.7985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1848 D_real_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1848 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1848 D_tricked_loss= tensor(1.7884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1849 D_real_loss= tensor(0.4358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1849 D_fake_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1849 D_tricked_loss= tensor(1.6570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1850 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1850 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1850 D_tricked_loss= tensor(1.7687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1851 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1851 D_fake_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1851 D_tricked_loss= tensor(1.8196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1852 D_real_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1852 D_fake_loss= tensor(0.4285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1852 D_tricked_loss= tensor(1.7026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1853 D_real_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1853 D_fake_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1853 D_tricked_loss= tensor(1.8043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1854 D_real_loss= tensor(0.4328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1854 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1854 D_tricked_loss= tensor(1.7056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1855 D_real_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1855 D_fake_loss= tensor(0.4080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1855 D_tricked_loss= tensor(1.8605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1856 D_real_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1856 D_fake_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1856 D_tricked_loss= tensor(1.7315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1857 D_real_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1857 D_fake_loss= tensor(0.4104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1857 D_tricked_loss= tensor(1.8062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1858 D_real_loss= tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1858 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1858 D_tricked_loss= tensor(1.7156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1859 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1859 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1859 D_tricked_loss= tensor(1.7096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1860 D_real_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1860 D_fake_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1860 D_tricked_loss= tensor(1.7164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1861 D_real_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1861 D_fake_loss= tensor(0.3915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1861 D_tricked_loss= tensor(1.6868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1862 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1862 D_fake_loss= tensor(0.4193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1862 D_tricked_loss= tensor(1.7025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1863 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1863 D_fake_loss= tensor(0.3974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1863 D_tricked_loss= tensor(1.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1864 D_real_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1864 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1864 D_tricked_loss= tensor(1.6601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1865 D_real_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1865 D_fake_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1865 D_tricked_loss= tensor(1.7816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1866 D_real_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1866 D_fake_loss= tensor(0.3868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1866 D_tricked_loss= tensor(1.7670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1867 D_real_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1867 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1867 D_tricked_loss= tensor(1.7966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1868 D_real_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1868 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1868 D_tricked_loss= tensor(1.7283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1869 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1869 D_fake_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1869 D_tricked_loss= tensor(1.7806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1870 D_real_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1870 D_fake_loss= tensor(0.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1870 D_tricked_loss= tensor(1.7724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1871 D_real_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1871 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1871 D_tricked_loss= tensor(1.8174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1872 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1872 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1872 D_tricked_loss= tensor(1.7045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1873 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1873 D_fake_loss= tensor(0.3895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1873 D_tricked_loss= tensor(1.7771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1874 D_real_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1874 D_fake_loss= tensor(0.3841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1874 D_tricked_loss= tensor(1.7601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1875 D_real_loss= tensor(0.4096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1875 D_fake_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1875 D_tricked_loss= tensor(1.8566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1876 D_real_loss= tensor(0.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1876 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1876 D_tricked_loss= tensor(1.8758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1877 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1877 D_fake_loss= tensor(0.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1877 D_tricked_loss= tensor(1.8020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1878 D_real_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1878 D_fake_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1878 D_tricked_loss= tensor(1.7470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1879 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1879 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1879 D_tricked_loss= tensor(1.8383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1880 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1880 D_fake_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1880 D_tricked_loss= tensor(1.9022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1881 D_real_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1881 D_fake_loss= tensor(0.4344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1881 D_tricked_loss= tensor(1.7362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1882 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1882 D_fake_loss= tensor(0.4153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1882 D_tricked_loss= tensor(1.7390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1883 D_real_loss= tensor(0.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1883 D_fake_loss= tensor(0.3972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1883 D_tricked_loss= tensor(1.7313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1884 D_real_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1884 D_fake_loss= tensor(0.4076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1884 D_tricked_loss= tensor(1.7735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1885 D_real_loss= tensor(0.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1885 D_fake_loss= tensor(0.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1885 D_tricked_loss= tensor(1.7721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1886 D_real_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1886 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1886 D_tricked_loss= tensor(1.7842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1887 D_real_loss= tensor(0.4444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1887 D_fake_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1887 D_tricked_loss= tensor(1.7165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1888 D_real_loss= tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1888 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1888 D_tricked_loss= tensor(1.7036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1889 D_real_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1889 D_fake_loss= tensor(0.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1889 D_tricked_loss= tensor(1.8673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1890 D_real_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1890 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1890 D_tricked_loss= tensor(1.7812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1891 D_real_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1891 D_fake_loss= tensor(0.3790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1891 D_tricked_loss= tensor(1.8185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1892 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1892 D_fake_loss= tensor(0.3905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1892 D_tricked_loss= tensor(1.7944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1893 D_real_loss= tensor(0.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1893 D_fake_loss= tensor(0.3844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1893 D_tricked_loss= tensor(1.7765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1894 D_real_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1894 D_fake_loss= tensor(0.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1894 D_tricked_loss= tensor(1.8746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1895 D_real_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1895 D_fake_loss= tensor(0.4094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1895 D_tricked_loss= tensor(1.8267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1896 D_real_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1896 D_fake_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1896 D_tricked_loss= tensor(1.8644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1897 D_real_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1897 D_fake_loss= tensor(0.4165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1897 D_tricked_loss= tensor(1.7876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1898 D_real_loss= tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1898 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1898 D_tricked_loss= tensor(1.7269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1899 D_real_loss= tensor(0.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1899 D_fake_loss= tensor(0.4386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1899 D_tricked_loss= tensor(1.7306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1900 D_real_loss= tensor(0.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1900 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1900 D_tricked_loss= tensor(1.7512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1901 D_real_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1901 D_fake_loss= tensor(0.4259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1901 D_tricked_loss= tensor(1.8156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1902 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1902 D_fake_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1902 D_tricked_loss= tensor(1.7821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1903 D_real_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1903 D_fake_loss= tensor(0.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1903 D_tricked_loss= tensor(1.7401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1904 D_real_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1904 D_fake_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1904 D_tricked_loss= tensor(1.7257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1905 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1905 D_fake_loss= tensor(0.3940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1905 D_tricked_loss= tensor(1.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1906 D_real_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1906 D_fake_loss= tensor(0.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1906 D_tricked_loss= tensor(1.7560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1907 D_real_loss= tensor(0.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1907 D_fake_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1907 D_tricked_loss= tensor(1.6723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1908 D_real_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1908 D_fake_loss= tensor(0.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1908 D_tricked_loss= tensor(1.7355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1909 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1909 D_fake_loss= tensor(0.4386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1909 D_tricked_loss= tensor(1.7155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1910 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1910 D_fake_loss= tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1910 D_tricked_loss= tensor(1.6663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1911 D_real_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1911 D_fake_loss= tensor(0.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1911 D_tricked_loss= tensor(1.7380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1912 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1912 D_fake_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1912 D_tricked_loss= tensor(1.6466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1913 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1913 D_fake_loss= tensor(0.4053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1913 D_tricked_loss= tensor(1.7024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1914 D_real_loss= tensor(0.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1914 D_fake_loss= tensor(0.4295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1914 D_tricked_loss= tensor(1.6899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1915 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1915 D_fake_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1915 D_tricked_loss= tensor(1.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1916 D_real_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1916 D_fake_loss= tensor(0.4225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1916 D_tricked_loss= tensor(1.6686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1917 D_real_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1917 D_fake_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1917 D_tricked_loss= tensor(1.6329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1918 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1918 D_fake_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1918 D_tricked_loss= tensor(1.6845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1919 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1919 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1919 D_tricked_loss= tensor(1.7385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1920 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1920 D_fake_loss= tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1920 D_tricked_loss= tensor(1.7112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1921 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1921 D_fake_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1921 D_tricked_loss= tensor(1.7171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1922 D_real_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1922 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1922 D_tricked_loss= tensor(1.7307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1923 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1923 D_fake_loss= tensor(0.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1923 D_tricked_loss= tensor(1.6254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1924 D_real_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1924 D_fake_loss= tensor(0.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1924 D_tricked_loss= tensor(1.7523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1925 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1925 D_fake_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1925 D_tricked_loss= tensor(1.6788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1926 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1926 D_fake_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1926 D_tricked_loss= tensor(1.7285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1927 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1927 D_fake_loss= tensor(0.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1927 D_tricked_loss= tensor(1.7454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1928 D_real_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1928 D_fake_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1928 D_tricked_loss= tensor(1.7547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1929 D_real_loss= tensor(0.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1929 D_fake_loss= tensor(0.4241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1929 D_tricked_loss= tensor(1.7292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1930 D_real_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1930 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1930 D_tricked_loss= tensor(1.6886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1931 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1931 D_fake_loss= tensor(0.4287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1931 D_tricked_loss= tensor(1.7161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1932 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1932 D_fake_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1932 D_tricked_loss= tensor(1.7340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1933 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1933 D_fake_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1933 D_tricked_loss= tensor(1.6922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1934 D_real_loss= tensor(0.4778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1934 D_fake_loss= tensor(0.4391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1934 D_tricked_loss= tensor(1.7317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1935 D_real_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1935 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1935 D_tricked_loss= tensor(1.6268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1936 D_real_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1936 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1936 D_tricked_loss= tensor(1.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1937 D_real_loss= tensor(0.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1937 D_fake_loss= tensor(0.4049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1937 D_tricked_loss= tensor(1.7121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1938 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1938 D_fake_loss= tensor(0.4172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1938 D_tricked_loss= tensor(1.6910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1939 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1939 D_fake_loss= tensor(0.4132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1939 D_tricked_loss= tensor(1.7495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1940 D_real_loss= tensor(0.4301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1940 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1940 D_tricked_loss= tensor(1.6644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1941 D_real_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1941 D_fake_loss= tensor(0.4045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1941 D_tricked_loss= tensor(1.7366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1942 D_real_loss= tensor(0.4205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1942 D_fake_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1942 D_tricked_loss= tensor(1.7229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1943 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1943 D_fake_loss= tensor(0.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1943 D_tricked_loss= tensor(1.8050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1944 D_real_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1944 D_fake_loss= tensor(0.4010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1944 D_tricked_loss= tensor(1.7450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1945 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1945 D_fake_loss= tensor(0.4262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1945 D_tricked_loss= tensor(1.7246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1946 D_real_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1946 D_fake_loss= tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1946 D_tricked_loss= tensor(1.7580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1947 D_real_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1947 D_fake_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1947 D_tricked_loss= tensor(1.7379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1948 D_real_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1948 D_fake_loss= tensor(0.4495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1948 D_tricked_loss= tensor(1.6773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1949 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1949 D_fake_loss= tensor(0.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1949 D_tricked_loss= tensor(1.7657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1950 D_real_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1950 D_fake_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1950 D_tricked_loss= tensor(1.7112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1951 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1951 D_fake_loss= tensor(0.4301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1951 D_tricked_loss= tensor(1.7560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1952 D_real_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1952 D_fake_loss= tensor(0.4418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1952 D_tricked_loss= tensor(1.7064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1953 D_real_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1953 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1953 D_tricked_loss= tensor(1.6867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1954 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1954 D_fake_loss= tensor(0.3929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1954 D_tricked_loss= tensor(1.7791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1955 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1955 D_fake_loss= tensor(0.4056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1955 D_tricked_loss= tensor(1.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1956 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1956 D_fake_loss= tensor(0.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1956 D_tricked_loss= tensor(1.7285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1957 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1957 D_fake_loss= tensor(0.3940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1957 D_tricked_loss= tensor(1.7626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1958 D_real_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1958 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1958 D_tricked_loss= tensor(1.7214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1959 D_real_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1959 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1959 D_tricked_loss= tensor(1.8667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1960 D_real_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1960 D_fake_loss= tensor(0.4036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1960 D_tricked_loss= tensor(1.7661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1961 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1961 D_fake_loss= tensor(0.4162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1961 D_tricked_loss= tensor(1.8509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1962 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1962 D_fake_loss= tensor(0.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1962 D_tricked_loss= tensor(1.8010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1963 D_real_loss= tensor(0.4312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1963 D_fake_loss= tensor(0.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1963 D_tricked_loss= tensor(1.8391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1964 D_real_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1964 D_fake_loss= tensor(0.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1964 D_tricked_loss= tensor(1.7434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1965 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1965 D_fake_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1965 D_tricked_loss= tensor(1.6806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1966 D_real_loss= tensor(0.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1966 D_fake_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1966 D_tricked_loss= tensor(1.7221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1967 D_real_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1967 D_fake_loss= tensor(0.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1967 D_tricked_loss= tensor(1.6695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1968 D_real_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1968 D_fake_loss= tensor(0.4536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1968 D_tricked_loss= tensor(1.7146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1969 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1969 D_fake_loss= tensor(0.4421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1969 D_tricked_loss= tensor(1.6818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1970 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1970 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1970 D_tricked_loss= tensor(1.7666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1971 D_real_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1971 D_fake_loss= tensor(0.4102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1971 D_tricked_loss= tensor(1.7319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1972 D_real_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1972 D_fake_loss= tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1972 D_tricked_loss= tensor(1.7745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1973 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1973 D_fake_loss= tensor(0.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1973 D_tricked_loss= tensor(1.7229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1974 D_real_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1974 D_fake_loss= tensor(0.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1974 D_tricked_loss= tensor(1.7577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1975 D_real_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1975 D_fake_loss= tensor(0.4079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1975 D_tricked_loss= tensor(1.7556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1976 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1976 D_fake_loss= tensor(0.4006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1976 D_tricked_loss= tensor(1.7226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1977 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1977 D_fake_loss= tensor(0.3860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1977 D_tricked_loss= tensor(1.7663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1978 D_real_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1978 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1978 D_tricked_loss= tensor(1.6872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1979 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1979 D_fake_loss= tensor(0.4122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1979 D_tricked_loss= tensor(1.6886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1980 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1980 D_fake_loss= tensor(0.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1980 D_tricked_loss= tensor(1.6586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1981 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1981 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1981 D_tricked_loss= tensor(1.6336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1982 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1982 D_fake_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1982 D_tricked_loss= tensor(1.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1983 D_real_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1983 D_fake_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1983 D_tricked_loss= tensor(1.7282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1984 D_real_loss= tensor(0.4455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1984 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1984 D_tricked_loss= tensor(1.6311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1985 D_real_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1985 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1985 D_tricked_loss= tensor(1.6357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1986 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1986 D_fake_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1986 D_tricked_loss= tensor(1.6436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1987 D_real_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1987 D_fake_loss= tensor(0.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1987 D_tricked_loss= tensor(1.6499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1988 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1988 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1988 D_tricked_loss= tensor(1.6109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1989 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1989 D_fake_loss= tensor(0.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1989 D_tricked_loss= tensor(1.7094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1990 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1990 D_fake_loss= tensor(0.4336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1990 D_tricked_loss= tensor(1.6705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1991 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1991 D_fake_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1991 D_tricked_loss= tensor(1.6525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1992 D_real_loss= tensor(0.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1992 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1992 D_tricked_loss= tensor(1.6735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1993 D_real_loss= tensor(0.4440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1993 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1993 D_tricked_loss= tensor(1.7387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1994 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1994 D_fake_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1994 D_tricked_loss= tensor(1.7841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1995 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1995 D_fake_loss= tensor(0.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1995 D_tricked_loss= tensor(1.7530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1996 D_real_loss= tensor(0.4134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1996 D_fake_loss= tensor(0.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1996 D_tricked_loss= tensor(1.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1997 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1997 D_fake_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1997 D_tricked_loss= tensor(1.7190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1998 D_real_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1998 D_fake_loss= tensor(0.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1998 D_tricked_loss= tensor(1.7691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "1999 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1999 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1999 D_tricked_loss= tensor(1.6558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2000 D_real_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2000 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2000 D_tricked_loss= tensor(1.6494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2001 D_real_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2001 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2001 D_tricked_loss= tensor(1.6369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2002 D_real_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2002 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2002 D_tricked_loss= tensor(1.6492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2003 D_real_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2003 D_fake_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2003 D_tricked_loss= tensor(1.6797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2004 D_real_loss= tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2004 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2004 D_tricked_loss= tensor(1.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2005 D_real_loss= tensor(0.4643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2005 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2005 D_tricked_loss= tensor(1.6805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2006 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2006 D_fake_loss= tensor(0.4124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2006 D_tricked_loss= tensor(1.6419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2007 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2007 D_fake_loss= tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2007 D_tricked_loss= tensor(1.7404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2008 D_real_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2008 D_fake_loss= tensor(0.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2008 D_tricked_loss= tensor(1.7153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2009 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2009 D_fake_loss= tensor(0.4165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2009 D_tricked_loss= tensor(1.7190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2010 D_real_loss= tensor(0.4837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2010 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2010 D_tricked_loss= tensor(1.7011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2011 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2011 D_fake_loss= tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2011 D_tricked_loss= tensor(1.7620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2012 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2012 D_fake_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2012 D_tricked_loss= tensor(1.6864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2013 D_real_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2013 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2013 D_tricked_loss= tensor(1.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2014 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2014 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2014 D_tricked_loss= tensor(1.7467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2015 D_real_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2015 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2015 D_tricked_loss= tensor(1.7475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2016 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2016 D_fake_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2016 D_tricked_loss= tensor(1.6371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2017 D_real_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2017 D_fake_loss= tensor(0.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2017 D_tricked_loss= tensor(1.6144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2018 D_real_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2018 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2018 D_tricked_loss= tensor(1.6546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2019 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2019 D_fake_loss= tensor(0.4233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2019 D_tricked_loss= tensor(1.6223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2020 D_real_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2020 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2020 D_tricked_loss= tensor(1.6357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2021 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2021 D_fake_loss= tensor(0.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2021 D_tricked_loss= tensor(1.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2022 D_real_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2022 D_fake_loss= tensor(0.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2022 D_tricked_loss= tensor(1.7178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2023 D_real_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2023 D_fake_loss= tensor(0.4035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2023 D_tricked_loss= tensor(1.6901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2024 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2024 D_fake_loss= tensor(0.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2024 D_tricked_loss= tensor(1.6825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2025 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2025 D_fake_loss= tensor(0.4444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2025 D_tricked_loss= tensor(1.6265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2026 D_real_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2026 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2026 D_tricked_loss= tensor(1.6344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2027 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2027 D_fake_loss= tensor(0.4413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2027 D_tricked_loss= tensor(1.6796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2028 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2028 D_fake_loss= tensor(0.4178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2028 D_tricked_loss= tensor(1.7215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2029 D_real_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2029 D_fake_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2029 D_tricked_loss= tensor(1.7201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2030 D_real_loss= tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2030 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2030 D_tricked_loss= tensor(1.7014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2031 D_real_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2031 D_fake_loss= tensor(0.4103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2031 D_tricked_loss= tensor(1.7353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2032 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2032 D_fake_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2032 D_tricked_loss= tensor(1.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2033 D_real_loss= tensor(0.4744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2033 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2033 D_tricked_loss= tensor(1.6120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2034 D_real_loss= tensor(0.4660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2034 D_fake_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2034 D_tricked_loss= tensor(1.7516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2035 D_real_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2035 D_fake_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2035 D_tricked_loss= tensor(1.7008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2036 D_real_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2036 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2036 D_tricked_loss= tensor(1.7057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2037 D_real_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2037 D_fake_loss= tensor(0.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2037 D_tricked_loss= tensor(1.7566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2038 D_real_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2038 D_fake_loss= tensor(0.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2038 D_tricked_loss= tensor(1.6707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2039 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2039 D_fake_loss= tensor(0.4044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2039 D_tricked_loss= tensor(1.7760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2040 D_real_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2040 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2040 D_tricked_loss= tensor(1.7489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2041 D_real_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2041 D_fake_loss= tensor(0.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2041 D_tricked_loss= tensor(1.7642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2042 D_real_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2042 D_fake_loss= tensor(0.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2042 D_tricked_loss= tensor(1.7152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2043 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2043 D_fake_loss= tensor(0.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2043 D_tricked_loss= tensor(1.6895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2044 D_real_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2044 D_fake_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2044 D_tricked_loss= tensor(1.7684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2045 D_real_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2045 D_fake_loss= tensor(0.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2045 D_tricked_loss= tensor(1.7351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2046 D_real_loss= tensor(0.4395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2046 D_fake_loss= tensor(0.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2046 D_tricked_loss= tensor(1.7472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2047 D_real_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2047 D_fake_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2047 D_tricked_loss= tensor(1.7483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2048 D_real_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2048 D_fake_loss= tensor(0.4408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2048 D_tricked_loss= tensor(1.6905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2049 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2049 D_fake_loss= tensor(0.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2049 D_tricked_loss= tensor(1.7230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2050 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2050 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2050 D_tricked_loss= tensor(1.7908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2051 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2051 D_fake_loss= tensor(0.4284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2051 D_tricked_loss= tensor(1.7295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2052 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2052 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2052 D_tricked_loss= tensor(1.7237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2053 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2053 D_fake_loss= tensor(0.4137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2053 D_tricked_loss= tensor(1.7078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2054 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2054 D_fake_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2054 D_tricked_loss= tensor(1.7871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2055 D_real_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2055 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2055 D_tricked_loss= tensor(1.7219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2056 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2056 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2056 D_tricked_loss= tensor(1.7001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2057 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2057 D_fake_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2057 D_tricked_loss= tensor(1.6643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2058 D_real_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2058 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2058 D_tricked_loss= tensor(1.6852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2059 D_real_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2059 D_fake_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2059 D_tricked_loss= tensor(1.7328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2060 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2060 D_fake_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2060 D_tricked_loss= tensor(1.6104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2061 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2061 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2061 D_tricked_loss= tensor(1.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2062 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2062 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2062 D_tricked_loss= tensor(1.6183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2063 D_real_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2063 D_fake_loss= tensor(0.4285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2063 D_tricked_loss= tensor(1.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2064 D_real_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2064 D_fake_loss= tensor(0.3906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2064 D_tricked_loss= tensor(1.7371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2065 D_real_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2065 D_fake_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2065 D_tricked_loss= tensor(1.7203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2066 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2066 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2066 D_tricked_loss= tensor(1.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2067 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2067 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2067 D_tricked_loss= tensor(1.6600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2068 D_real_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2068 D_fake_loss= tensor(0.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2068 D_tricked_loss= tensor(1.6430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2069 D_real_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2069 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2069 D_tricked_loss= tensor(1.6715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2070 D_real_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2070 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2070 D_tricked_loss= tensor(1.6558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2071 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2071 D_fake_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2071 D_tricked_loss= tensor(1.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2072 D_real_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2072 D_fake_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2072 D_tricked_loss= tensor(1.6653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2073 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2073 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2073 D_tricked_loss= tensor(1.5972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2074 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2074 D_fake_loss= tensor(0.3936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2074 D_tricked_loss= tensor(1.7091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2075 D_real_loss= tensor(0.4410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2075 D_fake_loss= tensor(0.4223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2075 D_tricked_loss= tensor(1.6633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2076 D_real_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2076 D_fake_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2076 D_tricked_loss= tensor(1.7225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2077 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2077 D_fake_loss= tensor(0.4104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2077 D_tricked_loss= tensor(1.6632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2078 D_real_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2078 D_fake_loss= tensor(0.4600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2078 D_tricked_loss= tensor(1.6196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2079 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2079 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2079 D_tricked_loss= tensor(1.6549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2080 D_real_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2080 D_fake_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2080 D_tricked_loss= tensor(1.7295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2081 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2081 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2081 D_tricked_loss= tensor(1.6811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2082 D_real_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2082 D_fake_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2082 D_tricked_loss= tensor(1.6899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2083 D_real_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2083 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2083 D_tricked_loss= tensor(1.6355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2084 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2084 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2084 D_tricked_loss= tensor(1.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2085 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2085 D_fake_loss= tensor(0.4079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2085 D_tricked_loss= tensor(1.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2086 D_real_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2086 D_fake_loss= tensor(0.4233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2086 D_tricked_loss= tensor(1.7400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2087 D_real_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2087 D_fake_loss= tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2087 D_tricked_loss= tensor(1.7158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2088 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2088 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2088 D_tricked_loss= tensor(1.7089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2089 D_real_loss= tensor(0.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2089 D_fake_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2089 D_tricked_loss= tensor(1.6124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2090 D_real_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2090 D_fake_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2090 D_tricked_loss= tensor(1.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2091 D_real_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2091 D_fake_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2091 D_tricked_loss= tensor(1.6543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2092 D_real_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2092 D_fake_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2092 D_tricked_loss= tensor(1.6482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2093 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2093 D_fake_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2093 D_tricked_loss= tensor(1.6469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2094 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2094 D_fake_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2094 D_tricked_loss= tensor(1.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2095 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2095 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2095 D_tricked_loss= tensor(1.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2096 D_real_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2096 D_fake_loss= tensor(0.4124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2096 D_tricked_loss= tensor(1.6184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2097 D_real_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2097 D_fake_loss= tensor(0.3842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2097 D_tricked_loss= tensor(1.5996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2098 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2098 D_fake_loss= tensor(0.4081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2098 D_tricked_loss= tensor(1.6734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2099 D_real_loss= tensor(0.4377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2099 D_fake_loss= tensor(0.3862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2099 D_tricked_loss= tensor(1.6855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2100 D_real_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2100 D_fake_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2100 D_tricked_loss= tensor(1.6171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2101 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2101 D_fake_loss= tensor(0.4210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2101 D_tricked_loss= tensor(1.6900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2102 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2102 D_fake_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2102 D_tricked_loss= tensor(1.7347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2103 D_real_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2103 D_fake_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2103 D_tricked_loss= tensor(1.6854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2104 D_real_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2104 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2104 D_tricked_loss= tensor(1.7198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2105 D_real_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2105 D_fake_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2105 D_tricked_loss= tensor(1.6310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2106 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2106 D_fake_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2106 D_tricked_loss= tensor(1.6270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2107 D_real_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2107 D_fake_loss= tensor(0.4577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2107 D_tricked_loss= tensor(1.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2108 D_real_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2108 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2108 D_tricked_loss= tensor(1.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2109 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2109 D_fake_loss= tensor(0.4167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2109 D_tricked_loss= tensor(1.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2110 D_real_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2110 D_fake_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2110 D_tricked_loss= tensor(1.6195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2111 D_real_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2111 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2111 D_tricked_loss= tensor(1.6152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2112 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2112 D_fake_loss= tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2112 D_tricked_loss= tensor(1.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2113 D_real_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2113 D_fake_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2113 D_tricked_loss= tensor(1.6708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2114 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2114 D_fake_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2114 D_tricked_loss= tensor(1.6756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2115 D_real_loss= tensor(0.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2115 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2115 D_tricked_loss= tensor(1.7171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2116 D_real_loss= tensor(0.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2116 D_fake_loss= tensor(0.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2116 D_tricked_loss= tensor(1.6370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2117 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2117 D_fake_loss= tensor(0.4225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2117 D_tricked_loss= tensor(1.6540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2118 D_real_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2118 D_fake_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2118 D_tricked_loss= tensor(1.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2119 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2119 D_fake_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2119 D_tricked_loss= tensor(1.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2120 D_real_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2120 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2120 D_tricked_loss= tensor(1.6325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2121 D_real_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2121 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2121 D_tricked_loss= tensor(1.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2122 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2122 D_fake_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2122 D_tricked_loss= tensor(1.6285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2123 D_real_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2123 D_fake_loss= tensor(0.4365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2123 D_tricked_loss= tensor(1.6850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2124 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2124 D_fake_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2124 D_tricked_loss= tensor(1.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2125 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2125 D_fake_loss= tensor(0.4077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2125 D_tricked_loss= tensor(1.6779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2126 D_real_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2126 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2126 D_tricked_loss= tensor(1.6294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2127 D_real_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2127 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2127 D_tricked_loss= tensor(1.6745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2128 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2128 D_fake_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2128 D_tricked_loss= tensor(1.6105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2129 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2129 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2129 D_tricked_loss= tensor(1.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2130 D_real_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2130 D_fake_loss= tensor(0.4344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2130 D_tricked_loss= tensor(1.6432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2131 D_real_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2131 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2131 D_tricked_loss= tensor(1.6608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2132 D_real_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2132 D_fake_loss= tensor(0.4062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2132 D_tricked_loss= tensor(1.7124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2133 D_real_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2133 D_fake_loss= tensor(0.4180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2133 D_tricked_loss= tensor(1.6691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2134 D_real_loss= tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2134 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2134 D_tricked_loss= tensor(1.6621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2135 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2135 D_fake_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2135 D_tricked_loss= tensor(1.6662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2136 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2136 D_fake_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2136 D_tricked_loss= tensor(1.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2137 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2137 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2137 D_tricked_loss= tensor(1.6140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2138 D_real_loss= tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2138 D_fake_loss= tensor(0.4517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2138 D_tricked_loss= tensor(1.6733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2139 D_real_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2139 D_fake_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2139 D_tricked_loss= tensor(1.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2140 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2140 D_fake_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2140 D_tricked_loss= tensor(1.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2141 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2141 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2141 D_tricked_loss= tensor(1.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2142 D_real_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2142 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2142 D_tricked_loss= tensor(1.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2143 D_real_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2143 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2143 D_tricked_loss= tensor(1.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2144 D_real_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2144 D_fake_loss= tensor(0.4333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2144 D_tricked_loss= tensor(1.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2145 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2145 D_fake_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2145 D_tricked_loss= tensor(1.6410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2146 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2146 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2146 D_tricked_loss= tensor(1.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2147 D_real_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2147 D_fake_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2147 D_tricked_loss= tensor(1.6074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2148 D_real_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2148 D_fake_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2148 D_tricked_loss= tensor(1.6197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2149 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2149 D_fake_loss= tensor(0.4518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2149 D_tricked_loss= tensor(1.6322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2150 D_real_loss= tensor(0.4927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2150 D_fake_loss= tensor(0.4173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2150 D_tricked_loss= tensor(1.7405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2151 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2151 D_fake_loss= tensor(0.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2151 D_tricked_loss= tensor(1.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2152 D_real_loss= tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2152 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2152 D_tricked_loss= tensor(1.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2153 D_real_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2153 D_fake_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2153 D_tricked_loss= tensor(1.6153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2154 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2154 D_fake_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2154 D_tricked_loss= tensor(1.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2155 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2155 D_fake_loss= tensor(0.4155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2155 D_tricked_loss= tensor(1.6512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2156 D_real_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2156 D_fake_loss= tensor(0.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2156 D_tricked_loss= tensor(1.5683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2157 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2157 D_fake_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2157 D_tricked_loss= tensor(1.6163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2158 D_real_loss= tensor(0.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2158 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2158 D_tricked_loss= tensor(1.6647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2159 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2159 D_fake_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2159 D_tricked_loss= tensor(1.6744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2160 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2160 D_fake_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2160 D_tricked_loss= tensor(1.6370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2161 D_real_loss= tensor(0.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2161 D_fake_loss= tensor(0.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2161 D_tricked_loss= tensor(1.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2162 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2162 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2162 D_tricked_loss= tensor(1.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2163 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2163 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2163 D_tricked_loss= tensor(1.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2164 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2164 D_fake_loss= tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2164 D_tricked_loss= tensor(1.6374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2165 D_real_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2165 D_fake_loss= tensor(0.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2165 D_tricked_loss= tensor(1.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2166 D_real_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2166 D_fake_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2166 D_tricked_loss= tensor(1.6539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2167 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2167 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2167 D_tricked_loss= tensor(1.6692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2168 D_real_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2168 D_fake_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2168 D_tricked_loss= tensor(1.6632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2169 D_real_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2169 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2169 D_tricked_loss= tensor(1.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2170 D_real_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2170 D_fake_loss= tensor(0.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2170 D_tricked_loss= tensor(1.7267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2171 D_real_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2171 D_fake_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2171 D_tricked_loss= tensor(1.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2172 D_real_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2172 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2172 D_tricked_loss= tensor(1.6493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2173 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2173 D_fake_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2173 D_tricked_loss= tensor(1.6341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2174 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2174 D_fake_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2174 D_tricked_loss= tensor(1.6066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2175 D_real_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2175 D_fake_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2175 D_tricked_loss= tensor(1.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2176 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2176 D_fake_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2176 D_tricked_loss= tensor(1.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2177 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2177 D_fake_loss= tensor(0.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2177 D_tricked_loss= tensor(1.6190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2178 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2178 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2178 D_tricked_loss= tensor(1.6466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2179 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2179 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2179 D_tricked_loss= tensor(1.6674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2180 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2180 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2180 D_tricked_loss= tensor(1.6225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2181 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2181 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2181 D_tricked_loss= tensor(1.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2182 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2182 D_fake_loss= tensor(0.4408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2182 D_tricked_loss= tensor(1.5994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2183 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2183 D_fake_loss= tensor(0.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2183 D_tricked_loss= tensor(1.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2184 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2184 D_fake_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2184 D_tricked_loss= tensor(1.6141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2185 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2185 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2185 D_tricked_loss= tensor(1.6545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2186 D_real_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2186 D_fake_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2186 D_tricked_loss= tensor(1.6043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2187 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2187 D_fake_loss= tensor(0.4643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2187 D_tricked_loss= tensor(1.6339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2188 D_real_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2188 D_fake_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2188 D_tricked_loss= tensor(1.6258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2189 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2189 D_fake_loss= tensor(0.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2189 D_tricked_loss= tensor(1.6455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2190 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2190 D_fake_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2190 D_tricked_loss= tensor(1.6190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2191 D_real_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2191 D_fake_loss= tensor(0.4018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2191 D_tricked_loss= tensor(1.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2192 D_real_loss= tensor(0.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2192 D_fake_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2192 D_tricked_loss= tensor(1.6230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2193 D_real_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2193 D_fake_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2193 D_tricked_loss= tensor(1.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2194 D_real_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2194 D_fake_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2194 D_tricked_loss= tensor(1.6149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2195 D_real_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2195 D_fake_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2195 D_tricked_loss= tensor(1.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2196 D_real_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2196 D_fake_loss= tensor(0.4527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2196 D_tricked_loss= tensor(1.6521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2197 D_real_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2197 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2197 D_tricked_loss= tensor(1.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2198 D_real_loss= tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2198 D_fake_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2198 D_tricked_loss= tensor(1.6387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2199 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2199 D_fake_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2199 D_tricked_loss= tensor(1.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2200 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2200 D_fake_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2200 D_tricked_loss= tensor(1.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2201 D_real_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2201 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2201 D_tricked_loss= tensor(1.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2202 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2202 D_fake_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2202 D_tricked_loss= tensor(1.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2203 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2203 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2203 D_tricked_loss= tensor(1.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2204 D_real_loss= tensor(0.4740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2204 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2204 D_tricked_loss= tensor(1.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2205 D_real_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2205 D_fake_loss= tensor(0.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2205 D_tricked_loss= tensor(1.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2206 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2206 D_fake_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2206 D_tricked_loss= tensor(1.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2207 D_real_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2207 D_fake_loss= tensor(0.4620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2207 D_tricked_loss= tensor(1.6079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2208 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2208 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2208 D_tricked_loss= tensor(1.6229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2209 D_real_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2209 D_fake_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2209 D_tricked_loss= tensor(1.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2210 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2210 D_fake_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2210 D_tricked_loss= tensor(1.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2211 D_real_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2211 D_fake_loss= tensor(0.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2211 D_tricked_loss= tensor(1.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2212 D_real_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2212 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2212 D_tricked_loss= tensor(1.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2213 D_real_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2213 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2213 D_tricked_loss= tensor(1.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2214 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2214 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2214 D_tricked_loss= tensor(1.5946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2215 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2215 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2215 D_tricked_loss= tensor(1.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2216 D_real_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2216 D_fake_loss= tensor(0.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2216 D_tricked_loss= tensor(1.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2217 D_real_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2217 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2217 D_tricked_loss= tensor(1.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2218 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2218 D_fake_loss= tensor(0.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2218 D_tricked_loss= tensor(1.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2219 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2219 D_fake_loss= tensor(0.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2219 D_tricked_loss= tensor(1.6888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2220 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2220 D_fake_loss= tensor(0.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2220 D_tricked_loss= tensor(1.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2221 D_real_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2221 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2221 D_tricked_loss= tensor(1.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2222 D_real_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2222 D_fake_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2222 D_tricked_loss= tensor(1.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2223 D_real_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2223 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2223 D_tricked_loss= tensor(1.6572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2224 D_real_loss= tensor(0.4344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2224 D_fake_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2224 D_tricked_loss= tensor(1.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2225 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2225 D_fake_loss= tensor(0.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2225 D_tricked_loss= tensor(1.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2226 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2226 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2226 D_tricked_loss= tensor(1.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2227 D_real_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2227 D_fake_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2227 D_tricked_loss= tensor(1.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2228 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2228 D_fake_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2228 D_tricked_loss= tensor(1.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2229 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2229 D_fake_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2229 D_tricked_loss= tensor(1.6263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2230 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2230 D_fake_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2230 D_tricked_loss= tensor(1.6523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2231 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2231 D_fake_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2231 D_tricked_loss= tensor(1.6718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2232 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2232 D_fake_loss= tensor(0.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2232 D_tricked_loss= tensor(1.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2233 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2233 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2233 D_tricked_loss= tensor(1.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2234 D_real_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2234 D_fake_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2234 D_tricked_loss= tensor(1.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2235 D_real_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2235 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2235 D_tricked_loss= tensor(1.6445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2236 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2236 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2236 D_tricked_loss= tensor(1.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2237 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2237 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2237 D_tricked_loss= tensor(1.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2238 D_real_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2238 D_fake_loss= tensor(0.4603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2238 D_tricked_loss= tensor(1.6205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2239 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2239 D_fake_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2239 D_tricked_loss= tensor(1.7241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2240 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2240 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2240 D_tricked_loss= tensor(1.6693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2241 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2241 D_fake_loss= tensor(0.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2241 D_tricked_loss= tensor(1.6930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2242 D_real_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2242 D_fake_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2242 D_tricked_loss= tensor(1.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2243 D_real_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2243 D_fake_loss= tensor(0.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2243 D_tricked_loss= tensor(1.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2244 D_real_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2244 D_fake_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2244 D_tricked_loss= tensor(1.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2245 D_real_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2245 D_fake_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2245 D_tricked_loss= tensor(1.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2246 D_real_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2246 D_fake_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2246 D_tricked_loss= tensor(1.7348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2247 D_real_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2247 D_fake_loss= tensor(0.4287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2247 D_tricked_loss= tensor(1.7375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2248 D_real_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2248 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2248 D_tricked_loss= tensor(1.6365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2249 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2249 D_fake_loss= tensor(0.4400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2249 D_tricked_loss= tensor(1.6698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2250 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2250 D_fake_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2250 D_tricked_loss= tensor(1.6387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2251 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2251 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2251 D_tricked_loss= tensor(1.6848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2252 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2252 D_fake_loss= tensor(0.4400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2252 D_tricked_loss= tensor(1.6598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2253 D_real_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2253 D_fake_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2253 D_tricked_loss= tensor(1.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2254 D_real_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2254 D_fake_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2254 D_tricked_loss= tensor(1.6118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2255 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2255 D_fake_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2255 D_tricked_loss= tensor(1.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2256 D_real_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2256 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2256 D_tricked_loss= tensor(1.6237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2257 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2257 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2257 D_tricked_loss= tensor(1.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2258 D_real_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2258 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2258 D_tricked_loss= tensor(1.6204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2259 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2259 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2259 D_tricked_loss= tensor(1.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2260 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2260 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2260 D_tricked_loss= tensor(1.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2261 D_real_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2261 D_fake_loss= tensor(0.4223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2261 D_tricked_loss= tensor(1.6913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2262 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2262 D_fake_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2262 D_tricked_loss= tensor(1.6301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2263 D_real_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2263 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2263 D_tricked_loss= tensor(1.6176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2264 D_real_loss= tensor(0.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2264 D_fake_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2264 D_tricked_loss= tensor(1.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2265 D_real_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2265 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2265 D_tricked_loss= tensor(1.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2266 D_real_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2266 D_fake_loss= tensor(0.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2266 D_tricked_loss= tensor(1.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2267 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2267 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2267 D_tricked_loss= tensor(1.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2268 D_real_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2268 D_fake_loss= tensor(0.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2268 D_tricked_loss= tensor(1.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2269 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2269 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2269 D_tricked_loss= tensor(1.6807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2270 D_real_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2270 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2270 D_tricked_loss= tensor(1.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2271 D_real_loss= tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2271 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2271 D_tricked_loss= tensor(1.6490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2272 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2272 D_fake_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2272 D_tricked_loss= tensor(1.6331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2273 D_real_loss= tensor(0.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2273 D_fake_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2273 D_tricked_loss= tensor(1.6162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2274 D_real_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2274 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2274 D_tricked_loss= tensor(1.6276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2275 D_real_loss= tensor(0.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2275 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2275 D_tricked_loss= tensor(1.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2276 D_real_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2276 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2276 D_tricked_loss= tensor(1.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2277 D_real_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2277 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2277 D_tricked_loss= tensor(1.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2278 D_real_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2278 D_fake_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2278 D_tricked_loss= tensor(1.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2279 D_real_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2279 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2279 D_tricked_loss= tensor(1.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2280 D_real_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2280 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2280 D_tricked_loss= tensor(1.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2281 D_real_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2281 D_fake_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2281 D_tricked_loss= tensor(1.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2282 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2282 D_fake_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2282 D_tricked_loss= tensor(1.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2283 D_real_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2283 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2283 D_tricked_loss= tensor(1.6092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2284 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2284 D_fake_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2284 D_tricked_loss= tensor(1.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2285 D_real_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2285 D_fake_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2285 D_tricked_loss= tensor(1.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2286 D_real_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2286 D_fake_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2286 D_tricked_loss= tensor(1.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2287 D_real_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2287 D_fake_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2287 D_tricked_loss= tensor(1.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2288 D_real_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2288 D_fake_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2288 D_tricked_loss= tensor(1.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2289 D_real_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2289 D_fake_loss= tensor(0.4425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2289 D_tricked_loss= tensor(1.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2290 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2290 D_fake_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2290 D_tricked_loss= tensor(1.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2291 D_real_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2291 D_fake_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2291 D_tricked_loss= tensor(1.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2292 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2292 D_fake_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2292 D_tricked_loss= tensor(1.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2293 D_real_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2293 D_fake_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2293 D_tricked_loss= tensor(1.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2294 D_real_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2294 D_fake_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2294 D_tricked_loss= tensor(1.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2295 D_real_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2295 D_fake_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2295 D_tricked_loss= tensor(1.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2296 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2296 D_fake_loss= tensor(0.4704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2296 D_tricked_loss= tensor(1.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2297 D_real_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2297 D_fake_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2297 D_tricked_loss= tensor(1.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2298 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2298 D_fake_loss= tensor(0.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2298 D_tricked_loss= tensor(1.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2299 D_real_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2299 D_fake_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2299 D_tricked_loss= tensor(1.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2300 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2300 D_fake_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2300 D_tricked_loss= tensor(1.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2301 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2301 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2301 D_tricked_loss= tensor(1.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2302 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2302 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2302 D_tricked_loss= tensor(1.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2303 D_real_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2303 D_fake_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2303 D_tricked_loss= tensor(1.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2304 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2304 D_fake_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2304 D_tricked_loss= tensor(1.6487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2305 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2305 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2305 D_tricked_loss= tensor(1.6299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2306 D_real_loss= tensor(0.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2306 D_fake_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2306 D_tricked_loss= tensor(1.6626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2307 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2307 D_fake_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2307 D_tricked_loss= tensor(1.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2308 D_real_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2308 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2308 D_tricked_loss= tensor(1.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2309 D_real_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2309 D_fake_loss= tensor(0.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2309 D_tricked_loss= tensor(1.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2310 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2310 D_fake_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2310 D_tricked_loss= tensor(1.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2311 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2311 D_fake_loss= tensor(0.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2311 D_tricked_loss= tensor(1.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2312 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2312 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2312 D_tricked_loss= tensor(1.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2313 D_real_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2313 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2313 D_tricked_loss= tensor(1.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2314 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2314 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2314 D_tricked_loss= tensor(1.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2315 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2315 D_fake_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2315 D_tricked_loss= tensor(1.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2316 D_real_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2316 D_fake_loss= tensor(0.4391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2316 D_tricked_loss= tensor(1.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2317 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2317 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2317 D_tricked_loss= tensor(1.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2318 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2318 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2318 D_tricked_loss= tensor(1.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2319 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2319 D_fake_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2319 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2320 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2320 D_fake_loss= tensor(0.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2320 D_tricked_loss= tensor(1.6166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2321 D_real_loss= tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2321 D_fake_loss= tensor(0.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2321 D_tricked_loss= tensor(1.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2322 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2322 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2322 D_tricked_loss= tensor(1.6244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2323 D_real_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2323 D_fake_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2323 D_tricked_loss= tensor(1.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2324 D_real_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2324 D_fake_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2324 D_tricked_loss= tensor(1.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2325 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2325 D_fake_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2325 D_tricked_loss= tensor(1.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2326 D_real_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2326 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2326 D_tricked_loss= tensor(1.6229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2327 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2327 D_fake_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2327 D_tricked_loss= tensor(1.6589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2328 D_real_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2328 D_fake_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2328 D_tricked_loss= tensor(1.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2329 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2329 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2329 D_tricked_loss= tensor(1.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2330 D_real_loss= tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2330 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2330 D_tricked_loss= tensor(1.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2331 D_real_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2331 D_fake_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2331 D_tricked_loss= tensor(1.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2332 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2332 D_fake_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2332 D_tricked_loss= tensor(1.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2333 D_real_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2333 D_fake_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2333 D_tricked_loss= tensor(1.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2334 D_real_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2334 D_fake_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2334 D_tricked_loss= tensor(1.6397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2335 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2335 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2335 D_tricked_loss= tensor(1.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2336 D_real_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2336 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2336 D_tricked_loss= tensor(1.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2337 D_real_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2337 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2337 D_tricked_loss= tensor(1.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2338 D_real_loss= tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2338 D_fake_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2338 D_tricked_loss= tensor(1.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2339 D_real_loss= tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2339 D_fake_loss= tensor(0.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2339 D_tricked_loss= tensor(1.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2340 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2340 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2340 D_tricked_loss= tensor(1.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2341 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2341 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2341 D_tricked_loss= tensor(1.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2342 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2342 D_fake_loss= tensor(0.4927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2342 D_tricked_loss= tensor(1.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2343 D_real_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2343 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2343 D_tricked_loss= tensor(1.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2344 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2344 D_fake_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2344 D_tricked_loss= tensor(1.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2345 D_real_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2345 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2345 D_tricked_loss= tensor(1.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2346 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2346 D_fake_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2346 D_tricked_loss= tensor(1.6222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2347 D_real_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2347 D_fake_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2347 D_tricked_loss= tensor(1.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2348 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2348 D_fake_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2348 D_tricked_loss= tensor(1.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2349 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2349 D_fake_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2349 D_tricked_loss= tensor(1.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2350 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2350 D_fake_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2350 D_tricked_loss= tensor(1.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2351 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2351 D_fake_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2351 D_tricked_loss= tensor(1.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2352 D_real_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2352 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2352 D_tricked_loss= tensor(1.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2353 D_real_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2353 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2353 D_tricked_loss= tensor(1.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2354 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2354 D_fake_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2354 D_tricked_loss= tensor(1.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2355 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2355 D_fake_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2355 D_tricked_loss= tensor(1.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2356 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2356 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2356 D_tricked_loss= tensor(1.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2357 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2357 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2357 D_tricked_loss= tensor(1.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2358 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2358 D_fake_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2358 D_tricked_loss= tensor(1.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2359 D_real_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2359 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2359 D_tricked_loss= tensor(1.6355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2360 D_real_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2360 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2360 D_tricked_loss= tensor(1.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2361 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2361 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2361 D_tricked_loss= tensor(1.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2362 D_real_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2362 D_fake_loss= tensor(0.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2362 D_tricked_loss= tensor(1.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2363 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2363 D_fake_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2363 D_tricked_loss= tensor(1.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2364 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2364 D_fake_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2364 D_tricked_loss= tensor(1.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2365 D_real_loss= tensor(0.5115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2365 D_fake_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2365 D_tricked_loss= tensor(1.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2366 D_real_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2366 D_fake_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2366 D_tricked_loss= tensor(1.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2367 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2367 D_fake_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2367 D_tricked_loss= tensor(1.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2368 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2368 D_fake_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2368 D_tricked_loss= tensor(1.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2369 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2369 D_fake_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2369 D_tricked_loss= tensor(1.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2370 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2370 D_fake_loss= tensor(0.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2370 D_tricked_loss= tensor(1.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2371 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2371 D_fake_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2371 D_tricked_loss= tensor(1.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2372 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2372 D_fake_loss= tensor(0.4903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2372 D_tricked_loss= tensor(1.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2373 D_real_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2373 D_fake_loss= tensor(0.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2373 D_tricked_loss= tensor(1.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2374 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2374 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2374 D_tricked_loss= tensor(1.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2375 D_real_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2375 D_fake_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2375 D_tricked_loss= tensor(1.6205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2376 D_real_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2376 D_fake_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2376 D_tricked_loss= tensor(1.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2377 D_real_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2377 D_fake_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2377 D_tricked_loss= tensor(1.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2378 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2378 D_fake_loss= tensor(0.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2378 D_tricked_loss= tensor(1.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2379 D_real_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2379 D_fake_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2379 D_tricked_loss= tensor(1.6235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2380 D_real_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2380 D_fake_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2380 D_tricked_loss= tensor(1.7093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2381 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2381 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2381 D_tricked_loss= tensor(1.6522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2382 D_real_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2382 D_fake_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2382 D_tricked_loss= tensor(1.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2383 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2383 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2383 D_tricked_loss= tensor(1.5957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2384 D_real_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2384 D_fake_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2384 D_tricked_loss= tensor(1.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2385 D_real_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2385 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2385 D_tricked_loss= tensor(1.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2386 D_real_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2386 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2386 D_tricked_loss= tensor(1.6130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2387 D_real_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2387 D_fake_loss= tensor(0.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2387 D_tricked_loss= tensor(1.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2388 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2388 D_fake_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2388 D_tricked_loss= tensor(1.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2389 D_real_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2389 D_fake_loss= tensor(0.4747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2389 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2390 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2390 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2390 D_tricked_loss= tensor(1.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2391 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2391 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2391 D_tricked_loss= tensor(1.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2392 D_real_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2392 D_fake_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2392 D_tricked_loss= tensor(1.6276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2393 D_real_loss= tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2393 D_fake_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2393 D_tricked_loss= tensor(1.6022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2394 D_real_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2394 D_fake_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2394 D_tricked_loss= tensor(1.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2395 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2395 D_fake_loss= tensor(0.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2395 D_tricked_loss= tensor(1.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2396 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2396 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2396 D_tricked_loss= tensor(1.6356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2397 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2397 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2397 D_tricked_loss= tensor(1.7066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2398 D_real_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2398 D_fake_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2398 D_tricked_loss= tensor(1.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2399 D_real_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2399 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2399 D_tricked_loss= tensor(1.6697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2400 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2400 D_fake_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2400 D_tricked_loss= tensor(1.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2401 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2401 D_fake_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2401 D_tricked_loss= tensor(1.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2402 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2402 D_fake_loss= tensor(0.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2402 D_tricked_loss= tensor(1.6352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2403 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2403 D_fake_loss= tensor(0.4135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2403 D_tricked_loss= tensor(1.6235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2404 D_real_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2404 D_fake_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2404 D_tricked_loss= tensor(1.6546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2405 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2405 D_fake_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2405 D_tricked_loss= tensor(1.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2406 D_real_loss= tensor(0.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2406 D_fake_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2406 D_tricked_loss= tensor(1.7465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2407 D_real_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2407 D_fake_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2407 D_tricked_loss= tensor(1.6324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2408 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2408 D_fake_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2408 D_tricked_loss= tensor(1.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2409 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2409 D_fake_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2409 D_tricked_loss= tensor(1.6439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2410 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2410 D_fake_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2410 D_tricked_loss= tensor(1.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2411 D_real_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2411 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2411 D_tricked_loss= tensor(1.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2412 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2412 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2412 D_tricked_loss= tensor(1.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2413 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2413 D_fake_loss= tensor(0.4222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2413 D_tricked_loss= tensor(1.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2414 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2414 D_fake_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2414 D_tricked_loss= tensor(1.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2415 D_real_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2415 D_fake_loss= tensor(0.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2415 D_tricked_loss= tensor(1.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2416 D_real_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2416 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2416 D_tricked_loss= tensor(1.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2417 D_real_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2417 D_fake_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2417 D_tricked_loss= tensor(1.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2418 D_real_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2418 D_fake_loss= tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2418 D_tricked_loss= tensor(1.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2419 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2419 D_fake_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2419 D_tricked_loss= tensor(1.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2420 D_real_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2420 D_fake_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2420 D_tricked_loss= tensor(1.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2421 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2421 D_fake_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2421 D_tricked_loss= tensor(1.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2422 D_real_loss= tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2422 D_fake_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2422 D_tricked_loss= tensor(1.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2423 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2423 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2423 D_tricked_loss= tensor(1.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2424 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2424 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2424 D_tricked_loss= tensor(1.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2425 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2425 D_fake_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2425 D_tricked_loss= tensor(1.5983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2426 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2426 D_fake_loss= tensor(0.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2426 D_tricked_loss= tensor(1.6094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2427 D_real_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2427 D_fake_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2427 D_tricked_loss= tensor(1.6853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2428 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2428 D_fake_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2428 D_tricked_loss= tensor(1.6595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2429 D_real_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2429 D_fake_loss= tensor(0.3923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2429 D_tricked_loss= tensor(1.6470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2430 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2430 D_fake_loss= tensor(0.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2430 D_tricked_loss= tensor(1.6797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2431 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2431 D_fake_loss= tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2431 D_tricked_loss= tensor(1.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2432 D_real_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2432 D_fake_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2432 D_tricked_loss= tensor(1.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2433 D_real_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2433 D_fake_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2433 D_tricked_loss= tensor(1.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2434 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2434 D_fake_loss= tensor(0.4377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2434 D_tricked_loss= tensor(1.6208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2435 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2435 D_fake_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2435 D_tricked_loss= tensor(1.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2436 D_real_loss= tensor(0.5372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2436 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2436 D_tricked_loss= tensor(1.6057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2437 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2437 D_fake_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2437 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2438 D_real_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2438 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2438 D_tricked_loss= tensor(1.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2439 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2439 D_fake_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2439 D_tricked_loss= tensor(1.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2440 D_real_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2440 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2440 D_tricked_loss= tensor(1.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2441 D_real_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2441 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2441 D_tricked_loss= tensor(1.7081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2442 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2442 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2442 D_tricked_loss= tensor(1.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2443 D_real_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2443 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2443 D_tricked_loss= tensor(1.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2444 D_real_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2444 D_fake_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2444 D_tricked_loss= tensor(1.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2445 D_real_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2445 D_fake_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2445 D_tricked_loss= tensor(1.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2446 D_real_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2446 D_fake_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2446 D_tricked_loss= tensor(1.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2447 D_real_loss= tensor(0.4949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2447 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2447 D_tricked_loss= tensor(1.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2448 D_real_loss= tensor(0.5073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2448 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2448 D_tricked_loss= tensor(1.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2449 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2449 D_fake_loss= tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2449 D_tricked_loss= tensor(1.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2450 D_real_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2450 D_fake_loss= tensor(0.4180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2450 D_tricked_loss= tensor(1.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2451 D_real_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2451 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2451 D_tricked_loss= tensor(1.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2452 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2452 D_fake_loss= tensor(0.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2452 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2453 D_real_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2453 D_fake_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2453 D_tricked_loss= tensor(1.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2454 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2454 D_fake_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2454 D_tricked_loss= tensor(1.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2455 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2455 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2455 D_tricked_loss= tensor(1.6296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2456 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2456 D_fake_loss= tensor(0.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2456 D_tricked_loss= tensor(1.6578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2457 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2457 D_fake_loss= tensor(0.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2457 D_tricked_loss= tensor(1.6144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2458 D_real_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2458 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2458 D_tricked_loss= tensor(1.6114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2459 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2459 D_fake_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2459 D_tricked_loss= tensor(1.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2460 D_real_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2460 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2460 D_tricked_loss= tensor(1.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2461 D_real_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2461 D_fake_loss= tensor(0.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2461 D_tricked_loss= tensor(1.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2462 D_real_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2462 D_fake_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2462 D_tricked_loss= tensor(1.5988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2463 D_real_loss= tensor(0.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2463 D_fake_loss= tensor(0.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2463 D_tricked_loss= tensor(1.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2464 D_real_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2464 D_fake_loss= tensor(0.4410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2464 D_tricked_loss= tensor(1.6070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2465 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2465 D_fake_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2465 D_tricked_loss= tensor(1.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2466 D_real_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2466 D_fake_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2466 D_tricked_loss= tensor(1.6139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2467 D_real_loss= tensor(0.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2467 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2467 D_tricked_loss= tensor(1.6194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2468 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2468 D_fake_loss= tensor(0.4704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2468 D_tricked_loss= tensor(1.6268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2469 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2469 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2469 D_tricked_loss= tensor(1.6559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2470 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2470 D_fake_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2470 D_tricked_loss= tensor(1.6518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2471 D_real_loss= tensor(0.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2471 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2471 D_tricked_loss= tensor(1.6058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2472 D_real_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2472 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2472 D_tricked_loss= tensor(1.6286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2473 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2473 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2473 D_tricked_loss= tensor(1.6392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2474 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2474 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2474 D_tricked_loss= tensor(1.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2475 D_real_loss= tensor(0.4604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2475 D_fake_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2475 D_tricked_loss= tensor(1.5225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2476 D_real_loss= tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2476 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2476 D_tricked_loss= tensor(1.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2477 D_real_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2477 D_fake_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2477 D_tricked_loss= tensor(1.6171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2478 D_real_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2478 D_fake_loss= tensor(0.4525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2478 D_tricked_loss= tensor(1.6323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2479 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2479 D_fake_loss= tensor(0.4418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2479 D_tricked_loss= tensor(1.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2480 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2480 D_fake_loss= tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2480 D_tricked_loss= tensor(1.6182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2481 D_real_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2481 D_fake_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2481 D_tricked_loss= tensor(1.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2482 D_real_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2482 D_fake_loss= tensor(0.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2482 D_tricked_loss= tensor(1.6428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2483 D_real_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2483 D_fake_loss= tensor(0.4660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2483 D_tricked_loss= tensor(1.6635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2484 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2484 D_fake_loss= tensor(0.4344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2484 D_tricked_loss= tensor(1.6470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2485 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2485 D_fake_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2485 D_tricked_loss= tensor(1.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2486 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2486 D_fake_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2486 D_tricked_loss= tensor(1.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2487 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2487 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2487 D_tricked_loss= tensor(1.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2488 D_real_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2488 D_fake_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2488 D_tricked_loss= tensor(1.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2489 D_real_loss= tensor(0.5075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2489 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2489 D_tricked_loss= tensor(1.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2490 D_real_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2490 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2490 D_tricked_loss= tensor(1.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2491 D_real_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2491 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2491 D_tricked_loss= tensor(1.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2492 D_real_loss= tensor(0.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2492 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2492 D_tricked_loss= tensor(1.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2493 D_real_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2493 D_fake_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2493 D_tricked_loss= tensor(1.6215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2494 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2494 D_fake_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2494 D_tricked_loss= tensor(1.6366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2495 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2495 D_fake_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2495 D_tricked_loss= tensor(1.6165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2496 D_real_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2496 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2496 D_tricked_loss= tensor(1.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2497 D_real_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2497 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2497 D_tricked_loss= tensor(1.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2498 D_real_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2498 D_fake_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2498 D_tricked_loss= tensor(1.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2499 D_real_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2499 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2499 D_tricked_loss= tensor(1.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2500 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2500 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2500 D_tricked_loss= tensor(1.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2501 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2501 D_fake_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2501 D_tricked_loss= tensor(1.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2502 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2502 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2502 D_tricked_loss= tensor(1.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2503 D_real_loss= tensor(0.4730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2503 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2503 D_tricked_loss= tensor(1.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2504 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2504 D_fake_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2504 D_tricked_loss= tensor(1.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2505 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2505 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2505 D_tricked_loss= tensor(1.6433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2506 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2506 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2506 D_tricked_loss= tensor(1.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2507 D_real_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2507 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2507 D_tricked_loss= tensor(1.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2508 D_real_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2508 D_fake_loss= tensor(0.4072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2508 D_tricked_loss= tensor(1.6307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2509 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2509 D_fake_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2509 D_tricked_loss= tensor(1.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2510 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2510 D_fake_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2510 D_tricked_loss= tensor(1.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2511 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2511 D_fake_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2511 D_tricked_loss= tensor(1.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2512 D_real_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2512 D_fake_loss= tensor(0.4241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2512 D_tricked_loss= tensor(1.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2513 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2513 D_fake_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2513 D_tricked_loss= tensor(1.6462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2514 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2514 D_fake_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2514 D_tricked_loss= tensor(1.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2515 D_real_loss= tensor(0.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2515 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2515 D_tricked_loss= tensor(1.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2516 D_real_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2516 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2516 D_tricked_loss= tensor(1.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2517 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2517 D_fake_loss= tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2517 D_tricked_loss= tensor(1.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2518 D_real_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2518 D_fake_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2518 D_tricked_loss= tensor(1.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2519 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2519 D_fake_loss= tensor(0.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2519 D_tricked_loss= tensor(1.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2520 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2520 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2520 D_tricked_loss= tensor(1.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2521 D_real_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2521 D_fake_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2521 D_tricked_loss= tensor(1.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2522 D_real_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2522 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2522 D_tricked_loss= tensor(1.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2523 D_real_loss= tensor(0.5228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2523 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2523 D_tricked_loss= tensor(1.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2524 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2524 D_fake_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2524 D_tricked_loss= tensor(1.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2525 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2525 D_fake_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2525 D_tricked_loss= tensor(1.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2526 D_real_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2526 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2526 D_tricked_loss= tensor(1.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2527 D_real_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2527 D_fake_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2527 D_tricked_loss= tensor(1.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2528 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2528 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2528 D_tricked_loss= tensor(1.6083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2529 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2529 D_fake_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2529 D_tricked_loss= tensor(1.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2530 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2530 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2530 D_tricked_loss= tensor(1.6253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2531 D_real_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2531 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2531 D_tricked_loss= tensor(1.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2532 D_real_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2532 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2532 D_tricked_loss= tensor(1.5070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2533 D_real_loss= tensor(0.4968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2533 D_fake_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2533 D_tricked_loss= tensor(1.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2534 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2534 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2534 D_tricked_loss= tensor(1.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2535 D_real_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2535 D_fake_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2535 D_tricked_loss= tensor(1.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2536 D_real_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2536 D_fake_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2536 D_tricked_loss= tensor(1.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2537 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2537 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2537 D_tricked_loss= tensor(1.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2538 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2538 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2538 D_tricked_loss= tensor(1.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2539 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2539 D_fake_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2539 D_tricked_loss= tensor(1.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2540 D_real_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2540 D_fake_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2540 D_tricked_loss= tensor(1.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2541 D_real_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2541 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2541 D_tricked_loss= tensor(1.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2542 D_real_loss= tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2542 D_fake_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2542 D_tricked_loss= tensor(1.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2543 D_real_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2543 D_fake_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2543 D_tricked_loss= tensor(1.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2544 D_real_loss= tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2544 D_fake_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2544 D_tricked_loss= tensor(1.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2545 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2545 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2545 D_tricked_loss= tensor(1.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2546 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2546 D_fake_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2546 D_tricked_loss= tensor(1.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2547 D_real_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2547 D_fake_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2547 D_tricked_loss= tensor(1.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2548 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2548 D_fake_loss= tensor(0.4263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2548 D_tricked_loss= tensor(1.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2549 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2549 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2549 D_tricked_loss= tensor(1.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2550 D_real_loss= tensor(0.4577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2550 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2550 D_tricked_loss= tensor(1.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2551 D_real_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2551 D_fake_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2551 D_tricked_loss= tensor(1.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2552 D_real_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2552 D_fake_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2552 D_tricked_loss= tensor(1.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2553 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2553 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2553 D_tricked_loss= tensor(1.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2554 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2554 D_fake_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2554 D_tricked_loss= tensor(1.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2555 D_real_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2555 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2555 D_tricked_loss= tensor(1.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2556 D_real_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2556 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2556 D_tricked_loss= tensor(1.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2557 D_real_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2557 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2557 D_tricked_loss= tensor(1.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2558 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2558 D_fake_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2558 D_tricked_loss= tensor(1.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2559 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2559 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2559 D_tricked_loss= tensor(1.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2560 D_real_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2560 D_fake_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2560 D_tricked_loss= tensor(1.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2561 D_real_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2561 D_fake_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2561 D_tricked_loss= tensor(1.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2562 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2562 D_fake_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2562 D_tricked_loss= tensor(1.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2563 D_real_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2563 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2563 D_tricked_loss= tensor(1.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2564 D_real_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2564 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2564 D_tricked_loss= tensor(1.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2565 D_real_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2565 D_fake_loss= tensor(0.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2565 D_tricked_loss= tensor(1.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2566 D_real_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2566 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2566 D_tricked_loss= tensor(1.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2567 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2567 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2567 D_tricked_loss= tensor(1.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2568 D_real_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2568 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2568 D_tricked_loss= tensor(1.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2569 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2569 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2569 D_tricked_loss= tensor(1.5327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2570 D_real_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2570 D_fake_loss= tensor(0.4016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2570 D_tricked_loss= tensor(1.6161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2571 D_real_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2571 D_fake_loss= tensor(0.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2571 D_tricked_loss= tensor(1.6605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2572 D_real_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2572 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2572 D_tricked_loss= tensor(1.6502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2573 D_real_loss= tensor(0.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2573 D_fake_loss= tensor(0.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2573 D_tricked_loss= tensor(1.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2574 D_real_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2574 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2574 D_tricked_loss= tensor(1.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2575 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2575 D_fake_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2575 D_tricked_loss= tensor(1.6225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2576 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2576 D_fake_loss= tensor(0.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2576 D_tricked_loss= tensor(1.6181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2577 D_real_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2577 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2577 D_tricked_loss= tensor(1.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2578 D_real_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2578 D_fake_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2578 D_tricked_loss= tensor(1.5214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2579 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2579 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2579 D_tricked_loss= tensor(1.4222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2580 D_real_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2580 D_fake_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2580 D_tricked_loss= tensor(1.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2581 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2581 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2581 D_tricked_loss= tensor(1.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2582 D_real_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2582 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2582 D_tricked_loss= tensor(1.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2583 D_real_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2583 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2583 D_tricked_loss= tensor(1.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2584 D_real_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2584 D_fake_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2584 D_tricked_loss= tensor(1.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2585 D_real_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2585 D_fake_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2585 D_tricked_loss= tensor(1.4118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2586 D_real_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2586 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2586 D_tricked_loss= tensor(1.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2587 D_real_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2587 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2587 D_tricked_loss= tensor(1.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2588 D_real_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2588 D_fake_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2588 D_tricked_loss= tensor(1.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2589 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2589 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2589 D_tricked_loss= tensor(1.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2590 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2590 D_fake_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2590 D_tricked_loss= tensor(1.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2591 D_real_loss= tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2591 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2591 D_tricked_loss= tensor(1.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2592 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2592 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2592 D_tricked_loss= tensor(1.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2593 D_real_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2593 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2593 D_tricked_loss= tensor(1.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2594 D_real_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2594 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2594 D_tricked_loss= tensor(1.5228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2595 D_real_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2595 D_fake_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2595 D_tricked_loss= tensor(1.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2596 D_real_loss= tensor(0.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2596 D_fake_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2596 D_tricked_loss= tensor(1.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2597 D_real_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2597 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2597 D_tricked_loss= tensor(1.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2598 D_real_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2598 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2598 D_tricked_loss= tensor(1.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2599 D_real_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2599 D_fake_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2599 D_tricked_loss= tensor(1.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2600 D_real_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2600 D_fake_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2600 D_tricked_loss= tensor(1.4660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2601 D_real_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2601 D_fake_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2601 D_tricked_loss= tensor(1.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2602 D_real_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2602 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2602 D_tricked_loss= tensor(1.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2603 D_real_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2603 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2603 D_tricked_loss= tensor(1.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2604 D_real_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2604 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2604 D_tricked_loss= tensor(1.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2605 D_real_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2605 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2605 D_tricked_loss= tensor(1.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2606 D_real_loss= tensor(0.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2606 D_fake_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2606 D_tricked_loss= tensor(1.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2607 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2607 D_fake_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2607 D_tricked_loss= tensor(1.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2608 D_real_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2608 D_fake_loss= tensor(0.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2608 D_tricked_loss= tensor(1.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2609 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2609 D_fake_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2609 D_tricked_loss= tensor(1.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2610 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2610 D_fake_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2610 D_tricked_loss= tensor(1.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2611 D_real_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2611 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2611 D_tricked_loss= tensor(1.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2612 D_real_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2612 D_fake_loss= tensor(0.4603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2612 D_tricked_loss= tensor(1.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2613 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2613 D_fake_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2613 D_tricked_loss= tensor(1.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2614 D_real_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2614 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2614 D_tricked_loss= tensor(1.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2615 D_real_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2615 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2615 D_tricked_loss= tensor(1.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2616 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2616 D_fake_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2616 D_tricked_loss= tensor(1.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2617 D_real_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2617 D_fake_loss= tensor(0.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2617 D_tricked_loss= tensor(1.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2618 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2618 D_fake_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2618 D_tricked_loss= tensor(1.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2619 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2619 D_fake_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2619 D_tricked_loss= tensor(1.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2620 D_real_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2620 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2620 D_tricked_loss= tensor(1.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2621 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2621 D_fake_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2621 D_tricked_loss= tensor(1.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2622 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2622 D_fake_loss= tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2622 D_tricked_loss= tensor(1.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2623 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2623 D_fake_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2623 D_tricked_loss= tensor(1.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2624 D_real_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2624 D_fake_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2624 D_tricked_loss= tensor(1.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2625 D_real_loss= tensor(0.4604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2625 D_fake_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2625 D_tricked_loss= tensor(1.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2626 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2626 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2626 D_tricked_loss= tensor(1.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2627 D_real_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2627 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2627 D_tricked_loss= tensor(1.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2628 D_real_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2628 D_fake_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2628 D_tricked_loss= tensor(1.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2629 D_real_loss= tensor(0.4744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2629 D_fake_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2629 D_tricked_loss= tensor(1.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2630 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2630 D_fake_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2630 D_tricked_loss= tensor(1.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2631 D_real_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2631 D_fake_loss= tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2631 D_tricked_loss= tensor(1.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2632 D_real_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2632 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2632 D_tricked_loss= tensor(1.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2633 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2633 D_fake_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2633 D_tricked_loss= tensor(1.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2634 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2634 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2634 D_tricked_loss= tensor(1.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2635 D_real_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2635 D_fake_loss= tensor(0.4648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2635 D_tricked_loss= tensor(1.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2636 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2636 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2636 D_tricked_loss= tensor(1.5966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2637 D_real_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2637 D_fake_loss= tensor(0.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2637 D_tricked_loss= tensor(1.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2638 D_real_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2638 D_fake_loss= tensor(0.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2638 D_tricked_loss= tensor(1.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2639 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2639 D_fake_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2639 D_tricked_loss= tensor(1.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2640 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2640 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2640 D_tricked_loss= tensor(1.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2641 D_real_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2641 D_fake_loss= tensor(0.4517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2641 D_tricked_loss= tensor(1.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2642 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2642 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2642 D_tricked_loss= tensor(1.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2643 D_real_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2643 D_fake_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2643 D_tricked_loss= tensor(1.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2644 D_real_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2644 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2644 D_tricked_loss= tensor(1.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2645 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2645 D_fake_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2645 D_tricked_loss= tensor(1.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2646 D_real_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2646 D_fake_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2646 D_tricked_loss= tensor(1.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2647 D_real_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2647 D_fake_loss= tensor(0.4517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2647 D_tricked_loss= tensor(1.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2648 D_real_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2648 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2648 D_tricked_loss= tensor(1.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2649 D_real_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2649 D_fake_loss= tensor(0.4299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2649 D_tricked_loss= tensor(1.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2650 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2650 D_fake_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2650 D_tricked_loss= tensor(1.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2651 D_real_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2651 D_fake_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2651 D_tricked_loss= tensor(1.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2652 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2652 D_fake_loss= tensor(0.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2652 D_tricked_loss= tensor(1.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2653 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2653 D_fake_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2653 D_tricked_loss= tensor(1.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2654 D_real_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2654 D_fake_loss= tensor(0.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2654 D_tricked_loss= tensor(1.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2655 D_real_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2655 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2655 D_tricked_loss= tensor(1.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2656 D_real_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2656 D_fake_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2656 D_tricked_loss= tensor(1.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2657 D_real_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2657 D_fake_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2657 D_tricked_loss= tensor(1.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2658 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2658 D_fake_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2658 D_tricked_loss= tensor(1.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2659 D_real_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2659 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2659 D_tricked_loss= tensor(1.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2660 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2660 D_fake_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2660 D_tricked_loss= tensor(1.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2661 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2661 D_fake_loss= tensor(0.4455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2661 D_tricked_loss= tensor(1.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2662 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2662 D_fake_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2662 D_tricked_loss= tensor(1.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2663 D_real_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2663 D_fake_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2663 D_tricked_loss= tensor(1.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2664 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2664 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2664 D_tricked_loss= tensor(1.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2665 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2665 D_fake_loss= tensor(0.4704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2665 D_tricked_loss= tensor(1.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2666 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2666 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2666 D_tricked_loss= tensor(1.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2667 D_real_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2667 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2667 D_tricked_loss= tensor(1.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2668 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2668 D_fake_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2668 D_tricked_loss= tensor(1.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2669 D_real_loss= tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2669 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2669 D_tricked_loss= tensor(1.4482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2670 D_real_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2670 D_fake_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2670 D_tricked_loss= tensor(1.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2671 D_real_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2671 D_fake_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2671 D_tricked_loss= tensor(1.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2672 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2672 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2672 D_tricked_loss= tensor(1.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2673 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2673 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2673 D_tricked_loss= tensor(1.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2674 D_real_loss= tensor(0.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2674 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2674 D_tricked_loss= tensor(1.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2675 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2675 D_fake_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2675 D_tricked_loss= tensor(1.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2676 D_real_loss= tensor(0.5103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2676 D_fake_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2676 D_tricked_loss= tensor(1.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2677 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2677 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2677 D_tricked_loss= tensor(1.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2678 D_real_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2678 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2678 D_tricked_loss= tensor(1.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2679 D_real_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2679 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2679 D_tricked_loss= tensor(1.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2680 D_real_loss= tensor(0.5075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2680 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2680 D_tricked_loss= tensor(1.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2681 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2681 D_fake_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2681 D_tricked_loss= tensor(1.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2682 D_real_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2682 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2682 D_tricked_loss= tensor(1.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2683 D_real_loss= tensor(0.5214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2683 D_fake_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2683 D_tricked_loss= tensor(1.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2684 D_real_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2684 D_fake_loss= tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2684 D_tricked_loss= tensor(1.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2685 D_real_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2685 D_fake_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2685 D_tricked_loss= tensor(1.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2686 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2686 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2686 D_tricked_loss= tensor(1.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2687 D_real_loss= tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2687 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2687 D_tricked_loss= tensor(1.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2688 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2688 D_fake_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2688 D_tricked_loss= tensor(1.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2689 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2689 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2689 D_tricked_loss= tensor(1.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2690 D_real_loss= tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2690 D_fake_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2690 D_tricked_loss= tensor(1.4029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2691 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2691 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2691 D_tricked_loss= tensor(1.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2692 D_real_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2692 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2692 D_tricked_loss= tensor(1.4413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2693 D_real_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2693 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2693 D_tricked_loss= tensor(1.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2694 D_real_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2694 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2694 D_tricked_loss= tensor(1.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2695 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2695 D_fake_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2695 D_tricked_loss= tensor(1.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2696 D_real_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2696 D_fake_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2696 D_tricked_loss= tensor(1.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2697 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2697 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2697 D_tricked_loss= tensor(1.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2698 D_real_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2698 D_fake_loss= tensor(0.4730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2698 D_tricked_loss= tensor(1.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2699 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2699 D_fake_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2699 D_tricked_loss= tensor(1.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2700 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2700 D_fake_loss= tensor(0.4707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2700 D_tricked_loss= tensor(1.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2701 D_real_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2701 D_fake_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2701 D_tricked_loss= tensor(1.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2702 D_real_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2702 D_fake_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2702 D_tricked_loss= tensor(1.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2703 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2703 D_fake_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2703 D_tricked_loss= tensor(1.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2704 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2704 D_fake_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2704 D_tricked_loss= tensor(1.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2705 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2705 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2705 D_tricked_loss= tensor(1.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2706 D_real_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2706 D_fake_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2706 D_tricked_loss= tensor(1.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2707 D_real_loss= tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2707 D_fake_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2707 D_tricked_loss= tensor(1.3951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2708 D_real_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2708 D_fake_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2708 D_tricked_loss= tensor(1.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2709 D_real_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2709 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2709 D_tricked_loss= tensor(1.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2710 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2710 D_fake_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2710 D_tricked_loss= tensor(1.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2711 D_real_loss= tensor(0.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2711 D_fake_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2711 D_tricked_loss= tensor(1.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2712 D_real_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2712 D_fake_loss= tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2712 D_tricked_loss= tensor(1.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2713 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2713 D_fake_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2713 D_tricked_loss= tensor(1.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2714 D_real_loss= tensor(0.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2714 D_fake_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2714 D_tricked_loss= tensor(1.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2715 D_real_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2715 D_fake_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2715 D_tricked_loss= tensor(1.6246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2716 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2716 D_fake_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2716 D_tricked_loss= tensor(1.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2717 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2717 D_fake_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2717 D_tricked_loss= tensor(1.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2718 D_real_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2718 D_fake_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2718 D_tricked_loss= tensor(1.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2719 D_real_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2719 D_fake_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2719 D_tricked_loss= tensor(1.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2720 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2720 D_fake_loss= tensor(0.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2720 D_tricked_loss= tensor(1.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2721 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2721 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2721 D_tricked_loss= tensor(1.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2722 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2722 D_fake_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2722 D_tricked_loss= tensor(1.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2723 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2723 D_fake_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2723 D_tricked_loss= tensor(1.6575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2724 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2724 D_fake_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2724 D_tricked_loss= tensor(1.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2725 D_real_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2725 D_fake_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2725 D_tricked_loss= tensor(1.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2726 D_real_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2726 D_fake_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2726 D_tricked_loss= tensor(1.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2727 D_real_loss= tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2727 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2727 D_tricked_loss= tensor(1.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2728 D_real_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2728 D_fake_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2728 D_tricked_loss= tensor(1.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2729 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2729 D_fake_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2729 D_tricked_loss= tensor(1.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2730 D_real_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2730 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2730 D_tricked_loss= tensor(1.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2731 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2731 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2731 D_tricked_loss= tensor(1.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2732 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2732 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2732 D_tricked_loss= tensor(1.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2733 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2733 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2733 D_tricked_loss= tensor(1.5004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2734 D_real_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2734 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2734 D_tricked_loss= tensor(1.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2735 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2735 D_fake_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2735 D_tricked_loss= tensor(1.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2736 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2736 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2736 D_tricked_loss= tensor(1.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2737 D_real_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2737 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2737 D_tricked_loss= tensor(1.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2738 D_real_loss= tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2738 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2738 D_tricked_loss= tensor(1.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2739 D_real_loss= tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2739 D_fake_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2739 D_tricked_loss= tensor(1.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2740 D_real_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2740 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2740 D_tricked_loss= tensor(1.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2741 D_real_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2741 D_fake_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2741 D_tricked_loss= tensor(1.5139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2742 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2742 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2742 D_tricked_loss= tensor(1.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2743 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2743 D_fake_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2743 D_tricked_loss= tensor(1.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2744 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2744 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2744 D_tricked_loss= tensor(1.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2745 D_real_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2745 D_fake_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2745 D_tricked_loss= tensor(1.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2746 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2746 D_fake_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2746 D_tricked_loss= tensor(1.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2747 D_real_loss= tensor(0.5075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2747 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2747 D_tricked_loss= tensor(1.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2748 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2748 D_fake_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2748 D_tricked_loss= tensor(1.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2749 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2749 D_fake_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2749 D_tricked_loss= tensor(1.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2750 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2750 D_fake_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2750 D_tricked_loss= tensor(1.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2751 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2751 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2751 D_tricked_loss= tensor(1.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2752 D_real_loss= tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2752 D_fake_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2752 D_tricked_loss= tensor(1.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2753 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2753 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2753 D_tricked_loss= tensor(1.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2754 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2754 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2754 D_tricked_loss= tensor(1.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2755 D_real_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2755 D_fake_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2755 D_tricked_loss= tensor(1.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2756 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2756 D_fake_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2756 D_tricked_loss= tensor(1.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2757 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2757 D_fake_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2757 D_tricked_loss= tensor(1.3872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2758 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2758 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2758 D_tricked_loss= tensor(1.4096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2759 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2759 D_fake_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2759 D_tricked_loss= tensor(1.4328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2760 D_real_loss= tensor(0.5075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2760 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2760 D_tricked_loss= tensor(1.4257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2761 D_real_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2761 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2761 D_tricked_loss= tensor(1.4418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2762 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2762 D_fake_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2762 D_tricked_loss= tensor(1.4068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2763 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2763 D_fake_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2763 D_tricked_loss= tensor(1.4195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2764 D_real_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2764 D_fake_loss= tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2764 D_tricked_loss= tensor(1.3873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2765 D_real_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2765 D_fake_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2765 D_tricked_loss= tensor(1.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2766 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2766 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2766 D_tricked_loss= tensor(1.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2767 D_real_loss= tensor(0.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2767 D_fake_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2767 D_tricked_loss= tensor(1.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2768 D_real_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2768 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2768 D_tricked_loss= tensor(1.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2769 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2769 D_fake_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2769 D_tricked_loss= tensor(1.4042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2770 D_real_loss= tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2770 D_fake_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2770 D_tricked_loss= tensor(1.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2771 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2771 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2771 D_tricked_loss= tensor(1.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2772 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2772 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2772 D_tricked_loss= tensor(1.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2773 D_real_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2773 D_fake_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2773 D_tricked_loss= tensor(1.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2774 D_real_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2774 D_fake_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2774 D_tricked_loss= tensor(1.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2775 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2775 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2775 D_tricked_loss= tensor(1.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2776 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2776 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2776 D_tricked_loss= tensor(1.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2777 D_real_loss= tensor(0.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2777 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2777 D_tricked_loss= tensor(1.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2778 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2778 D_fake_loss= tensor(0.4525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2778 D_tricked_loss= tensor(1.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2779 D_real_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2779 D_fake_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2779 D_tricked_loss= tensor(1.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2780 D_real_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2780 D_fake_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2780 D_tricked_loss= tensor(1.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2781 D_real_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2781 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2781 D_tricked_loss= tensor(1.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2782 D_real_loss= tensor(0.4903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2782 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2782 D_tricked_loss= tensor(1.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2783 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2783 D_fake_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2783 D_tricked_loss= tensor(1.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2784 D_real_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2784 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2784 D_tricked_loss= tensor(1.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2785 D_real_loss= tensor(0.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2785 D_fake_loss= tensor(0.4079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2785 D_tricked_loss= tensor(1.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2786 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2786 D_fake_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2786 D_tricked_loss= tensor(1.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2787 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2787 D_fake_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2787 D_tricked_loss= tensor(1.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2788 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2788 D_fake_loss= tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2788 D_tricked_loss= tensor(1.4440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2789 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2789 D_fake_loss= tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2789 D_tricked_loss= tensor(1.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2790 D_real_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2790 D_fake_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2790 D_tricked_loss= tensor(1.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2791 D_real_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2791 D_fake_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2791 D_tricked_loss= tensor(1.4421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2792 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2792 D_fake_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2792 D_tricked_loss= tensor(1.4328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2793 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2793 D_fake_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2793 D_tricked_loss= tensor(1.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2794 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2794 D_fake_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2794 D_tricked_loss= tensor(1.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2795 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2795 D_fake_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2795 D_tricked_loss= tensor(1.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2796 D_real_loss= tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2796 D_fake_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2796 D_tricked_loss= tensor(1.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2797 D_real_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2797 D_fake_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2797 D_tricked_loss= tensor(1.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2798 D_real_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2798 D_fake_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2798 D_tricked_loss= tensor(1.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2799 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2799 D_fake_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2799 D_tricked_loss= tensor(1.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2800 D_real_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2800 D_fake_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2800 D_tricked_loss= tensor(1.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2801 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2801 D_fake_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2801 D_tricked_loss= tensor(1.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2802 D_real_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2802 D_fake_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2802 D_tricked_loss= tensor(1.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2803 D_real_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2803 D_fake_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2803 D_tricked_loss= tensor(1.3963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2804 D_real_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2804 D_fake_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2804 D_tricked_loss= tensor(1.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2805 D_real_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2805 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2805 D_tricked_loss= tensor(1.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2806 D_real_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2806 D_fake_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2806 D_tricked_loss= tensor(1.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2807 D_real_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2807 D_fake_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2807 D_tricked_loss= tensor(1.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2808 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2808 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2808 D_tricked_loss= tensor(1.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2809 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2809 D_fake_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2809 D_tricked_loss= tensor(1.4306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2810 D_real_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2810 D_fake_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2810 D_tricked_loss= tensor(1.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2811 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2811 D_fake_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2811 D_tricked_loss= tensor(1.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2812 D_real_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2812 D_fake_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2812 D_tricked_loss= tensor(1.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2813 D_real_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2813 D_fake_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2813 D_tricked_loss= tensor(1.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2814 D_real_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2814 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2814 D_tricked_loss= tensor(1.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2815 D_real_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2815 D_fake_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2815 D_tricked_loss= tensor(1.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2816 D_real_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2816 D_fake_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2816 D_tricked_loss= tensor(1.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2817 D_real_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2817 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2817 D_tricked_loss= tensor(1.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2818 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2818 D_fake_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2818 D_tricked_loss= tensor(1.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2819 D_real_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2819 D_fake_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2819 D_tricked_loss= tensor(1.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2820 D_real_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2820 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2820 D_tricked_loss= tensor(1.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2821 D_real_loss= tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2821 D_fake_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2821 D_tricked_loss= tensor(1.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2822 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2822 D_fake_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2822 D_tricked_loss= tensor(1.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2823 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2823 D_fake_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2823 D_tricked_loss= tensor(1.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2824 D_real_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2824 D_fake_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2824 D_tricked_loss= tensor(1.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2825 D_real_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2825 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2825 D_tricked_loss= tensor(1.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2826 D_real_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2826 D_fake_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2826 D_tricked_loss= tensor(1.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2827 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2827 D_fake_loss= tensor(0.4922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2827 D_tricked_loss= tensor(1.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2828 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2828 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2828 D_tricked_loss= tensor(1.3884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2829 D_real_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2829 D_fake_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2829 D_tricked_loss= tensor(1.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2830 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2830 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2830 D_tricked_loss= tensor(1.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2831 D_real_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2831 D_fake_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2831 D_tricked_loss= tensor(1.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2832 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2832 D_fake_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2832 D_tricked_loss= tensor(1.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2833 D_real_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2833 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2833 D_tricked_loss= tensor(1.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2834 D_real_loss= tensor(0.5168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2834 D_fake_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2834 D_tricked_loss= tensor(1.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2835 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2835 D_fake_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2835 D_tricked_loss= tensor(1.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2836 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2836 D_fake_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2836 D_tricked_loss= tensor(1.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2837 D_real_loss= tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2837 D_fake_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2837 D_tricked_loss= tensor(1.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2838 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2838 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2838 D_tricked_loss= tensor(1.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2839 D_real_loss= tensor(0.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2839 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2839 D_tricked_loss= tensor(1.3905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2840 D_real_loss= tensor(0.4997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2840 D_fake_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2840 D_tricked_loss= tensor(1.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2841 D_real_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2841 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2841 D_tricked_loss= tensor(1.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2842 D_real_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2842 D_fake_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2842 D_tricked_loss= tensor(1.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2843 D_real_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2843 D_fake_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2843 D_tricked_loss= tensor(1.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2844 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2844 D_fake_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2844 D_tricked_loss= tensor(1.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2845 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2845 D_fake_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2845 D_tricked_loss= tensor(1.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2846 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2846 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2846 D_tricked_loss= tensor(1.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2847 D_real_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2847 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2847 D_tricked_loss= tensor(1.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2848 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2848 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2848 D_tricked_loss= tensor(1.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2849 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2849 D_fake_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2849 D_tricked_loss= tensor(1.3705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2850 D_real_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2850 D_fake_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2850 D_tricked_loss= tensor(1.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2851 D_real_loss= tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2851 D_fake_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2851 D_tricked_loss= tensor(1.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2852 D_real_loss= tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2852 D_fake_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2852 D_tricked_loss= tensor(1.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2853 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2853 D_fake_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2853 D_tricked_loss= tensor(1.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2854 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2854 D_fake_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2854 D_tricked_loss= tensor(1.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2855 D_real_loss= tensor(0.5168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2855 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2855 D_tricked_loss= tensor(1.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2856 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2856 D_fake_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2856 D_tricked_loss= tensor(1.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2857 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2857 D_fake_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2857 D_tricked_loss= tensor(1.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2858 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2858 D_fake_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2858 D_tricked_loss= tensor(1.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2859 D_real_loss= tensor(0.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2859 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2859 D_tricked_loss= tensor(1.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2860 D_real_loss= tensor(0.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2860 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2860 D_tricked_loss= tensor(1.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2861 D_real_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2861 D_fake_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2861 D_tricked_loss= tensor(1.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2862 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2862 D_fake_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2862 D_tricked_loss= tensor(1.3600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2863 D_real_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2863 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2863 D_tricked_loss= tensor(1.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2864 D_real_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2864 D_fake_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2864 D_tricked_loss= tensor(1.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2865 D_real_loss= tensor(0.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2865 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2865 D_tricked_loss= tensor(1.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2866 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2866 D_fake_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2866 D_tricked_loss= tensor(1.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2867 D_real_loss= tensor(0.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2867 D_fake_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2867 D_tricked_loss= tensor(1.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2868 D_real_loss= tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2868 D_fake_loss= tensor(0.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2868 D_tricked_loss= tensor(1.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2869 D_real_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2869 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2869 D_tricked_loss= tensor(1.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2870 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2870 D_fake_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2870 D_tricked_loss= tensor(1.4109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2871 D_real_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2871 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2871 D_tricked_loss= tensor(1.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2872 D_real_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2872 D_fake_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2872 D_tricked_loss= tensor(1.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2873 D_real_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2873 D_fake_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2873 D_tricked_loss= tensor(1.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2874 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2874 D_fake_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2874 D_tricked_loss= tensor(1.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2875 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2875 D_fake_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2875 D_tricked_loss= tensor(1.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2876 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2876 D_fake_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2876 D_tricked_loss= tensor(1.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2877 D_real_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2877 D_fake_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2877 D_tricked_loss= tensor(1.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2878 D_real_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2878 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2878 D_tricked_loss= tensor(1.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2879 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2879 D_fake_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2879 D_tricked_loss= tensor(1.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2880 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2880 D_fake_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2880 D_tricked_loss= tensor(1.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2881 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2881 D_fake_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2881 D_tricked_loss= tensor(1.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2882 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2882 D_fake_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2882 D_tricked_loss= tensor(1.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2883 D_real_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2883 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2883 D_tricked_loss= tensor(1.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2884 D_real_loss= tensor(0.4967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2884 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2884 D_tricked_loss= tensor(1.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2885 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2885 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2885 D_tricked_loss= tensor(1.4031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2886 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2886 D_fake_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2886 D_tricked_loss= tensor(1.4035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2887 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2887 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2887 D_tricked_loss= tensor(1.3895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2888 D_real_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2888 D_fake_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2888 D_tricked_loss= tensor(1.4006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2889 D_real_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2889 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2889 D_tricked_loss= tensor(1.3935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2890 D_real_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2890 D_fake_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2890 D_tricked_loss= tensor(1.4051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2891 D_real_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2891 D_fake_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2891 D_tricked_loss= tensor(1.3872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2892 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2892 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2892 D_tricked_loss= tensor(1.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2893 D_real_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2893 D_fake_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2893 D_tricked_loss= tensor(1.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2894 D_real_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2894 D_fake_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2894 D_tricked_loss= tensor(1.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2895 D_real_loss= tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2895 D_fake_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2895 D_tricked_loss= tensor(1.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2896 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2896 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2896 D_tricked_loss= tensor(1.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2897 D_real_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2897 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2897 D_tricked_loss= tensor(1.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2898 D_real_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2898 D_fake_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2898 D_tricked_loss= tensor(1.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2899 D_real_loss= tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2899 D_fake_loss= tensor(0.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2899 D_tricked_loss= tensor(1.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2900 D_real_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2900 D_fake_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2900 D_tricked_loss= tensor(1.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2901 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2901 D_fake_loss= tensor(0.4806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2901 D_tricked_loss= tensor(1.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2902 D_real_loss= tensor(0.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2902 D_fake_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2902 D_tricked_loss= tensor(1.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2903 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2903 D_fake_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2903 D_tricked_loss= tensor(1.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2904 D_real_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2904 D_fake_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2904 D_tricked_loss= tensor(1.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2905 D_real_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2905 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2905 D_tricked_loss= tensor(1.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2906 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2906 D_fake_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2906 D_tricked_loss= tensor(1.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2907 D_real_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2907 D_fake_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2907 D_tricked_loss= tensor(1.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2908 D_real_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2908 D_fake_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2908 D_tricked_loss= tensor(1.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2909 D_real_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2909 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2909 D_tricked_loss= tensor(1.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2910 D_real_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2910 D_fake_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2910 D_tricked_loss= tensor(1.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2911 D_real_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2911 D_fake_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2911 D_tricked_loss= tensor(1.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2912 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2912 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2912 D_tricked_loss= tensor(1.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2913 D_real_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2913 D_fake_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2913 D_tricked_loss= tensor(1.3997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2914 D_real_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2914 D_fake_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2914 D_tricked_loss= tensor(1.3898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2915 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2915 D_fake_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2915 D_tricked_loss= tensor(1.3854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2916 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2916 D_fake_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2916 D_tricked_loss= tensor(1.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2917 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2917 D_fake_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2917 D_tricked_loss= tensor(1.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2918 D_real_loss= tensor(0.5087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2918 D_fake_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2918 D_tricked_loss= tensor(1.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2919 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2919 D_fake_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2919 D_tricked_loss= tensor(1.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2920 D_real_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2920 D_fake_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2920 D_tricked_loss= tensor(1.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2921 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2921 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2921 D_tricked_loss= tensor(1.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2922 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2922 D_fake_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2922 D_tricked_loss= tensor(1.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2923 D_real_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2923 D_fake_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2923 D_tricked_loss= tensor(1.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2924 D_real_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2924 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2924 D_tricked_loss= tensor(1.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2925 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2925 D_fake_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2925 D_tricked_loss= tensor(1.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2926 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2926 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2926 D_tricked_loss= tensor(1.3798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2927 D_real_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2927 D_fake_loss= tensor(0.4967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2927 D_tricked_loss= tensor(1.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2928 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2928 D_fake_loss= tensor(0.4778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2928 D_tricked_loss= tensor(1.4070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2929 D_real_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2929 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2929 D_tricked_loss= tensor(1.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2930 D_real_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2930 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2930 D_tricked_loss= tensor(1.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2931 D_real_loss= tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2931 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2931 D_tricked_loss= tensor(1.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2932 D_real_loss= tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2932 D_fake_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2932 D_tricked_loss= tensor(1.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2933 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2933 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2933 D_tricked_loss= tensor(1.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2934 D_real_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2934 D_fake_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2934 D_tricked_loss= tensor(1.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2935 D_real_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2935 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2935 D_tricked_loss= tensor(1.4036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2936 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2936 D_fake_loss= tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2936 D_tricked_loss= tensor(1.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2937 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2937 D_fake_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2937 D_tricked_loss= tensor(1.4032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2938 D_real_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2938 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2938 D_tricked_loss= tensor(1.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2939 D_real_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2939 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2939 D_tricked_loss= tensor(1.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2940 D_real_loss= tensor(0.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2940 D_fake_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2940 D_tricked_loss= tensor(1.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2941 D_real_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2941 D_fake_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2941 D_tricked_loss= tensor(1.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2942 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2942 D_fake_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2942 D_tricked_loss= tensor(1.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2943 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2943 D_fake_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2943 D_tricked_loss= tensor(1.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2944 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2944 D_fake_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2944 D_tricked_loss= tensor(1.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2945 D_real_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2945 D_fake_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2945 D_tricked_loss= tensor(1.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2946 D_real_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2946 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2946 D_tricked_loss= tensor(1.3800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2947 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2947 D_fake_loss= tensor(0.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2947 D_tricked_loss= tensor(1.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2948 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2948 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2948 D_tricked_loss= tensor(1.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2949 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2949 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2949 D_tricked_loss= tensor(1.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2950 D_real_loss= tensor(0.5025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2950 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2950 D_tricked_loss= tensor(1.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2951 D_real_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2951 D_fake_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2951 D_tricked_loss= tensor(1.4482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2952 D_real_loss= tensor(0.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2952 D_fake_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2952 D_tricked_loss= tensor(1.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2953 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2953 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2953 D_tricked_loss= tensor(1.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2954 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2954 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2954 D_tricked_loss= tensor(1.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2955 D_real_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2955 D_fake_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2955 D_tricked_loss= tensor(1.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2956 D_real_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2956 D_fake_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2956 D_tricked_loss= tensor(1.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2957 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2957 D_fake_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2957 D_tricked_loss= tensor(1.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2958 D_real_loss= tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2958 D_fake_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2958 D_tricked_loss= tensor(1.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2959 D_real_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2959 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2959 D_tricked_loss= tensor(1.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2960 D_real_loss= tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2960 D_fake_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2960 D_tricked_loss= tensor(1.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2961 D_real_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2961 D_fake_loss= tensor(0.4902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2961 D_tricked_loss= tensor(1.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2962 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2962 D_fake_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2962 D_tricked_loss= tensor(1.3835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2963 D_real_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2963 D_fake_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2963 D_tricked_loss= tensor(1.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2964 D_real_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2964 D_fake_loss= tensor(0.4744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2964 D_tricked_loss= tensor(1.4241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2965 D_real_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2965 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2965 D_tricked_loss= tensor(1.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2966 D_real_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2966 D_fake_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2966 D_tricked_loss= tensor(1.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2967 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2967 D_fake_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2967 D_tricked_loss= tensor(1.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2968 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2968 D_fake_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2968 D_tricked_loss= tensor(1.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2969 D_real_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2969 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2969 D_tricked_loss= tensor(1.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2970 D_real_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2970 D_fake_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2970 D_tricked_loss= tensor(1.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2971 D_real_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2971 D_fake_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2971 D_tricked_loss= tensor(1.4041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2972 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2972 D_fake_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2972 D_tricked_loss= tensor(1.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2973 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2973 D_fake_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2973 D_tricked_loss= tensor(1.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2974 D_real_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2974 D_fake_loss= tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2974 D_tricked_loss= tensor(1.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2975 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2975 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2975 D_tricked_loss= tensor(1.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2976 D_real_loss= tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2976 D_fake_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2976 D_tricked_loss= tensor(1.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2977 D_real_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2977 D_fake_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2977 D_tricked_loss= tensor(1.4643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2978 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2978 D_fake_loss= tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2978 D_tricked_loss= tensor(1.3834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2979 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2979 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2979 D_tricked_loss= tensor(1.4106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2980 D_real_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2980 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2980 D_tricked_loss= tensor(1.4199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2981 D_real_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2981 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2981 D_tricked_loss= tensor(1.3853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2982 D_real_loss= tensor(0.5100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2982 D_fake_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2982 D_tricked_loss= tensor(1.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2983 D_real_loss= tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2983 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2983 D_tricked_loss= tensor(1.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2984 D_real_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2984 D_fake_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2984 D_tricked_loss= tensor(1.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2985 D_real_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2985 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2985 D_tricked_loss= tensor(1.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2986 D_real_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2986 D_fake_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2986 D_tricked_loss= tensor(1.4034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2987 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2987 D_fake_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2987 D_tricked_loss= tensor(1.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2988 D_real_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2988 D_fake_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2988 D_tricked_loss= tensor(1.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2989 D_real_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2989 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2989 D_tricked_loss= tensor(1.3995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2990 D_real_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2990 D_fake_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2990 D_tricked_loss= tensor(1.3875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2991 D_real_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2991 D_fake_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2991 D_tricked_loss= tensor(1.3912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2992 D_real_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2992 D_fake_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2992 D_tricked_loss= tensor(1.4050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2993 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2993 D_fake_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2993 D_tricked_loss= tensor(1.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2994 D_real_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2994 D_fake_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2994 D_tricked_loss= tensor(1.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2995 D_real_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2995 D_fake_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2995 D_tricked_loss= tensor(1.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2996 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2996 D_fake_loss= tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2996 D_tricked_loss= tensor(1.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2997 D_real_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2997 D_fake_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2997 D_tricked_loss= tensor(1.4060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2998 D_real_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2998 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2998 D_tricked_loss= tensor(1.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "2999 D_real_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2999 D_fake_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2999 D_tricked_loss= tensor(1.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3000 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3000 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3000 D_tricked_loss= tensor(1.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3001 D_real_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3001 D_fake_loss= tensor(0.4949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3001 D_tricked_loss= tensor(1.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3002 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3002 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3002 D_tricked_loss= tensor(1.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3003 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3003 D_fake_loss= tensor(0.4858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3003 D_tricked_loss= tensor(1.4287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3004 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3004 D_fake_loss= tensor(0.4518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3004 D_tricked_loss= tensor(1.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3005 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3005 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3005 D_tricked_loss= tensor(1.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3006 D_real_loss= tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3006 D_fake_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3006 D_tricked_loss= tensor(1.3911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3007 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3007 D_fake_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3007 D_tricked_loss= tensor(1.4212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3008 D_real_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3008 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3008 D_tricked_loss= tensor(1.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3009 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3009 D_fake_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3009 D_tricked_loss= tensor(1.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3010 D_real_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3010 D_fake_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3010 D_tricked_loss= tensor(1.4138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3011 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3011 D_fake_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3011 D_tricked_loss= tensor(1.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3012 D_real_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3012 D_fake_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3012 D_tricked_loss= tensor(1.3580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3013 D_real_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3013 D_fake_loss= tensor(0.4922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3013 D_tricked_loss= tensor(1.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3014 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3014 D_fake_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3014 D_tricked_loss= tensor(1.4073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3015 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3015 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3015 D_tricked_loss= tensor(1.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3016 D_real_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3016 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3016 D_tricked_loss= tensor(1.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3017 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3017 D_fake_loss= tensor(0.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3017 D_tricked_loss= tensor(1.3861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3018 D_real_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3018 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3018 D_tricked_loss= tensor(1.3954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3019 D_real_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3019 D_fake_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3019 D_tricked_loss= tensor(1.3777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3020 D_real_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3020 D_fake_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3020 D_tricked_loss= tensor(1.3992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3021 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3021 D_fake_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3021 D_tricked_loss= tensor(1.3691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3022 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3022 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3022 D_tricked_loss= tensor(1.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3023 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3023 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3023 D_tricked_loss= tensor(1.4404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3024 D_real_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3024 D_fake_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3024 D_tricked_loss= tensor(1.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3025 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3025 D_fake_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3025 D_tricked_loss= tensor(1.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3026 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3026 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3026 D_tricked_loss= tensor(1.4681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3027 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3027 D_fake_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3027 D_tricked_loss= tensor(1.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3028 D_real_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3028 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3028 D_tricked_loss= tensor(1.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3029 D_real_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3029 D_fake_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3029 D_tricked_loss= tensor(1.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3030 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3030 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3030 D_tricked_loss= tensor(1.5122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3031 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3031 D_fake_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3031 D_tricked_loss= tensor(1.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3032 D_real_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3032 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3032 D_tricked_loss= tensor(1.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3033 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3033 D_fake_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3033 D_tricked_loss= tensor(1.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3034 D_real_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3034 D_fake_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3034 D_tricked_loss= tensor(1.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3035 D_real_loss= tensor(0.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3035 D_fake_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3035 D_tricked_loss= tensor(1.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3036 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3036 D_fake_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3036 D_tricked_loss= tensor(1.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3037 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3037 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3037 D_tricked_loss= tensor(1.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3038 D_real_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3038 D_fake_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3038 D_tricked_loss= tensor(1.4100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3039 D_real_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3039 D_fake_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3039 D_tricked_loss= tensor(1.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3040 D_real_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3040 D_fake_loss= tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3040 D_tricked_loss= tensor(1.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3041 D_real_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3041 D_fake_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3041 D_tricked_loss= tensor(1.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3042 D_real_loss= tensor(0.4850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3042 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3042 D_tricked_loss= tensor(1.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3043 D_real_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3043 D_fake_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3043 D_tricked_loss= tensor(1.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3044 D_real_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3044 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3044 D_tricked_loss= tensor(1.4275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3045 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3045 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3045 D_tricked_loss= tensor(1.3677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3046 D_real_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3046 D_fake_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3046 D_tricked_loss= tensor(1.4178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3047 D_real_loss= tensor(0.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3047 D_fake_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3047 D_tricked_loss= tensor(1.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3048 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3048 D_fake_loss= tensor(0.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3048 D_tricked_loss= tensor(1.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3049 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3049 D_fake_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3049 D_tricked_loss= tensor(1.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3050 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3050 D_fake_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3050 D_tricked_loss= tensor(1.4133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3051 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3051 D_fake_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3051 D_tricked_loss= tensor(1.3903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3052 D_real_loss= tensor(0.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3052 D_fake_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3052 D_tricked_loss= tensor(1.3648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3053 D_real_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3053 D_fake_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3053 D_tricked_loss= tensor(1.3903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3054 D_real_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3054 D_fake_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3054 D_tricked_loss= tensor(1.3814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3055 D_real_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3055 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3055 D_tricked_loss= tensor(1.4102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3056 D_real_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3056 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3056 D_tricked_loss= tensor(1.3603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3057 D_real_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3057 D_fake_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3057 D_tricked_loss= tensor(1.3475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3058 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3058 D_fake_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3058 D_tricked_loss= tensor(1.3861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3059 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3059 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3059 D_tricked_loss= tensor(1.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3060 D_real_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3060 D_fake_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3060 D_tricked_loss= tensor(1.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3061 D_real_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3061 D_fake_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3061 D_tricked_loss= tensor(1.3908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3062 D_real_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3062 D_fake_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3062 D_tricked_loss= tensor(1.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3063 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3063 D_fake_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3063 D_tricked_loss= tensor(1.4002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3064 D_real_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3064 D_fake_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3064 D_tricked_loss= tensor(1.4019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3065 D_real_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3065 D_fake_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3065 D_tricked_loss= tensor(1.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3066 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3066 D_fake_loss= tensor(0.4778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3066 D_tricked_loss= tensor(1.4077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3067 D_real_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3067 D_fake_loss= tensor(0.5180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3067 D_tricked_loss= tensor(1.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3068 D_real_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3068 D_fake_loss= tensor(0.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3068 D_tricked_loss= tensor(1.3815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3069 D_real_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3069 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3069 D_tricked_loss= tensor(1.3910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3070 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3070 D_fake_loss= tensor(0.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3070 D_tricked_loss= tensor(1.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3071 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3071 D_fake_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3071 D_tricked_loss= tensor(1.4418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3072 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3072 D_fake_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3072 D_tricked_loss= tensor(1.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3073 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3073 D_fake_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3073 D_tricked_loss= tensor(1.3862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3074 D_real_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3074 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3074 D_tricked_loss= tensor(1.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3075 D_real_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3075 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3075 D_tricked_loss= tensor(1.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3076 D_real_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3076 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3076 D_tricked_loss= tensor(1.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3077 D_real_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3077 D_fake_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3077 D_tricked_loss= tensor(1.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3078 D_real_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3078 D_fake_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3078 D_tricked_loss= tensor(1.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3079 D_real_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3079 D_fake_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3079 D_tricked_loss= tensor(1.3905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3080 D_real_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3080 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3080 D_tricked_loss= tensor(1.3989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3081 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3081 D_fake_loss= tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3081 D_tricked_loss= tensor(1.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3082 D_real_loss= tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3082 D_fake_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3082 D_tricked_loss= tensor(1.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3083 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3083 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3083 D_tricked_loss= tensor(1.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3084 D_real_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3084 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3084 D_tricked_loss= tensor(1.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3085 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3085 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3085 D_tricked_loss= tensor(1.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3086 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3086 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3086 D_tricked_loss= tensor(1.4707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3087 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3087 D_fake_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3087 D_tricked_loss= tensor(1.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3088 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3088 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3088 D_tricked_loss= tensor(1.4029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3089 D_real_loss= tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3089 D_fake_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3089 D_tricked_loss= tensor(1.4241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3090 D_real_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3090 D_fake_loss= tensor(0.4707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3090 D_tricked_loss= tensor(1.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3091 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3091 D_fake_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3091 D_tricked_loss= tensor(1.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3092 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3092 D_fake_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3092 D_tricked_loss= tensor(1.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3093 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3093 D_fake_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3093 D_tricked_loss= tensor(1.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3094 D_real_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3094 D_fake_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3094 D_tricked_loss= tensor(1.3751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3095 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3095 D_fake_loss= tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3095 D_tricked_loss= tensor(1.3808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3096 D_real_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3096 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3096 D_tricked_loss= tensor(1.3769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3097 D_real_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3097 D_fake_loss= tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3097 D_tricked_loss= tensor(1.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3098 D_real_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3098 D_fake_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3098 D_tricked_loss= tensor(1.3802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3099 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3099 D_fake_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3099 D_tricked_loss= tensor(1.3990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3100 D_real_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3100 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3100 D_tricked_loss= tensor(1.3244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3101 D_real_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3101 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3101 D_tricked_loss= tensor(1.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3102 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3102 D_fake_loss= tensor(0.4927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3102 D_tricked_loss= tensor(1.3779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3103 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3103 D_fake_loss= tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3103 D_tricked_loss= tensor(1.3459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3104 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3104 D_fake_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3104 D_tricked_loss= tensor(1.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3105 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3105 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3105 D_tricked_loss= tensor(1.3510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3106 D_real_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3106 D_fake_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3106 D_tricked_loss= tensor(1.3777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3107 D_real_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3107 D_fake_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3107 D_tricked_loss= tensor(1.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3108 D_real_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3108 D_fake_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3108 D_tricked_loss= tensor(1.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3109 D_real_loss= tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3109 D_fake_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3109 D_tricked_loss= tensor(1.3850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3110 D_real_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3110 D_fake_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3110 D_tricked_loss= tensor(1.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3111 D_real_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3111 D_fake_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3111 D_tricked_loss= tensor(1.3691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3112 D_real_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3112 D_fake_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3112 D_tricked_loss= tensor(1.4093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3113 D_real_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3113 D_fake_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3113 D_tricked_loss= tensor(1.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3114 D_real_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3114 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3114 D_tricked_loss= tensor(1.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3115 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3115 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3115 D_tricked_loss= tensor(1.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3116 D_real_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3116 D_fake_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3116 D_tricked_loss= tensor(1.3626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3117 D_real_loss= tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3117 D_fake_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3117 D_tricked_loss= tensor(1.4002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3118 D_real_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3118 D_fake_loss= tensor(0.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3118 D_tricked_loss= tensor(1.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3119 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3119 D_fake_loss= tensor(0.5218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3119 D_tricked_loss= tensor(1.3969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3120 D_real_loss= tensor(0.5139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3120 D_fake_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3120 D_tricked_loss= tensor(1.3861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3121 D_real_loss= tensor(0.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3121 D_fake_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3121 D_tricked_loss= tensor(1.4156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3122 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3122 D_fake_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3122 D_tricked_loss= tensor(1.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3123 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3123 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3123 D_tricked_loss= tensor(1.4076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3124 D_real_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3124 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3124 D_tricked_loss= tensor(1.4036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3125 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3125 D_fake_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3125 D_tricked_loss= tensor(1.4004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3126 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3126 D_fake_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3126 D_tricked_loss= tensor(1.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3127 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3127 D_fake_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3127 D_tricked_loss= tensor(1.4408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3128 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3128 D_fake_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3128 D_tricked_loss= tensor(1.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3129 D_real_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3129 D_fake_loss= tensor(0.4713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3129 D_tricked_loss= tensor(1.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3130 D_real_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3130 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3130 D_tricked_loss= tensor(1.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3131 D_real_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3131 D_fake_loss= tensor(0.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3131 D_tricked_loss= tensor(1.4042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3132 D_real_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3132 D_fake_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3132 D_tricked_loss= tensor(1.3950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3133 D_real_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3133 D_fake_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3133 D_tricked_loss= tensor(1.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3134 D_real_loss= tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3134 D_fake_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3134 D_tricked_loss= tensor(1.3348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3135 D_real_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3135 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3135 D_tricked_loss= tensor(1.3958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3136 D_real_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3136 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3136 D_tricked_loss= tensor(1.3558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3137 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3137 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3137 D_tricked_loss= tensor(1.3847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3138 D_real_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3138 D_fake_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3138 D_tricked_loss= tensor(1.4205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3139 D_real_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3139 D_fake_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3139 D_tricked_loss= tensor(1.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3140 D_real_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3140 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3140 D_tricked_loss= tensor(1.4009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3141 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3141 D_fake_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3141 D_tricked_loss= tensor(1.3797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3142 D_real_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3142 D_fake_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3142 D_tricked_loss= tensor(1.3772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3143 D_real_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3143 D_fake_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3143 D_tricked_loss= tensor(1.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3144 D_real_loss= tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3144 D_fake_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3144 D_tricked_loss= tensor(1.4121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3145 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3145 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3145 D_tricked_loss= tensor(1.3995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3146 D_real_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3146 D_fake_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3146 D_tricked_loss= tensor(1.3837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3147 D_real_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3147 D_fake_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3147 D_tricked_loss= tensor(1.3861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3148 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3148 D_fake_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3148 D_tricked_loss= tensor(1.4379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3149 D_real_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3149 D_fake_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3149 D_tricked_loss= tensor(1.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3150 D_real_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3150 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3150 D_tricked_loss= tensor(1.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3151 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3151 D_fake_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3151 D_tricked_loss= tensor(1.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3152 D_real_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3152 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3152 D_tricked_loss= tensor(1.3868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3153 D_real_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3153 D_fake_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3153 D_tricked_loss= tensor(1.3728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3154 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3154 D_fake_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3154 D_tricked_loss= tensor(1.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3155 D_real_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3155 D_fake_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3155 D_tricked_loss= tensor(1.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3156 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3156 D_fake_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3156 D_tricked_loss= tensor(1.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3157 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3157 D_fake_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3157 D_tricked_loss= tensor(1.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3158 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3158 D_fake_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3158 D_tricked_loss= tensor(1.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3159 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3159 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3159 D_tricked_loss= tensor(1.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3160 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3160 D_fake_loss= tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3160 D_tricked_loss= tensor(1.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3161 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3161 D_fake_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3161 D_tricked_loss= tensor(1.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3162 D_real_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3162 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3162 D_tricked_loss= tensor(1.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3163 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3163 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3163 D_tricked_loss= tensor(1.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3164 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3164 D_fake_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3164 D_tricked_loss= tensor(1.3908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3165 D_real_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3165 D_fake_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3165 D_tricked_loss= tensor(1.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3166 D_real_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3166 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3166 D_tricked_loss= tensor(1.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3167 D_real_loss= tensor(0.5214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3167 D_fake_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3167 D_tricked_loss= tensor(1.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3168 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3168 D_fake_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3168 D_tricked_loss= tensor(1.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3169 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3169 D_fake_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3169 D_tricked_loss= tensor(1.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3170 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3170 D_fake_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3170 D_tricked_loss= tensor(1.3903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3171 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3171 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3171 D_tricked_loss= tensor(1.3792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3172 D_real_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3172 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3172 D_tricked_loss= tensor(1.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3173 D_real_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3173 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3173 D_tricked_loss= tensor(1.4045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3174 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3174 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3174 D_tricked_loss= tensor(1.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3175 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3175 D_fake_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3175 D_tricked_loss= tensor(1.3586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3176 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3176 D_fake_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3176 D_tricked_loss= tensor(1.3249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3177 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3177 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3177 D_tricked_loss= tensor(1.3878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3178 D_real_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3178 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3178 D_tricked_loss= tensor(1.3760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3179 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3179 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3179 D_tricked_loss= tensor(1.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3180 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3180 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3180 D_tricked_loss= tensor(1.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3181 D_real_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3181 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3181 D_tricked_loss= tensor(1.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3182 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3182 D_fake_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3182 D_tricked_loss= tensor(1.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3183 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3183 D_fake_loss= tensor(0.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3183 D_tricked_loss= tensor(1.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3184 D_real_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3184 D_fake_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3184 D_tricked_loss= tensor(1.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3185 D_real_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3185 D_fake_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3185 D_tricked_loss= tensor(1.4114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3186 D_real_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3186 D_fake_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3186 D_tricked_loss= tensor(1.3768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3187 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3187 D_fake_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3187 D_tricked_loss= tensor(1.3749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3188 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3188 D_fake_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3188 D_tricked_loss= tensor(1.3200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3189 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3189 D_fake_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3189 D_tricked_loss= tensor(1.2729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3190 D_real_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3190 D_fake_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3190 D_tricked_loss= tensor(1.3260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3191 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3191 D_fake_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3191 D_tricked_loss= tensor(1.3443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3192 D_real_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3192 D_fake_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3192 D_tricked_loss= tensor(1.3274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3193 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3193 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3193 D_tricked_loss= tensor(1.3952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3194 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3194 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3194 D_tricked_loss= tensor(1.3140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3195 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3195 D_fake_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3195 D_tricked_loss= tensor(1.3732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3196 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3196 D_fake_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3196 D_tricked_loss= tensor(1.3655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3197 D_real_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3197 D_fake_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3197 D_tricked_loss= tensor(1.3929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3198 D_real_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3198 D_fake_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3198 D_tricked_loss= tensor(1.4116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3199 D_real_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3199 D_fake_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3199 D_tricked_loss= tensor(1.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3200 D_real_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3200 D_fake_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3200 D_tricked_loss= tensor(1.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3201 D_real_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3201 D_fake_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3201 D_tricked_loss= tensor(1.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3202 D_real_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3202 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3202 D_tricked_loss= tensor(1.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3203 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3203 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3203 D_tricked_loss= tensor(1.3844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3204 D_real_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3204 D_fake_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3204 D_tricked_loss= tensor(1.3901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3205 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3205 D_fake_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3205 D_tricked_loss= tensor(1.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3206 D_real_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3206 D_fake_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3206 D_tricked_loss= tensor(1.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3207 D_real_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3207 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3207 D_tricked_loss= tensor(1.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3208 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3208 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3208 D_tricked_loss= tensor(1.3876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3209 D_real_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3209 D_fake_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3209 D_tricked_loss= tensor(1.3135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3210 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3210 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3210 D_tricked_loss= tensor(1.4117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3211 D_real_loss= tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3211 D_fake_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3211 D_tricked_loss= tensor(1.3843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3212 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3212 D_fake_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3212 D_tricked_loss= tensor(1.3910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3213 D_real_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3213 D_fake_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3213 D_tricked_loss= tensor(1.3895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3214 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3214 D_fake_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3214 D_tricked_loss= tensor(1.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3215 D_real_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3215 D_fake_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3215 D_tricked_loss= tensor(1.3914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3216 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3216 D_fake_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3216 D_tricked_loss= tensor(1.3796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3217 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3217 D_fake_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3217 D_tricked_loss= tensor(1.3605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3218 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3218 D_fake_loss= tensor(0.5225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3218 D_tricked_loss= tensor(1.3690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3219 D_real_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3219 D_fake_loss= tensor(0.4786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3219 D_tricked_loss= tensor(1.3159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3220 D_real_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3220 D_fake_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3220 D_tricked_loss= tensor(1.3791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3221 D_real_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3221 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3221 D_tricked_loss= tensor(1.3219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3222 D_real_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3222 D_fake_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3222 D_tricked_loss= tensor(1.3317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3223 D_real_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3223 D_fake_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3223 D_tricked_loss= tensor(1.3654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3224 D_real_loss= tensor(0.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3224 D_fake_loss= tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3224 D_tricked_loss= tensor(1.2887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3225 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3225 D_fake_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3225 D_tricked_loss= tensor(1.3136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3226 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3226 D_fake_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3226 D_tricked_loss= tensor(1.3363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3227 D_real_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3227 D_fake_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3227 D_tricked_loss= tensor(1.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3228 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3228 D_fake_loss= tensor(0.4952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3228 D_tricked_loss= tensor(1.3406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3229 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3229 D_fake_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3229 D_tricked_loss= tensor(1.3290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3230 D_real_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3230 D_fake_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3230 D_tricked_loss= tensor(1.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3231 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3231 D_fake_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3231 D_tricked_loss= tensor(1.3420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3232 D_real_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3232 D_fake_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3232 D_tricked_loss= tensor(1.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3233 D_real_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3233 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3233 D_tricked_loss= tensor(1.2963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3234 D_real_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3234 D_fake_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3234 D_tricked_loss= tensor(1.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3235 D_real_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3235 D_fake_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3235 D_tricked_loss= tensor(1.3563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3236 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3236 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3236 D_tricked_loss= tensor(1.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3237 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3237 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3237 D_tricked_loss= tensor(1.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3238 D_real_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3238 D_fake_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3238 D_tricked_loss= tensor(1.3718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3239 D_real_loss= tensor(0.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3239 D_fake_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3239 D_tricked_loss= tensor(1.4061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3240 D_real_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3240 D_fake_loss= tensor(0.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3240 D_tricked_loss= tensor(1.3871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3241 D_real_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3241 D_fake_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3241 D_tricked_loss= tensor(1.3444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3242 D_real_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3242 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3242 D_tricked_loss= tensor(1.3640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3243 D_real_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3243 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3243 D_tricked_loss= tensor(1.3406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3244 D_real_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3244 D_fake_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3244 D_tricked_loss= tensor(1.3154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3245 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3245 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3245 D_tricked_loss= tensor(1.3298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3246 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3246 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3246 D_tricked_loss= tensor(1.3327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3247 D_real_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3247 D_fake_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3247 D_tricked_loss= tensor(1.3478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3248 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3248 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3248 D_tricked_loss= tensor(1.2831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3249 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3249 D_fake_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3249 D_tricked_loss= tensor(1.3622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3250 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3250 D_fake_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3250 D_tricked_loss= tensor(1.3359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3251 D_real_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3251 D_fake_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3251 D_tricked_loss= tensor(1.3775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3252 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3252 D_fake_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3252 D_tricked_loss= tensor(1.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3253 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3253 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3253 D_tricked_loss= tensor(1.3932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3254 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3254 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3254 D_tricked_loss= tensor(1.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3255 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3255 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3255 D_tricked_loss= tensor(1.4076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3256 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3256 D_fake_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3256 D_tricked_loss= tensor(1.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3257 D_real_loss= tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3257 D_fake_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3257 D_tricked_loss= tensor(1.3915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3258 D_real_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3258 D_fake_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3258 D_tricked_loss= tensor(1.3582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3259 D_real_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3259 D_fake_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3259 D_tricked_loss= tensor(1.3878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3260 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3260 D_fake_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3260 D_tricked_loss= tensor(1.2969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3261 D_real_loss= tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3261 D_fake_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3261 D_tricked_loss= tensor(1.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3262 D_real_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3262 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3262 D_tricked_loss= tensor(1.4052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3263 D_real_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3263 D_fake_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3263 D_tricked_loss= tensor(1.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3264 D_real_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3264 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3264 D_tricked_loss= tensor(1.3935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3265 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3265 D_fake_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3265 D_tricked_loss= tensor(1.3434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3266 D_real_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3266 D_fake_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3266 D_tricked_loss= tensor(1.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3267 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3267 D_fake_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3267 D_tricked_loss= tensor(1.3298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3268 D_real_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3268 D_fake_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3268 D_tricked_loss= tensor(1.4108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3269 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3269 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3269 D_tricked_loss= tensor(1.3186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3270 D_real_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3270 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3270 D_tricked_loss= tensor(1.3587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3271 D_real_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3271 D_fake_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3271 D_tricked_loss= tensor(1.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3272 D_real_loss= tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3272 D_fake_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3272 D_tricked_loss= tensor(1.3931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3273 D_real_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3273 D_fake_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3273 D_tricked_loss= tensor(1.3780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3274 D_real_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3274 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3274 D_tricked_loss= tensor(1.3962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3275 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3275 D_fake_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3275 D_tricked_loss= tensor(1.3485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3276 D_real_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3276 D_fake_loss= tensor(0.4713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3276 D_tricked_loss= tensor(1.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3277 D_real_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3277 D_fake_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3277 D_tricked_loss= tensor(1.3975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3278 D_real_loss= tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3278 D_fake_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3278 D_tricked_loss= tensor(1.4051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3279 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3279 D_fake_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3279 D_tricked_loss= tensor(1.3801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3280 D_real_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3280 D_fake_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3280 D_tricked_loss= tensor(1.3299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3281 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3281 D_fake_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3281 D_tricked_loss= tensor(1.3713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3282 D_real_loss= tensor(0.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3282 D_fake_loss= tensor(0.4783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3282 D_tricked_loss= tensor(1.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3283 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3283 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3283 D_tricked_loss= tensor(1.4193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3284 D_real_loss= tensor(0.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3284 D_fake_loss= tensor(0.4967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3284 D_tricked_loss= tensor(1.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3285 D_real_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3285 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3285 D_tricked_loss= tensor(1.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3286 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3286 D_fake_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3286 D_tricked_loss= tensor(1.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3287 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3287 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3287 D_tricked_loss= tensor(1.3873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3288 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3288 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3288 D_tricked_loss= tensor(1.4025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3289 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3289 D_fake_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3289 D_tricked_loss= tensor(1.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3290 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3290 D_fake_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3290 D_tricked_loss= tensor(1.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3291 D_real_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3291 D_fake_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3291 D_tricked_loss= tensor(1.3678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3292 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3292 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3292 D_tricked_loss= tensor(1.3198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3293 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3293 D_fake_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3293 D_tricked_loss= tensor(1.2499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3294 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3294 D_fake_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3294 D_tricked_loss= tensor(1.3392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3295 D_real_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3295 D_fake_loss= tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3295 D_tricked_loss= tensor(1.3028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3296 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3296 D_fake_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3296 D_tricked_loss= tensor(1.3234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3297 D_real_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3297 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3297 D_tricked_loss= tensor(1.3150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3298 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3298 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3298 D_tricked_loss= tensor(1.3698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3299 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3299 D_fake_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3299 D_tricked_loss= tensor(1.3965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3300 D_real_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3300 D_fake_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3300 D_tricked_loss= tensor(1.2713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3301 D_real_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3301 D_fake_loss= tensor(0.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3301 D_tricked_loss= tensor(1.2939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3302 D_real_loss= tensor(0.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3302 D_fake_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3302 D_tricked_loss= tensor(1.3746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3303 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3303 D_fake_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3303 D_tricked_loss= tensor(1.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3304 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3304 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3304 D_tricked_loss= tensor(1.4115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3305 D_real_loss= tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3305 D_fake_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3305 D_tricked_loss= tensor(1.3336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3306 D_real_loss= tensor(0.5180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3306 D_fake_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3306 D_tricked_loss= tensor(1.3124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3307 D_real_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3307 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3307 D_tricked_loss= tensor(1.3639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3308 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3308 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3308 D_tricked_loss= tensor(1.4097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3309 D_real_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3309 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3309 D_tricked_loss= tensor(1.3871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3310 D_real_loss= tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3310 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3310 D_tricked_loss= tensor(1.2961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3311 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3311 D_fake_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3311 D_tricked_loss= tensor(1.2803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3312 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3312 D_fake_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3312 D_tricked_loss= tensor(1.3165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3313 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3313 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3313 D_tricked_loss= tensor(1.2911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3314 D_real_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3314 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3314 D_tricked_loss= tensor(1.2724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3315 D_real_loss= tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3315 D_fake_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3315 D_tricked_loss= tensor(1.3658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3316 D_real_loss= tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3316 D_fake_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3316 D_tricked_loss= tensor(1.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3317 D_real_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3317 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3317 D_tricked_loss= tensor(1.3643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3318 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3318 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3318 D_tricked_loss= tensor(1.3215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3319 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3319 D_fake_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3319 D_tricked_loss= tensor(1.3607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3320 D_real_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3320 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3320 D_tricked_loss= tensor(1.3092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3321 D_real_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3321 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3321 D_tricked_loss= tensor(1.3594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3322 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3322 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3322 D_tricked_loss= tensor(1.3263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3323 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3323 D_fake_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3323 D_tricked_loss= tensor(1.3220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3324 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3324 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3324 D_tricked_loss= tensor(1.3262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3325 D_real_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3325 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3325 D_tricked_loss= tensor(1.3598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3326 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3326 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3326 D_tricked_loss= tensor(1.2969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3327 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3327 D_fake_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3327 D_tricked_loss= tensor(1.3306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3328 D_real_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3328 D_fake_loss= tensor(0.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3328 D_tricked_loss= tensor(1.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3329 D_real_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3329 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3329 D_tricked_loss= tensor(1.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3330 D_real_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3330 D_fake_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3330 D_tricked_loss= tensor(1.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3331 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3331 D_fake_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3331 D_tricked_loss= tensor(1.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3332 D_real_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3332 D_fake_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3332 D_tricked_loss= tensor(1.3903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3333 D_real_loss= tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3333 D_fake_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3333 D_tricked_loss= tensor(1.3767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3334 D_real_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3334 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3334 D_tricked_loss= tensor(1.3810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3335 D_real_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3335 D_fake_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3335 D_tricked_loss= tensor(1.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3336 D_real_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3336 D_fake_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3336 D_tricked_loss= tensor(1.3656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3337 D_real_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3337 D_fake_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3337 D_tricked_loss= tensor(1.3742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3338 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3338 D_fake_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3338 D_tricked_loss= tensor(1.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3339 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3339 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3339 D_tricked_loss= tensor(1.3572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3340 D_real_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3340 D_fake_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3340 D_tricked_loss= tensor(1.3224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3341 D_real_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3341 D_fake_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3341 D_tricked_loss= tensor(1.3801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3342 D_real_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3342 D_fake_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3342 D_tricked_loss= tensor(1.3483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3343 D_real_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3343 D_fake_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3343 D_tricked_loss= tensor(1.3233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3344 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3344 D_fake_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3344 D_tricked_loss= tensor(1.3187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3345 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3345 D_fake_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3345 D_tricked_loss= tensor(1.3454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3346 D_real_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3346 D_fake_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3346 D_tricked_loss= tensor(1.3762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3347 D_real_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3347 D_fake_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3347 D_tricked_loss= tensor(1.3456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3348 D_real_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3348 D_fake_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3348 D_tricked_loss= tensor(1.3206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3349 D_real_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3349 D_fake_loss= tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3349 D_tricked_loss= tensor(1.3628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3350 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3350 D_fake_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3350 D_tricked_loss= tensor(1.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3351 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3351 D_fake_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3351 D_tricked_loss= tensor(1.4003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3352 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3352 D_fake_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3352 D_tricked_loss= tensor(1.3516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3353 D_real_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3353 D_fake_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3353 D_tricked_loss= tensor(1.3543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3354 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3354 D_fake_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3354 D_tricked_loss= tensor(1.4002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3355 D_real_loss= tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3355 D_fake_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3355 D_tricked_loss= tensor(1.3781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3356 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3356 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3356 D_tricked_loss= tensor(1.3840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3357 D_real_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3357 D_fake_loss= tensor(0.5098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3357 D_tricked_loss= tensor(1.3570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3358 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3358 D_fake_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3358 D_tricked_loss= tensor(1.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3359 D_real_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3359 D_fake_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3359 D_tricked_loss= tensor(1.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3360 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3360 D_fake_loss= tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3360 D_tricked_loss= tensor(1.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3361 D_real_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3361 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3361 D_tricked_loss= tensor(1.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3362 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3362 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3362 D_tricked_loss= tensor(1.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3363 D_real_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3363 D_fake_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3363 D_tricked_loss= tensor(1.4104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3364 D_real_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3364 D_fake_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3364 D_tricked_loss= tensor(1.3743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3365 D_real_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3365 D_fake_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3365 D_tricked_loss= tensor(1.3857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3366 D_real_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3366 D_fake_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3366 D_tricked_loss= tensor(1.3338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3367 D_real_loss= tensor(0.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3367 D_fake_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3367 D_tricked_loss= tensor(1.3197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3368 D_real_loss= tensor(0.5214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3368 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3368 D_tricked_loss= tensor(1.3688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3369 D_real_loss= tensor(0.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3369 D_fake_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3369 D_tricked_loss= tensor(1.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3370 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3370 D_fake_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3370 D_tricked_loss= tensor(1.3136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3371 D_real_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3371 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3371 D_tricked_loss= tensor(1.3757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3372 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3372 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3372 D_tricked_loss= tensor(1.3714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3373 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3373 D_fake_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3373 D_tricked_loss= tensor(1.4034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3374 D_real_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3374 D_fake_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3374 D_tricked_loss= tensor(1.3772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3375 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3375 D_fake_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3375 D_tricked_loss= tensor(1.3465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3376 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3376 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3376 D_tricked_loss= tensor(1.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3377 D_real_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3377 D_fake_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3377 D_tricked_loss= tensor(1.3946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3378 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3378 D_fake_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3378 D_tricked_loss= tensor(1.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3379 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3379 D_fake_loss= tensor(0.4952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3379 D_tricked_loss= tensor(1.4082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3380 D_real_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3380 D_fake_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3380 D_tricked_loss= tensor(1.3775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3381 D_real_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3381 D_fake_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3381 D_tricked_loss= tensor(1.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3382 D_real_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3382 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3382 D_tricked_loss= tensor(1.3606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3383 D_real_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3383 D_fake_loss= tensor(0.5100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3383 D_tricked_loss= tensor(1.3025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3384 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3384 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3384 D_tricked_loss= tensor(1.3130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3385 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3385 D_fake_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3385 D_tricked_loss= tensor(1.3346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3386 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3386 D_fake_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3386 D_tricked_loss= tensor(1.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3387 D_real_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3387 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3387 D_tricked_loss= tensor(1.3340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3388 D_real_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3388 D_fake_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3388 D_tricked_loss= tensor(1.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3389 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3389 D_fake_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3389 D_tricked_loss= tensor(1.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3390 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3390 D_fake_loss= tensor(0.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3390 D_tricked_loss= tensor(1.3625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3391 D_real_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3391 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3391 D_tricked_loss= tensor(1.3750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3392 D_real_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3392 D_fake_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3392 D_tricked_loss= tensor(1.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3393 D_real_loss= tensor(0.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3393 D_fake_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3393 D_tricked_loss= tensor(1.3663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3394 D_real_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3394 D_fake_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3394 D_tricked_loss= tensor(1.4040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3395 D_real_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3395 D_fake_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3395 D_tricked_loss= tensor(1.3521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3396 D_real_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3396 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3396 D_tricked_loss= tensor(1.3527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3397 D_real_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3397 D_fake_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3397 D_tricked_loss= tensor(1.3321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3398 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3398 D_fake_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3398 D_tricked_loss= tensor(1.3616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3399 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3399 D_fake_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3399 D_tricked_loss= tensor(1.3745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3400 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3400 D_fake_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3400 D_tricked_loss= tensor(1.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3401 D_real_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3401 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3401 D_tricked_loss= tensor(1.3812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3402 D_real_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3402 D_fake_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3402 D_tricked_loss= tensor(1.3938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3403 D_real_loss= tensor(0.5155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3403 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3403 D_tricked_loss= tensor(1.3570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3404 D_real_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3404 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3404 D_tricked_loss= tensor(1.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3405 D_real_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3405 D_fake_loss= tensor(0.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3405 D_tricked_loss= tensor(1.3984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3406 D_real_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3406 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3406 D_tricked_loss= tensor(1.3667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3407 D_real_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3407 D_fake_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3407 D_tricked_loss= tensor(1.3739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3408 D_real_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3408 D_fake_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3408 D_tricked_loss= tensor(1.3665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3409 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3409 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3409 D_tricked_loss= tensor(1.3371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3410 D_real_loss= tensor(0.5327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3410 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3410 D_tricked_loss= tensor(1.3163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3411 D_real_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3411 D_fake_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3411 D_tricked_loss= tensor(1.3274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3412 D_real_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3412 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3412 D_tricked_loss= tensor(1.3020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3413 D_real_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3413 D_fake_loss= tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3413 D_tricked_loss= tensor(1.3091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3414 D_real_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3414 D_fake_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3414 D_tricked_loss= tensor(1.2955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3415 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3415 D_fake_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3415 D_tricked_loss= tensor(1.3136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3416 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3416 D_fake_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3416 D_tricked_loss= tensor(1.3729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3417 D_real_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3417 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3417 D_tricked_loss= tensor(1.3570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3418 D_real_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3418 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3418 D_tricked_loss= tensor(1.3520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3419 D_real_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3419 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3419 D_tricked_loss= tensor(1.3664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3420 D_real_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3420 D_fake_loss= tensor(0.4973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3420 D_tricked_loss= tensor(1.3382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3421 D_real_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3421 D_fake_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3421 D_tricked_loss= tensor(1.4124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3422 D_real_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3422 D_fake_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3422 D_tricked_loss= tensor(1.4032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3423 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3423 D_fake_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3423 D_tricked_loss= tensor(1.2879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3424 D_real_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3424 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3424 D_tricked_loss= tensor(1.3373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3425 D_real_loss= tensor(0.5155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3425 D_fake_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3425 D_tricked_loss= tensor(1.3496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3426 D_real_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3426 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3426 D_tricked_loss= tensor(1.3342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3427 D_real_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3427 D_fake_loss= tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3427 D_tricked_loss= tensor(1.3676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3428 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3428 D_fake_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3428 D_tricked_loss= tensor(1.3344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3429 D_real_loss= tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3429 D_fake_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3429 D_tricked_loss= tensor(1.3898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3430 D_real_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3430 D_fake_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3430 D_tricked_loss= tensor(1.3218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3431 D_real_loss= tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3431 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3431 D_tricked_loss= tensor(1.3649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3432 D_real_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3432 D_fake_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3432 D_tricked_loss= tensor(1.2728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3433 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3433 D_fake_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3433 D_tricked_loss= tensor(1.3517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3434 D_real_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3434 D_fake_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3434 D_tricked_loss= tensor(1.3372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3435 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3435 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3435 D_tricked_loss= tensor(1.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3436 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3436 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3436 D_tricked_loss= tensor(1.3631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3437 D_real_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3437 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3437 D_tricked_loss= tensor(1.4085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3438 D_real_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3438 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3438 D_tricked_loss= tensor(1.3209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3439 D_real_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3439 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3439 D_tricked_loss= tensor(1.3419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3440 D_real_loss= tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3440 D_fake_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3440 D_tricked_loss= tensor(1.3199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3441 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3441 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3441 D_tricked_loss= tensor(1.3460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3442 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3442 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3442 D_tricked_loss= tensor(1.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3443 D_real_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3443 D_fake_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3443 D_tricked_loss= tensor(1.3726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3444 D_real_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3444 D_fake_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3444 D_tricked_loss= tensor(1.3429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3445 D_real_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3445 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3445 D_tricked_loss= tensor(1.4072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3446 D_real_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3446 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3446 D_tricked_loss= tensor(1.3344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3447 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3447 D_fake_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3447 D_tricked_loss= tensor(1.4046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3448 D_real_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3448 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3448 D_tricked_loss= tensor(1.4022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3449 D_real_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3449 D_fake_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3449 D_tricked_loss= tensor(1.3891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3450 D_real_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3450 D_fake_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3450 D_tricked_loss= tensor(1.3683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3451 D_real_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3451 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3451 D_tricked_loss= tensor(1.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3452 D_real_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3452 D_fake_loss= tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3452 D_tricked_loss= tensor(1.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3453 D_real_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3453 D_fake_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3453 D_tricked_loss= tensor(1.3700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3454 D_real_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3454 D_fake_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3454 D_tricked_loss= tensor(1.3548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3455 D_real_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3455 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3455 D_tricked_loss= tensor(1.3273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3456 D_real_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3456 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3456 D_tricked_loss= tensor(1.3265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3457 D_real_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3457 D_fake_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3457 D_tricked_loss= tensor(1.3635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3458 D_real_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3458 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3458 D_tricked_loss= tensor(1.3733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3459 D_real_loss= tensor(0.5139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3459 D_fake_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3459 D_tricked_loss= tensor(1.3735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3460 D_real_loss= tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3460 D_fake_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3460 D_tricked_loss= tensor(1.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3461 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3461 D_fake_loss= tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3461 D_tricked_loss= tensor(1.3732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3462 D_real_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3462 D_fake_loss= tensor(0.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3462 D_tricked_loss= tensor(1.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3463 D_real_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3463 D_fake_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3463 D_tricked_loss= tensor(1.3872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3464 D_real_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3464 D_fake_loss= tensor(0.5218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3464 D_tricked_loss= tensor(1.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3465 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3465 D_fake_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3465 D_tricked_loss= tensor(1.3755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3466 D_real_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3466 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3466 D_tricked_loss= tensor(1.3801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3467 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3467 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3467 D_tricked_loss= tensor(1.3844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3468 D_real_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3468 D_fake_loss= tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3468 D_tricked_loss= tensor(1.3226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3469 D_real_loss= tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3469 D_fake_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3469 D_tricked_loss= tensor(1.3530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3470 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3470 D_fake_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3470 D_tricked_loss= tensor(1.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3471 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3471 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3471 D_tricked_loss= tensor(1.3647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3472 D_real_loss= tensor(0.5073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3472 D_fake_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3472 D_tricked_loss= tensor(1.3752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3473 D_real_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3473 D_fake_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3473 D_tricked_loss= tensor(1.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3474 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3474 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3474 D_tricked_loss= tensor(1.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3475 D_real_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3475 D_fake_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3475 D_tricked_loss= tensor(1.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3476 D_real_loss= tensor(0.5303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3476 D_fake_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3476 D_tricked_loss= tensor(1.3722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3477 D_real_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3477 D_fake_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3477 D_tricked_loss= tensor(1.3552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3478 D_real_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3478 D_fake_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3478 D_tricked_loss= tensor(1.4051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3479 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3479 D_fake_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3479 D_tricked_loss= tensor(1.3928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3480 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3480 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3480 D_tricked_loss= tensor(1.3949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3481 D_real_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3481 D_fake_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3481 D_tricked_loss= tensor(1.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3482 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3482 D_fake_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3482 D_tricked_loss= tensor(1.3394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3483 D_real_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3483 D_fake_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3483 D_tricked_loss= tensor(1.3658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3484 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3484 D_fake_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3484 D_tricked_loss= tensor(1.3455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3485 D_real_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3485 D_fake_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3485 D_tricked_loss= tensor(1.3272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3486 D_real_loss= tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3486 D_fake_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3486 D_tricked_loss= tensor(1.3003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3487 D_real_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3487 D_fake_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3487 D_tricked_loss= tensor(1.3259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3488 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3488 D_fake_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3488 D_tricked_loss= tensor(1.3322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3489 D_real_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3489 D_fake_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3489 D_tricked_loss= tensor(1.2744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3490 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3490 D_fake_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3490 D_tricked_loss= tensor(1.3486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3491 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3491 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3491 D_tricked_loss= tensor(1.3440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3492 D_real_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3492 D_fake_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3492 D_tricked_loss= tensor(1.2974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3493 D_real_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3493 D_fake_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3493 D_tricked_loss= tensor(1.3831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3494 D_real_loss= tensor(0.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3494 D_fake_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3494 D_tricked_loss= tensor(1.3889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3495 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3495 D_fake_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3495 D_tricked_loss= tensor(1.3404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3496 D_real_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3496 D_fake_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3496 D_tricked_loss= tensor(1.3276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3497 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3497 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3497 D_tricked_loss= tensor(1.3038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3498 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3498 D_fake_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3498 D_tricked_loss= tensor(1.3299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3499 D_real_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3499 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3499 D_tricked_loss= tensor(1.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3500 D_real_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3500 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3500 D_tricked_loss= tensor(1.3336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3501 D_real_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3501 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3501 D_tricked_loss= tensor(1.3895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3502 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3502 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3502 D_tricked_loss= tensor(1.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3503 D_real_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3503 D_fake_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3503 D_tricked_loss= tensor(1.3703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3504 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3504 D_fake_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3504 D_tricked_loss= tensor(1.3466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3505 D_real_loss= tensor(0.4949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3505 D_fake_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3505 D_tricked_loss= tensor(1.3637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3506 D_real_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3506 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3506 D_tricked_loss= tensor(1.3859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3507 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3507 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3507 D_tricked_loss= tensor(1.3678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3508 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3508 D_fake_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3508 D_tricked_loss= tensor(1.3481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3509 D_real_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3509 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3509 D_tricked_loss= tensor(1.3387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3510 D_real_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3510 D_fake_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3510 D_tricked_loss= tensor(1.3477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3511 D_real_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3511 D_fake_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3511 D_tricked_loss= tensor(1.3311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3512 D_real_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3512 D_fake_loss= tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3512 D_tricked_loss= tensor(1.3658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3513 D_real_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3513 D_fake_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3513 D_tricked_loss= tensor(1.3430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3514 D_real_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3514 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3514 D_tricked_loss= tensor(1.3395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3515 D_real_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3515 D_fake_loss= tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3515 D_tricked_loss= tensor(1.3179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3516 D_real_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3516 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3516 D_tricked_loss= tensor(1.3300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3517 D_real_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3517 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3517 D_tricked_loss= tensor(1.3988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3518 D_real_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3518 D_fake_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3518 D_tricked_loss= tensor(1.3621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3519 D_real_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3519 D_fake_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3519 D_tricked_loss= tensor(1.4094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3520 D_real_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3520 D_fake_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3520 D_tricked_loss= tensor(1.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3521 D_real_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3521 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3521 D_tricked_loss= tensor(1.4011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3522 D_real_loss= tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3522 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3522 D_tricked_loss= tensor(1.3494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3523 D_real_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3523 D_fake_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3523 D_tricked_loss= tensor(1.3266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3524 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3524 D_fake_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3524 D_tricked_loss= tensor(1.3327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3525 D_real_loss= tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3525 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3525 D_tricked_loss= tensor(1.3108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3526 D_real_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3526 D_fake_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3526 D_tricked_loss= tensor(1.3057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3527 D_real_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3527 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3527 D_tricked_loss= tensor(1.3373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3528 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3528 D_fake_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3528 D_tricked_loss= tensor(1.2811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3529 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3529 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3529 D_tricked_loss= tensor(1.3002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3530 D_real_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3530 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3530 D_tricked_loss= tensor(1.3359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3531 D_real_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3531 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3531 D_tricked_loss= tensor(1.2721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3532 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3532 D_fake_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3532 D_tricked_loss= tensor(1.2925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3533 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3533 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3533 D_tricked_loss= tensor(1.3080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3534 D_real_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3534 D_fake_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3534 D_tricked_loss= tensor(1.2903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3535 D_real_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3535 D_fake_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3535 D_tricked_loss= tensor(1.2991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3536 D_real_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3536 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3536 D_tricked_loss= tensor(1.3352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3537 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3537 D_fake_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3537 D_tricked_loss= tensor(1.3167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3538 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3538 D_fake_loss= tensor(0.5155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3538 D_tricked_loss= tensor(1.3097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3539 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3539 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3539 D_tricked_loss= tensor(1.3646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3540 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3540 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3540 D_tricked_loss= tensor(1.3938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3541 D_real_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3541 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3541 D_tricked_loss= tensor(1.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3542 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3542 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3542 D_tricked_loss= tensor(1.3467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3543 D_real_loss= tensor(0.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3543 D_fake_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3543 D_tricked_loss= tensor(1.3014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3544 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3544 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3544 D_tricked_loss= tensor(1.3053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3545 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3545 D_fake_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3545 D_tricked_loss= tensor(1.3160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3546 D_real_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3546 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3546 D_tricked_loss= tensor(1.3122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3547 D_real_loss= tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3547 D_fake_loss= tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3547 D_tricked_loss= tensor(1.2757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3548 D_real_loss= tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3548 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3548 D_tricked_loss= tensor(1.2836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3549 D_real_loss= tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3549 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3549 D_tricked_loss= tensor(1.2688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3550 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3550 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3550 D_tricked_loss= tensor(1.3172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3551 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3551 D_fake_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3551 D_tricked_loss= tensor(1.3400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3552 D_real_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3552 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3552 D_tricked_loss= tensor(1.3965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3553 D_real_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3553 D_fake_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3553 D_tricked_loss= tensor(1.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3554 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3554 D_fake_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3554 D_tricked_loss= tensor(1.2978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3555 D_real_loss= tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3555 D_fake_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3555 D_tricked_loss= tensor(1.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3556 D_real_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3556 D_fake_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3556 D_tricked_loss= tensor(1.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3557 D_real_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3557 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3557 D_tricked_loss= tensor(1.3905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3558 D_real_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3558 D_fake_loss= tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3558 D_tricked_loss= tensor(1.3823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3559 D_real_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3559 D_fake_loss= tensor(0.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3559 D_tricked_loss= tensor(1.3486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3560 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3560 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3560 D_tricked_loss= tensor(1.3514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3561 D_real_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3561 D_fake_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3561 D_tricked_loss= tensor(1.3022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3562 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3562 D_fake_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3562 D_tricked_loss= tensor(1.3633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3563 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3563 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3563 D_tricked_loss= tensor(1.3774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3564 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3564 D_fake_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3564 D_tricked_loss= tensor(1.3847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3565 D_real_loss= tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3565 D_fake_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3565 D_tricked_loss= tensor(1.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3566 D_real_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3566 D_fake_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3566 D_tricked_loss= tensor(1.3232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3567 D_real_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3567 D_fake_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3567 D_tricked_loss= tensor(1.3428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3568 D_real_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3568 D_fake_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3568 D_tricked_loss= tensor(1.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3569 D_real_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3569 D_fake_loss= tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3569 D_tricked_loss= tensor(1.3580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3570 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3570 D_fake_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3570 D_tricked_loss= tensor(1.3368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3571 D_real_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3571 D_fake_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3571 D_tricked_loss= tensor(1.3657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3572 D_real_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3572 D_fake_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3572 D_tricked_loss= tensor(1.3675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3573 D_real_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3573 D_fake_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3573 D_tricked_loss= tensor(1.3676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3574 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3574 D_fake_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3574 D_tricked_loss= tensor(1.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3575 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3575 D_fake_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3575 D_tricked_loss= tensor(1.3496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3576 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3576 D_fake_loss= tensor(0.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3576 D_tricked_loss= tensor(1.3428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3577 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3577 D_fake_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3577 D_tricked_loss= tensor(1.2668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3578 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3578 D_fake_loss= tensor(0.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3578 D_tricked_loss= tensor(1.3211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3579 D_real_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3579 D_fake_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3579 D_tricked_loss= tensor(1.3430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3580 D_real_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3580 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3580 D_tricked_loss= tensor(1.2869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3581 D_real_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3581 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3581 D_tricked_loss= tensor(1.3402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3582 D_real_loss= tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3582 D_fake_loss= tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3582 D_tricked_loss= tensor(1.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3583 D_real_loss= tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3583 D_fake_loss= tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3583 D_tricked_loss= tensor(1.3328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3584 D_real_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3584 D_fake_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3584 D_tricked_loss= tensor(1.3078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3585 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3585 D_fake_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3585 D_tricked_loss= tensor(1.3187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3586 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3586 D_fake_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3586 D_tricked_loss= tensor(1.3732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3587 D_real_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3587 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3587 D_tricked_loss= tensor(1.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3588 D_real_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3588 D_fake_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3588 D_tricked_loss= tensor(1.3545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3589 D_real_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3589 D_fake_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3589 D_tricked_loss= tensor(1.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3590 D_real_loss= tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3590 D_fake_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3590 D_tricked_loss= tensor(1.3593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3591 D_real_loss= tensor(0.4967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3591 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3591 D_tricked_loss= tensor(1.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3592 D_real_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3592 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3592 D_tricked_loss= tensor(1.3685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3593 D_real_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3593 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3593 D_tricked_loss= tensor(1.3549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3594 D_real_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3594 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3594 D_tricked_loss= tensor(1.4282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3595 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3595 D_fake_loss= tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3595 D_tricked_loss= tensor(1.3702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3596 D_real_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3596 D_fake_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3596 D_tricked_loss= tensor(1.3374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3597 D_real_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3597 D_fake_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3597 D_tricked_loss= tensor(1.3697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3598 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3598 D_fake_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3598 D_tricked_loss= tensor(1.3071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3599 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3599 D_fake_loss= tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3599 D_tricked_loss= tensor(1.3096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3600 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3600 D_fake_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3600 D_tricked_loss= tensor(1.2947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3601 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3601 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3601 D_tricked_loss= tensor(1.3223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3602 D_real_loss= tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3602 D_fake_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3602 D_tricked_loss= tensor(1.2961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3603 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3603 D_fake_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3603 D_tricked_loss= tensor(1.2867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3604 D_real_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3604 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3604 D_tricked_loss= tensor(1.3307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3605 D_real_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3605 D_fake_loss= tensor(0.5327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3605 D_tricked_loss= tensor(1.3271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3606 D_real_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3606 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3606 D_tricked_loss= tensor(1.3354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3607 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3607 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3607 D_tricked_loss= tensor(1.3506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3608 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3608 D_fake_loss= tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3608 D_tricked_loss= tensor(1.3168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3609 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3609 D_fake_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3609 D_tricked_loss= tensor(1.3763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3610 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3610 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3610 D_tricked_loss= tensor(1.3157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3611 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3611 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3611 D_tricked_loss= tensor(1.3604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3612 D_real_loss= tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3612 D_fake_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3612 D_tricked_loss= tensor(1.3282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3613 D_real_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3613 D_fake_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3613 D_tricked_loss= tensor(1.3194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3614 D_real_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3614 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3614 D_tricked_loss= tensor(1.4007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3615 D_real_loss= tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3615 D_fake_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3615 D_tricked_loss= tensor(1.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3616 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3616 D_fake_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3616 D_tricked_loss= tensor(1.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3617 D_real_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3617 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3617 D_tricked_loss= tensor(1.3649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3618 D_real_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3618 D_fake_loss= tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3618 D_tricked_loss= tensor(1.3495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3619 D_real_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3619 D_fake_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3619 D_tricked_loss= tensor(1.3544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3620 D_real_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3620 D_fake_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3620 D_tricked_loss= tensor(1.3262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3621 D_real_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3621 D_fake_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3621 D_tricked_loss= tensor(1.2884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3622 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3622 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3622 D_tricked_loss= tensor(1.3059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3623 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3623 D_fake_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3623 D_tricked_loss= tensor(1.3104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3624 D_real_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3624 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3624 D_tricked_loss= tensor(1.2663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3625 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3625 D_fake_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3625 D_tricked_loss= tensor(1.2822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3626 D_real_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3626 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3626 D_tricked_loss= tensor(1.3371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3627 D_real_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3627 D_fake_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3627 D_tricked_loss= tensor(1.3482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3628 D_real_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3628 D_fake_loss= tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3628 D_tricked_loss= tensor(1.3132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3629 D_real_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3629 D_fake_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3629 D_tricked_loss= tensor(1.3583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3630 D_real_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3630 D_fake_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3630 D_tricked_loss= tensor(1.3499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3631 D_real_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3631 D_fake_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3631 D_tricked_loss= tensor(1.3215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3632 D_real_loss= tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3632 D_fake_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3632 D_tricked_loss= tensor(1.3408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3633 D_real_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3633 D_fake_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3633 D_tricked_loss= tensor(1.2679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3634 D_real_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3634 D_fake_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3634 D_tricked_loss= tensor(1.2967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3635 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3635 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3635 D_tricked_loss= tensor(1.3088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3636 D_real_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3636 D_fake_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3636 D_tricked_loss= tensor(1.3369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3637 D_real_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3637 D_fake_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3637 D_tricked_loss= tensor(1.3380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3638 D_real_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3638 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3638 D_tricked_loss= tensor(1.2795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3639 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3639 D_fake_loss= tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3639 D_tricked_loss= tensor(1.3042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3640 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3640 D_fake_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3640 D_tricked_loss= tensor(1.3668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3641 D_real_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3641 D_fake_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3641 D_tricked_loss= tensor(1.3293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3642 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3642 D_fake_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3642 D_tricked_loss= tensor(1.3565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3643 D_real_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3643 D_fake_loss= tensor(0.5131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3643 D_tricked_loss= tensor(1.3474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3644 D_real_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3644 D_fake_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3644 D_tricked_loss= tensor(1.3627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3645 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3645 D_fake_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3645 D_tricked_loss= tensor(1.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3646 D_real_loss= tensor(0.5053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3646 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3646 D_tricked_loss= tensor(1.3273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3647 D_real_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3647 D_fake_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3647 D_tricked_loss= tensor(1.3379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3648 D_real_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3648 D_fake_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3648 D_tricked_loss= tensor(1.3331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3649 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3649 D_fake_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3649 D_tricked_loss= tensor(1.2987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3650 D_real_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3650 D_fake_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3650 D_tricked_loss= tensor(1.3266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3651 D_real_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3651 D_fake_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3651 D_tricked_loss= tensor(1.3008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3652 D_real_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3652 D_fake_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3652 D_tricked_loss= tensor(1.2617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3653 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3653 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3653 D_tricked_loss= tensor(1.2649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3654 D_real_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3654 D_fake_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3654 D_tricked_loss= tensor(1.2946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3655 D_real_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3655 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3655 D_tricked_loss= tensor(1.2712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3656 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3656 D_fake_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3656 D_tricked_loss= tensor(1.2644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3657 D_real_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3657 D_fake_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3657 D_tricked_loss= tensor(1.2815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3658 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3658 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3658 D_tricked_loss= tensor(1.2941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3659 D_real_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3659 D_fake_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3659 D_tricked_loss= tensor(1.3174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3660 D_real_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3660 D_fake_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3660 D_tricked_loss= tensor(1.2700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3661 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3661 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3661 D_tricked_loss= tensor(1.2719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3662 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3662 D_fake_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3662 D_tricked_loss= tensor(1.2735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3663 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3663 D_fake_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3663 D_tricked_loss= tensor(1.2233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3664 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3664 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3664 D_tricked_loss= tensor(1.2488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3665 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3665 D_fake_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3665 D_tricked_loss= tensor(1.2697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3666 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3666 D_fake_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3666 D_tricked_loss= tensor(1.2454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3667 D_real_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3667 D_fake_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3667 D_tricked_loss= tensor(1.2753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3668 D_real_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3668 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3668 D_tricked_loss= tensor(1.2863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3669 D_real_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3669 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3669 D_tricked_loss= tensor(1.2816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3670 D_real_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3670 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3670 D_tricked_loss= tensor(1.3126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3671 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3671 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3671 D_tricked_loss= tensor(1.3292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3672 D_real_loss= tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3672 D_fake_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3672 D_tricked_loss= tensor(1.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3673 D_real_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3673 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3673 D_tricked_loss= tensor(1.3518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3674 D_real_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3674 D_fake_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3674 D_tricked_loss= tensor(1.3076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3675 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3675 D_fake_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3675 D_tricked_loss= tensor(1.3244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3676 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3676 D_fake_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3676 D_tricked_loss= tensor(1.3132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3677 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3677 D_fake_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3677 D_tricked_loss= tensor(1.2195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3678 D_real_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3678 D_fake_loss= tensor(0.5098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3678 D_tricked_loss= tensor(1.2491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3679 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3679 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3679 D_tricked_loss= tensor(1.2413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3680 D_real_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3680 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3680 D_tricked_loss= tensor(1.2658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3681 D_real_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3681 D_fake_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3681 D_tricked_loss= tensor(1.3080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3682 D_real_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3682 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3682 D_tricked_loss= tensor(1.2818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3683 D_real_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3683 D_fake_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3683 D_tricked_loss= tensor(1.2853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3684 D_real_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3684 D_fake_loss= tensor(0.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3684 D_tricked_loss= tensor(1.3072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3685 D_real_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3685 D_fake_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3685 D_tricked_loss= tensor(1.2722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3686 D_real_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3686 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3686 D_tricked_loss= tensor(1.2747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3687 D_real_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3687 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3687 D_tricked_loss= tensor(1.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3688 D_real_loss= tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3688 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3688 D_tricked_loss= tensor(1.2745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3689 D_real_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3689 D_fake_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3689 D_tricked_loss= tensor(1.2591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3690 D_real_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3690 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3690 D_tricked_loss= tensor(1.2240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3691 D_real_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3691 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3691 D_tricked_loss= tensor(1.2767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3692 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3692 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3692 D_tricked_loss= tensor(1.2596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3693 D_real_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3693 D_fake_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3693 D_tricked_loss= tensor(1.2656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3694 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3694 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3694 D_tricked_loss= tensor(1.2731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3695 D_real_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3695 D_fake_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3695 D_tricked_loss= tensor(1.3192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3696 D_real_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3696 D_fake_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3696 D_tricked_loss= tensor(1.3478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3697 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3697 D_fake_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3697 D_tricked_loss= tensor(1.3263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3698 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3698 D_fake_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3698 D_tricked_loss= tensor(1.3151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3699 D_real_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3699 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3699 D_tricked_loss= tensor(1.2895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3700 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3700 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3700 D_tricked_loss= tensor(1.2815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3701 D_real_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3701 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3701 D_tricked_loss= tensor(1.3196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3702 D_real_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3702 D_fake_loss= tensor(0.5012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3702 D_tricked_loss= tensor(1.2851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3703 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3703 D_fake_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3703 D_tricked_loss= tensor(1.3267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3704 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3704 D_fake_loss= tensor(0.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3704 D_tricked_loss= tensor(1.3400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3705 D_real_loss= tensor(0.5139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3705 D_fake_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3705 D_tricked_loss= tensor(1.3238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3706 D_real_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3706 D_fake_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3706 D_tricked_loss= tensor(1.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3707 D_real_loss= tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3707 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3707 D_tricked_loss= tensor(1.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3708 D_real_loss= tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3708 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3708 D_tricked_loss= tensor(1.4145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3709 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3709 D_fake_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3709 D_tricked_loss= tensor(1.3653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3710 D_real_loss= tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3710 D_fake_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3710 D_tricked_loss= tensor(1.3822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3711 D_real_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3711 D_fake_loss= tensor(0.5347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3711 D_tricked_loss= tensor(1.3124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3712 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3712 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3712 D_tricked_loss= tensor(1.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3713 D_real_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3713 D_fake_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3713 D_tricked_loss= tensor(1.3640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3714 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3714 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3714 D_tricked_loss= tensor(1.3413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3715 D_real_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3715 D_fake_loss= tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3715 D_tricked_loss= tensor(1.3269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3716 D_real_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3716 D_fake_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3716 D_tricked_loss= tensor(1.3002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3717 D_real_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3717 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3717 D_tricked_loss= tensor(1.2767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3718 D_real_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3718 D_fake_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3718 D_tricked_loss= tensor(1.3263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3719 D_real_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3719 D_fake_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3719 D_tricked_loss= tensor(1.3225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3720 D_real_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3720 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3720 D_tricked_loss= tensor(1.4063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3721 D_real_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3721 D_fake_loss= tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3721 D_tricked_loss= tensor(1.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3722 D_real_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3722 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3722 D_tricked_loss= tensor(1.2762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3723 D_real_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3723 D_fake_loss= tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3723 D_tricked_loss= tensor(1.3160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3724 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3724 D_fake_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3724 D_tricked_loss= tensor(1.3472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3725 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3725 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3725 D_tricked_loss= tensor(1.3129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3726 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3726 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3726 D_tricked_loss= tensor(1.2661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3727 D_real_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3727 D_fake_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3727 D_tricked_loss= tensor(1.2656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3728 D_real_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3728 D_fake_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3728 D_tricked_loss= tensor(1.3470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3729 D_real_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3729 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3729 D_tricked_loss= tensor(1.3109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3730 D_real_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3730 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3730 D_tricked_loss= tensor(1.2873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3731 D_real_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3731 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3731 D_tricked_loss= tensor(1.3159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3732 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3732 D_fake_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3732 D_tricked_loss= tensor(1.2373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3733 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3733 D_fake_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3733 D_tricked_loss= tensor(1.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3734 D_real_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3734 D_fake_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3734 D_tricked_loss= tensor(1.3401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3735 D_real_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3735 D_fake_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3735 D_tricked_loss= tensor(1.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3736 D_real_loss= tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3736 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3736 D_tricked_loss= tensor(1.2766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3737 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3737 D_fake_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3737 D_tricked_loss= tensor(1.3446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3738 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3738 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3738 D_tricked_loss= tensor(1.2401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3739 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3739 D_fake_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3739 D_tricked_loss= tensor(1.2417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3740 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3740 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3740 D_tricked_loss= tensor(1.2546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3741 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3741 D_fake_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3741 D_tricked_loss= tensor(1.2737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3742 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3742 D_fake_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3742 D_tricked_loss= tensor(1.2690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3743 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3743 D_fake_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3743 D_tricked_loss= tensor(1.2841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3744 D_real_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3744 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3744 D_tricked_loss= tensor(1.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3745 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3745 D_fake_loss= tensor(0.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3745 D_tricked_loss= tensor(1.3692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3746 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3746 D_fake_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3746 D_tricked_loss= tensor(1.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3747 D_real_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3747 D_fake_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3747 D_tricked_loss= tensor(1.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3748 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3748 D_fake_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3748 D_tricked_loss= tensor(1.3331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3749 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3749 D_fake_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3749 D_tricked_loss= tensor(1.3633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3750 D_real_loss= tensor(0.5303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3750 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3750 D_tricked_loss= tensor(1.3585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3751 D_real_loss= tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3751 D_fake_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3751 D_tricked_loss= tensor(1.2681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3752 D_real_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3752 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3752 D_tricked_loss= tensor(1.2853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3753 D_real_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3753 D_fake_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3753 D_tricked_loss= tensor(1.3106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3754 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3754 D_fake_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3754 D_tricked_loss= tensor(1.2459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3755 D_real_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3755 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3755 D_tricked_loss= tensor(1.2221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3756 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3756 D_fake_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3756 D_tricked_loss= tensor(1.2888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3757 D_real_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3757 D_fake_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3757 D_tricked_loss= tensor(1.2470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3758 D_real_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3758 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3758 D_tricked_loss= tensor(1.3105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3759 D_real_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3759 D_fake_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3759 D_tricked_loss= tensor(1.2632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3760 D_real_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3760 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3760 D_tricked_loss= tensor(1.2601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3761 D_real_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3761 D_fake_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3761 D_tricked_loss= tensor(1.3390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3762 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3762 D_fake_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3762 D_tricked_loss= tensor(1.2824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3763 D_real_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3763 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3763 D_tricked_loss= tensor(1.3204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3764 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3764 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3764 D_tricked_loss= tensor(1.2543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3765 D_real_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3765 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3765 D_tricked_loss= tensor(1.2744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3766 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3766 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3766 D_tricked_loss= tensor(1.2841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3767 D_real_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3767 D_fake_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3767 D_tricked_loss= tensor(1.2978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3768 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3768 D_fake_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3768 D_tricked_loss= tensor(1.2507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3769 D_real_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3769 D_fake_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3769 D_tricked_loss= tensor(1.2715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3770 D_real_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3770 D_fake_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3770 D_tricked_loss= tensor(1.2599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3771 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3771 D_fake_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3771 D_tricked_loss= tensor(1.2571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3772 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3772 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3772 D_tricked_loss= tensor(1.2832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3773 D_real_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3773 D_fake_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3773 D_tricked_loss= tensor(1.2933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3774 D_real_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3774 D_fake_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3774 D_tricked_loss= tensor(1.3299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3775 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3775 D_fake_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3775 D_tricked_loss= tensor(1.2896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3776 D_real_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3776 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3776 D_tricked_loss= tensor(1.2897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3777 D_real_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3777 D_fake_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3777 D_tricked_loss= tensor(1.2837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3778 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3778 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3778 D_tricked_loss= tensor(1.2377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3779 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3779 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3779 D_tricked_loss= tensor(1.2616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3780 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3780 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3780 D_tricked_loss= tensor(1.2675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3781 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3781 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3781 D_tricked_loss= tensor(1.2847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3782 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3782 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3782 D_tricked_loss= tensor(1.3274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3783 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3783 D_fake_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3783 D_tricked_loss= tensor(1.2859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3784 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3784 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3784 D_tricked_loss= tensor(1.3691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3785 D_real_loss= tensor(0.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3785 D_fake_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3785 D_tricked_loss= tensor(1.2835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3786 D_real_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3786 D_fake_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3786 D_tricked_loss= tensor(1.3262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3787 D_real_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3787 D_fake_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3787 D_tricked_loss= tensor(1.2890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3788 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3788 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3788 D_tricked_loss= tensor(1.2811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3789 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3789 D_fake_loss= tensor(0.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3789 D_tricked_loss= tensor(1.3409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3790 D_real_loss= tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3790 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3790 D_tricked_loss= tensor(1.2988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3791 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3791 D_fake_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3791 D_tricked_loss= tensor(1.2737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3792 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3792 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3792 D_tricked_loss= tensor(1.2817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3793 D_real_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3793 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3793 D_tricked_loss= tensor(1.2696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3794 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3794 D_fake_loss= tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3794 D_tricked_loss= tensor(1.2090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3795 D_real_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3795 D_fake_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3795 D_tricked_loss= tensor(1.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3796 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3796 D_fake_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3796 D_tricked_loss= tensor(1.2440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3797 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3797 D_fake_loss= tensor(0.4997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3797 D_tricked_loss= tensor(1.3226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3798 D_real_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3798 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3798 D_tricked_loss= tensor(1.3134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3799 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3799 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3799 D_tricked_loss= tensor(1.2707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3800 D_real_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3800 D_fake_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3800 D_tricked_loss= tensor(1.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3801 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3801 D_fake_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3801 D_tricked_loss= tensor(1.2972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3802 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3802 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3802 D_tricked_loss= tensor(1.2793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3803 D_real_loss= tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3803 D_fake_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3803 D_tricked_loss= tensor(1.2657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3804 D_real_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3804 D_fake_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3804 D_tricked_loss= tensor(1.3182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3805 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3805 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3805 D_tricked_loss= tensor(1.3308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3806 D_real_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3806 D_fake_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3806 D_tricked_loss= tensor(1.3469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3807 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3807 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3807 D_tricked_loss= tensor(1.3188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3808 D_real_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3808 D_fake_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3808 D_tricked_loss= tensor(1.3310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3809 D_real_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3809 D_fake_loss= tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3809 D_tricked_loss= tensor(1.3491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3810 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3810 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3810 D_tricked_loss= tensor(1.2904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3811 D_real_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3811 D_fake_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3811 D_tricked_loss= tensor(1.2980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3812 D_real_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3812 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3812 D_tricked_loss= tensor(1.2839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3813 D_real_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3813 D_fake_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3813 D_tricked_loss= tensor(1.3707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3814 D_real_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3814 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3814 D_tricked_loss= tensor(1.3400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3815 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3815 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3815 D_tricked_loss= tensor(1.2215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3816 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3816 D_fake_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3816 D_tricked_loss= tensor(1.3270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3817 D_real_loss= tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3817 D_fake_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3817 D_tricked_loss= tensor(1.2602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3818 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3818 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3818 D_tricked_loss= tensor(1.2358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3819 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3819 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3819 D_tricked_loss= tensor(1.2696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3820 D_real_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3820 D_fake_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3820 D_tricked_loss= tensor(1.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3821 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3821 D_fake_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3821 D_tricked_loss= tensor(1.2554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3822 D_real_loss= tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3822 D_fake_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3822 D_tricked_loss= tensor(1.2041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3823 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3823 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3823 D_tricked_loss= tensor(1.2388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3824 D_real_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3824 D_fake_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3824 D_tricked_loss= tensor(1.2297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3825 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3825 D_fake_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3825 D_tricked_loss= tensor(1.2611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3826 D_real_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3826 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3826 D_tricked_loss= tensor(1.3308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3827 D_real_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3827 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3827 D_tricked_loss= tensor(1.2832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3828 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3828 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3828 D_tricked_loss= tensor(1.2695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3829 D_real_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3829 D_fake_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3829 D_tricked_loss= tensor(1.3143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3830 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3830 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3830 D_tricked_loss= tensor(1.2859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3831 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3831 D_fake_loss= tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3831 D_tricked_loss= tensor(1.3397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3832 D_real_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3832 D_fake_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3832 D_tricked_loss= tensor(1.2823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3833 D_real_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3833 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3833 D_tricked_loss= tensor(1.2524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3834 D_real_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3834 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3834 D_tricked_loss= tensor(1.2388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3835 D_real_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3835 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3835 D_tricked_loss= tensor(1.2311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3836 D_real_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3836 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3836 D_tricked_loss= tensor(1.2635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3837 D_real_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3837 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3837 D_tricked_loss= tensor(1.2995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3838 D_real_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3838 D_fake_loss= tensor(0.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3838 D_tricked_loss= tensor(1.2724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3839 D_real_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3839 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3839 D_tricked_loss= tensor(1.3628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3840 D_real_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3840 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3840 D_tricked_loss= tensor(1.2947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3841 D_real_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3841 D_fake_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3841 D_tricked_loss= tensor(1.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3842 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3842 D_fake_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3842 D_tricked_loss= tensor(1.2835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3843 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3843 D_fake_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3843 D_tricked_loss= tensor(1.2498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3844 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3844 D_fake_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3844 D_tricked_loss= tensor(1.2914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3845 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3845 D_fake_loss= tensor(0.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3845 D_tricked_loss= tensor(1.2247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3846 D_real_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3846 D_fake_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3846 D_tricked_loss= tensor(1.2293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3847 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3847 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3847 D_tricked_loss= tensor(1.2365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3848 D_real_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3848 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3848 D_tricked_loss= tensor(1.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3849 D_real_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3849 D_fake_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3849 D_tricked_loss= tensor(1.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3850 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3850 D_fake_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3850 D_tricked_loss= tensor(1.2421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3851 D_real_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3851 D_fake_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3851 D_tricked_loss= tensor(1.2466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3852 D_real_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3852 D_fake_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3852 D_tricked_loss= tensor(1.2720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3853 D_real_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3853 D_fake_loss= tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3853 D_tricked_loss= tensor(1.2317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3854 D_real_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3854 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3854 D_tricked_loss= tensor(1.3244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3855 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3855 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3855 D_tricked_loss= tensor(1.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3856 D_real_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3856 D_fake_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3856 D_tricked_loss= tensor(1.2733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3857 D_real_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3857 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3857 D_tricked_loss= tensor(1.3051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3858 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3858 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3858 D_tricked_loss= tensor(1.2677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3859 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3859 D_fake_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3859 D_tricked_loss= tensor(1.2648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3860 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3860 D_fake_loss= tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3860 D_tricked_loss= tensor(1.2446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3861 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3861 D_fake_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3861 D_tricked_loss= tensor(1.2606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3862 D_real_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3862 D_fake_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3862 D_tricked_loss= tensor(1.2913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3863 D_real_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3863 D_fake_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3863 D_tricked_loss= tensor(1.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3864 D_real_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3864 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3864 D_tricked_loss= tensor(1.2676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3865 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3865 D_fake_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3865 D_tricked_loss= tensor(1.2787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3866 D_real_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3866 D_fake_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3866 D_tricked_loss= tensor(1.2625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3867 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3867 D_fake_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3867 D_tricked_loss= tensor(1.2803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3868 D_real_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3868 D_fake_loss= tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3868 D_tricked_loss= tensor(1.3034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3869 D_real_loss= tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3869 D_fake_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3869 D_tricked_loss= tensor(1.2550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3870 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3870 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3870 D_tricked_loss= tensor(1.3562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3871 D_real_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3871 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3871 D_tricked_loss= tensor(1.2679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3872 D_real_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3872 D_fake_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3872 D_tricked_loss= tensor(1.3179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3873 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3873 D_fake_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3873 D_tricked_loss= tensor(1.3273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3874 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3874 D_fake_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3874 D_tricked_loss= tensor(1.2921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3875 D_real_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3875 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3875 D_tricked_loss= tensor(1.3154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3876 D_real_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3876 D_fake_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3876 D_tricked_loss= tensor(1.3077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3877 D_real_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3877 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3877 D_tricked_loss= tensor(1.3230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3878 D_real_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3878 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3878 D_tricked_loss= tensor(1.2805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3879 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3879 D_fake_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3879 D_tricked_loss= tensor(1.3020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3880 D_real_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3880 D_fake_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3880 D_tricked_loss= tensor(1.3452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3881 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3881 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3881 D_tricked_loss= tensor(1.2497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3882 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3882 D_fake_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3882 D_tricked_loss= tensor(1.2987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3883 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3883 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3883 D_tricked_loss= tensor(1.3190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3884 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3884 D_fake_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3884 D_tricked_loss= tensor(1.3114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3885 D_real_loss= tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3885 D_fake_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3885 D_tricked_loss= tensor(1.3572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3886 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3886 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3886 D_tricked_loss= tensor(1.3737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3887 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3887 D_fake_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3887 D_tricked_loss= tensor(1.2903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3888 D_real_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3888 D_fake_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3888 D_tricked_loss= tensor(1.3455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3889 D_real_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3889 D_fake_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3889 D_tricked_loss= tensor(1.3435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3890 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3890 D_fake_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3890 D_tricked_loss= tensor(1.3467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3891 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3891 D_fake_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3891 D_tricked_loss= tensor(1.2957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3892 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3892 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3892 D_tricked_loss= tensor(1.3144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3893 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3893 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3893 D_tricked_loss= tensor(1.2887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3894 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3894 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3894 D_tricked_loss= tensor(1.2950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3895 D_real_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3895 D_fake_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3895 D_tricked_loss= tensor(1.3212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3896 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3896 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3896 D_tricked_loss= tensor(1.2917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3897 D_real_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3897 D_fake_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3897 D_tricked_loss= tensor(1.2639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3898 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3898 D_fake_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3898 D_tricked_loss= tensor(1.2621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3899 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3899 D_fake_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3899 D_tricked_loss= tensor(1.2872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3900 D_real_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3900 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3900 D_tricked_loss= tensor(1.2563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3901 D_real_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3901 D_fake_loss= tensor(0.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3901 D_tricked_loss= tensor(1.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3902 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3902 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3902 D_tricked_loss= tensor(1.3324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3903 D_real_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3903 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3903 D_tricked_loss= tensor(1.3214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3904 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3904 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3904 D_tricked_loss= tensor(1.2549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3905 D_real_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3905 D_fake_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3905 D_tricked_loss= tensor(1.2426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3906 D_real_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3906 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3906 D_tricked_loss= tensor(1.2337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3907 D_real_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3907 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3907 D_tricked_loss= tensor(1.2671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3908 D_real_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3908 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3908 D_tricked_loss= tensor(1.2474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3909 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3909 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3909 D_tricked_loss= tensor(1.2257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3910 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3910 D_fake_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3910 D_tricked_loss= tensor(1.2230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3911 D_real_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3911 D_fake_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3911 D_tricked_loss= tensor(1.2207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3912 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3912 D_fake_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3912 D_tricked_loss= tensor(1.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3913 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3913 D_fake_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3913 D_tricked_loss= tensor(1.3165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3914 D_real_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3914 D_fake_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3914 D_tricked_loss= tensor(1.2693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3915 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3915 D_fake_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3915 D_tricked_loss= tensor(1.3107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3916 D_real_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3916 D_fake_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3916 D_tricked_loss= tensor(1.2656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3917 D_real_loss= tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3917 D_fake_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3917 D_tricked_loss= tensor(1.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3918 D_real_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3918 D_fake_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3918 D_tricked_loss= tensor(1.3110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3919 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3919 D_fake_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3919 D_tricked_loss= tensor(1.2559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3920 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3920 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3920 D_tricked_loss= tensor(1.2552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3921 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3921 D_fake_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3921 D_tricked_loss= tensor(1.3301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3922 D_real_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3922 D_fake_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3922 D_tricked_loss= tensor(1.2054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3923 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3923 D_fake_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3923 D_tricked_loss= tensor(1.2359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3924 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3924 D_fake_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3924 D_tricked_loss= tensor(1.2872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3925 D_real_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3925 D_fake_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3925 D_tricked_loss= tensor(1.2313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3926 D_real_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3926 D_fake_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3926 D_tricked_loss= tensor(1.2208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3927 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3927 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3927 D_tricked_loss= tensor(1.2404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3928 D_real_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3928 D_fake_loss= tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3928 D_tricked_loss= tensor(1.2028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3929 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3929 D_fake_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3929 D_tricked_loss= tensor(1.2810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3930 D_real_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3930 D_fake_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3930 D_tricked_loss= tensor(1.2685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3931 D_real_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3931 D_fake_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3931 D_tricked_loss= tensor(1.2773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3932 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3932 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3932 D_tricked_loss= tensor(1.2981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3933 D_real_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3933 D_fake_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3933 D_tricked_loss= tensor(1.2153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3934 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3934 D_fake_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3934 D_tricked_loss= tensor(1.2464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3935 D_real_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3935 D_fake_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3935 D_tricked_loss= tensor(1.2481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3936 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3936 D_fake_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3936 D_tricked_loss= tensor(1.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3937 D_real_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3937 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3937 D_tricked_loss= tensor(1.2675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3938 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3938 D_fake_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3938 D_tricked_loss= tensor(1.2086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3939 D_real_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3939 D_fake_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3939 D_tricked_loss= tensor(1.2556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3940 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3940 D_fake_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3940 D_tricked_loss= tensor(1.2079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3941 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3941 D_fake_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3941 D_tricked_loss= tensor(1.2339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3942 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3942 D_fake_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3942 D_tricked_loss= tensor(1.2301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3943 D_real_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3943 D_fake_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3943 D_tricked_loss= tensor(1.2439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3944 D_real_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3944 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3944 D_tricked_loss= tensor(1.3162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3945 D_real_loss= tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3945 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3945 D_tricked_loss= tensor(1.2387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3946 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3946 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3946 D_tricked_loss= tensor(1.2492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3947 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3947 D_fake_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3947 D_tricked_loss= tensor(1.2604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3948 D_real_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3948 D_fake_loss= tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3948 D_tricked_loss= tensor(1.2552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3949 D_real_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3949 D_fake_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3949 D_tricked_loss= tensor(1.2522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3950 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3950 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3950 D_tricked_loss= tensor(1.2301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3951 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3951 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3951 D_tricked_loss= tensor(1.2459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3952 D_real_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3952 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3952 D_tricked_loss= tensor(1.2095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3953 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3953 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3953 D_tricked_loss= tensor(1.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3954 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3954 D_fake_loss= tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3954 D_tricked_loss= tensor(1.2023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3955 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3955 D_fake_loss= tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3955 D_tricked_loss= tensor(1.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3956 D_real_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3956 D_fake_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3956 D_tricked_loss= tensor(1.2462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3957 D_real_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3957 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3957 D_tricked_loss= tensor(1.2694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3958 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3958 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3958 D_tricked_loss= tensor(1.2433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3959 D_real_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3959 D_fake_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3959 D_tricked_loss= tensor(1.2663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3960 D_real_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3960 D_fake_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3960 D_tricked_loss= tensor(1.2321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3961 D_real_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3961 D_fake_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3961 D_tricked_loss= tensor(1.2542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3962 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3962 D_fake_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3962 D_tricked_loss= tensor(1.1999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3963 D_real_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3963 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3963 D_tricked_loss= tensor(1.2551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3964 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3964 D_fake_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3964 D_tricked_loss= tensor(1.2240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3965 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3965 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3965 D_tricked_loss= tensor(1.2170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3966 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3966 D_fake_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3966 D_tricked_loss= tensor(1.2742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3967 D_real_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3967 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3967 D_tricked_loss= tensor(1.2749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3968 D_real_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3968 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3968 D_tricked_loss= tensor(1.2309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3969 D_real_loss= tensor(0.5225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3969 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3969 D_tricked_loss= tensor(1.2813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3970 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3970 D_fake_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3970 D_tricked_loss= tensor(1.3176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3971 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3971 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3971 D_tricked_loss= tensor(1.2614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3972 D_real_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3972 D_fake_loss= tensor(0.5225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3972 D_tricked_loss= tensor(1.2593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3973 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3973 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3973 D_tricked_loss= tensor(1.3059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3974 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3974 D_fake_loss= tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3974 D_tricked_loss= tensor(1.2645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3975 D_real_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3975 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3975 D_tricked_loss= tensor(1.3062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3976 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3976 D_fake_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3976 D_tricked_loss= tensor(1.2836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3977 D_real_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3977 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3977 D_tricked_loss= tensor(1.2791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3978 D_real_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3978 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3978 D_tricked_loss= tensor(1.2661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3979 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3979 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3979 D_tricked_loss= tensor(1.2223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3980 D_real_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3980 D_fake_loss= tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3980 D_tricked_loss= tensor(1.2781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3981 D_real_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3981 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3981 D_tricked_loss= tensor(1.2050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3982 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3982 D_fake_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3982 D_tricked_loss= tensor(1.2287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3983 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3983 D_fake_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3983 D_tricked_loss= tensor(1.2605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3984 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3984 D_fake_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3984 D_tricked_loss= tensor(1.2447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3985 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3985 D_fake_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3985 D_tricked_loss= tensor(1.2342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3986 D_real_loss= tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3986 D_fake_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3986 D_tricked_loss= tensor(1.2311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3987 D_real_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3987 D_fake_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3987 D_tricked_loss= tensor(1.2007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3988 D_real_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3988 D_fake_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3988 D_tricked_loss= tensor(1.2128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3989 D_real_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3989 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3989 D_tricked_loss= tensor(1.1996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3990 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3990 D_fake_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3990 D_tricked_loss= tensor(1.2210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3991 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3991 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3991 D_tricked_loss= tensor(1.2075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3992 D_real_loss= tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3992 D_fake_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3992 D_tricked_loss= tensor(1.1901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3993 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3993 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3993 D_tricked_loss= tensor(1.2807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3994 D_real_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3994 D_fake_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3994 D_tricked_loss= tensor(1.2282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3995 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3995 D_fake_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3995 D_tricked_loss= tensor(1.2258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3996 D_real_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3996 D_fake_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3996 D_tricked_loss= tensor(1.2569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3997 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3997 D_fake_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3997 D_tricked_loss= tensor(1.2017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3998 D_real_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3998 D_fake_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3998 D_tricked_loss= tensor(1.2493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "3999 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3999 D_fake_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3999 D_tricked_loss= tensor(1.2286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4000 D_real_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4000 D_fake_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4000 D_tricked_loss= tensor(1.2462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4001 D_real_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4001 D_fake_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4001 D_tricked_loss= tensor(1.2596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4002 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4002 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4002 D_tricked_loss= tensor(1.2240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4003 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4003 D_fake_loss= tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4003 D_tricked_loss= tensor(1.3038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4004 D_real_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4004 D_fake_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4004 D_tricked_loss= tensor(1.2572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4005 D_real_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4005 D_fake_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4005 D_tricked_loss= tensor(1.2529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4006 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4006 D_fake_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4006 D_tricked_loss= tensor(1.2480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4007 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4007 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4007 D_tricked_loss= tensor(1.2661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4008 D_real_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4008 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4008 D_tricked_loss= tensor(1.2537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4009 D_real_loss= tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4009 D_fake_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4009 D_tricked_loss= tensor(1.1962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4010 D_real_loss= tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4010 D_fake_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4010 D_tricked_loss= tensor(1.1744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4011 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4011 D_fake_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4011 D_tricked_loss= tensor(1.1789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4012 D_real_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4012 D_fake_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4012 D_tricked_loss= tensor(1.1896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4013 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4013 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4013 D_tricked_loss= tensor(1.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4014 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4014 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4014 D_tricked_loss= tensor(1.2521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4015 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4015 D_fake_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4015 D_tricked_loss= tensor(1.2356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4016 D_real_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4016 D_fake_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4016 D_tricked_loss= tensor(1.2719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4017 D_real_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4017 D_fake_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4017 D_tricked_loss= tensor(1.2243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4018 D_real_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4018 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4018 D_tricked_loss= tensor(1.2170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4019 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4019 D_fake_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4019 D_tricked_loss= tensor(1.2751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4020 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4020 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4020 D_tricked_loss= tensor(1.2495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4021 D_real_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4021 D_fake_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4021 D_tricked_loss= tensor(1.2843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4022 D_real_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4022 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4022 D_tricked_loss= tensor(1.2655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4023 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4023 D_fake_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4023 D_tricked_loss= tensor(1.2578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4024 D_real_loss= tensor(0.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4024 D_fake_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4024 D_tricked_loss= tensor(1.2607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4025 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4025 D_fake_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4025 D_tricked_loss= tensor(1.2147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4026 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4026 D_fake_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4026 D_tricked_loss= tensor(1.2831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4027 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4027 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4027 D_tricked_loss= tensor(1.3286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4028 D_real_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4028 D_fake_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4028 D_tricked_loss= tensor(1.2801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4029 D_real_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4029 D_fake_loss= tensor(0.5214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4029 D_tricked_loss= tensor(1.2710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4030 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4030 D_fake_loss= tensor(0.5303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4030 D_tricked_loss= tensor(1.2782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4031 D_real_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4031 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4031 D_tricked_loss= tensor(1.2721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4032 D_real_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4032 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4032 D_tricked_loss= tensor(1.3615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4033 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4033 D_fake_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4033 D_tricked_loss= tensor(1.2246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4034 D_real_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4034 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4034 D_tricked_loss= tensor(1.2112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4035 D_real_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4035 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4035 D_tricked_loss= tensor(1.2284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4036 D_real_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4036 D_fake_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4036 D_tricked_loss= tensor(1.2335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4037 D_real_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4037 D_fake_loss= tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4037 D_tricked_loss= tensor(1.2344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4038 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4038 D_fake_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4038 D_tricked_loss= tensor(1.2784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4039 D_real_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4039 D_fake_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4039 D_tricked_loss= tensor(1.2608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4040 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4040 D_fake_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4040 D_tricked_loss= tensor(1.2066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4041 D_real_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4041 D_fake_loss= tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4041 D_tricked_loss= tensor(1.1977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4042 D_real_loss= tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4042 D_fake_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4042 D_tricked_loss= tensor(1.2253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4043 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4043 D_fake_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4043 D_tricked_loss= tensor(1.2362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4044 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4044 D_fake_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4044 D_tricked_loss= tensor(1.1875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4045 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4045 D_fake_loss= tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4045 D_tricked_loss= tensor(1.2367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4046 D_real_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4046 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4046 D_tricked_loss= tensor(1.2868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4047 D_real_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4047 D_fake_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4047 D_tricked_loss= tensor(1.2096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4048 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4048 D_fake_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4048 D_tricked_loss= tensor(1.2363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4049 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4049 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4049 D_tricked_loss= tensor(1.2612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4050 D_real_loss= tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4050 D_fake_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4050 D_tricked_loss= tensor(1.2274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4051 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4051 D_fake_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4051 D_tricked_loss= tensor(1.2794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4052 D_real_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4052 D_fake_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4052 D_tricked_loss= tensor(1.2307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4053 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4053 D_fake_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4053 D_tricked_loss= tensor(1.2609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4054 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4054 D_fake_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4054 D_tricked_loss= tensor(1.2093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4055 D_real_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4055 D_fake_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4055 D_tricked_loss= tensor(1.2245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4056 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4056 D_fake_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4056 D_tricked_loss= tensor(1.2481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4057 D_real_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4057 D_fake_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4057 D_tricked_loss= tensor(1.2383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4058 D_real_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4058 D_fake_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4058 D_tricked_loss= tensor(1.3020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4059 D_real_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4059 D_fake_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4059 D_tricked_loss= tensor(1.1955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4060 D_real_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4060 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4060 D_tricked_loss= tensor(1.2024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4061 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4061 D_fake_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4061 D_tricked_loss= tensor(1.2582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4062 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4062 D_fake_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4062 D_tricked_loss= tensor(1.1886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4063 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4063 D_fake_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4063 D_tricked_loss= tensor(1.2438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4064 D_real_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4064 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4064 D_tricked_loss= tensor(1.2246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4065 D_real_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4065 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4065 D_tricked_loss= tensor(1.2332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4066 D_real_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4066 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4066 D_tricked_loss= tensor(1.2244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4067 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4067 D_fake_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4067 D_tricked_loss= tensor(1.2317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4068 D_real_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4068 D_fake_loss= tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4068 D_tricked_loss= tensor(1.1886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4069 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4069 D_fake_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4069 D_tricked_loss= tensor(1.2287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4070 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4070 D_fake_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4070 D_tricked_loss= tensor(1.1930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4071 D_real_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4071 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4071 D_tricked_loss= tensor(1.2151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4072 D_real_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4072 D_fake_loss= tensor(0.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4072 D_tricked_loss= tensor(1.2316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4073 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4073 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4073 D_tricked_loss= tensor(1.2012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4074 D_real_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4074 D_fake_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4074 D_tricked_loss= tensor(1.2042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4075 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4075 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4075 D_tricked_loss= tensor(1.2198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4076 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4076 D_fake_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4076 D_tricked_loss= tensor(1.2243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4077 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4077 D_fake_loss= tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4077 D_tricked_loss= tensor(1.2052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4078 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4078 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4078 D_tricked_loss= tensor(1.1722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4079 D_real_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4079 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4079 D_tricked_loss= tensor(1.2148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4080 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4080 D_fake_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4080 D_tricked_loss= tensor(1.2372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4081 D_real_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4081 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4081 D_tricked_loss= tensor(1.2334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4082 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4082 D_fake_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4082 D_tricked_loss= tensor(1.2526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4083 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4083 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4083 D_tricked_loss= tensor(1.2396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4084 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4084 D_fake_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4084 D_tricked_loss= tensor(1.2051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4085 D_real_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4085 D_fake_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4085 D_tricked_loss= tensor(1.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4086 D_real_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4086 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4086 D_tricked_loss= tensor(1.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4087 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4087 D_fake_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4087 D_tricked_loss= tensor(1.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4088 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4088 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4088 D_tricked_loss= tensor(1.2417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4089 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4089 D_fake_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4089 D_tricked_loss= tensor(1.2712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4090 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4090 D_fake_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4090 D_tricked_loss= tensor(1.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4091 D_real_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4091 D_fake_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4091 D_tricked_loss= tensor(1.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4092 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4092 D_fake_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4092 D_tricked_loss= tensor(1.2305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4093 D_real_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4093 D_fake_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4093 D_tricked_loss= tensor(1.2954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4094 D_real_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4094 D_fake_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4094 D_tricked_loss= tensor(1.3135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4095 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4095 D_fake_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4095 D_tricked_loss= tensor(1.2084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4096 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4096 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4096 D_tricked_loss= tensor(1.3217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4097 D_real_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4097 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4097 D_tricked_loss= tensor(1.3491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4098 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4098 D_fake_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4098 D_tricked_loss= tensor(1.2320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4099 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4099 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4099 D_tricked_loss= tensor(1.2926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4100 D_real_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4100 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4100 D_tricked_loss= tensor(1.2144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4101 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4101 D_fake_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4101 D_tricked_loss= tensor(1.2906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4102 D_real_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4102 D_fake_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4102 D_tricked_loss= tensor(1.2716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4103 D_real_loss= tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4103 D_fake_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4103 D_tricked_loss= tensor(1.2216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4104 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4104 D_fake_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4104 D_tricked_loss= tensor(1.2354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4105 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4105 D_fake_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4105 D_tricked_loss= tensor(1.2248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4106 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4106 D_fake_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4106 D_tricked_loss= tensor(1.2388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4107 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4107 D_fake_loss= tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4107 D_tricked_loss= tensor(1.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4108 D_real_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4108 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4108 D_tricked_loss= tensor(1.2941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4109 D_real_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4109 D_fake_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4109 D_tricked_loss= tensor(1.2917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4110 D_real_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4110 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4110 D_tricked_loss= tensor(1.2452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4111 D_real_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4111 D_fake_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4111 D_tricked_loss= tensor(1.2434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4112 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4112 D_fake_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4112 D_tricked_loss= tensor(1.2611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4113 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4113 D_fake_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4113 D_tricked_loss= tensor(1.2643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4114 D_real_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4114 D_fake_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4114 D_tricked_loss= tensor(1.2722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4115 D_real_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4115 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4115 D_tricked_loss= tensor(1.2902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4116 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4116 D_fake_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4116 D_tricked_loss= tensor(1.2692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4117 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4117 D_fake_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4117 D_tricked_loss= tensor(1.2669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4118 D_real_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4118 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4118 D_tricked_loss= tensor(1.2434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4119 D_real_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4119 D_fake_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4119 D_tricked_loss= tensor(1.2680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4120 D_real_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4120 D_fake_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4120 D_tricked_loss= tensor(1.2656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4121 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4121 D_fake_loss= tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4121 D_tricked_loss= tensor(1.2416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4122 D_real_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4122 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4122 D_tricked_loss= tensor(1.2421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4123 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4123 D_fake_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4123 D_tricked_loss= tensor(1.2823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4124 D_real_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4124 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4124 D_tricked_loss= tensor(1.1766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4125 D_real_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4125 D_fake_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4125 D_tricked_loss= tensor(1.2557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4126 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4126 D_fake_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4126 D_tricked_loss= tensor(1.2547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4127 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4127 D_fake_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4127 D_tricked_loss= tensor(1.2189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4128 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4128 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4128 D_tricked_loss= tensor(1.2088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4129 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4129 D_fake_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4129 D_tricked_loss= tensor(1.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4130 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4130 D_fake_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4130 D_tricked_loss= tensor(1.1681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4131 D_real_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4131 D_fake_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4131 D_tricked_loss= tensor(1.2025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4132 D_real_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4132 D_fake_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4132 D_tricked_loss= tensor(1.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4133 D_real_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4133 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4133 D_tricked_loss= tensor(1.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4134 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4134 D_fake_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4134 D_tricked_loss= tensor(1.1860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4135 D_real_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4135 D_fake_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4135 D_tricked_loss= tensor(1.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4136 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4136 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4136 D_tricked_loss= tensor(1.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4137 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4137 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4137 D_tricked_loss= tensor(1.2056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4138 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4138 D_fake_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4138 D_tricked_loss= tensor(1.2140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4139 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4139 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4139 D_tricked_loss= tensor(1.2017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4140 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4140 D_fake_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4140 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4141 D_real_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4141 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4141 D_tricked_loss= tensor(1.1718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4142 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4142 D_fake_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4142 D_tricked_loss= tensor(1.2376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4143 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4143 D_fake_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4143 D_tricked_loss= tensor(1.2234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4144 D_real_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4144 D_fake_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4144 D_tricked_loss= tensor(1.3549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4145 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4145 D_fake_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4145 D_tricked_loss= tensor(1.3366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4146 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4146 D_fake_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4146 D_tricked_loss= tensor(1.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4147 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4147 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4147 D_tricked_loss= tensor(1.3030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4148 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4148 D_fake_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4148 D_tricked_loss= tensor(1.2494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4149 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4149 D_fake_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4149 D_tricked_loss= tensor(1.2271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4150 D_real_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4150 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4150 D_tricked_loss= tensor(1.2539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4151 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4151 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4151 D_tricked_loss= tensor(1.2424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4152 D_real_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4152 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4152 D_tricked_loss= tensor(1.1704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4153 D_real_loss= tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4153 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4153 D_tricked_loss= tensor(1.1670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4154 D_real_loss= tensor(0.6210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4154 D_fake_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4154 D_tricked_loss= tensor(1.2019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4155 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4155 D_fake_loss= tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4155 D_tricked_loss= tensor(1.1643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4156 D_real_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4156 D_fake_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4156 D_tricked_loss= tensor(1.1933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4157 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4157 D_fake_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4157 D_tricked_loss= tensor(1.2331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4158 D_real_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4158 D_fake_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4158 D_tricked_loss= tensor(1.2282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4159 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4159 D_fake_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4159 D_tricked_loss= tensor(1.2579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4160 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4160 D_fake_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4160 D_tricked_loss= tensor(1.1680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4161 D_real_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4161 D_fake_loss= tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4161 D_tricked_loss= tensor(1.2254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4162 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4162 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4162 D_tricked_loss= tensor(1.2603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4163 D_real_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4163 D_fake_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4163 D_tricked_loss= tensor(1.2609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4164 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4164 D_fake_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4164 D_tricked_loss= tensor(1.3058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4165 D_real_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4165 D_fake_loss= tensor(0.5218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4165 D_tricked_loss= tensor(1.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4166 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4166 D_fake_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4166 D_tricked_loss= tensor(1.2233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4167 D_real_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4167 D_fake_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4167 D_tricked_loss= tensor(1.2663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4168 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4168 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4168 D_tricked_loss= tensor(1.1929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4169 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4169 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4169 D_tricked_loss= tensor(1.2244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4170 D_real_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4170 D_fake_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4170 D_tricked_loss= tensor(1.2267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4171 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4171 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4171 D_tricked_loss= tensor(1.2586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4172 D_real_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4172 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4172 D_tricked_loss= tensor(1.2440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4173 D_real_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4173 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4173 D_tricked_loss= tensor(1.2360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4174 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4174 D_fake_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4174 D_tricked_loss= tensor(1.2956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4175 D_real_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4175 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4175 D_tricked_loss= tensor(1.2665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4176 D_real_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4176 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4176 D_tricked_loss= tensor(1.2113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4177 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4177 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4177 D_tricked_loss= tensor(1.2985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4178 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4178 D_fake_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4178 D_tricked_loss= tensor(1.2216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4179 D_real_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4179 D_fake_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4179 D_tricked_loss= tensor(1.2296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4180 D_real_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4180 D_fake_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4180 D_tricked_loss= tensor(1.2147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4181 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4181 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4181 D_tricked_loss= tensor(1.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4182 D_real_loss= tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4182 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4182 D_tricked_loss= tensor(1.2206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4183 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4183 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4183 D_tricked_loss= tensor(1.1769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4184 D_real_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4184 D_fake_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4184 D_tricked_loss= tensor(1.1878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4185 D_real_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4185 D_fake_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4185 D_tricked_loss= tensor(1.2514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4186 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4186 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4186 D_tricked_loss= tensor(1.2167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4187 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4187 D_fake_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4187 D_tricked_loss= tensor(1.2933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4188 D_real_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4188 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4188 D_tricked_loss= tensor(1.2644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4189 D_real_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4189 D_fake_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4189 D_tricked_loss= tensor(1.2802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4190 D_real_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4190 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4190 D_tricked_loss= tensor(1.3177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4191 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4191 D_fake_loss= tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4191 D_tricked_loss= tensor(1.2784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4192 D_real_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4192 D_fake_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4192 D_tricked_loss= tensor(1.2387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4193 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4193 D_fake_loss= tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4193 D_tricked_loss= tensor(1.1834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4194 D_real_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4194 D_fake_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4194 D_tricked_loss= tensor(1.1922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4195 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4195 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4195 D_tricked_loss= tensor(1.1843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4196 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4196 D_fake_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4196 D_tricked_loss= tensor(1.2080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4197 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4197 D_fake_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4197 D_tricked_loss= tensor(1.2231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4198 D_real_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4198 D_fake_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4198 D_tricked_loss= tensor(1.2310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4199 D_real_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4199 D_fake_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4199 D_tricked_loss= tensor(1.2427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4200 D_real_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4200 D_fake_loss= tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4200 D_tricked_loss= tensor(1.2332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4201 D_real_loss= tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4201 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4201 D_tricked_loss= tensor(1.2461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4202 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4202 D_fake_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4202 D_tricked_loss= tensor(1.2262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4203 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4203 D_fake_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4203 D_tricked_loss= tensor(1.2061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4204 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4204 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4204 D_tricked_loss= tensor(1.2065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4205 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4205 D_fake_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4205 D_tricked_loss= tensor(1.2419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4206 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4206 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4206 D_tricked_loss= tensor(1.2357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4207 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4207 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4207 D_tricked_loss= tensor(1.2952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4208 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4208 D_fake_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4208 D_tricked_loss= tensor(1.2688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4209 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4209 D_fake_loss= tensor(0.5218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4209 D_tricked_loss= tensor(1.2348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4210 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4210 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4210 D_tricked_loss= tensor(1.2324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4211 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4211 D_fake_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4211 D_tricked_loss= tensor(1.2140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4212 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4212 D_fake_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4212 D_tricked_loss= tensor(1.2431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4213 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4213 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4213 D_tricked_loss= tensor(1.1927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4214 D_real_loss= tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4214 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4214 D_tricked_loss= tensor(1.2199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4215 D_real_loss= tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4215 D_fake_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4215 D_tricked_loss= tensor(1.2031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4216 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4216 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4216 D_tricked_loss= tensor(1.2004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4217 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4217 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4217 D_tricked_loss= tensor(1.2477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4218 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4218 D_fake_loss= tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4218 D_tricked_loss= tensor(1.2469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4219 D_real_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4219 D_fake_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4219 D_tricked_loss= tensor(1.2138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4220 D_real_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4220 D_fake_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4220 D_tricked_loss= tensor(1.2466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4221 D_real_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4221 D_fake_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4221 D_tricked_loss= tensor(1.2094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4222 D_real_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4222 D_fake_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4222 D_tricked_loss= tensor(1.2202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4223 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4223 D_fake_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4223 D_tricked_loss= tensor(1.2577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4224 D_real_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4224 D_fake_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4224 D_tricked_loss= tensor(1.2241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4225 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4225 D_fake_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4225 D_tricked_loss= tensor(1.2370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4226 D_real_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4226 D_fake_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4226 D_tricked_loss= tensor(1.2625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4227 D_real_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4227 D_fake_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4227 D_tricked_loss= tensor(1.2534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4228 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4228 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4228 D_tricked_loss= tensor(1.3139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4229 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4229 D_fake_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4229 D_tricked_loss= tensor(1.2605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4230 D_real_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4230 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4230 D_tricked_loss= tensor(1.3080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4231 D_real_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4231 D_fake_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4231 D_tricked_loss= tensor(1.2540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4232 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4232 D_fake_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4232 D_tricked_loss= tensor(1.2664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4233 D_real_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4233 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4233 D_tricked_loss= tensor(1.2561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4234 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4234 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4234 D_tricked_loss= tensor(1.2587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4235 D_real_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4235 D_fake_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4235 D_tricked_loss= tensor(1.2110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4236 D_real_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4236 D_fake_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4236 D_tricked_loss= tensor(1.2139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4237 D_real_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4237 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4237 D_tricked_loss= tensor(1.2424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4238 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4238 D_fake_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4238 D_tricked_loss= tensor(1.2228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4239 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4239 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4239 D_tricked_loss= tensor(1.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4240 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4240 D_fake_loss= tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4240 D_tricked_loss= tensor(1.2057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4241 D_real_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4241 D_fake_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4241 D_tricked_loss= tensor(1.2655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4242 D_real_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4242 D_fake_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4242 D_tricked_loss= tensor(1.2327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4243 D_real_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4243 D_fake_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4243 D_tricked_loss= tensor(1.2601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4244 D_real_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4244 D_fake_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4244 D_tricked_loss= tensor(1.2933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4245 D_real_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4245 D_fake_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4245 D_tricked_loss= tensor(1.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4246 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4246 D_fake_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4246 D_tricked_loss= tensor(1.2993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4247 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4247 D_fake_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4247 D_tricked_loss= tensor(1.2684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4248 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4248 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4248 D_tricked_loss= tensor(1.2370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4249 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4249 D_fake_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4249 D_tricked_loss= tensor(1.2324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4250 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4250 D_fake_loss= tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4250 D_tricked_loss= tensor(1.1705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4251 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4251 D_fake_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4251 D_tricked_loss= tensor(1.2430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4252 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4252 D_fake_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4252 D_tricked_loss= tensor(1.2156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4253 D_real_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4253 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4253 D_tricked_loss= tensor(1.1875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4254 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4254 D_fake_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4254 D_tricked_loss= tensor(1.2304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4255 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4255 D_fake_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4255 D_tricked_loss= tensor(1.2089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4256 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4256 D_fake_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4256 D_tricked_loss= tensor(1.2385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4257 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4257 D_fake_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4257 D_tricked_loss= tensor(1.1642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4258 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4258 D_fake_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4258 D_tricked_loss= tensor(1.2224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4259 D_real_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4259 D_fake_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4259 D_tricked_loss= tensor(1.2486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4260 D_real_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4260 D_fake_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4260 D_tricked_loss= tensor(1.2462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4261 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4261 D_fake_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4261 D_tricked_loss= tensor(1.2625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4262 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4262 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4262 D_tricked_loss= tensor(1.2032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4263 D_real_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4263 D_fake_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4263 D_tricked_loss= tensor(1.2188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4264 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4264 D_fake_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4264 D_tricked_loss= tensor(1.2335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4265 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4265 D_fake_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4265 D_tricked_loss= tensor(1.2397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4266 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4266 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4266 D_tricked_loss= tensor(1.2494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4267 D_real_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4267 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4267 D_tricked_loss= tensor(1.2387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4268 D_real_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4268 D_fake_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4268 D_tricked_loss= tensor(1.2351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4269 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4269 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4269 D_tricked_loss= tensor(1.2870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4270 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4270 D_fake_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4270 D_tricked_loss= tensor(1.2010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4271 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4271 D_fake_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4271 D_tricked_loss= tensor(1.2467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4272 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4272 D_fake_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4272 D_tricked_loss= tensor(1.2498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4273 D_real_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4273 D_fake_loss= tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4273 D_tricked_loss= tensor(1.2588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4274 D_real_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4274 D_fake_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4274 D_tricked_loss= tensor(1.2757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4275 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4275 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4275 D_tricked_loss= tensor(1.2470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4276 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4276 D_fake_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4276 D_tricked_loss= tensor(1.2761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4277 D_real_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4277 D_fake_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4277 D_tricked_loss= tensor(1.3110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4278 D_real_loss= tensor(0.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4278 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4278 D_tricked_loss= tensor(1.2954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4279 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4279 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4279 D_tricked_loss= tensor(1.2638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4280 D_real_loss= tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4280 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4280 D_tricked_loss= tensor(1.2292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4281 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4281 D_fake_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4281 D_tricked_loss= tensor(1.2595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4282 D_real_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4282 D_fake_loss= tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4282 D_tricked_loss= tensor(1.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4283 D_real_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4283 D_fake_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4283 D_tricked_loss= tensor(1.2141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4284 D_real_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4284 D_fake_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4284 D_tricked_loss= tensor(1.2293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4285 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4285 D_fake_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4285 D_tricked_loss= tensor(1.2433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4286 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4286 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4286 D_tricked_loss= tensor(1.2615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4287 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4287 D_fake_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4287 D_tricked_loss= tensor(1.2056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4288 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4288 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4288 D_tricked_loss= tensor(1.2134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4289 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4289 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4289 D_tricked_loss= tensor(1.2354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4290 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4290 D_fake_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4290 D_tricked_loss= tensor(1.2004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4291 D_real_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4291 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4291 D_tricked_loss= tensor(1.2469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4292 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4292 D_fake_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4292 D_tricked_loss= tensor(1.1672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4293 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4293 D_fake_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4293 D_tricked_loss= tensor(1.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4294 D_real_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4294 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4294 D_tricked_loss= tensor(1.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4295 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4295 D_fake_loss= tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4295 D_tricked_loss= tensor(1.2232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4296 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4296 D_fake_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4296 D_tricked_loss= tensor(1.1668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4297 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4297 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4297 D_tricked_loss= tensor(1.2300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4298 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4298 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4298 D_tricked_loss= tensor(1.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4299 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4299 D_fake_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4299 D_tricked_loss= tensor(1.1477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4300 D_real_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4300 D_fake_loss= tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4300 D_tricked_loss= tensor(1.2072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4301 D_real_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4301 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4301 D_tricked_loss= tensor(1.1507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4302 D_real_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4302 D_fake_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4302 D_tricked_loss= tensor(1.1908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4303 D_real_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4303 D_fake_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4303 D_tricked_loss= tensor(1.1784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4304 D_real_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4304 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4304 D_tricked_loss= tensor(1.1802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4305 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4305 D_fake_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4305 D_tricked_loss= tensor(1.2358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4306 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4306 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4306 D_tricked_loss= tensor(1.1867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4307 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4307 D_fake_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4307 D_tricked_loss= tensor(1.2328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4308 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4308 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4308 D_tricked_loss= tensor(1.2189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4309 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4309 D_fake_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4309 D_tricked_loss= tensor(1.2103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4310 D_real_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4310 D_fake_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4310 D_tricked_loss= tensor(1.2446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4311 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4311 D_fake_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4311 D_tricked_loss= tensor(1.1925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4312 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4312 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4312 D_tricked_loss= tensor(1.2547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4313 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4313 D_fake_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4313 D_tricked_loss= tensor(1.1535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4314 D_real_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4314 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4314 D_tricked_loss= tensor(1.1884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4315 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4315 D_fake_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4315 D_tricked_loss= tensor(1.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4316 D_real_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4316 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4316 D_tricked_loss= tensor(1.1837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4317 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4317 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4317 D_tricked_loss= tensor(1.2410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4318 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4318 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4318 D_tricked_loss= tensor(1.1605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4319 D_real_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4319 D_fake_loss= tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4319 D_tricked_loss= tensor(1.2317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4320 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4320 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4320 D_tricked_loss= tensor(1.2286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4321 D_real_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4321 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4321 D_tricked_loss= tensor(1.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4322 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4322 D_fake_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4322 D_tricked_loss= tensor(1.2269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4323 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4323 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4323 D_tricked_loss= tensor(1.2238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4324 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4324 D_fake_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4324 D_tricked_loss= tensor(1.2078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4325 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4325 D_fake_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4325 D_tricked_loss= tensor(1.2703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4326 D_real_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4326 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4326 D_tricked_loss= tensor(1.2110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4327 D_real_loss= tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4327 D_fake_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4327 D_tricked_loss= tensor(1.2693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4328 D_real_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4328 D_fake_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4328 D_tricked_loss= tensor(1.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4329 D_real_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4329 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4329 D_tricked_loss= tensor(1.2490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4330 D_real_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4330 D_fake_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4330 D_tricked_loss= tensor(1.3070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4331 D_real_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4331 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4331 D_tricked_loss= tensor(1.2525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4332 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4332 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4332 D_tricked_loss= tensor(1.2348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4333 D_real_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4333 D_fake_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4333 D_tricked_loss= tensor(1.2918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4334 D_real_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4334 D_fake_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4334 D_tricked_loss= tensor(1.1982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4335 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4335 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4335 D_tricked_loss= tensor(1.2213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4336 D_real_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4336 D_fake_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4336 D_tricked_loss= tensor(1.2044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4337 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4337 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4337 D_tricked_loss= tensor(1.2105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4338 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4338 D_fake_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4338 D_tricked_loss= tensor(1.2478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4339 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4339 D_fake_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4339 D_tricked_loss= tensor(1.2215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4340 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4340 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4340 D_tricked_loss= tensor(1.2235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4341 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4341 D_fake_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4341 D_tricked_loss= tensor(1.2087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4342 D_real_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4342 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4342 D_tricked_loss= tensor(1.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4343 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4343 D_fake_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4343 D_tricked_loss= tensor(1.2207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4344 D_real_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4344 D_fake_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4344 D_tricked_loss= tensor(1.2088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4345 D_real_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4345 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4345 D_tricked_loss= tensor(1.2194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4346 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4346 D_fake_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4346 D_tricked_loss= tensor(1.1859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4347 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4347 D_fake_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4347 D_tricked_loss= tensor(1.1931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4348 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4348 D_fake_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4348 D_tricked_loss= tensor(1.2251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4349 D_real_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4349 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4349 D_tricked_loss= tensor(1.1796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4350 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4350 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4350 D_tricked_loss= tensor(1.1774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4351 D_real_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4351 D_fake_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4351 D_tricked_loss= tensor(1.1377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4352 D_real_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4352 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4352 D_tricked_loss= tensor(1.1510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4353 D_real_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4353 D_fake_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4353 D_tricked_loss= tensor(1.1405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4354 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4354 D_fake_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4354 D_tricked_loss= tensor(1.1642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4355 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4355 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4355 D_tricked_loss= tensor(1.1609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4356 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4356 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4356 D_tricked_loss= tensor(1.2221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4357 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4357 D_fake_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4357 D_tricked_loss= tensor(1.1997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4358 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4358 D_fake_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4358 D_tricked_loss= tensor(1.1512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4359 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4359 D_fake_loss= tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4359 D_tricked_loss= tensor(1.1670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4360 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4360 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4360 D_tricked_loss= tensor(1.2125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4361 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4361 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4361 D_tricked_loss= tensor(1.1953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4362 D_real_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4362 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4362 D_tricked_loss= tensor(1.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4363 D_real_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4363 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4363 D_tricked_loss= tensor(1.1895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4364 D_real_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4364 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4364 D_tricked_loss= tensor(1.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4365 D_real_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4365 D_fake_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4365 D_tricked_loss= tensor(1.2274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4366 D_real_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4366 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4366 D_tricked_loss= tensor(1.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4367 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4367 D_fake_loss= tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4367 D_tricked_loss= tensor(1.2010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4368 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4368 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4368 D_tricked_loss= tensor(1.1944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4369 D_real_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4369 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4369 D_tricked_loss= tensor(1.2131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4370 D_real_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4370 D_fake_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4370 D_tricked_loss= tensor(1.2495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4371 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4371 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4371 D_tricked_loss= tensor(1.2358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4372 D_real_loss= tensor(0.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4372 D_fake_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4372 D_tricked_loss= tensor(1.2311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4373 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4373 D_fake_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4373 D_tricked_loss= tensor(1.2835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4374 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4374 D_fake_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4374 D_tricked_loss= tensor(1.2454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4375 D_real_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4375 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4375 D_tricked_loss= tensor(1.2746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4376 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4376 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4376 D_tricked_loss= tensor(1.2396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4377 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4377 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4377 D_tricked_loss= tensor(1.2298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4378 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4378 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4378 D_tricked_loss= tensor(1.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4379 D_real_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4379 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4379 D_tricked_loss= tensor(1.2347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4380 D_real_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4380 D_fake_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4380 D_tricked_loss= tensor(1.2575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4381 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4381 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4381 D_tricked_loss= tensor(1.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4382 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4382 D_fake_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4382 D_tricked_loss= tensor(1.2640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4383 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4383 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4383 D_tricked_loss= tensor(1.2708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4384 D_real_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4384 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4384 D_tricked_loss= tensor(1.2150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4385 D_real_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4385 D_fake_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4385 D_tricked_loss= tensor(1.1877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4386 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4386 D_fake_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4386 D_tricked_loss= tensor(1.1867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4387 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4387 D_fake_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4387 D_tricked_loss= tensor(1.1822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4388 D_real_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4388 D_fake_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4388 D_tricked_loss= tensor(1.2380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4389 D_real_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4389 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4389 D_tricked_loss= tensor(1.2000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4390 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4390 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4390 D_tricked_loss= tensor(1.2150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4391 D_real_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4391 D_fake_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4391 D_tricked_loss= tensor(1.1805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4392 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4392 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4392 D_tricked_loss= tensor(1.2100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4393 D_real_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4393 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4393 D_tricked_loss= tensor(1.2153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4394 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4394 D_fake_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4394 D_tricked_loss= tensor(1.1854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4395 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4395 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4395 D_tricked_loss= tensor(1.1990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4396 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4396 D_fake_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4396 D_tricked_loss= tensor(1.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4397 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4397 D_fake_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4397 D_tricked_loss= tensor(1.1941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4398 D_real_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4398 D_fake_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4398 D_tricked_loss= tensor(1.1778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4399 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4399 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4399 D_tricked_loss= tensor(1.1914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4400 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4400 D_fake_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4400 D_tricked_loss= tensor(1.2001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4401 D_real_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4401 D_fake_loss= tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4401 D_tricked_loss= tensor(1.2072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4402 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4402 D_fake_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4402 D_tricked_loss= tensor(1.2513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4403 D_real_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4403 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4403 D_tricked_loss= tensor(1.2877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4404 D_real_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4404 D_fake_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4404 D_tricked_loss= tensor(1.2999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4405 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4405 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4405 D_tricked_loss= tensor(1.3093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4406 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4406 D_fake_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4406 D_tricked_loss= tensor(1.2037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4407 D_real_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4407 D_fake_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4407 D_tricked_loss= tensor(1.2772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4408 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4408 D_fake_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4408 D_tricked_loss= tensor(1.2335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4409 D_real_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4409 D_fake_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4409 D_tricked_loss= tensor(1.2102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4410 D_real_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4410 D_fake_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4410 D_tricked_loss= tensor(1.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4411 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4411 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4411 D_tricked_loss= tensor(1.2373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4412 D_real_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4412 D_fake_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4412 D_tricked_loss= tensor(1.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4413 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4413 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4413 D_tricked_loss= tensor(1.2484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4414 D_real_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4414 D_fake_loss= tensor(0.5168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4414 D_tricked_loss= tensor(1.3064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4415 D_real_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4415 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4415 D_tricked_loss= tensor(1.2892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4416 D_real_loss= tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4416 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4416 D_tricked_loss= tensor(1.2274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4417 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4417 D_fake_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4417 D_tricked_loss= tensor(1.2727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4418 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4418 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4418 D_tricked_loss= tensor(1.2596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4419 D_real_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4419 D_fake_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4419 D_tricked_loss= tensor(1.1748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4420 D_real_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4420 D_fake_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4420 D_tricked_loss= tensor(1.1858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4421 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4421 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4421 D_tricked_loss= tensor(1.1582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4422 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4422 D_fake_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4422 D_tricked_loss= tensor(1.2022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4423 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4423 D_fake_loss= tensor(0.4922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4423 D_tricked_loss= tensor(1.2418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4424 D_real_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4424 D_fake_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4424 D_tricked_loss= tensor(1.2489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4425 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4425 D_fake_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4425 D_tricked_loss= tensor(1.2236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4426 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4426 D_fake_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4426 D_tricked_loss= tensor(1.2547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4427 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4427 D_fake_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4427 D_tricked_loss= tensor(1.2408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4428 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4428 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4428 D_tricked_loss= tensor(1.2306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4429 D_real_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4429 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4429 D_tricked_loss= tensor(1.2133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4430 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4430 D_fake_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4430 D_tricked_loss= tensor(1.2246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4431 D_real_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4431 D_fake_loss= tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4431 D_tricked_loss= tensor(1.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4432 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4432 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4432 D_tricked_loss= tensor(1.1898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4433 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4433 D_fake_loss= tensor(0.5472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4433 D_tricked_loss= tensor(1.2285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4434 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4434 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4434 D_tricked_loss= tensor(1.2115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4435 D_real_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4435 D_fake_loss= tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4435 D_tricked_loss= tensor(1.1755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4436 D_real_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4436 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4436 D_tricked_loss= tensor(1.2352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4437 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4437 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4437 D_tricked_loss= tensor(1.1935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4438 D_real_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4438 D_fake_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4438 D_tricked_loss= tensor(1.1642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4439 D_real_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4439 D_fake_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4439 D_tricked_loss= tensor(1.2154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4440 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4440 D_fake_loss= tensor(0.6068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4440 D_tricked_loss= tensor(1.1470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4441 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4441 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4441 D_tricked_loss= tensor(1.2030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4442 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4442 D_fake_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4442 D_tricked_loss= tensor(1.2482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4443 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4443 D_fake_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4443 D_tricked_loss= tensor(1.2018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4444 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4444 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4444 D_tricked_loss= tensor(1.2660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4445 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4445 D_fake_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4445 D_tricked_loss= tensor(1.1901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4446 D_real_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4446 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4446 D_tricked_loss= tensor(1.2003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4447 D_real_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4447 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4447 D_tricked_loss= tensor(1.2414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4448 D_real_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4448 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4448 D_tricked_loss= tensor(1.1978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4449 D_real_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4449 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4449 D_tricked_loss= tensor(1.2074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4450 D_real_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4450 D_fake_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4450 D_tricked_loss= tensor(1.2310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4451 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4451 D_fake_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4451 D_tricked_loss= tensor(1.2256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4452 D_real_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4452 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4452 D_tricked_loss= tensor(1.2444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4453 D_real_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4453 D_fake_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4453 D_tricked_loss= tensor(1.2162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4454 D_real_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4454 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4454 D_tricked_loss= tensor(1.2242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4455 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4455 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4455 D_tricked_loss= tensor(1.2277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4456 D_real_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4456 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4456 D_tricked_loss= tensor(1.2119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4457 D_real_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4457 D_fake_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4457 D_tricked_loss= tensor(1.2354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4458 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4458 D_fake_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4458 D_tricked_loss= tensor(1.2096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4459 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4459 D_fake_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4459 D_tricked_loss= tensor(1.2015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4460 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4460 D_fake_loss= tensor(0.5298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4460 D_tricked_loss= tensor(1.1916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4461 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4461 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4461 D_tricked_loss= tensor(1.2076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4462 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4462 D_fake_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4462 D_tricked_loss= tensor(1.2382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4463 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4463 D_fake_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4463 D_tricked_loss= tensor(1.2664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4464 D_real_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4464 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4464 D_tricked_loss= tensor(1.2410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4465 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4465 D_fake_loss= tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4465 D_tricked_loss= tensor(1.2663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4466 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4466 D_fake_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4466 D_tricked_loss= tensor(1.2172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4467 D_real_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4467 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4467 D_tricked_loss= tensor(1.2840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4468 D_real_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4468 D_fake_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4468 D_tricked_loss= tensor(1.1879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4469 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4469 D_fake_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4469 D_tricked_loss= tensor(1.2296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4470 D_real_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4470 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4470 D_tricked_loss= tensor(1.2286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4471 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4471 D_fake_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4471 D_tricked_loss= tensor(1.2039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4472 D_real_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4472 D_fake_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4472 D_tricked_loss= tensor(1.2387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4473 D_real_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4473 D_fake_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4473 D_tricked_loss= tensor(1.1793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4474 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4474 D_fake_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4474 D_tricked_loss= tensor(1.1959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4475 D_real_loss= tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4475 D_fake_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4475 D_tricked_loss= tensor(1.1954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4476 D_real_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4476 D_fake_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4476 D_tricked_loss= tensor(1.1868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4477 D_real_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4477 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4477 D_tricked_loss= tensor(1.2030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4478 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4478 D_fake_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4478 D_tricked_loss= tensor(1.2162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4479 D_real_loss= tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4479 D_fake_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4479 D_tricked_loss= tensor(1.2592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4480 D_real_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4480 D_fake_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4480 D_tricked_loss= tensor(1.2632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4481 D_real_loss= tensor(0.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4481 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4481 D_tricked_loss= tensor(1.2888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4482 D_real_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4482 D_fake_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4482 D_tricked_loss= tensor(1.2891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4483 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4483 D_fake_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4483 D_tricked_loss= tensor(1.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4484 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4484 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4484 D_tricked_loss= tensor(1.2267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4485 D_real_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4485 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4485 D_tricked_loss= tensor(1.2445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4486 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4486 D_fake_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4486 D_tricked_loss= tensor(1.2312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4487 D_real_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4487 D_fake_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4487 D_tricked_loss= tensor(1.2354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4488 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4488 D_fake_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4488 D_tricked_loss= tensor(1.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4489 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4489 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4489 D_tricked_loss= tensor(1.2188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4490 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4490 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4490 D_tricked_loss= tensor(1.2346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4491 D_real_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4491 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4491 D_tricked_loss= tensor(1.1954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4492 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4492 D_fake_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4492 D_tricked_loss= tensor(1.2587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4493 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4493 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4493 D_tricked_loss= tensor(1.2076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4494 D_real_loss= tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4494 D_fake_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4494 D_tricked_loss= tensor(1.2876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4495 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4495 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4495 D_tricked_loss= tensor(1.2031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4496 D_real_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4496 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4496 D_tricked_loss= tensor(1.2067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4497 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4497 D_fake_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4497 D_tricked_loss= tensor(1.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4498 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4498 D_fake_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4498 D_tricked_loss= tensor(1.1655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4499 D_real_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4499 D_fake_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4499 D_tricked_loss= tensor(1.2109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4500 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4500 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4500 D_tricked_loss= tensor(1.1686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4501 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4501 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4501 D_tricked_loss= tensor(1.1588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4502 D_real_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4502 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4502 D_tricked_loss= tensor(1.2045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4503 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4503 D_fake_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4503 D_tricked_loss= tensor(1.1896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4504 D_real_loss= tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4504 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4504 D_tricked_loss= tensor(1.1538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4505 D_real_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4505 D_fake_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4505 D_tricked_loss= tensor(1.1689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4506 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4506 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4506 D_tricked_loss= tensor(1.1628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4507 D_real_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4507 D_fake_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4507 D_tricked_loss= tensor(1.1609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4508 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4508 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4508 D_tricked_loss= tensor(1.2029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4509 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4509 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4509 D_tricked_loss= tensor(1.2456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4510 D_real_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4510 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4510 D_tricked_loss= tensor(1.2600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4511 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4511 D_fake_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4511 D_tricked_loss= tensor(1.2142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4512 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4512 D_fake_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4512 D_tricked_loss= tensor(1.2396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4513 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4513 D_fake_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4513 D_tricked_loss= tensor(1.2097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4514 D_real_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4514 D_fake_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4514 D_tricked_loss= tensor(1.2065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4515 D_real_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4515 D_fake_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4515 D_tricked_loss= tensor(1.2226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4516 D_real_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4516 D_fake_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4516 D_tricked_loss= tensor(1.2284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4517 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4517 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4517 D_tricked_loss= tensor(1.2060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4518 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4518 D_fake_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4518 D_tricked_loss= tensor(1.2508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4519 D_real_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4519 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4519 D_tricked_loss= tensor(1.2159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4520 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4520 D_fake_loss= tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4520 D_tricked_loss= tensor(1.2104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4521 D_real_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4521 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4521 D_tricked_loss= tensor(1.1492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4522 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4522 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4522 D_tricked_loss= tensor(1.1579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4523 D_real_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4523 D_fake_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4523 D_tricked_loss= tensor(1.2164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4524 D_real_loss= tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4524 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4524 D_tricked_loss= tensor(1.2001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4525 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4525 D_fake_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4525 D_tricked_loss= tensor(1.1987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4526 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4526 D_fake_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4526 D_tricked_loss= tensor(1.1513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4527 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4527 D_fake_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4527 D_tricked_loss= tensor(1.1785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4528 D_real_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4528 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4528 D_tricked_loss= tensor(1.1938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4529 D_real_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4529 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4529 D_tricked_loss= tensor(1.2135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4530 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4530 D_fake_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4530 D_tricked_loss= tensor(1.2495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4531 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4531 D_fake_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4531 D_tricked_loss= tensor(1.2124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4532 D_real_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4532 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4532 D_tricked_loss= tensor(1.2493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4533 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4533 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4533 D_tricked_loss= tensor(1.2143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4534 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4534 D_fake_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4534 D_tricked_loss= tensor(1.2823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4535 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4535 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4535 D_tricked_loss= tensor(1.2375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4536 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4536 D_fake_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4536 D_tricked_loss= tensor(1.2567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4537 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4537 D_fake_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4537 D_tricked_loss= tensor(1.2541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4538 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4538 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4538 D_tricked_loss= tensor(1.2092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4539 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4539 D_fake_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4539 D_tricked_loss= tensor(1.2125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4540 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4540 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4540 D_tricked_loss= tensor(1.2156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4541 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4541 D_fake_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4541 D_tricked_loss= tensor(1.2142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4542 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4542 D_fake_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4542 D_tricked_loss= tensor(1.1771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4543 D_real_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4543 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4543 D_tricked_loss= tensor(1.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4544 D_real_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4544 D_fake_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4544 D_tricked_loss= tensor(1.1718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4545 D_real_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4545 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4545 D_tricked_loss= tensor(1.1725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4546 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4546 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4546 D_tricked_loss= tensor(1.1824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4547 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4547 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4547 D_tricked_loss= tensor(1.1804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4548 D_real_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4548 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4548 D_tricked_loss= tensor(1.1891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4549 D_real_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4549 D_fake_loss= tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4549 D_tricked_loss= tensor(1.1860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4550 D_real_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4550 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4550 D_tricked_loss= tensor(1.2205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4551 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4551 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4551 D_tricked_loss= tensor(1.2156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4552 D_real_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4552 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4552 D_tricked_loss= tensor(1.2293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4553 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4553 D_fake_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4553 D_tricked_loss= tensor(1.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4554 D_real_loss= tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4554 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4554 D_tricked_loss= tensor(1.1939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4555 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4555 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4555 D_tricked_loss= tensor(1.2257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4556 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4556 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4556 D_tricked_loss= tensor(1.2418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4557 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4557 D_fake_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4557 D_tricked_loss= tensor(1.2053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4558 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4558 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4558 D_tricked_loss= tensor(1.1988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4559 D_real_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4559 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4559 D_tricked_loss= tensor(1.2230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4560 D_real_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4560 D_fake_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4560 D_tricked_loss= tensor(1.1873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4561 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4561 D_fake_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4561 D_tricked_loss= tensor(1.2294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4562 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4562 D_fake_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4562 D_tricked_loss= tensor(1.1993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4563 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4563 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4563 D_tricked_loss= tensor(1.2212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4564 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4564 D_fake_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4564 D_tricked_loss= tensor(1.2845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4565 D_real_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4565 D_fake_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4565 D_tricked_loss= tensor(1.1977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4566 D_real_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4566 D_fake_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4566 D_tricked_loss= tensor(1.1967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4567 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4567 D_fake_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4567 D_tricked_loss= tensor(1.1918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4568 D_real_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4568 D_fake_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4568 D_tricked_loss= tensor(1.2055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4569 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4569 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4569 D_tricked_loss= tensor(1.1758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4570 D_real_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4570 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4570 D_tricked_loss= tensor(1.1792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4571 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4571 D_fake_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4571 D_tricked_loss= tensor(1.1810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4572 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4572 D_fake_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4572 D_tricked_loss= tensor(1.2038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4573 D_real_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4573 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4573 D_tricked_loss= tensor(1.1683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4574 D_real_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4574 D_fake_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4574 D_tricked_loss= tensor(1.1667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4575 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4575 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4575 D_tricked_loss= tensor(1.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4576 D_real_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4576 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4576 D_tricked_loss= tensor(1.1854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4577 D_real_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4577 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4577 D_tricked_loss= tensor(1.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4578 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4578 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4578 D_tricked_loss= tensor(1.1687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4579 D_real_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4579 D_fake_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4579 D_tricked_loss= tensor(1.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4580 D_real_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4580 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4580 D_tricked_loss= tensor(1.1871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4581 D_real_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4581 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4581 D_tricked_loss= tensor(1.2079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4582 D_real_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4582 D_fake_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4582 D_tricked_loss= tensor(1.1887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4583 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4583 D_fake_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4583 D_tricked_loss= tensor(1.1472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4584 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4584 D_fake_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4584 D_tricked_loss= tensor(1.1501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4585 D_real_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4585 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4585 D_tricked_loss= tensor(1.1771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4586 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4586 D_fake_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4586 D_tricked_loss= tensor(1.1461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4587 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4587 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4587 D_tricked_loss= tensor(1.1218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4588 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4588 D_fake_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4588 D_tricked_loss= tensor(1.1551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4589 D_real_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4589 D_fake_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4589 D_tricked_loss= tensor(1.1812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4590 D_real_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4590 D_fake_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4590 D_tricked_loss= tensor(1.2103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4591 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4591 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4591 D_tricked_loss= tensor(1.1914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4592 D_real_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4592 D_fake_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4592 D_tricked_loss= tensor(1.1915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4593 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4593 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4593 D_tricked_loss= tensor(1.2106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4594 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4594 D_fake_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4594 D_tricked_loss= tensor(1.1887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4595 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4595 D_fake_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4595 D_tricked_loss= tensor(1.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4596 D_real_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4596 D_fake_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4596 D_tricked_loss= tensor(1.1777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4597 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4597 D_fake_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4597 D_tricked_loss= tensor(1.1868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4598 D_real_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4598 D_fake_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4598 D_tricked_loss= tensor(1.1805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4599 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4599 D_fake_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4599 D_tricked_loss= tensor(1.1756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4600 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4600 D_fake_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4600 D_tricked_loss= tensor(1.1564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4601 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4601 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4601 D_tricked_loss= tensor(1.1959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4602 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4602 D_fake_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4602 D_tricked_loss= tensor(1.2215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4603 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4603 D_fake_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4603 D_tricked_loss= tensor(1.1853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4604 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4604 D_fake_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4604 D_tricked_loss= tensor(1.2212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4605 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4605 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4605 D_tricked_loss= tensor(1.1743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4606 D_real_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4606 D_fake_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4606 D_tricked_loss= tensor(1.1675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4607 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4607 D_fake_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4607 D_tricked_loss= tensor(1.2036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4608 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4608 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4608 D_tricked_loss= tensor(1.1802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4609 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4609 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4609 D_tricked_loss= tensor(1.1568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4610 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4610 D_fake_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4610 D_tricked_loss= tensor(1.2305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4611 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4611 D_fake_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4611 D_tricked_loss= tensor(1.2112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4612 D_real_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4612 D_fake_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4612 D_tricked_loss= tensor(1.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4613 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4613 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4613 D_tricked_loss= tensor(1.2235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4614 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4614 D_fake_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4614 D_tricked_loss= tensor(1.1849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4615 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4615 D_fake_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4615 D_tricked_loss= tensor(1.2239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4616 D_real_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4616 D_fake_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4616 D_tricked_loss= tensor(1.1740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4617 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4617 D_fake_loss= tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4617 D_tricked_loss= tensor(1.1535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4618 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4618 D_fake_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4618 D_tricked_loss= tensor(1.1796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4619 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4619 D_fake_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4619 D_tricked_loss= tensor(1.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4620 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4620 D_fake_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4620 D_tricked_loss= tensor(1.1680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4621 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4621 D_fake_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4621 D_tricked_loss= tensor(1.1908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4622 D_real_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4622 D_fake_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4622 D_tricked_loss= tensor(1.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4623 D_real_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4623 D_fake_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4623 D_tricked_loss= tensor(1.2138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4624 D_real_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4624 D_fake_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4624 D_tricked_loss= tensor(1.2070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4625 D_real_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4625 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4625 D_tricked_loss= tensor(1.2012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4626 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4626 D_fake_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4626 D_tricked_loss= tensor(1.2135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4627 D_real_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4627 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4627 D_tricked_loss= tensor(1.1954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4628 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4628 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4628 D_tricked_loss= tensor(1.2076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4629 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4629 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4629 D_tricked_loss= tensor(1.1917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4630 D_real_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4630 D_fake_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4630 D_tricked_loss= tensor(1.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4631 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4631 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4631 D_tricked_loss= tensor(1.1919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4632 D_real_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4632 D_fake_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4632 D_tricked_loss= tensor(1.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4633 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4633 D_fake_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4633 D_tricked_loss= tensor(1.1852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4634 D_real_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4634 D_fake_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4634 D_tricked_loss= tensor(1.1919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4635 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4635 D_fake_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4635 D_tricked_loss= tensor(1.2027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4636 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4636 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4636 D_tricked_loss= tensor(1.2186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4637 D_real_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4637 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4637 D_tricked_loss= tensor(1.2336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4638 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4638 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4638 D_tricked_loss= tensor(1.2568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4639 D_real_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4639 D_fake_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4639 D_tricked_loss= tensor(1.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4640 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4640 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4640 D_tricked_loss= tensor(1.1813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4641 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4641 D_fake_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4641 D_tricked_loss= tensor(1.1797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4642 D_real_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4642 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4642 D_tricked_loss= tensor(1.1617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4643 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4643 D_fake_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4643 D_tricked_loss= tensor(1.1433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4644 D_real_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4644 D_fake_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4644 D_tricked_loss= tensor(1.1802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4645 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4645 D_fake_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4645 D_tricked_loss= tensor(1.2057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4646 D_real_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4646 D_fake_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4646 D_tricked_loss= tensor(1.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4647 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4647 D_fake_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4647 D_tricked_loss= tensor(1.2350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4648 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4648 D_fake_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4648 D_tricked_loss= tensor(1.2127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4649 D_real_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4649 D_fake_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4649 D_tricked_loss= tensor(1.1957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4650 D_real_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4650 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4650 D_tricked_loss= tensor(1.2383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4651 D_real_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4651 D_fake_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4651 D_tricked_loss= tensor(1.1935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4652 D_real_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4652 D_fake_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4652 D_tricked_loss= tensor(1.2262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4653 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4653 D_fake_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4653 D_tricked_loss= tensor(1.2236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4654 D_real_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4654 D_fake_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4654 D_tricked_loss= tensor(1.2075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4655 D_real_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4655 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4655 D_tricked_loss= tensor(1.1972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4656 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4656 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4656 D_tricked_loss= tensor(1.1423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4657 D_real_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4657 D_fake_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4657 D_tricked_loss= tensor(1.1941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4658 D_real_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4658 D_fake_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4658 D_tricked_loss= tensor(1.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4659 D_real_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4659 D_fake_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4659 D_tricked_loss= tensor(1.1884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4660 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4660 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4660 D_tricked_loss= tensor(1.1723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4661 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4661 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4661 D_tricked_loss= tensor(1.1564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4662 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4662 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4662 D_tricked_loss= tensor(1.2120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4663 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4663 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4663 D_tricked_loss= tensor(1.1695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4664 D_real_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4664 D_fake_loss= tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4664 D_tricked_loss= tensor(1.1797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4665 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4665 D_fake_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4665 D_tricked_loss= tensor(1.1752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4666 D_real_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4666 D_fake_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4666 D_tricked_loss= tensor(1.1710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4667 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4667 D_fake_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4667 D_tricked_loss= tensor(1.1992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4668 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4668 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4668 D_tricked_loss= tensor(1.1750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4669 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4669 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4669 D_tricked_loss= tensor(1.1523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4670 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4670 D_fake_loss= tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4670 D_tricked_loss= tensor(1.1479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4671 D_real_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4671 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4671 D_tricked_loss= tensor(1.1826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4672 D_real_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4672 D_fake_loss= tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4672 D_tricked_loss= tensor(1.1817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4673 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4673 D_fake_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4673 D_tricked_loss= tensor(1.1205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4674 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4674 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4674 D_tricked_loss= tensor(1.1583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4675 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4675 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4675 D_tricked_loss= tensor(1.1579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4676 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4676 D_fake_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4676 D_tricked_loss= tensor(1.1163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4677 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4677 D_fake_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4677 D_tricked_loss= tensor(1.1498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4678 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4678 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4678 D_tricked_loss= tensor(1.1888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4679 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4679 D_fake_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4679 D_tricked_loss= tensor(1.1329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4680 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4680 D_fake_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4680 D_tricked_loss= tensor(1.1731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4681 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4681 D_fake_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4681 D_tricked_loss= tensor(1.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4682 D_real_loss= tensor(0.6057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4682 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4682 D_tricked_loss= tensor(1.1780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4683 D_real_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4683 D_fake_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4683 D_tricked_loss= tensor(1.1299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4684 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4684 D_fake_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4684 D_tricked_loss= tensor(1.1393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4685 D_real_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4685 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4685 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4686 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4686 D_fake_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4686 D_tricked_loss= tensor(1.1267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4687 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4687 D_fake_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4687 D_tricked_loss= tensor(1.1438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4688 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4688 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4688 D_tricked_loss= tensor(1.1898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4689 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4689 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4689 D_tricked_loss= tensor(1.1243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4690 D_real_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4690 D_fake_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4690 D_tricked_loss= tensor(1.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4691 D_real_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4691 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4691 D_tricked_loss= tensor(1.1116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4692 D_real_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4692 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4692 D_tricked_loss= tensor(1.1448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4693 D_real_loss= tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4693 D_fake_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4693 D_tricked_loss= tensor(1.1481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4694 D_real_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4694 D_fake_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4694 D_tricked_loss= tensor(1.1559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4695 D_real_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4695 D_fake_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4695 D_tricked_loss= tensor(1.1503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4696 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4696 D_fake_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4696 D_tricked_loss= tensor(1.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4697 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4697 D_fake_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4697 D_tricked_loss= tensor(1.1661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4698 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4698 D_fake_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4698 D_tricked_loss= tensor(1.1829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4699 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4699 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4699 D_tricked_loss= tensor(1.1771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4700 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4700 D_fake_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4700 D_tricked_loss= tensor(1.1442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4701 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4701 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4701 D_tricked_loss= tensor(1.2132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4702 D_real_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4702 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4702 D_tricked_loss= tensor(1.1452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4703 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4703 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4703 D_tricked_loss= tensor(1.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4704 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4704 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4704 D_tricked_loss= tensor(1.1910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4705 D_real_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4705 D_fake_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4705 D_tricked_loss= tensor(1.1642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4706 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4706 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4706 D_tricked_loss= tensor(1.1898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4707 D_real_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4707 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4707 D_tricked_loss= tensor(1.1857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4708 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4708 D_fake_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4708 D_tricked_loss= tensor(1.1473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4709 D_real_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4709 D_fake_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4709 D_tricked_loss= tensor(1.1165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4710 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4710 D_fake_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4710 D_tricked_loss= tensor(1.1716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4711 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4711 D_fake_loss= tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4711 D_tricked_loss= tensor(1.1640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4712 D_real_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4712 D_fake_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4712 D_tricked_loss= tensor(1.1776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4713 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4713 D_fake_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4713 D_tricked_loss= tensor(1.1635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4714 D_real_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4714 D_fake_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4714 D_tricked_loss= tensor(1.1851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4715 D_real_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4715 D_fake_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4715 D_tricked_loss= tensor(1.1970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4716 D_real_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4716 D_fake_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4716 D_tricked_loss= tensor(1.1417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4717 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4717 D_fake_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4717 D_tricked_loss= tensor(1.1863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4718 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4718 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4718 D_tricked_loss= tensor(1.1704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4719 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4719 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4719 D_tricked_loss= tensor(1.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4720 D_real_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4720 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4720 D_tricked_loss= tensor(1.2075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4721 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4721 D_fake_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4721 D_tricked_loss= tensor(1.1923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4722 D_real_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4722 D_fake_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4722 D_tricked_loss= tensor(1.1798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4723 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4723 D_fake_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4723 D_tricked_loss= tensor(1.1947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4724 D_real_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4724 D_fake_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4724 D_tricked_loss= tensor(1.1988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4725 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4725 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4725 D_tricked_loss= tensor(1.1439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4726 D_real_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4726 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4726 D_tricked_loss= tensor(1.1637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4727 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4727 D_fake_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4727 D_tricked_loss= tensor(1.1493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4728 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4728 D_fake_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4728 D_tricked_loss= tensor(1.2072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4729 D_real_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4729 D_fake_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4729 D_tricked_loss= tensor(1.1802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4730 D_real_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4730 D_fake_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4730 D_tricked_loss= tensor(1.1908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4731 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4731 D_fake_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4731 D_tricked_loss= tensor(1.1578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4732 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4732 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4732 D_tricked_loss= tensor(1.2379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4733 D_real_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4733 D_fake_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4733 D_tricked_loss= tensor(1.2605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4734 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4734 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4734 D_tricked_loss= tensor(1.2206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4735 D_real_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4735 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4735 D_tricked_loss= tensor(1.2577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4736 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4736 D_fake_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4736 D_tricked_loss= tensor(1.2861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4737 D_real_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4737 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4737 D_tricked_loss= tensor(1.1706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4738 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4738 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4738 D_tricked_loss= tensor(1.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4739 D_real_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4739 D_fake_loss= tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4739 D_tricked_loss= tensor(1.2036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4740 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4740 D_fake_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4740 D_tricked_loss= tensor(1.2640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4741 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4741 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4741 D_tricked_loss= tensor(1.2455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4742 D_real_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4742 D_fake_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4742 D_tricked_loss= tensor(1.1923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4743 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4743 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4743 D_tricked_loss= tensor(1.1711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4744 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4744 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4744 D_tricked_loss= tensor(1.1441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4745 D_real_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4745 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4745 D_tricked_loss= tensor(1.1933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4746 D_real_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4746 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4746 D_tricked_loss= tensor(1.1638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4747 D_real_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4747 D_fake_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4747 D_tricked_loss= tensor(1.1140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4748 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4748 D_fake_loss= tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4748 D_tricked_loss= tensor(1.2056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4749 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4749 D_fake_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4749 D_tricked_loss= tensor(1.1578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4750 D_real_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4750 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4750 D_tricked_loss= tensor(1.1860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4751 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4751 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4751 D_tricked_loss= tensor(1.1791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4752 D_real_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4752 D_fake_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4752 D_tricked_loss= tensor(1.1735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4753 D_real_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4753 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4753 D_tricked_loss= tensor(1.1325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4754 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4754 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4754 D_tricked_loss= tensor(1.1702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4755 D_real_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4755 D_fake_loss= tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4755 D_tricked_loss= tensor(1.2041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4756 D_real_loss= tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4756 D_fake_loss= tensor(0.5180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4756 D_tricked_loss= tensor(1.2365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4757 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4757 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4757 D_tricked_loss= tensor(1.1674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4758 D_real_loss= tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4758 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4758 D_tricked_loss= tensor(1.1991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4759 D_real_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4759 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4759 D_tricked_loss= tensor(1.1944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4760 D_real_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4760 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4760 D_tricked_loss= tensor(1.2133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4761 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4761 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4761 D_tricked_loss= tensor(1.2003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4762 D_real_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4762 D_fake_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4762 D_tricked_loss= tensor(1.2239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4763 D_real_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4763 D_fake_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4763 D_tricked_loss= tensor(1.2250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4764 D_real_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4764 D_fake_loss= tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4764 D_tricked_loss= tensor(1.1920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4765 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4765 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4765 D_tricked_loss= tensor(1.2078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4766 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4766 D_fake_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4766 D_tricked_loss= tensor(1.1480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4767 D_real_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4767 D_fake_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4767 D_tricked_loss= tensor(1.1532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4768 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4768 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4768 D_tricked_loss= tensor(1.1940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4769 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4769 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4769 D_tricked_loss= tensor(1.1160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4770 D_real_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4770 D_fake_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4770 D_tricked_loss= tensor(1.1453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4771 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4771 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4771 D_tricked_loss= tensor(1.1173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4772 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4772 D_fake_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4772 D_tricked_loss= tensor(1.1176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4773 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4773 D_fake_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4773 D_tricked_loss= tensor(1.1638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4774 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4774 D_fake_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4774 D_tricked_loss= tensor(1.1183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4775 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4775 D_fake_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4775 D_tricked_loss= tensor(1.1847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4776 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4776 D_fake_loss= tensor(0.5946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4776 D_tricked_loss= tensor(1.1100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4777 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4777 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4777 D_tricked_loss= tensor(1.1313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4778 D_real_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4778 D_fake_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4778 D_tricked_loss= tensor(1.1386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4779 D_real_loss= tensor(0.6245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4779 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4779 D_tricked_loss= tensor(1.1431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4780 D_real_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4780 D_fake_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4780 D_tricked_loss= tensor(1.1592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4781 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4781 D_fake_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4781 D_tricked_loss= tensor(1.1845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4782 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4782 D_fake_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4782 D_tricked_loss= tensor(1.1506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4783 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4783 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4783 D_tricked_loss= tensor(1.1934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4784 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4784 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4784 D_tricked_loss= tensor(1.1611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4785 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4785 D_fake_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4785 D_tricked_loss= tensor(1.2236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4786 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4786 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4786 D_tricked_loss= tensor(1.2152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4787 D_real_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4787 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4787 D_tricked_loss= tensor(1.1614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4788 D_real_loss= tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4788 D_fake_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4788 D_tricked_loss= tensor(1.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4789 D_real_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4789 D_fake_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4789 D_tricked_loss= tensor(1.1371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4790 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4790 D_fake_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4790 D_tricked_loss= tensor(1.1826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4791 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4791 D_fake_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4791 D_tricked_loss= tensor(1.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4792 D_real_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4792 D_fake_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4792 D_tricked_loss= tensor(1.1231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4793 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4793 D_fake_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4793 D_tricked_loss= tensor(1.2085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4794 D_real_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4794 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4794 D_tricked_loss= tensor(1.1775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4795 D_real_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4795 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4795 D_tricked_loss= tensor(1.1938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4796 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4796 D_fake_loss= tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4796 D_tricked_loss= tensor(1.2172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4797 D_real_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4797 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4797 D_tricked_loss= tensor(1.1719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4798 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4798 D_fake_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4798 D_tricked_loss= tensor(1.2199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4799 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4799 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4799 D_tricked_loss= tensor(1.1777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4800 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4800 D_fake_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4800 D_tricked_loss= tensor(1.1385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4801 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4801 D_fake_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4801 D_tricked_loss= tensor(1.1459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4802 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4802 D_fake_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4802 D_tricked_loss= tensor(1.1500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4803 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4803 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4803 D_tricked_loss= tensor(1.1391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4804 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4804 D_fake_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4804 D_tricked_loss= tensor(1.1602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4805 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4805 D_fake_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4805 D_tricked_loss= tensor(1.1737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4806 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4806 D_fake_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4806 D_tricked_loss= tensor(1.2285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4807 D_real_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4807 D_fake_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4807 D_tricked_loss= tensor(1.1688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4808 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4808 D_fake_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4808 D_tricked_loss= tensor(1.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4809 D_real_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4809 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4809 D_tricked_loss= tensor(1.2247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4810 D_real_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4810 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4810 D_tricked_loss= tensor(1.1992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4811 D_real_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4811 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4811 D_tricked_loss= tensor(1.2253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4812 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4812 D_fake_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4812 D_tricked_loss= tensor(1.2439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4813 D_real_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4813 D_fake_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4813 D_tricked_loss= tensor(1.2188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4814 D_real_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4814 D_fake_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4814 D_tricked_loss= tensor(1.2158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4815 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4815 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4815 D_tricked_loss= tensor(1.2266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4816 D_real_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4816 D_fake_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4816 D_tricked_loss= tensor(1.2103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4817 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4817 D_fake_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4817 D_tricked_loss= tensor(1.1696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4818 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4818 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4818 D_tricked_loss= tensor(1.1626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4819 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4819 D_fake_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4819 D_tricked_loss= tensor(1.1844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4820 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4820 D_fake_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4820 D_tricked_loss= tensor(1.1321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4821 D_real_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4821 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4821 D_tricked_loss= tensor(1.1354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4822 D_real_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4822 D_fake_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4822 D_tricked_loss= tensor(1.1229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4823 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4823 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4823 D_tricked_loss= tensor(1.1292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4824 D_real_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4824 D_fake_loss= tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4824 D_tricked_loss= tensor(1.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4825 D_real_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4825 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4825 D_tricked_loss= tensor(1.1628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4826 D_real_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4826 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4826 D_tricked_loss= tensor(1.1562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4827 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4827 D_fake_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4827 D_tricked_loss= tensor(1.1909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4828 D_real_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4828 D_fake_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4828 D_tricked_loss= tensor(1.1515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4829 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4829 D_fake_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4829 D_tricked_loss= tensor(1.2233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4830 D_real_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4830 D_fake_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4830 D_tricked_loss= tensor(1.2249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4831 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4831 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4831 D_tricked_loss= tensor(1.2377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4832 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4832 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4832 D_tricked_loss= tensor(1.1986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4833 D_real_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4833 D_fake_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4833 D_tricked_loss= tensor(1.1761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4834 D_real_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4834 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4834 D_tricked_loss= tensor(1.1079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4835 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4835 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4835 D_tricked_loss= tensor(1.1910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4836 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4836 D_fake_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4836 D_tricked_loss= tensor(1.1346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4837 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4837 D_fake_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4837 D_tricked_loss= tensor(1.1524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4838 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4838 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4838 D_tricked_loss= tensor(1.2198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4839 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4839 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4839 D_tricked_loss= tensor(1.2081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4840 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4840 D_fake_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4840 D_tricked_loss= tensor(1.2533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4841 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4841 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4841 D_tricked_loss= tensor(1.2361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4842 D_real_loss= tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4842 D_fake_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4842 D_tricked_loss= tensor(1.2506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4843 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4843 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4843 D_tricked_loss= tensor(1.1670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4844 D_real_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4844 D_fake_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4844 D_tricked_loss= tensor(1.1504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4845 D_real_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4845 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4845 D_tricked_loss= tensor(1.1759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4846 D_real_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4846 D_fake_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4846 D_tricked_loss= tensor(1.1353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4847 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4847 D_fake_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4847 D_tricked_loss= tensor(1.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4848 D_real_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4848 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4848 D_tricked_loss= tensor(1.1176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4849 D_real_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4849 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4849 D_tricked_loss= tensor(1.1459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4850 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4850 D_fake_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4850 D_tricked_loss= tensor(1.1898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4851 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4851 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4851 D_tricked_loss= tensor(1.1634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4852 D_real_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4852 D_fake_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4852 D_tricked_loss= tensor(1.2044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4853 D_real_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4853 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4853 D_tricked_loss= tensor(1.2275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4854 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4854 D_fake_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4854 D_tricked_loss= tensor(1.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4855 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4855 D_fake_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4855 D_tricked_loss= tensor(1.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4856 D_real_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4856 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4856 D_tricked_loss= tensor(1.1672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4857 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4857 D_fake_loss= tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4857 D_tricked_loss= tensor(1.1998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4858 D_real_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4858 D_fake_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4858 D_tricked_loss= tensor(1.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4859 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4859 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4859 D_tricked_loss= tensor(1.1741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4860 D_real_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4860 D_fake_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4860 D_tricked_loss= tensor(1.1591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4861 D_real_loss= tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4861 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4861 D_tricked_loss= tensor(1.1498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4862 D_real_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4862 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4862 D_tricked_loss= tensor(1.1748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4863 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4863 D_fake_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4863 D_tricked_loss= tensor(1.1906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4864 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4864 D_fake_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4864 D_tricked_loss= tensor(1.1670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4865 D_real_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4865 D_fake_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4865 D_tricked_loss= tensor(1.1460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4866 D_real_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4866 D_fake_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4866 D_tricked_loss= tensor(1.1646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4867 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4867 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4867 D_tricked_loss= tensor(1.1828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4868 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4868 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4868 D_tricked_loss= tensor(1.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4869 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4869 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4869 D_tricked_loss= tensor(1.1844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4870 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4870 D_fake_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4870 D_tricked_loss= tensor(1.1218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4871 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4871 D_fake_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4871 D_tricked_loss= tensor(1.1570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4872 D_real_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4872 D_fake_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4872 D_tricked_loss= tensor(1.1380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4873 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4873 D_fake_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4873 D_tricked_loss= tensor(1.1290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4874 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4874 D_fake_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4874 D_tricked_loss= tensor(1.1950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4875 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4875 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4875 D_tricked_loss= tensor(1.1759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4876 D_real_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4876 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4876 D_tricked_loss= tensor(1.1653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4877 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4877 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4877 D_tricked_loss= tensor(1.1615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4878 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4878 D_fake_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4878 D_tricked_loss= tensor(1.1529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4879 D_real_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4879 D_fake_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4879 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4880 D_real_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4880 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4880 D_tricked_loss= tensor(1.1630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4881 D_real_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4881 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4881 D_tricked_loss= tensor(1.1745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4882 D_real_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4882 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4882 D_tricked_loss= tensor(1.1564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4883 D_real_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4883 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4883 D_tricked_loss= tensor(1.1463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4884 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4884 D_fake_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4884 D_tricked_loss= tensor(1.1804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4885 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4885 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4885 D_tricked_loss= tensor(1.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4886 D_real_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4886 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4886 D_tricked_loss= tensor(1.2361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4887 D_real_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4887 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4887 D_tricked_loss= tensor(1.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4888 D_real_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4888 D_fake_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4888 D_tricked_loss= tensor(1.1671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4889 D_real_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4889 D_fake_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4889 D_tricked_loss= tensor(1.1962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4890 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4890 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4890 D_tricked_loss= tensor(1.1779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4891 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4891 D_fake_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4891 D_tricked_loss= tensor(1.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4892 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4892 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4892 D_tricked_loss= tensor(1.1996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4893 D_real_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4893 D_fake_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4893 D_tricked_loss= tensor(1.1343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4894 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4894 D_fake_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4894 D_tricked_loss= tensor(1.1577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4895 D_real_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4895 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4895 D_tricked_loss= tensor(1.1565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4896 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4896 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4896 D_tricked_loss= tensor(1.1199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4897 D_real_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4897 D_fake_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4897 D_tricked_loss= tensor(1.1532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4898 D_real_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4898 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4898 D_tricked_loss= tensor(1.1550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4899 D_real_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4899 D_fake_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4899 D_tricked_loss= tensor(1.1645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4900 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4900 D_fake_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4900 D_tricked_loss= tensor(1.1465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4901 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4901 D_fake_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4901 D_tricked_loss= tensor(1.1727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4902 D_real_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4902 D_fake_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4902 D_tricked_loss= tensor(1.1582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4903 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4903 D_fake_loss= tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4903 D_tricked_loss= tensor(1.1695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4904 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4904 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4904 D_tricked_loss= tensor(1.1484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4905 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4905 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4905 D_tricked_loss= tensor(1.1439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4906 D_real_loss= tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4906 D_fake_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4906 D_tricked_loss= tensor(1.1368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4907 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4907 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4907 D_tricked_loss= tensor(1.1513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4908 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4908 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4908 D_tricked_loss= tensor(1.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4909 D_real_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4909 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4909 D_tricked_loss= tensor(1.1484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4910 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4910 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4910 D_tricked_loss= tensor(1.1329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4911 D_real_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4911 D_fake_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4911 D_tricked_loss= tensor(1.1562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4912 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4912 D_fake_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4912 D_tricked_loss= tensor(1.1218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4913 D_real_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4913 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4913 D_tricked_loss= tensor(1.1283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4914 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4914 D_fake_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4914 D_tricked_loss= tensor(1.1182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4915 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4915 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4915 D_tricked_loss= tensor(1.0889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4916 D_real_loss= tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4916 D_fake_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4916 D_tricked_loss= tensor(1.1516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4917 D_real_loss= tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4917 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4917 D_tricked_loss= tensor(1.1210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4918 D_real_loss= tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4918 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4918 D_tricked_loss= tensor(1.1341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4919 D_real_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4919 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4919 D_tricked_loss= tensor(1.1006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4920 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4920 D_fake_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4920 D_tricked_loss= tensor(1.0794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4921 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4921 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4921 D_tricked_loss= tensor(1.0816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4922 D_real_loss= tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4922 D_fake_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4922 D_tricked_loss= tensor(1.1073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4923 D_real_loss= tensor(0.6126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4923 D_fake_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4923 D_tricked_loss= tensor(1.1421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4924 D_real_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4924 D_fake_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4924 D_tricked_loss= tensor(1.1084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4925 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4925 D_fake_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4925 D_tricked_loss= tensor(1.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4926 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4926 D_fake_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4926 D_tricked_loss= tensor(1.1822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4927 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4927 D_fake_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4927 D_tricked_loss= tensor(1.1469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4928 D_real_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4928 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4928 D_tricked_loss= tensor(1.1673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4929 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4929 D_fake_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4929 D_tricked_loss= tensor(1.1693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4930 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4930 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4930 D_tricked_loss= tensor(1.1302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4931 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4931 D_fake_loss= tensor(0.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4931 D_tricked_loss= tensor(1.1494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4932 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4932 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4932 D_tricked_loss= tensor(1.1658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4933 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4933 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4933 D_tricked_loss= tensor(1.1882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4934 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4934 D_fake_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4934 D_tricked_loss= tensor(1.1632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4935 D_real_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4935 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4935 D_tricked_loss= tensor(1.1335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4936 D_real_loss= tensor(0.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4936 D_fake_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4936 D_tricked_loss= tensor(1.1395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4937 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4937 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4937 D_tricked_loss= tensor(1.1710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4938 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4938 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4938 D_tricked_loss= tensor(1.1668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4939 D_real_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4939 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4939 D_tricked_loss= tensor(1.1201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4940 D_real_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4940 D_fake_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4940 D_tricked_loss= tensor(1.1578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4941 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4941 D_fake_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4941 D_tricked_loss= tensor(1.1605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4942 D_real_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4942 D_fake_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4942 D_tricked_loss= tensor(1.1254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4943 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4943 D_fake_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4943 D_tricked_loss= tensor(1.1692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4944 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4944 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4944 D_tricked_loss= tensor(1.1229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4945 D_real_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4945 D_fake_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4945 D_tricked_loss= tensor(1.1528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4946 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4946 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4946 D_tricked_loss= tensor(1.1643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4947 D_real_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4947 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4947 D_tricked_loss= tensor(1.1470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4948 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4948 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4948 D_tricked_loss= tensor(1.1521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4949 D_real_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4949 D_fake_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4949 D_tricked_loss= tensor(1.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4950 D_real_loss= tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4950 D_fake_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4950 D_tricked_loss= tensor(1.1755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4951 D_real_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4951 D_fake_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4951 D_tricked_loss= tensor(1.2030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4952 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4952 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4952 D_tricked_loss= tensor(1.1640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4953 D_real_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4953 D_fake_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4953 D_tricked_loss= tensor(1.1743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4954 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4954 D_fake_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4954 D_tricked_loss= tensor(1.1735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4955 D_real_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4955 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4955 D_tricked_loss= tensor(1.2136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4956 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4956 D_fake_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4956 D_tricked_loss= tensor(1.2324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4957 D_real_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4957 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4957 D_tricked_loss= tensor(1.1628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4958 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4958 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4958 D_tricked_loss= tensor(1.1664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4959 D_real_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4959 D_fake_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4959 D_tricked_loss= tensor(1.1400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4960 D_real_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4960 D_fake_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4960 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4961 D_real_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4961 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4961 D_tricked_loss= tensor(1.1527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4962 D_real_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4962 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4962 D_tricked_loss= tensor(1.1854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4963 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4963 D_fake_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4963 D_tricked_loss= tensor(1.1415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4964 D_real_loss= tensor(0.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4964 D_fake_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4964 D_tricked_loss= tensor(1.1315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4965 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4965 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4965 D_tricked_loss= tensor(1.1481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4966 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4966 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4966 D_tricked_loss= tensor(1.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4967 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4967 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4967 D_tricked_loss= tensor(1.1431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4968 D_real_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4968 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4968 D_tricked_loss= tensor(1.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4969 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4969 D_fake_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4969 D_tricked_loss= tensor(1.1790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4970 D_real_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4970 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4970 D_tricked_loss= tensor(1.1447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4971 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4971 D_fake_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4971 D_tricked_loss= tensor(1.1683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4972 D_real_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4972 D_fake_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4972 D_tricked_loss= tensor(1.1179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4973 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4973 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4973 D_tricked_loss= tensor(1.1268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4974 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4974 D_fake_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4974 D_tricked_loss= tensor(1.1419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4975 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4975 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4975 D_tricked_loss= tensor(1.1192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4976 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4976 D_fake_loss= tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4976 D_tricked_loss= tensor(1.1465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4977 D_real_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4977 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4977 D_tricked_loss= tensor(1.1293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4978 D_real_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4978 D_fake_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4978 D_tricked_loss= tensor(1.1474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4979 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4979 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4979 D_tricked_loss= tensor(1.1421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4980 D_real_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4980 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4980 D_tricked_loss= tensor(1.1361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4981 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4981 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4981 D_tricked_loss= tensor(1.1863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4982 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4982 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4982 D_tricked_loss= tensor(1.1284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4983 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4983 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4983 D_tricked_loss= tensor(1.1224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4984 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4984 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4984 D_tricked_loss= tensor(1.1388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4985 D_real_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4985 D_fake_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4985 D_tricked_loss= tensor(1.1232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4986 D_real_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4986 D_fake_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4986 D_tricked_loss= tensor(1.1242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4987 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4987 D_fake_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4987 D_tricked_loss= tensor(1.1704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4988 D_real_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4988 D_fake_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4988 D_tricked_loss= tensor(1.1586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4989 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4989 D_fake_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4989 D_tricked_loss= tensor(1.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4990 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4990 D_fake_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4990 D_tricked_loss= tensor(1.1654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4991 D_real_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4991 D_fake_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4991 D_tricked_loss= tensor(1.1913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4992 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4992 D_fake_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4992 D_tricked_loss= tensor(1.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4993 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4993 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4993 D_tricked_loss= tensor(1.1158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4994 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4994 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4994 D_tricked_loss= tensor(1.1721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4995 D_real_loss= tensor(0.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4995 D_fake_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4995 D_tricked_loss= tensor(1.2027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4996 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4996 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4996 D_tricked_loss= tensor(1.1730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4997 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4997 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4997 D_tricked_loss= tensor(1.1779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4998 D_real_loss= tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4998 D_fake_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4998 D_tricked_loss= tensor(1.1566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "4999 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4999 D_fake_loss= tensor(0.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4999 D_tricked_loss= tensor(1.1779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5000 D_real_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5000 D_fake_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5000 D_tricked_loss= tensor(1.1400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5001 D_real_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5001 D_fake_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5001 D_tricked_loss= tensor(1.1376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5002 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5002 D_fake_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5002 D_tricked_loss= tensor(1.1604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5003 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5003 D_fake_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5003 D_tricked_loss= tensor(1.1795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5004 D_real_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5004 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5004 D_tricked_loss= tensor(1.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5005 D_real_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5005 D_fake_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5005 D_tricked_loss= tensor(1.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5006 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5006 D_fake_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5006 D_tricked_loss= tensor(1.1379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5007 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5007 D_fake_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5007 D_tricked_loss= tensor(1.1440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5008 D_real_loss= tensor(0.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5008 D_fake_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5008 D_tricked_loss= tensor(1.1649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5009 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5009 D_fake_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5009 D_tricked_loss= tensor(1.1580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5010 D_real_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5010 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5010 D_tricked_loss= tensor(1.1342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5011 D_real_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5011 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5011 D_tricked_loss= tensor(1.1554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5012 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5012 D_fake_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5012 D_tricked_loss= tensor(1.1755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5013 D_real_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5013 D_fake_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5013 D_tricked_loss= tensor(1.1718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5014 D_real_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5014 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5014 D_tricked_loss= tensor(1.1607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5015 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5015 D_fake_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5015 D_tricked_loss= tensor(1.1442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5016 D_real_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5016 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5016 D_tricked_loss= tensor(1.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5017 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5017 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5017 D_tricked_loss= tensor(1.1767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5018 D_real_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5018 D_fake_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5018 D_tricked_loss= tensor(1.1165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5019 D_real_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5019 D_fake_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5019 D_tricked_loss= tensor(1.1777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5020 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5020 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5020 D_tricked_loss= tensor(1.1188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5021 D_real_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5021 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5021 D_tricked_loss= tensor(1.1740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5022 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5022 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5022 D_tricked_loss= tensor(1.1624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5023 D_real_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5023 D_fake_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5023 D_tricked_loss= tensor(1.1544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5024 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5024 D_fake_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5024 D_tricked_loss= tensor(1.2053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5025 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5025 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5025 D_tricked_loss= tensor(1.1668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5026 D_real_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5026 D_fake_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5026 D_tricked_loss= tensor(1.1467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5027 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5027 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5027 D_tricked_loss= tensor(1.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5028 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5028 D_fake_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5028 D_tricked_loss= tensor(1.1879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5029 D_real_loss= tensor(0.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5029 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5029 D_tricked_loss= tensor(1.1756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5030 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5030 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5030 D_tricked_loss= tensor(1.1635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5031 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5031 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5031 D_tricked_loss= tensor(1.1500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5032 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5032 D_fake_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5032 D_tricked_loss= tensor(1.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5033 D_real_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5033 D_fake_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5033 D_tricked_loss= tensor(1.1304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5034 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5034 D_fake_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5034 D_tricked_loss= tensor(1.1844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5035 D_real_loss= tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5035 D_fake_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5035 D_tricked_loss= tensor(1.1466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5036 D_real_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5036 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5036 D_tricked_loss= tensor(1.1699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5037 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5037 D_fake_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5037 D_tricked_loss= tensor(1.1950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5038 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5038 D_fake_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5038 D_tricked_loss= tensor(1.1353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5039 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5039 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5039 D_tricked_loss= tensor(1.1584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5040 D_real_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5040 D_fake_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5040 D_tricked_loss= tensor(1.1431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5041 D_real_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5041 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5041 D_tricked_loss= tensor(1.1540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5042 D_real_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5042 D_fake_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5042 D_tricked_loss= tensor(1.1328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5043 D_real_loss= tensor(0.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5043 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5043 D_tricked_loss= tensor(1.1532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5044 D_real_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5044 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5044 D_tricked_loss= tensor(1.1709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5045 D_real_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5045 D_fake_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5045 D_tricked_loss= tensor(1.1397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5046 D_real_loss= tensor(0.6011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5046 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5046 D_tricked_loss= tensor(1.1907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5047 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5047 D_fake_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5047 D_tricked_loss= tensor(1.1903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5048 D_real_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5048 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5048 D_tricked_loss= tensor(1.1297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5049 D_real_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5049 D_fake_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5049 D_tricked_loss= tensor(1.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5050 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5050 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5050 D_tricked_loss= tensor(1.1235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5051 D_real_loss= tensor(0.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5051 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5051 D_tricked_loss= tensor(1.1615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5052 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5052 D_fake_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5052 D_tricked_loss= tensor(1.1390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5053 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5053 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5053 D_tricked_loss= tensor(1.1448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5054 D_real_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5054 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5054 D_tricked_loss= tensor(1.1657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5055 D_real_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5055 D_fake_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5055 D_tricked_loss= tensor(1.1433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5056 D_real_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5056 D_fake_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5056 D_tricked_loss= tensor(1.1488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5057 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5057 D_fake_loss= tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5057 D_tricked_loss= tensor(1.1299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5058 D_real_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5058 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5058 D_tricked_loss= tensor(1.1237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5059 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5059 D_fake_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5059 D_tricked_loss= tensor(1.1739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5060 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5060 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5060 D_tricked_loss= tensor(1.1539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5061 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5061 D_fake_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5061 D_tricked_loss= tensor(1.1667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5062 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5062 D_fake_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5062 D_tricked_loss= tensor(1.1729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5063 D_real_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5063 D_fake_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5063 D_tricked_loss= tensor(1.0949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5064 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5064 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5064 D_tricked_loss= tensor(1.1735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5065 D_real_loss= tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5065 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5065 D_tricked_loss= tensor(1.1454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5066 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5066 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5066 D_tricked_loss= tensor(1.1850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5067 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5067 D_fake_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5067 D_tricked_loss= tensor(1.1949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5068 D_real_loss= tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5068 D_fake_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5068 D_tricked_loss= tensor(1.1601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5069 D_real_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5069 D_fake_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5069 D_tricked_loss= tensor(1.1606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5070 D_real_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5070 D_fake_loss= tensor(0.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5070 D_tricked_loss= tensor(1.1291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5071 D_real_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5071 D_fake_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5071 D_tricked_loss= tensor(1.1338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5072 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5072 D_fake_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5072 D_tricked_loss= tensor(1.1725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5073 D_real_loss= tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5073 D_fake_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5073 D_tricked_loss= tensor(1.1501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5074 D_real_loss= tensor(0.6111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5074 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5074 D_tricked_loss= tensor(1.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5075 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5075 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5075 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5076 D_real_loss= tensor(0.6048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5076 D_fake_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5076 D_tricked_loss= tensor(1.1867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5077 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5077 D_fake_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5077 D_tricked_loss= tensor(1.1304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5078 D_real_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5078 D_fake_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5078 D_tricked_loss= tensor(1.1482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5079 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5079 D_fake_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5079 D_tricked_loss= tensor(1.1283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5080 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5080 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5080 D_tricked_loss= tensor(1.1371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5081 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5081 D_fake_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5081 D_tricked_loss= tensor(1.1413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5082 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5082 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5082 D_tricked_loss= tensor(1.1705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5083 D_real_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5083 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5083 D_tricked_loss= tensor(1.1335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5084 D_real_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5084 D_fake_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5084 D_tricked_loss= tensor(1.1452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5085 D_real_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5085 D_fake_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5085 D_tricked_loss= tensor(1.1912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5086 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5086 D_fake_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5086 D_tricked_loss= tensor(1.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5087 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5087 D_fake_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5087 D_tricked_loss= tensor(1.1293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5088 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5088 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5088 D_tricked_loss= tensor(1.1610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5089 D_real_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5089 D_fake_loss= tensor(0.5683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5089 D_tricked_loss= tensor(1.1032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5090 D_real_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5090 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5090 D_tricked_loss= tensor(1.1286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5091 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5091 D_fake_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5091 D_tricked_loss= tensor(1.1393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5092 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5092 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5092 D_tricked_loss= tensor(1.1613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5093 D_real_loss= tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5093 D_fake_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5093 D_tricked_loss= tensor(1.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5094 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5094 D_fake_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5094 D_tricked_loss= tensor(1.1341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5095 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5095 D_fake_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5095 D_tricked_loss= tensor(1.1395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5096 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5096 D_fake_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5096 D_tricked_loss= tensor(1.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5097 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5097 D_fake_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5097 D_tricked_loss= tensor(1.1338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5098 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5098 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5098 D_tricked_loss= tensor(1.1575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5099 D_real_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5099 D_fake_loss= tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5099 D_tricked_loss= tensor(1.1117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5100 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5100 D_fake_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5100 D_tricked_loss= tensor(1.1093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5101 D_real_loss= tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5101 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5101 D_tricked_loss= tensor(1.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5102 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5102 D_fake_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5102 D_tricked_loss= tensor(1.1034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5103 D_real_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5103 D_fake_loss= tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5103 D_tricked_loss= tensor(1.1570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5104 D_real_loss= tensor(0.6139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5104 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5104 D_tricked_loss= tensor(1.1226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5105 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5105 D_fake_loss= tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5105 D_tricked_loss= tensor(1.0967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5106 D_real_loss= tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5106 D_fake_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5106 D_tricked_loss= tensor(1.1171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5107 D_real_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5107 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5107 D_tricked_loss= tensor(1.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5108 D_real_loss= tensor(0.6137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5108 D_fake_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5108 D_tricked_loss= tensor(1.1320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5109 D_real_loss= tensor(0.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5109 D_fake_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5109 D_tricked_loss= tensor(1.0768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5110 D_real_loss= tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5110 D_fake_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5110 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5111 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5111 D_fake_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5111 D_tricked_loss= tensor(1.1266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5112 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5112 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5112 D_tricked_loss= tensor(1.1273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5113 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5113 D_fake_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5113 D_tricked_loss= tensor(1.1591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5114 D_real_loss= tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5114 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5114 D_tricked_loss= tensor(1.0945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5115 D_real_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5115 D_fake_loss= tensor(0.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5115 D_tricked_loss= tensor(1.1546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5116 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5116 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5116 D_tricked_loss= tensor(1.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5117 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5117 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5117 D_tricked_loss= tensor(1.0982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5118 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5118 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5118 D_tricked_loss= tensor(1.1693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5119 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5119 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5119 D_tricked_loss= tensor(1.1243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5120 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5120 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5120 D_tricked_loss= tensor(1.1342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5121 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5121 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5121 D_tricked_loss= tensor(1.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5122 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5122 D_fake_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5122 D_tricked_loss= tensor(1.0982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5123 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5123 D_fake_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5123 D_tricked_loss= tensor(1.1431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5124 D_real_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5124 D_fake_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5124 D_tricked_loss= tensor(1.1268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5125 D_real_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5125 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5125 D_tricked_loss= tensor(1.1474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5126 D_real_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5126 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5126 D_tricked_loss= tensor(1.1325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5127 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5127 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5127 D_tricked_loss= tensor(1.1069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5128 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5128 D_fake_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5128 D_tricked_loss= tensor(1.1375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5129 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5129 D_fake_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5129 D_tricked_loss= tensor(1.1428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5130 D_real_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5130 D_fake_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5130 D_tricked_loss= tensor(1.0923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5131 D_real_loss= tensor(0.6104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5131 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5131 D_tricked_loss= tensor(1.1298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5132 D_real_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5132 D_fake_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5132 D_tricked_loss= tensor(1.0880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5133 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5133 D_fake_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5133 D_tricked_loss= tensor(1.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5134 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5134 D_fake_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5134 D_tricked_loss= tensor(1.1688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5135 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5135 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5135 D_tricked_loss= tensor(1.1742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5136 D_real_loss= tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5136 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5136 D_tricked_loss= tensor(1.1823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5137 D_real_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5137 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5137 D_tricked_loss= tensor(1.1507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5138 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5138 D_fake_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5138 D_tricked_loss= tensor(1.1182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5139 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5139 D_fake_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5139 D_tricked_loss= tensor(1.1432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5140 D_real_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5140 D_fake_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5140 D_tricked_loss= tensor(1.1800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5141 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5141 D_fake_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5141 D_tricked_loss= tensor(1.1060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5142 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5142 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5142 D_tricked_loss= tensor(1.1211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5143 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5143 D_fake_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5143 D_tricked_loss= tensor(1.1070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5144 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5144 D_fake_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5144 D_tricked_loss= tensor(1.1121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5145 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5145 D_fake_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5145 D_tricked_loss= tensor(1.1171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5146 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5146 D_fake_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5146 D_tricked_loss= tensor(1.1071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5147 D_real_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5147 D_fake_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5147 D_tricked_loss= tensor(1.1445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5148 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5148 D_fake_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5148 D_tricked_loss= tensor(1.0940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5149 D_real_loss= tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5149 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5149 D_tricked_loss= tensor(1.1229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5150 D_real_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5150 D_fake_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5150 D_tricked_loss= tensor(1.1237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5151 D_real_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5151 D_fake_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5151 D_tricked_loss= tensor(1.1000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5152 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5152 D_fake_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5152 D_tricked_loss= tensor(1.1388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5153 D_real_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5153 D_fake_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5153 D_tricked_loss= tensor(1.0972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5154 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5154 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5154 D_tricked_loss= tensor(1.1250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5155 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5155 D_fake_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5155 D_tricked_loss= tensor(1.1395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5156 D_real_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5156 D_fake_loss= tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5156 D_tricked_loss= tensor(1.1497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5157 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5157 D_fake_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5157 D_tricked_loss= tensor(1.2015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5158 D_real_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5158 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5158 D_tricked_loss= tensor(1.1510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5159 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5159 D_fake_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5159 D_tricked_loss= tensor(1.1456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5160 D_real_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5160 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5160 D_tricked_loss= tensor(1.1701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5161 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5161 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5161 D_tricked_loss= tensor(1.1624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5162 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5162 D_fake_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5162 D_tricked_loss= tensor(1.1456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5163 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5163 D_fake_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5163 D_tricked_loss= tensor(1.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5164 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5164 D_fake_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5164 D_tricked_loss= tensor(1.1457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5165 D_real_loss= tensor(0.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5165 D_fake_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5165 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5166 D_real_loss= tensor(0.6070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5166 D_fake_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5166 D_tricked_loss= tensor(1.1462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5167 D_real_loss= tensor(0.6101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5167 D_fake_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5167 D_tricked_loss= tensor(1.1290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5168 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5168 D_fake_loss= tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5168 D_tricked_loss= tensor(1.1329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5169 D_real_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5169 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5169 D_tricked_loss= tensor(1.0882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5170 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5170 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5170 D_tricked_loss= tensor(1.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5171 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5171 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5171 D_tricked_loss= tensor(1.1544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5172 D_real_loss= tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5172 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5172 D_tricked_loss= tensor(1.1177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5173 D_real_loss= tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5173 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5173 D_tricked_loss= tensor(1.1666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5174 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5174 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5174 D_tricked_loss= tensor(1.1069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5175 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5175 D_fake_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5175 D_tricked_loss= tensor(1.0954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5176 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5176 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5176 D_tricked_loss= tensor(1.1240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5177 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5177 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5177 D_tricked_loss= tensor(1.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5178 D_real_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5178 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5178 D_tricked_loss= tensor(1.1273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5179 D_real_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5179 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5179 D_tricked_loss= tensor(1.1638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5180 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5180 D_fake_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5180 D_tricked_loss= tensor(1.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5181 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5181 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5181 D_tricked_loss= tensor(1.0992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5182 D_real_loss= tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5182 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5182 D_tricked_loss= tensor(1.1577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5183 D_real_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5183 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5183 D_tricked_loss= tensor(1.1486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5184 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5184 D_fake_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5184 D_tricked_loss= tensor(1.1428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5185 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5185 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5185 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5186 D_real_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5186 D_fake_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5186 D_tricked_loss= tensor(1.0931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5187 D_real_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5187 D_fake_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5187 D_tricked_loss= tensor(1.1486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5188 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5188 D_fake_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5188 D_tricked_loss= tensor(1.1772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5189 D_real_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5189 D_fake_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5189 D_tricked_loss= tensor(1.1245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5190 D_real_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5190 D_fake_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5190 D_tricked_loss= tensor(1.1689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5191 D_real_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5191 D_fake_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5191 D_tricked_loss= tensor(1.1288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5192 D_real_loss= tensor(0.6008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5192 D_fake_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5192 D_tricked_loss= tensor(1.1132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5193 D_real_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5193 D_fake_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5193 D_tricked_loss= tensor(1.0981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5194 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5194 D_fake_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5194 D_tricked_loss= tensor(1.0542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5195 D_real_loss= tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5195 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5195 D_tricked_loss= tensor(1.0880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5196 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5196 D_fake_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5196 D_tricked_loss= tensor(1.1042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5197 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5197 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5197 D_tricked_loss= tensor(1.1782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5198 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5198 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5198 D_tricked_loss= tensor(1.1667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5199 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5199 D_fake_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5199 D_tricked_loss= tensor(1.1571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5200 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5200 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5200 D_tricked_loss= tensor(1.1449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5201 D_real_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5201 D_fake_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5201 D_tricked_loss= tensor(1.1460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5202 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5202 D_fake_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5202 D_tricked_loss= tensor(1.1536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5203 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5203 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5203 D_tricked_loss= tensor(1.0759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5204 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5204 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5204 D_tricked_loss= tensor(1.1225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5205 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5205 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5205 D_tricked_loss= tensor(1.1045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5206 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5206 D_fake_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5206 D_tricked_loss= tensor(1.0933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5207 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5207 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5207 D_tricked_loss= tensor(1.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5208 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5208 D_fake_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5208 D_tricked_loss= tensor(1.1083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5209 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5209 D_fake_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5209 D_tricked_loss= tensor(1.1453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5210 D_real_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5210 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5210 D_tricked_loss= tensor(1.1047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5211 D_real_loss= tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5211 D_fake_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5211 D_tricked_loss= tensor(1.1312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5212 D_real_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5212 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5212 D_tricked_loss= tensor(1.0959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5213 D_real_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5213 D_fake_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5213 D_tricked_loss= tensor(1.1166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5214 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5214 D_fake_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5214 D_tricked_loss= tensor(1.1565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5215 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5215 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5215 D_tricked_loss= tensor(1.1161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5216 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5216 D_fake_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5216 D_tricked_loss= tensor(1.1390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5217 D_real_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5217 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5217 D_tricked_loss= tensor(1.1610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5218 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5218 D_fake_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5218 D_tricked_loss= tensor(1.1342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5219 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5219 D_fake_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5219 D_tricked_loss= tensor(1.1148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5220 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5220 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5220 D_tricked_loss= tensor(1.1752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5221 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5221 D_fake_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5221 D_tricked_loss= tensor(1.1442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5222 D_real_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5222 D_fake_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5222 D_tricked_loss= tensor(1.1780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5223 D_real_loss= tensor(0.5957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5223 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5223 D_tricked_loss= tensor(1.1258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5224 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5224 D_fake_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5224 D_tricked_loss= tensor(1.1439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5225 D_real_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5225 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5225 D_tricked_loss= tensor(1.0743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5226 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5226 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5226 D_tricked_loss= tensor(1.0892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5227 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5227 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5227 D_tricked_loss= tensor(1.1447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5228 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5228 D_fake_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5228 D_tricked_loss= tensor(1.1257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5229 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5229 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5229 D_tricked_loss= tensor(1.1358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5230 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5230 D_fake_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5230 D_tricked_loss= tensor(1.1587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5231 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5231 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5231 D_tricked_loss= tensor(1.1083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5232 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5232 D_fake_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5232 D_tricked_loss= tensor(1.1590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5233 D_real_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5233 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5233 D_tricked_loss= tensor(1.1302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5234 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5234 D_fake_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5234 D_tricked_loss= tensor(1.1183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5235 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5235 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5235 D_tricked_loss= tensor(1.1502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5236 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5236 D_fake_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5236 D_tricked_loss= tensor(1.1005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5237 D_real_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5237 D_fake_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5237 D_tricked_loss= tensor(1.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5238 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5238 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5238 D_tricked_loss= tensor(1.1143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5239 D_real_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5239 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5239 D_tricked_loss= tensor(1.1087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5240 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5240 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5240 D_tricked_loss= tensor(1.1252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5241 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5241 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5241 D_tricked_loss= tensor(1.0517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5242 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5242 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5242 D_tricked_loss= tensor(1.1073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5243 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5243 D_fake_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5243 D_tricked_loss= tensor(1.0902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5244 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5244 D_fake_loss= tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5244 D_tricked_loss= tensor(1.1112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5245 D_real_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5245 D_fake_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5245 D_tricked_loss= tensor(1.1500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5246 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5246 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5246 D_tricked_loss= tensor(1.0896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5247 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5247 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5247 D_tricked_loss= tensor(1.0916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5248 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5248 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5248 D_tricked_loss= tensor(1.0729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5249 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5249 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5249 D_tricked_loss= tensor(1.1101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5250 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5250 D_fake_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5250 D_tricked_loss= tensor(1.1072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5251 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5251 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5251 D_tricked_loss= tensor(1.1374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5252 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5252 D_fake_loss= tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5252 D_tricked_loss= tensor(1.1574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5253 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5253 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5253 D_tricked_loss= tensor(1.1302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5254 D_real_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5254 D_fake_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5254 D_tricked_loss= tensor(1.1491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5255 D_real_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5255 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5255 D_tricked_loss= tensor(1.1493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5256 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5256 D_fake_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5256 D_tricked_loss= tensor(1.0878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5257 D_real_loss= tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5257 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5257 D_tricked_loss= tensor(1.1139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5258 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5258 D_fake_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5258 D_tricked_loss= tensor(1.1128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5259 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5259 D_fake_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5259 D_tricked_loss= tensor(1.1439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5260 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5260 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5260 D_tricked_loss= tensor(1.1361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5261 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5261 D_fake_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5261 D_tricked_loss= tensor(1.0921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5262 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5262 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5262 D_tricked_loss= tensor(1.1230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5263 D_real_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5263 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5263 D_tricked_loss= tensor(1.1187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5264 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5264 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5264 D_tricked_loss= tensor(1.1392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5265 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5265 D_fake_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5265 D_tricked_loss= tensor(1.1443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5266 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5266 D_fake_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5266 D_tricked_loss= tensor(1.0786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5267 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5267 D_fake_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5267 D_tricked_loss= tensor(1.0934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5268 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5268 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5268 D_tricked_loss= tensor(1.0556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5269 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5269 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5269 D_tricked_loss= tensor(1.1019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5270 D_real_loss= tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5270 D_fake_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5270 D_tricked_loss= tensor(1.1488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5271 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5271 D_fake_loss= tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5271 D_tricked_loss= tensor(1.1209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5272 D_real_loss= tensor(0.5983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5272 D_fake_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5272 D_tricked_loss= tensor(1.1269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5273 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5273 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5273 D_tricked_loss= tensor(1.1326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5274 D_real_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5274 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5274 D_tricked_loss= tensor(1.1402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5275 D_real_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5275 D_fake_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5275 D_tricked_loss= tensor(1.1213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5276 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5276 D_fake_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5276 D_tricked_loss= tensor(1.0781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5277 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5277 D_fake_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5277 D_tricked_loss= tensor(1.1204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5278 D_real_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5278 D_fake_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5278 D_tricked_loss= tensor(1.0987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5279 D_real_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5279 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5279 D_tricked_loss= tensor(1.1549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5280 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5280 D_fake_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5280 D_tricked_loss= tensor(1.1527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5281 D_real_loss= tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5281 D_fake_loss= tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5281 D_tricked_loss= tensor(1.1815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5282 D_real_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5282 D_fake_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5282 D_tricked_loss= tensor(1.1402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5283 D_real_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5283 D_fake_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5283 D_tricked_loss= tensor(1.1675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5284 D_real_loss= tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5284 D_fake_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5284 D_tricked_loss= tensor(1.2062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5285 D_real_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5285 D_fake_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5285 D_tricked_loss= tensor(1.0949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5286 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5286 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5286 D_tricked_loss= tensor(1.1294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5287 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5287 D_fake_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5287 D_tricked_loss= tensor(1.1232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5288 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5288 D_fake_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5288 D_tricked_loss= tensor(1.1146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5289 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5289 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5289 D_tricked_loss= tensor(1.1225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5290 D_real_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5290 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5290 D_tricked_loss= tensor(1.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5291 D_real_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5291 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5291 D_tricked_loss= tensor(1.1137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5292 D_real_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5292 D_fake_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5292 D_tricked_loss= tensor(1.1221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5293 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5293 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5293 D_tricked_loss= tensor(1.1117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5294 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5294 D_fake_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5294 D_tricked_loss= tensor(1.1426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5295 D_real_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5295 D_fake_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5295 D_tricked_loss= tensor(1.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5296 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5296 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5296 D_tricked_loss= tensor(1.1336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5297 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5297 D_fake_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5297 D_tricked_loss= tensor(1.1434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5298 D_real_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5298 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5298 D_tricked_loss= tensor(1.1149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5299 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5299 D_fake_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5299 D_tricked_loss= tensor(1.1024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5300 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5300 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5300 D_tricked_loss= tensor(1.0951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5301 D_real_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5301 D_fake_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5301 D_tricked_loss= tensor(1.1675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5302 D_real_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5302 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5302 D_tricked_loss= tensor(1.1331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5303 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5303 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5303 D_tricked_loss= tensor(1.1110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5304 D_real_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5304 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5304 D_tricked_loss= tensor(1.1467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5305 D_real_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5305 D_fake_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5305 D_tricked_loss= tensor(1.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5306 D_real_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5306 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5306 D_tricked_loss= tensor(1.1577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5307 D_real_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5307 D_fake_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5307 D_tricked_loss= tensor(1.1426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5308 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5308 D_fake_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5308 D_tricked_loss= tensor(1.1019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5309 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5309 D_fake_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5309 D_tricked_loss= tensor(1.0975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5310 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5310 D_fake_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5310 D_tricked_loss= tensor(1.1341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5311 D_real_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5311 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5311 D_tricked_loss= tensor(1.1602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5312 D_real_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5312 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5312 D_tricked_loss= tensor(1.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5313 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5313 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5313 D_tricked_loss= tensor(1.1227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5314 D_real_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5314 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5314 D_tricked_loss= tensor(1.1459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5315 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5315 D_fake_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5315 D_tricked_loss= tensor(1.1432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5316 D_real_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5316 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5316 D_tricked_loss= tensor(1.1490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5317 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5317 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5317 D_tricked_loss= tensor(1.1164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5318 D_real_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5318 D_fake_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5318 D_tricked_loss= tensor(1.1399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5319 D_real_loss= tensor(0.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5319 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5319 D_tricked_loss= tensor(1.1652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5320 D_real_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5320 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5320 D_tricked_loss= tensor(1.1160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5321 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5321 D_fake_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5321 D_tricked_loss= tensor(1.1608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5322 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5322 D_fake_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5322 D_tricked_loss= tensor(1.1611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5323 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5323 D_fake_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5323 D_tricked_loss= tensor(1.1795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5324 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5324 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5324 D_tricked_loss= tensor(1.1435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5325 D_real_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5325 D_fake_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5325 D_tricked_loss= tensor(1.1397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5326 D_real_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5326 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5326 D_tricked_loss= tensor(1.1030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5327 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5327 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5327 D_tricked_loss= tensor(1.1266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5328 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5328 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5328 D_tricked_loss= tensor(1.1391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5329 D_real_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5329 D_fake_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5329 D_tricked_loss= tensor(1.1003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5330 D_real_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5330 D_fake_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5330 D_tricked_loss= tensor(1.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5331 D_real_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5331 D_fake_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5331 D_tricked_loss= tensor(1.1241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5332 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5332 D_fake_loss= tensor(0.5472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5332 D_tricked_loss= tensor(1.0970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5333 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5333 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5333 D_tricked_loss= tensor(1.0993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5334 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5334 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5334 D_tricked_loss= tensor(1.1008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5335 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5335 D_fake_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5335 D_tricked_loss= tensor(1.1028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5336 D_real_loss= tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5336 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5336 D_tricked_loss= tensor(1.0935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5337 D_real_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5337 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5337 D_tricked_loss= tensor(1.1097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5338 D_real_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5338 D_fake_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5338 D_tricked_loss= tensor(1.1443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5339 D_real_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5339 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5339 D_tricked_loss= tensor(1.1247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5340 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5340 D_fake_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5340 D_tricked_loss= tensor(1.1793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5341 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5341 D_fake_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5341 D_tricked_loss= tensor(1.1498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5342 D_real_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5342 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5342 D_tricked_loss= tensor(1.1638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5343 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5343 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5343 D_tricked_loss= tensor(1.1327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5344 D_real_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5344 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5344 D_tricked_loss= tensor(1.0958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5345 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5345 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5345 D_tricked_loss= tensor(1.1034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5346 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5346 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5346 D_tricked_loss= tensor(1.0760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5347 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5347 D_fake_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5347 D_tricked_loss= tensor(1.0967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5348 D_real_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5348 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5348 D_tricked_loss= tensor(1.1291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5349 D_real_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5349 D_fake_loss= tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5349 D_tricked_loss= tensor(1.0875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5350 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5350 D_fake_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5350 D_tricked_loss= tensor(1.1630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5351 D_real_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5351 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5351 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5352 D_real_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5352 D_fake_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5352 D_tricked_loss= tensor(1.1704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5353 D_real_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5353 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5353 D_tricked_loss= tensor(1.1622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5354 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5354 D_fake_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5354 D_tricked_loss= tensor(1.1654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5355 D_real_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5355 D_fake_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5355 D_tricked_loss= tensor(1.1601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5356 D_real_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5356 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5356 D_tricked_loss= tensor(1.1548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5357 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5357 D_fake_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5357 D_tricked_loss= tensor(1.1168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5358 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5358 D_fake_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5358 D_tricked_loss= tensor(1.1517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5359 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5359 D_fake_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5359 D_tricked_loss= tensor(1.0827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5360 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5360 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5360 D_tricked_loss= tensor(1.0998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5361 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5361 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5361 D_tricked_loss= tensor(1.1062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5362 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5362 D_fake_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5362 D_tricked_loss= tensor(1.1189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5363 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5363 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5363 D_tricked_loss= tensor(1.0753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5364 D_real_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5364 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5364 D_tricked_loss= tensor(1.1502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5365 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5365 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5365 D_tricked_loss= tensor(1.1242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5366 D_real_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5366 D_fake_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5366 D_tricked_loss= tensor(1.0895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5367 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5367 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5367 D_tricked_loss= tensor(1.1308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5368 D_real_loss= tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5368 D_fake_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5368 D_tricked_loss= tensor(1.1820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5369 D_real_loss= tensor(0.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5369 D_fake_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5369 D_tricked_loss= tensor(1.1548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5370 D_real_loss= tensor(0.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5370 D_fake_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5370 D_tricked_loss= tensor(1.1535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5371 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5371 D_fake_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5371 D_tricked_loss= tensor(1.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5372 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5372 D_fake_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5372 D_tricked_loss= tensor(1.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5373 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5373 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5373 D_tricked_loss= tensor(1.1473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5374 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5374 D_fake_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5374 D_tricked_loss= tensor(1.1047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5375 D_real_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5375 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5375 D_tricked_loss= tensor(1.0838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5376 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5376 D_fake_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5376 D_tricked_loss= tensor(1.0697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5377 D_real_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5377 D_fake_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5377 D_tricked_loss= tensor(1.0878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5378 D_real_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5378 D_fake_loss= tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5378 D_tricked_loss= tensor(1.1243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5379 D_real_loss= tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5379 D_fake_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5379 D_tricked_loss= tensor(1.1326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5380 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5380 D_fake_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5380 D_tricked_loss= tensor(1.1202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5381 D_real_loss= tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5381 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5381 D_tricked_loss= tensor(1.0875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5382 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5382 D_fake_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5382 D_tricked_loss= tensor(1.1114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5383 D_real_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5383 D_fake_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5383 D_tricked_loss= tensor(1.1605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5384 D_real_loss= tensor(0.6101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5384 D_fake_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5384 D_tricked_loss= tensor(1.1544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5385 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5385 D_fake_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5385 D_tricked_loss= tensor(1.1369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5386 D_real_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5386 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5386 D_tricked_loss= tensor(1.1241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5387 D_real_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5387 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5387 D_tricked_loss= tensor(1.1030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5388 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5388 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5388 D_tricked_loss= tensor(1.0979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5389 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5389 D_fake_loss= tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5389 D_tricked_loss= tensor(1.1175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5390 D_real_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5390 D_fake_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5390 D_tricked_loss= tensor(1.0988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5391 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5391 D_fake_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5391 D_tricked_loss= tensor(1.0842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5392 D_real_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5392 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5392 D_tricked_loss= tensor(1.0975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5393 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5393 D_fake_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5393 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5394 D_real_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5394 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5394 D_tricked_loss= tensor(1.1418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5395 D_real_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5395 D_fake_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5395 D_tricked_loss= tensor(1.1233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5396 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5396 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5396 D_tricked_loss= tensor(1.1063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5397 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5397 D_fake_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5397 D_tricked_loss= tensor(1.0944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5398 D_real_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5398 D_fake_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5398 D_tricked_loss= tensor(1.1626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5399 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5399 D_fake_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5399 D_tricked_loss= tensor(1.1333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5400 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5400 D_fake_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5400 D_tricked_loss= tensor(1.1364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5401 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5401 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5401 D_tricked_loss= tensor(1.1630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5402 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5402 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5402 D_tricked_loss= tensor(1.1162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5403 D_real_loss= tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5403 D_fake_loss= tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5403 D_tricked_loss= tensor(1.1461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5404 D_real_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5404 D_fake_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5404 D_tricked_loss= tensor(1.1290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5405 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5405 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5405 D_tricked_loss= tensor(1.1167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5406 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5406 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5406 D_tricked_loss= tensor(1.1123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5407 D_real_loss= tensor(0.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5407 D_fake_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5407 D_tricked_loss= tensor(1.1378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5408 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5408 D_fake_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5408 D_tricked_loss= tensor(1.1184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5409 D_real_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5409 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5409 D_tricked_loss= tensor(1.1055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5410 D_real_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5410 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5410 D_tricked_loss= tensor(1.1062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5411 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5411 D_fake_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5411 D_tricked_loss= tensor(1.0799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5412 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5412 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5412 D_tricked_loss= tensor(1.0874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5413 D_real_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5413 D_fake_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5413 D_tricked_loss= tensor(1.0936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5414 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5414 D_fake_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5414 D_tricked_loss= tensor(1.1013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5415 D_real_loss= tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5415 D_fake_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5415 D_tricked_loss= tensor(1.1271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5416 D_real_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5416 D_fake_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5416 D_tricked_loss= tensor(1.1077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5417 D_real_loss= tensor(0.6191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5417 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5417 D_tricked_loss= tensor(1.1411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5418 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5418 D_fake_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5418 D_tricked_loss= tensor(1.0881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5419 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5419 D_fake_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5419 D_tricked_loss= tensor(1.0815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5420 D_real_loss= tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5420 D_fake_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5420 D_tricked_loss= tensor(1.0664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5421 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5421 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5421 D_tricked_loss= tensor(1.0842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5422 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5422 D_fake_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5422 D_tricked_loss= tensor(1.0644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5423 D_real_loss= tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5423 D_fake_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5423 D_tricked_loss= tensor(1.1188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5424 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5424 D_fake_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5424 D_tricked_loss= tensor(1.0784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5425 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5425 D_fake_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5425 D_tricked_loss= tensor(1.1118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5426 D_real_loss= tensor(0.5988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5426 D_fake_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5426 D_tricked_loss= tensor(1.0872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5427 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5427 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5427 D_tricked_loss= tensor(1.1068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5428 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5428 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5428 D_tricked_loss= tensor(1.1205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5429 D_real_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5429 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5429 D_tricked_loss= tensor(1.1191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5430 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5430 D_fake_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5430 D_tricked_loss= tensor(1.1216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5431 D_real_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5431 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5431 D_tricked_loss= tensor(1.1090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5432 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5432 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5432 D_tricked_loss= tensor(1.0960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5433 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5433 D_fake_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5433 D_tricked_loss= tensor(1.1437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5434 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5434 D_fake_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5434 D_tricked_loss= tensor(1.0669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5435 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5435 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5435 D_tricked_loss= tensor(1.1063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5436 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5436 D_fake_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5436 D_tricked_loss= tensor(1.0901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5437 D_real_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5437 D_fake_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5437 D_tricked_loss= tensor(1.0548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5438 D_real_loss= tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5438 D_fake_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5438 D_tricked_loss= tensor(1.0626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5439 D_real_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5439 D_fake_loss= tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5439 D_tricked_loss= tensor(1.0348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5440 D_real_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5440 D_fake_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5440 D_tricked_loss= tensor(1.0639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5441 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5441 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5441 D_tricked_loss= tensor(1.1219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5442 D_real_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5442 D_fake_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5442 D_tricked_loss= tensor(1.0983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5443 D_real_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5443 D_fake_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5443 D_tricked_loss= tensor(1.1337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5444 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5444 D_fake_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5444 D_tricked_loss= tensor(1.1201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5445 D_real_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5445 D_fake_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5445 D_tricked_loss= tensor(1.0832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5446 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5446 D_fake_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5446 D_tricked_loss= tensor(1.1429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5447 D_real_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5447 D_fake_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5447 D_tricked_loss= tensor(1.1354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5448 D_real_loss= tensor(0.6007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5448 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5448 D_tricked_loss= tensor(1.1347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5449 D_real_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5449 D_fake_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5449 D_tricked_loss= tensor(1.1157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5450 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5450 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5450 D_tricked_loss= tensor(1.0841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5451 D_real_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5451 D_fake_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5451 D_tricked_loss= tensor(1.0853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5452 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5452 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5452 D_tricked_loss= tensor(1.0872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5453 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5453 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5453 D_tricked_loss= tensor(1.1323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5454 D_real_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5454 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5454 D_tricked_loss= tensor(1.1053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5455 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5455 D_fake_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5455 D_tricked_loss= tensor(1.1360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5456 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5456 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5456 D_tricked_loss= tensor(1.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5457 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5457 D_fake_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5457 D_tricked_loss= tensor(1.1326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5458 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5458 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5458 D_tricked_loss= tensor(1.1567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5459 D_real_loss= tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5459 D_fake_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5459 D_tricked_loss= tensor(1.1358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5460 D_real_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5460 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5460 D_tricked_loss= tensor(1.1352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5461 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5461 D_fake_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5461 D_tricked_loss= tensor(1.1339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5462 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5462 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5462 D_tricked_loss= tensor(1.1608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5463 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5463 D_fake_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5463 D_tricked_loss= tensor(1.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5464 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5464 D_fake_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5464 D_tricked_loss= tensor(1.1048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5465 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5465 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5465 D_tricked_loss= tensor(1.1442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5466 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5466 D_fake_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5466 D_tricked_loss= tensor(1.1228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5467 D_real_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5467 D_fake_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5467 D_tricked_loss= tensor(1.1270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5468 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5468 D_fake_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5468 D_tricked_loss= tensor(1.1009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5469 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5469 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5469 D_tricked_loss= tensor(1.1252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5470 D_real_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5470 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5470 D_tricked_loss= tensor(1.0909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5471 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5471 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5471 D_tricked_loss= tensor(1.0881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5472 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5472 D_fake_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5472 D_tricked_loss= tensor(1.0954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5473 D_real_loss= tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5473 D_fake_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5473 D_tricked_loss= tensor(1.1345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5474 D_real_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5474 D_fake_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5474 D_tricked_loss= tensor(1.1289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5475 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5475 D_fake_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5475 D_tricked_loss= tensor(1.1119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5476 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5476 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5476 D_tricked_loss= tensor(1.1239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5477 D_real_loss= tensor(0.6058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5477 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5477 D_tricked_loss= tensor(1.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5478 D_real_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5478 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5478 D_tricked_loss= tensor(1.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5479 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5479 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5479 D_tricked_loss= tensor(1.0765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5480 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5480 D_fake_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5480 D_tricked_loss= tensor(1.0454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5481 D_real_loss= tensor(0.6001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5481 D_fake_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5481 D_tricked_loss= tensor(1.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5482 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5482 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5482 D_tricked_loss= tensor(1.0892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5483 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5483 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5483 D_tricked_loss= tensor(1.1225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5484 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5484 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5484 D_tricked_loss= tensor(1.1392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5485 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5485 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5485 D_tricked_loss= tensor(1.1393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5486 D_real_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5486 D_fake_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5486 D_tricked_loss= tensor(1.1457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5487 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5487 D_fake_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5487 D_tricked_loss= tensor(1.1451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5488 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5488 D_fake_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5488 D_tricked_loss= tensor(1.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5489 D_real_loss= tensor(0.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5489 D_fake_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5489 D_tricked_loss= tensor(1.1410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5490 D_real_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5490 D_fake_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5490 D_tricked_loss= tensor(1.1036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5491 D_real_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5491 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5491 D_tricked_loss= tensor(1.0727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5492 D_real_loss= tensor(0.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5492 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5492 D_tricked_loss= tensor(1.1156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5493 D_real_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5493 D_fake_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5493 D_tricked_loss= tensor(1.1108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5494 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5494 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5494 D_tricked_loss= tensor(1.1225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5495 D_real_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5495 D_fake_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5495 D_tricked_loss= tensor(1.1458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5496 D_real_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5496 D_fake_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5496 D_tricked_loss= tensor(1.0837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5497 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5497 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5497 D_tricked_loss= tensor(1.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5498 D_real_loss= tensor(0.6078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5498 D_fake_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5498 D_tricked_loss= tensor(1.0958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5499 D_real_loss= tensor(0.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5499 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5499 D_tricked_loss= tensor(1.0673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5500 D_real_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5500 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5500 D_tricked_loss= tensor(1.0804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5501 D_real_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5501 D_fake_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5501 D_tricked_loss= tensor(1.0768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5502 D_real_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5502 D_fake_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5502 D_tricked_loss= tensor(1.1291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5503 D_real_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5503 D_fake_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5503 D_tricked_loss= tensor(1.1391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5504 D_real_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5504 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5504 D_tricked_loss= tensor(1.1453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5505 D_real_loss= tensor(0.6100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5505 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5505 D_tricked_loss= tensor(1.1544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5506 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5506 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5506 D_tricked_loss= tensor(1.1268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5507 D_real_loss= tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5507 D_fake_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5507 D_tricked_loss= tensor(1.1329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5508 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5508 D_fake_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5508 D_tricked_loss= tensor(1.1630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5509 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5509 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5509 D_tricked_loss= tensor(1.1694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5510 D_real_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5510 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5510 D_tricked_loss= tensor(1.0895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5511 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5511 D_fake_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5511 D_tricked_loss= tensor(1.0958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5512 D_real_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5512 D_fake_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5512 D_tricked_loss= tensor(1.1200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5513 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5513 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5513 D_tricked_loss= tensor(1.1078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5514 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5514 D_fake_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5514 D_tricked_loss= tensor(1.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5515 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5515 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5515 D_tricked_loss= tensor(1.1124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5516 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5516 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5516 D_tricked_loss= tensor(1.1198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5517 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5517 D_fake_loss= tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5517 D_tricked_loss= tensor(1.1211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5518 D_real_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5518 D_fake_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5518 D_tricked_loss= tensor(1.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5519 D_real_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5519 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5519 D_tricked_loss= tensor(1.1142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5520 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5520 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5520 D_tricked_loss= tensor(1.0675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5521 D_real_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5521 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5521 D_tricked_loss= tensor(1.1029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5522 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5522 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5522 D_tricked_loss= tensor(1.1153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5523 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5523 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5523 D_tricked_loss= tensor(1.1064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5524 D_real_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5524 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5524 D_tricked_loss= tensor(1.1197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5525 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5525 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5525 D_tricked_loss= tensor(1.1146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5526 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5526 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5526 D_tricked_loss= tensor(1.1687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5527 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5527 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5527 D_tricked_loss= tensor(1.1491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5528 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5528 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5528 D_tricked_loss= tensor(1.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5529 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5529 D_fake_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5529 D_tricked_loss= tensor(1.0626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5530 D_real_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5530 D_fake_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5530 D_tricked_loss= tensor(1.1020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5531 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5531 D_fake_loss= tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5531 D_tricked_loss= tensor(1.0832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5532 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5532 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5532 D_tricked_loss= tensor(1.0831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5533 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5533 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5533 D_tricked_loss= tensor(1.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5534 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5534 D_fake_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5534 D_tricked_loss= tensor(1.0827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5535 D_real_loss= tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5535 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5535 D_tricked_loss= tensor(1.1640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5536 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5536 D_fake_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5536 D_tricked_loss= tensor(1.1145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5537 D_real_loss= tensor(0.6114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5537 D_fake_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5537 D_tricked_loss= tensor(1.1144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5538 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5538 D_fake_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5538 D_tricked_loss= tensor(1.0966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5539 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5539 D_fake_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5539 D_tricked_loss= tensor(1.0964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5540 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5540 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5540 D_tricked_loss= tensor(1.0826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5541 D_real_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5541 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5541 D_tricked_loss= tensor(1.0983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5542 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5542 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5542 D_tricked_loss= tensor(1.0612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5543 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5543 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5543 D_tricked_loss= tensor(1.1309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5544 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5544 D_fake_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5544 D_tricked_loss= tensor(1.0972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5545 D_real_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5545 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5545 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5546 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5546 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5546 D_tricked_loss= tensor(1.1438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5547 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5547 D_fake_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5547 D_tricked_loss= tensor(1.0961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5548 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5548 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5548 D_tricked_loss= tensor(1.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5549 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5549 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5549 D_tricked_loss= tensor(1.1072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5550 D_real_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5550 D_fake_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5550 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5551 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5551 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5551 D_tricked_loss= tensor(1.0973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5552 D_real_loss= tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5552 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5552 D_tricked_loss= tensor(1.0821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5553 D_real_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5553 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5553 D_tricked_loss= tensor(1.0941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5554 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5554 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5554 D_tricked_loss= tensor(1.0904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5555 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5555 D_fake_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5555 D_tricked_loss= tensor(1.1281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5556 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5556 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5556 D_tricked_loss= tensor(1.1407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5557 D_real_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5557 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5557 D_tricked_loss= tensor(1.1194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5558 D_real_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5558 D_fake_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5558 D_tricked_loss= tensor(1.0956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5559 D_real_loss= tensor(0.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5559 D_fake_loss= tensor(0.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5559 D_tricked_loss= tensor(1.0976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5560 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5560 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5560 D_tricked_loss= tensor(1.1082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5561 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5561 D_fake_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5561 D_tricked_loss= tensor(1.1073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5562 D_real_loss= tensor(0.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5562 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5562 D_tricked_loss= tensor(1.1238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5563 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5563 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5563 D_tricked_loss= tensor(1.0855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5564 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5564 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5564 D_tricked_loss= tensor(1.1015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5565 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5565 D_fake_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5565 D_tricked_loss= tensor(1.0793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5566 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5566 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5566 D_tricked_loss= tensor(1.1050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5567 D_real_loss= tensor(0.5983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5567 D_fake_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5567 D_tricked_loss= tensor(1.0846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5568 D_real_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5568 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5568 D_tricked_loss= tensor(1.0842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5569 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5569 D_fake_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5569 D_tricked_loss= tensor(1.0991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5570 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5570 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5570 D_tricked_loss= tensor(1.1127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5571 D_real_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5571 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5571 D_tricked_loss= tensor(1.1125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5572 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5572 D_fake_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5572 D_tricked_loss= tensor(1.0956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5573 D_real_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5573 D_fake_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5573 D_tricked_loss= tensor(1.1084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5574 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5574 D_fake_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5574 D_tricked_loss= tensor(1.1266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5575 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5575 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5575 D_tricked_loss= tensor(1.1034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5576 D_real_loss= tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5576 D_fake_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5576 D_tricked_loss= tensor(1.0918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5577 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5577 D_fake_loss= tensor(0.6224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5577 D_tricked_loss= tensor(1.0636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5578 D_real_loss= tensor(0.6094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5578 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5578 D_tricked_loss= tensor(1.0851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5579 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5579 D_fake_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5579 D_tricked_loss= tensor(1.0783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5580 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5580 D_fake_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5580 D_tricked_loss= tensor(1.0772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5581 D_real_loss= tensor(0.6156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5581 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5581 D_tricked_loss= tensor(1.1001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5582 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5582 D_fake_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5582 D_tricked_loss= tensor(1.0691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5583 D_real_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5583 D_fake_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5583 D_tricked_loss= tensor(1.0882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5584 D_real_loss= tensor(0.6074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5584 D_fake_loss= tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5584 D_tricked_loss= tensor(1.0918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5585 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5585 D_fake_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5585 D_tricked_loss= tensor(1.0704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5586 D_real_loss= tensor(0.6162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5586 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5586 D_tricked_loss= tensor(1.0937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5587 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5587 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5587 D_tricked_loss= tensor(1.0867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5588 D_real_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5588 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5588 D_tricked_loss= tensor(1.1192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5589 D_real_loss= tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5589 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5589 D_tricked_loss= tensor(1.0841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5590 D_real_loss= tensor(0.6163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5590 D_fake_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5590 D_tricked_loss= tensor(1.0457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5591 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5591 D_fake_loss= tensor(0.6125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5591 D_tricked_loss= tensor(1.0658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5592 D_real_loss= tensor(0.6142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5592 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5592 D_tricked_loss= tensor(1.0635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5593 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5593 D_fake_loss= tensor(0.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5593 D_tricked_loss= tensor(1.0385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5594 D_real_loss= tensor(0.6077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5594 D_fake_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5594 D_tricked_loss= tensor(1.0431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5595 D_real_loss= tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5595 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5595 D_tricked_loss= tensor(1.0684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5596 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5596 D_fake_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5596 D_tricked_loss= tensor(1.0286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5597 D_real_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5597 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5597 D_tricked_loss= tensor(1.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5598 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5598 D_fake_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5598 D_tricked_loss= tensor(1.0935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5599 D_real_loss= tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5599 D_fake_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5599 D_tricked_loss= tensor(1.0874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5600 D_real_loss= tensor(0.6103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5600 D_fake_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5600 D_tricked_loss= tensor(1.1097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5601 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5601 D_fake_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5601 D_tricked_loss= tensor(1.0509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5602 D_real_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5602 D_fake_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5602 D_tricked_loss= tensor(1.0754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5603 D_real_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5603 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5603 D_tricked_loss= tensor(1.0783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5604 D_real_loss= tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5604 D_fake_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5604 D_tricked_loss= tensor(1.1232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5605 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5605 D_fake_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5605 D_tricked_loss= tensor(1.1214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5606 D_real_loss= tensor(0.6168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5606 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5606 D_tricked_loss= tensor(1.1450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5607 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5607 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5607 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5608 D_real_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5608 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5608 D_tricked_loss= tensor(1.1493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5609 D_real_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5609 D_fake_loss= tensor(0.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5609 D_tricked_loss= tensor(1.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5610 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5610 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5610 D_tricked_loss= tensor(1.0987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5611 D_real_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5611 D_fake_loss= tensor(0.5988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5611 D_tricked_loss= tensor(1.0590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5612 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5612 D_fake_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5612 D_tricked_loss= tensor(1.0591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5613 D_real_loss= tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5613 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5613 D_tricked_loss= tensor(1.0613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5614 D_real_loss= tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5614 D_fake_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5614 D_tricked_loss= tensor(1.0807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5615 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5615 D_fake_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5615 D_tricked_loss= tensor(1.0687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5616 D_real_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5616 D_fake_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5616 D_tricked_loss= tensor(1.1289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5617 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5617 D_fake_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5617 D_tricked_loss= tensor(1.1201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5618 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5618 D_fake_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5618 D_tricked_loss= tensor(1.1012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5619 D_real_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5619 D_fake_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5619 D_tricked_loss= tensor(1.0878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5620 D_real_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5620 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5620 D_tricked_loss= tensor(1.1146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5621 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5621 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5621 D_tricked_loss= tensor(1.1051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5622 D_real_loss= tensor(0.6011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5622 D_fake_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5622 D_tricked_loss= tensor(1.1011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5623 D_real_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5623 D_fake_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5623 D_tricked_loss= tensor(1.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5624 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5624 D_fake_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5624 D_tricked_loss= tensor(1.0962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5625 D_real_loss= tensor(0.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5625 D_fake_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5625 D_tricked_loss= tensor(1.1070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5626 D_real_loss= tensor(0.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5626 D_fake_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5626 D_tricked_loss= tensor(1.0849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5627 D_real_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5627 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5627 D_tricked_loss= tensor(1.0546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5628 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5628 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5628 D_tricked_loss= tensor(1.1061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5629 D_real_loss= tensor(0.6090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5629 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5629 D_tricked_loss= tensor(1.0822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5630 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5630 D_fake_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5630 D_tricked_loss= tensor(1.0714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5631 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5631 D_fake_loss= tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5631 D_tricked_loss= tensor(1.0851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5632 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5632 D_fake_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5632 D_tricked_loss= tensor(1.0605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5633 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5633 D_fake_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5633 D_tricked_loss= tensor(1.0484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5634 D_real_loss= tensor(0.5903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5634 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5634 D_tricked_loss= tensor(1.0605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5635 D_real_loss= tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5635 D_fake_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5635 D_tricked_loss= tensor(1.1009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5636 D_real_loss= tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5636 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5636 D_tricked_loss= tensor(1.0186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5637 D_real_loss= tensor(0.6007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5637 D_fake_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5637 D_tricked_loss= tensor(1.0501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5638 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5638 D_fake_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5638 D_tricked_loss= tensor(1.0810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5639 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5639 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5639 D_tricked_loss= tensor(1.0593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5640 D_real_loss= tensor(0.6044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5640 D_fake_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5640 D_tricked_loss= tensor(1.1066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5641 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5641 D_fake_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5641 D_tricked_loss= tensor(1.0871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5642 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5642 D_fake_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5642 D_tricked_loss= tensor(1.1336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5643 D_real_loss= tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5643 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5643 D_tricked_loss= tensor(1.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5644 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5644 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5644 D_tricked_loss= tensor(1.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5645 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5645 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5645 D_tricked_loss= tensor(1.1233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5646 D_real_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5646 D_fake_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5646 D_tricked_loss= tensor(1.1028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5647 D_real_loss= tensor(0.5994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5647 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5647 D_tricked_loss= tensor(1.1029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5648 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5648 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5648 D_tricked_loss= tensor(1.1027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5649 D_real_loss= tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5649 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5649 D_tricked_loss= tensor(1.1021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5650 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5650 D_fake_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5650 D_tricked_loss= tensor(1.0510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5651 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5651 D_fake_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5651 D_tricked_loss= tensor(1.0785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5652 D_real_loss= tensor(0.6088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5652 D_fake_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5652 D_tricked_loss= tensor(1.0356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5653 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5653 D_fake_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5653 D_tricked_loss= tensor(1.0704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5654 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5654 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5654 D_tricked_loss= tensor(1.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5655 D_real_loss= tensor(0.6044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5655 D_fake_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5655 D_tricked_loss= tensor(1.0611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5656 D_real_loss= tensor(0.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5656 D_fake_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5656 D_tricked_loss= tensor(1.0929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5657 D_real_loss= tensor(0.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5657 D_fake_loss= tensor(0.6057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5657 D_tricked_loss= tensor(1.0536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5658 D_real_loss= tensor(0.6127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5658 D_fake_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5658 D_tricked_loss= tensor(1.0338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5659 D_real_loss= tensor(0.6186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5659 D_fake_loss= tensor(0.6343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5659 D_tricked_loss= tensor(1.0183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5660 D_real_loss= tensor(0.6157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5660 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5660 D_tricked_loss= tensor(1.0235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5661 D_real_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5661 D_fake_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5661 D_tricked_loss= tensor(1.0523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5662 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5662 D_fake_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5662 D_tricked_loss= tensor(1.0306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5663 D_real_loss= tensor(0.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5663 D_fake_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5663 D_tricked_loss= tensor(1.0452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5664 D_real_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5664 D_fake_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5664 D_tricked_loss= tensor(1.0662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5665 D_real_loss= tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5665 D_fake_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5665 D_tricked_loss= tensor(1.0639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5666 D_real_loss= tensor(0.6078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5666 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5666 D_tricked_loss= tensor(1.1408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5667 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5667 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5667 D_tricked_loss= tensor(1.0908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5668 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5668 D_fake_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5668 D_tricked_loss= tensor(1.1058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5669 D_real_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5669 D_fake_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5669 D_tricked_loss= tensor(1.1496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5670 D_real_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5670 D_fake_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5670 D_tricked_loss= tensor(1.1359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5671 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5671 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5671 D_tricked_loss= tensor(1.1010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5672 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5672 D_fake_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5672 D_tricked_loss= tensor(1.1230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5673 D_real_loss= tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5673 D_fake_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5673 D_tricked_loss= tensor(1.0826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5674 D_real_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5674 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5674 D_tricked_loss= tensor(1.0539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5675 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5675 D_fake_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5675 D_tricked_loss= tensor(1.1178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5676 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5676 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5676 D_tricked_loss= tensor(1.1244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5677 D_real_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5677 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5677 D_tricked_loss= tensor(1.1156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5678 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5678 D_fake_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5678 D_tricked_loss= tensor(1.1167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5679 D_real_loss= tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5679 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5679 D_tricked_loss= tensor(1.0858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5680 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5680 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5680 D_tricked_loss= tensor(1.0881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5681 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5681 D_fake_loss= tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5681 D_tricked_loss= tensor(1.1035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5682 D_real_loss= tensor(0.5966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5682 D_fake_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5682 D_tricked_loss= tensor(1.0804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5683 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5683 D_fake_loss= tensor(0.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5683 D_tricked_loss= tensor(1.1379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5684 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5684 D_fake_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5684 D_tricked_loss= tensor(1.0825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5685 D_real_loss= tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5685 D_fake_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5685 D_tricked_loss= tensor(1.0779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5686 D_real_loss= tensor(0.6171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5686 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5686 D_tricked_loss= tensor(1.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5687 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5687 D_fake_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5687 D_tricked_loss= tensor(1.0659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5688 D_real_loss= tensor(0.6176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5688 D_fake_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5688 D_tricked_loss= tensor(1.1080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5689 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5689 D_fake_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5689 D_tricked_loss= tensor(1.0547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5690 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5690 D_fake_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5690 D_tricked_loss= tensor(1.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5691 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5691 D_fake_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5691 D_tricked_loss= tensor(1.0554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5692 D_real_loss= tensor(0.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5692 D_fake_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5692 D_tricked_loss= tensor(1.0636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5693 D_real_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5693 D_fake_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5693 D_tricked_loss= tensor(1.0469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5694 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5694 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5694 D_tricked_loss= tensor(1.0710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5695 D_real_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5695 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5695 D_tricked_loss= tensor(1.0969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5696 D_real_loss= tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5696 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5696 D_tricked_loss= tensor(1.0808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5697 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5697 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5697 D_tricked_loss= tensor(1.1180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5698 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5698 D_fake_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5698 D_tricked_loss= tensor(1.0615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5699 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5699 D_fake_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5699 D_tricked_loss= tensor(1.0757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5700 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5700 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5700 D_tricked_loss= tensor(1.1099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5701 D_real_loss= tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5701 D_fake_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5701 D_tricked_loss= tensor(1.0751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5702 D_real_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5702 D_fake_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5702 D_tricked_loss= tensor(1.0751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5703 D_real_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5703 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5703 D_tricked_loss= tensor(1.0931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5704 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5704 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5704 D_tricked_loss= tensor(1.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5705 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5705 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5705 D_tricked_loss= tensor(1.1072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5706 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5706 D_fake_loss= tensor(0.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5706 D_tricked_loss= tensor(1.1065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5707 D_real_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5707 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5707 D_tricked_loss= tensor(1.0873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5708 D_real_loss= tensor(0.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5708 D_fake_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5708 D_tricked_loss= tensor(1.1209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5709 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5709 D_fake_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5709 D_tricked_loss= tensor(1.1468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5710 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5710 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5710 D_tricked_loss= tensor(1.1299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5711 D_real_loss= tensor(0.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5711 D_fake_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5711 D_tricked_loss= tensor(1.1332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5712 D_real_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5712 D_fake_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5712 D_tricked_loss= tensor(1.1565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5713 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5713 D_fake_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5713 D_tricked_loss= tensor(1.0795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5714 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5714 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5714 D_tricked_loss= tensor(1.0843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5715 D_real_loss= tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5715 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5715 D_tricked_loss= tensor(1.1026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5716 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5716 D_fake_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5716 D_tricked_loss= tensor(1.0698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5717 D_real_loss= tensor(0.6104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5717 D_fake_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5717 D_tricked_loss= tensor(1.0741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5718 D_real_loss= tensor(0.5972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5718 D_fake_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5718 D_tricked_loss= tensor(1.0955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5719 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5719 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5719 D_tricked_loss= tensor(1.1213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5720 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5720 D_fake_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5720 D_tricked_loss= tensor(1.0414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5721 D_real_loss= tensor(0.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5721 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5721 D_tricked_loss= tensor(1.0612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5722 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5722 D_fake_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5722 D_tricked_loss= tensor(1.0636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5723 D_real_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5723 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5723 D_tricked_loss= tensor(1.0435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5724 D_real_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5724 D_fake_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5724 D_tricked_loss= tensor(1.0941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5725 D_real_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5725 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5725 D_tricked_loss= tensor(1.0797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5726 D_real_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5726 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5726 D_tricked_loss= tensor(1.0816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5727 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5727 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5727 D_tricked_loss= tensor(1.1028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5728 D_real_loss= tensor(0.6099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5728 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5728 D_tricked_loss= tensor(1.0925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5729 D_real_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5729 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5729 D_tricked_loss= tensor(1.0491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5730 D_real_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5730 D_fake_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5730 D_tricked_loss= tensor(1.0574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5731 D_real_loss= tensor(0.5978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5731 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5731 D_tricked_loss= tensor(1.0699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5732 D_real_loss= tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5732 D_fake_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5732 D_tricked_loss= tensor(1.0567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5733 D_real_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5733 D_fake_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5733 D_tricked_loss= tensor(1.1199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5734 D_real_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5734 D_fake_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5734 D_tricked_loss= tensor(1.0391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5735 D_real_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5735 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5735 D_tricked_loss= tensor(1.0709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5736 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5736 D_fake_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5736 D_tricked_loss= tensor(1.0376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5737 D_real_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5737 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5737 D_tricked_loss= tensor(1.0650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5738 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5738 D_fake_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5738 D_tricked_loss= tensor(1.0622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5739 D_real_loss= tensor(0.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5739 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5739 D_tricked_loss= tensor(1.0427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5740 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5740 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5740 D_tricked_loss= tensor(1.0179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5741 D_real_loss= tensor(0.5966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5741 D_fake_loss= tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5741 D_tricked_loss= tensor(1.0119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5742 D_real_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5742 D_fake_loss= tensor(0.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5742 D_tricked_loss= tensor(1.0105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5743 D_real_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5743 D_fake_loss= tensor(0.6032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5743 D_tricked_loss= tensor(1.0375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5744 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5744 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5744 D_tricked_loss= tensor(1.0343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5745 D_real_loss= tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5745 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5745 D_tricked_loss= tensor(1.0626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5746 D_real_loss= tensor(0.5903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5746 D_fake_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5746 D_tricked_loss= tensor(1.0475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5747 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5747 D_fake_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5747 D_tricked_loss= tensor(1.0532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5748 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5748 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5748 D_tricked_loss= tensor(1.0687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5749 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5749 D_fake_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5749 D_tricked_loss= tensor(1.0655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5750 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5750 D_fake_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5750 D_tricked_loss= tensor(1.0946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5751 D_real_loss= tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5751 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5751 D_tricked_loss= tensor(1.1232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5752 D_real_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5752 D_fake_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5752 D_tricked_loss= tensor(1.1080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5753 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5753 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5753 D_tricked_loss= tensor(1.1014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5754 D_real_loss= tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5754 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5754 D_tricked_loss= tensor(1.1099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5755 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5755 D_fake_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5755 D_tricked_loss= tensor(1.0571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5756 D_real_loss= tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5756 D_fake_loss= tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5756 D_tricked_loss= tensor(1.0411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5757 D_real_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5757 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5757 D_tricked_loss= tensor(1.0761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5758 D_real_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5758 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5758 D_tricked_loss= tensor(1.0773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5759 D_real_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5759 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5759 D_tricked_loss= tensor(1.0584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5760 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5760 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5760 D_tricked_loss= tensor(1.0771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5761 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5761 D_fake_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5761 D_tricked_loss= tensor(1.1067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5762 D_real_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5762 D_fake_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5762 D_tricked_loss= tensor(1.0459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5763 D_real_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5763 D_fake_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5763 D_tricked_loss= tensor(1.0706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5764 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5764 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5764 D_tricked_loss= tensor(1.0837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5765 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5765 D_fake_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5765 D_tricked_loss= tensor(1.0931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5766 D_real_loss= tensor(0.6091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5766 D_fake_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5766 D_tricked_loss= tensor(1.0767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5767 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5767 D_fake_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5767 D_tricked_loss= tensor(1.0671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5768 D_real_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5768 D_fake_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5768 D_tricked_loss= tensor(1.0800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5769 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5769 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5769 D_tricked_loss= tensor(1.0879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5770 D_real_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5770 D_fake_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5770 D_tricked_loss= tensor(1.0284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5771 D_real_loss= tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5771 D_fake_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5771 D_tricked_loss= tensor(1.0799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5772 D_real_loss= tensor(0.6057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5772 D_fake_loss= tensor(0.5683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5772 D_tricked_loss= tensor(1.0691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5773 D_real_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5773 D_fake_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5773 D_tricked_loss= tensor(1.0680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5774 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5774 D_fake_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5774 D_tricked_loss= tensor(1.0530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5775 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5775 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5775 D_tricked_loss= tensor(1.0840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5776 D_real_loss= tensor(0.6058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5776 D_fake_loss= tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5776 D_tricked_loss= tensor(1.0316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5777 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5777 D_fake_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5777 D_tricked_loss= tensor(1.0650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5778 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5778 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5778 D_tricked_loss= tensor(1.0568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5779 D_real_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5779 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5779 D_tricked_loss= tensor(1.0748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5780 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5780 D_fake_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5780 D_tricked_loss= tensor(1.0942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5781 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5781 D_fake_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5781 D_tricked_loss= tensor(1.0808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5782 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5782 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5782 D_tricked_loss= tensor(1.1039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5783 D_real_loss= tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5783 D_fake_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5783 D_tricked_loss= tensor(1.0867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5784 D_real_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5784 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5784 D_tricked_loss= tensor(1.0862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5785 D_real_loss= tensor(0.6003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5785 D_fake_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5785 D_tricked_loss= tensor(1.0721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5786 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5786 D_fake_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5786 D_tricked_loss= tensor(1.0988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5787 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5787 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5787 D_tricked_loss= tensor(1.0339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5788 D_real_loss= tensor(0.6152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5788 D_fake_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5788 D_tricked_loss= tensor(1.0100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5789 D_real_loss= tensor(0.5978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5789 D_fake_loss= tensor(0.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5789 D_tricked_loss= tensor(1.0347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5790 D_real_loss= tensor(0.6088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5790 D_fake_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5790 D_tricked_loss= tensor(1.0207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5791 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5791 D_fake_loss= tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5791 D_tricked_loss= tensor(1.0521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5792 D_real_loss= tensor(0.6088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5792 D_fake_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5792 D_tricked_loss= tensor(1.0040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5793 D_real_loss= tensor(0.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5793 D_fake_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5793 D_tricked_loss= tensor(1.0361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5794 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5794 D_fake_loss= tensor(0.5988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5794 D_tricked_loss= tensor(1.0091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5795 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5795 D_fake_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5795 D_tricked_loss= tensor(1.0441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5796 D_real_loss= tensor(0.6194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5796 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5796 D_tricked_loss= tensor(1.0225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5797 D_real_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5797 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5797 D_tricked_loss= tensor(1.0417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5798 D_real_loss= tensor(0.6155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5798 D_fake_loss= tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5798 D_tricked_loss= tensor(1.0424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5799 D_real_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5799 D_fake_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5799 D_tricked_loss= tensor(1.0661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5800 D_real_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5800 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5800 D_tricked_loss= tensor(1.0548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5801 D_real_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5801 D_fake_loss= tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5801 D_tricked_loss= tensor(1.0576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5802 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5802 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5802 D_tricked_loss= tensor(1.0633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5803 D_real_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5803 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5803 D_tricked_loss= tensor(1.0587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5804 D_real_loss= tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5804 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5804 D_tricked_loss= tensor(1.0599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5805 D_real_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5805 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5805 D_tricked_loss= tensor(1.0875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5806 D_real_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5806 D_fake_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5806 D_tricked_loss= tensor(1.0726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5807 D_real_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5807 D_fake_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5807 D_tricked_loss= tensor(1.0841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5808 D_real_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5808 D_fake_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5808 D_tricked_loss= tensor(1.0790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5809 D_real_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5809 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5809 D_tricked_loss= tensor(1.0868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5810 D_real_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5810 D_fake_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5810 D_tricked_loss= tensor(1.0863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5811 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5811 D_fake_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5811 D_tricked_loss= tensor(1.0693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5812 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5812 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5812 D_tricked_loss= tensor(1.0746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5813 D_real_loss= tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5813 D_fake_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5813 D_tricked_loss= tensor(1.0710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5814 D_real_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5814 D_fake_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5814 D_tricked_loss= tensor(1.0800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5815 D_real_loss= tensor(0.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5815 D_fake_loss= tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5815 D_tricked_loss= tensor(1.0285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5816 D_real_loss= tensor(0.6021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5816 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5816 D_tricked_loss= tensor(1.0455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5817 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5817 D_fake_loss= tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5817 D_tricked_loss= tensor(1.0352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5818 D_real_loss= tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5818 D_fake_loss= tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5818 D_tricked_loss= tensor(1.0394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5819 D_real_loss= tensor(0.6008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5819 D_fake_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5819 D_tricked_loss= tensor(1.0375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5820 D_real_loss= tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5820 D_fake_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5820 D_tricked_loss= tensor(1.0890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5821 D_real_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5821 D_fake_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5821 D_tricked_loss= tensor(1.0618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5822 D_real_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5822 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5822 D_tricked_loss= tensor(1.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5823 D_real_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5823 D_fake_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5823 D_tricked_loss= tensor(1.0653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5824 D_real_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5824 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5824 D_tricked_loss= tensor(1.0616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5825 D_real_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5825 D_fake_loss= tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5825 D_tricked_loss= tensor(1.0243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5826 D_real_loss= tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5826 D_fake_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5826 D_tricked_loss= tensor(1.0453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5827 D_real_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5827 D_fake_loss= tensor(0.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5827 D_tricked_loss= tensor(1.0190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5828 D_real_loss= tensor(0.6274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5828 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5828 D_tricked_loss= tensor(1.0467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5829 D_real_loss= tensor(0.6040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5829 D_fake_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5829 D_tricked_loss= tensor(1.0395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5830 D_real_loss= tensor(0.6067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5830 D_fake_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5830 D_tricked_loss= tensor(1.0310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5831 D_real_loss= tensor(0.6146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5831 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5831 D_tricked_loss= tensor(1.0475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5832 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5832 D_fake_loss= tensor(0.6150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5832 D_tricked_loss= tensor(0.9807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5833 D_real_loss= tensor(0.6178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5833 D_fake_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5833 D_tricked_loss= tensor(1.0283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5834 D_real_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5834 D_fake_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5834 D_tricked_loss= tensor(1.0568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5835 D_real_loss= tensor(0.6181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5835 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5835 D_tricked_loss= tensor(1.0436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5836 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5836 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5836 D_tricked_loss= tensor(1.0634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5837 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5837 D_fake_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5837 D_tricked_loss= tensor(1.0220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5838 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5838 D_fake_loss= tensor(0.5683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5838 D_tricked_loss= tensor(1.0390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5839 D_real_loss= tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5839 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5839 D_tricked_loss= tensor(1.0248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5840 D_real_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5840 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5840 D_tricked_loss= tensor(1.0848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5841 D_real_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5841 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5841 D_tricked_loss= tensor(1.0392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5842 D_real_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5842 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5842 D_tricked_loss= tensor(1.0577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5843 D_real_loss= tensor(0.5983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5843 D_fake_loss= tensor(0.6110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5843 D_tricked_loss= tensor(1.0123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5844 D_real_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5844 D_fake_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5844 D_tricked_loss= tensor(1.0300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5845 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5845 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5845 D_tricked_loss= tensor(1.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5846 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5846 D_fake_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5846 D_tricked_loss= tensor(1.0345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5847 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5847 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5847 D_tricked_loss= tensor(1.0595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5848 D_real_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5848 D_fake_loss= tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5848 D_tricked_loss= tensor(1.0784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5849 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5849 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5849 D_tricked_loss= tensor(1.0696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5850 D_real_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5850 D_fake_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5850 D_tricked_loss= tensor(1.0579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5851 D_real_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5851 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5851 D_tricked_loss= tensor(1.1201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5852 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5852 D_fake_loss= tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5852 D_tricked_loss= tensor(1.0900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5853 D_real_loss= tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5853 D_fake_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5853 D_tricked_loss= tensor(1.0567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5854 D_real_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5854 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5854 D_tricked_loss= tensor(1.0560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5855 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5855 D_fake_loss= tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5855 D_tricked_loss= tensor(1.0502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5856 D_real_loss= tensor(0.6151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5856 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5856 D_tricked_loss= tensor(1.0437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5857 D_real_loss= tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5857 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5857 D_tricked_loss= tensor(1.0744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5858 D_real_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5858 D_fake_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5858 D_tricked_loss= tensor(1.0373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5859 D_real_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5859 D_fake_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5859 D_tricked_loss= tensor(1.0430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5860 D_real_loss= tensor(0.6181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5860 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5860 D_tricked_loss= tensor(1.0706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5861 D_real_loss= tensor(0.6174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5861 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5861 D_tricked_loss= tensor(1.0798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5862 D_real_loss= tensor(0.6124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5862 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5862 D_tricked_loss= tensor(1.0336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5863 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5863 D_fake_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5863 D_tricked_loss= tensor(1.0292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5864 D_real_loss= tensor(0.6176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5864 D_fake_loss= tensor(0.6118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5864 D_tricked_loss= tensor(1.0723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5865 D_real_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5865 D_fake_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5865 D_tricked_loss= tensor(1.0569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5866 D_real_loss= tensor(0.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5866 D_fake_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5866 D_tricked_loss= tensor(1.0758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5867 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5867 D_fake_loss= tensor(0.6078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5867 D_tricked_loss= tensor(1.0508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5868 D_real_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5868 D_fake_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5868 D_tricked_loss= tensor(1.0937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5869 D_real_loss= tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5869 D_fake_loss= tensor(0.6135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5869 D_tricked_loss= tensor(1.0379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5870 D_real_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5870 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5870 D_tricked_loss= tensor(1.0555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5871 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5871 D_fake_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5871 D_tricked_loss= tensor(1.0662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5872 D_real_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5872 D_fake_loss= tensor(0.6128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5872 D_tricked_loss= tensor(1.0202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5873 D_real_loss= tensor(0.6194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5873 D_fake_loss= tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5873 D_tricked_loss= tensor(1.0858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5874 D_real_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5874 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5874 D_tricked_loss= tensor(1.0383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5875 D_real_loss= tensor(0.6093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5875 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5875 D_tricked_loss= tensor(1.0768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5876 D_real_loss= tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5876 D_fake_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5876 D_tricked_loss= tensor(1.0552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5877 D_real_loss= tensor(0.6160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5877 D_fake_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5877 D_tricked_loss= tensor(1.0616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5878 D_real_loss= tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5878 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5878 D_tricked_loss= tensor(1.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5879 D_real_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5879 D_fake_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5879 D_tricked_loss= tensor(1.0624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5880 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5880 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5880 D_tricked_loss= tensor(1.0686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5881 D_real_loss= tensor(0.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5881 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5881 D_tricked_loss= tensor(1.0780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5882 D_real_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5882 D_fake_loss= tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5882 D_tricked_loss= tensor(1.0669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5883 D_real_loss= tensor(0.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5883 D_fake_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5883 D_tricked_loss= tensor(1.0692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5884 D_real_loss= tensor(0.6116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5884 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5884 D_tricked_loss= tensor(1.0402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5885 D_real_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5885 D_fake_loss= tensor(0.6094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5885 D_tricked_loss= tensor(1.0326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5886 D_real_loss= tensor(0.6252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5886 D_fake_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5886 D_tricked_loss= tensor(1.0603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5887 D_real_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5887 D_fake_loss= tensor(0.6092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5887 D_tricked_loss= tensor(1.0621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5888 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5888 D_fake_loss= tensor(0.6043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5888 D_tricked_loss= tensor(1.0320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5889 D_real_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5889 D_fake_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5889 D_tricked_loss= tensor(1.0826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5890 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5890 D_fake_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5890 D_tricked_loss= tensor(1.0866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5891 D_real_loss= tensor(0.6116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5891 D_fake_loss= tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5891 D_tricked_loss= tensor(1.0447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5892 D_real_loss= tensor(0.6239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5892 D_fake_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5892 D_tricked_loss= tensor(1.0655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5893 D_real_loss= tensor(0.6172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5893 D_fake_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5893 D_tricked_loss= tensor(1.0568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5894 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5894 D_fake_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5894 D_tricked_loss= tensor(1.0525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5895 D_real_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5895 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5895 D_tricked_loss= tensor(1.0859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5896 D_real_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5896 D_fake_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5896 D_tricked_loss= tensor(1.0879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5897 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5897 D_fake_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5897 D_tricked_loss= tensor(1.0563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5898 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5898 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5898 D_tricked_loss= tensor(1.0436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5899 D_real_loss= tensor(0.6126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5899 D_fake_loss= tensor(0.5903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5899 D_tricked_loss= tensor(1.0885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5900 D_real_loss= tensor(0.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5900 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5900 D_tricked_loss= tensor(1.0500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5901 D_real_loss= tensor(0.6081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5901 D_fake_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5901 D_tricked_loss= tensor(1.0486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5902 D_real_loss= tensor(0.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5902 D_fake_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5902 D_tricked_loss= tensor(1.0576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5903 D_real_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5903 D_fake_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5903 D_tricked_loss= tensor(1.0532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5904 D_real_loss= tensor(0.6135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5904 D_fake_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5904 D_tricked_loss= tensor(1.0461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5905 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5905 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5905 D_tricked_loss= tensor(1.0247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5906 D_real_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5906 D_fake_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5906 D_tricked_loss= tensor(1.0837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5907 D_real_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5907 D_fake_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5907 D_tricked_loss= tensor(1.0681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5908 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5908 D_fake_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5908 D_tricked_loss= tensor(1.0620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5909 D_real_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5909 D_fake_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5909 D_tricked_loss= tensor(1.0463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5910 D_real_loss= tensor(0.6106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5910 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5910 D_tricked_loss= tensor(1.0795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5911 D_real_loss= tensor(0.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5911 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5911 D_tricked_loss= tensor(1.0702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5912 D_real_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5912 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5912 D_tricked_loss= tensor(1.1059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5913 D_real_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5913 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5913 D_tricked_loss= tensor(1.0850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5914 D_real_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5914 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5914 D_tricked_loss= tensor(1.0781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5915 D_real_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5915 D_fake_loss= tensor(0.6087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5915 D_tricked_loss= tensor(1.0847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5916 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5916 D_fake_loss= tensor(0.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5916 D_tricked_loss= tensor(1.0469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5917 D_real_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5917 D_fake_loss= tensor(0.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5917 D_tricked_loss= tensor(1.0524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5918 D_real_loss= tensor(0.6282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5918 D_fake_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5918 D_tricked_loss= tensor(1.0232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5919 D_real_loss= tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5919 D_fake_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5919 D_tricked_loss= tensor(1.0652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5920 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5920 D_fake_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5920 D_tricked_loss= tensor(1.0522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5921 D_real_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5921 D_fake_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5921 D_tricked_loss= tensor(1.0935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5922 D_real_loss= tensor(0.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5922 D_fake_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5922 D_tricked_loss= tensor(1.0580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5923 D_real_loss= tensor(0.6001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5923 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5923 D_tricked_loss= tensor(1.0870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5924 D_real_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5924 D_fake_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5924 D_tricked_loss= tensor(1.0496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5925 D_real_loss= tensor(0.6116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5925 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5925 D_tricked_loss= tensor(1.0493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5926 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5926 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5926 D_tricked_loss= tensor(1.0739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5927 D_real_loss= tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5927 D_fake_loss= tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5927 D_tricked_loss= tensor(1.1008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5928 D_real_loss= tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5928 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5928 D_tricked_loss= tensor(1.1011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5929 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5929 D_fake_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5929 D_tricked_loss= tensor(1.0694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5930 D_real_loss= tensor(0.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5930 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5930 D_tricked_loss= tensor(1.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5931 D_real_loss= tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5931 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5931 D_tricked_loss= tensor(1.0920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5932 D_real_loss= tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5932 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5932 D_tricked_loss= tensor(1.0638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5933 D_real_loss= tensor(0.6115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5933 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5933 D_tricked_loss= tensor(1.0270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5934 D_real_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5934 D_fake_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5934 D_tricked_loss= tensor(1.0751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5935 D_real_loss= tensor(0.6070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5935 D_fake_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5935 D_tricked_loss= tensor(1.0346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5936 D_real_loss= tensor(0.6165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5936 D_fake_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5936 D_tricked_loss= tensor(1.0190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5937 D_real_loss= tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5937 D_fake_loss= tensor(0.5903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5937 D_tricked_loss= tensor(1.0596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5938 D_real_loss= tensor(0.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5938 D_fake_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5938 D_tricked_loss= tensor(1.0264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5939 D_real_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5939 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5939 D_tricked_loss= tensor(1.0519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5940 D_real_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5940 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5940 D_tricked_loss= tensor(1.0559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5941 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5941 D_fake_loss= tensor(0.6084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5941 D_tricked_loss= tensor(1.0330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5942 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5942 D_fake_loss= tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5942 D_tricked_loss= tensor(1.0761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5943 D_real_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5943 D_fake_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5943 D_tricked_loss= tensor(1.0394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5944 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5944 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5944 D_tricked_loss= tensor(1.0844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5945 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5945 D_fake_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5945 D_tricked_loss= tensor(1.0713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5946 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5946 D_fake_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5946 D_tricked_loss= tensor(1.0753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5947 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5947 D_fake_loss= tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5947 D_tricked_loss= tensor(1.0570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5948 D_real_loss= tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5948 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5948 D_tricked_loss= tensor(1.1000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5949 D_real_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5949 D_fake_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5949 D_tricked_loss= tensor(1.0656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5950 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5950 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5950 D_tricked_loss= tensor(1.0773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5951 D_real_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5951 D_fake_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5951 D_tricked_loss= tensor(1.0788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5952 D_real_loss= tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5952 D_fake_loss= tensor(0.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5952 D_tricked_loss= tensor(1.0490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5953 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5953 D_fake_loss= tensor(0.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5953 D_tricked_loss= tensor(1.0617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5954 D_real_loss= tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5954 D_fake_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5954 D_tricked_loss= tensor(1.0346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5955 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5955 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5955 D_tricked_loss= tensor(1.0284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5956 D_real_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5956 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5956 D_tricked_loss= tensor(1.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5957 D_real_loss= tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5957 D_fake_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5957 D_tricked_loss= tensor(1.0268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5958 D_real_loss= tensor(0.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5958 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5958 D_tricked_loss= tensor(1.0584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5959 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5959 D_fake_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5959 D_tricked_loss= tensor(1.0426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5960 D_real_loss= tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5960 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5960 D_tricked_loss= tensor(1.0534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5961 D_real_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5961 D_fake_loss= tensor(0.5972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5961 D_tricked_loss= tensor(1.0552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5962 D_real_loss= tensor(0.6081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5962 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5962 D_tricked_loss= tensor(1.0710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5963 D_real_loss= tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5963 D_fake_loss= tensor(0.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5963 D_tricked_loss= tensor(1.0643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5964 D_real_loss= tensor(0.5978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5964 D_fake_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5964 D_tricked_loss= tensor(1.0182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5965 D_real_loss= tensor(0.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5965 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5965 D_tricked_loss= tensor(1.0489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5966 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5966 D_fake_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5966 D_tricked_loss= tensor(1.0393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5967 D_real_loss= tensor(0.6235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5967 D_fake_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5967 D_tricked_loss= tensor(1.0322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5968 D_real_loss= tensor(0.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5968 D_fake_loss= tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5968 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5969 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5969 D_fake_loss= tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5969 D_tricked_loss= tensor(1.0493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5970 D_real_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5970 D_fake_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5970 D_tricked_loss= tensor(1.0451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5971 D_real_loss= tensor(0.6001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5971 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5971 D_tricked_loss= tensor(1.0684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5972 D_real_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5972 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5972 D_tricked_loss= tensor(1.0515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5973 D_real_loss= tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5973 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5973 D_tricked_loss= tensor(1.0419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5974 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5974 D_fake_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5974 D_tricked_loss= tensor(1.0747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5975 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5975 D_fake_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5975 D_tricked_loss= tensor(1.0591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5976 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5976 D_fake_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5976 D_tricked_loss= tensor(1.0935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5977 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5977 D_fake_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5977 D_tricked_loss= tensor(1.0495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5978 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5978 D_fake_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5978 D_tricked_loss= tensor(1.0904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5979 D_real_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5979 D_fake_loss= tensor(0.6165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5979 D_tricked_loss= tensor(1.0133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5980 D_real_loss= tensor(0.6122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5980 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5980 D_tricked_loss= tensor(1.0729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5981 D_real_loss= tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5981 D_fake_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5981 D_tricked_loss= tensor(0.9867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5982 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5982 D_fake_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5982 D_tricked_loss= tensor(1.0168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5983 D_real_loss= tensor(0.6069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5983 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5983 D_tricked_loss= tensor(1.0533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5984 D_real_loss= tensor(0.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5984 D_fake_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5984 D_tricked_loss= tensor(1.0462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5985 D_real_loss= tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5985 D_fake_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5985 D_tricked_loss= tensor(1.0485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5986 D_real_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5986 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5986 D_tricked_loss= tensor(1.0626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5987 D_real_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5987 D_fake_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5987 D_tricked_loss= tensor(1.0869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5988 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5988 D_fake_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5988 D_tricked_loss= tensor(1.0095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5989 D_real_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5989 D_fake_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5989 D_tricked_loss= tensor(1.0447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5990 D_real_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5990 D_fake_loss= tensor(0.6066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5990 D_tricked_loss= tensor(0.9991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5991 D_real_loss= tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5991 D_fake_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5991 D_tricked_loss= tensor(1.0405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5992 D_real_loss= tensor(0.6100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5992 D_fake_loss= tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5992 D_tricked_loss= tensor(1.0016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5993 D_real_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5993 D_fake_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5993 D_tricked_loss= tensor(1.0128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5994 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5994 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5994 D_tricked_loss= tensor(1.0600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5995 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5995 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5995 D_tricked_loss= tensor(1.0300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5996 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5996 D_fake_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5996 D_tricked_loss= tensor(1.0521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5997 D_real_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5997 D_fake_loss= tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5997 D_tricked_loss= tensor(1.0580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5998 D_real_loss= tensor(0.6061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5998 D_fake_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5998 D_tricked_loss= tensor(1.0994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "5999 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5999 D_fake_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5999 D_tricked_loss= tensor(1.0655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6000 D_real_loss= tensor(0.6046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6000 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6000 D_tricked_loss= tensor(1.0675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6001 D_real_loss= tensor(0.6046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6001 D_fake_loss= tensor(0.6105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6001 D_tricked_loss= tensor(1.0610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6002 D_real_loss= tensor(0.6158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6002 D_fake_loss= tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6002 D_tricked_loss= tensor(1.0158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6003 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6003 D_fake_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6003 D_tricked_loss= tensor(1.0030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6004 D_real_loss= tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6004 D_fake_loss= tensor(0.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6004 D_tricked_loss= tensor(0.9873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6005 D_real_loss= tensor(0.6069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6005 D_fake_loss= tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6005 D_tricked_loss= tensor(1.0488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6006 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6006 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6006 D_tricked_loss= tensor(1.0492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6007 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6007 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6007 D_tricked_loss= tensor(1.0781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6008 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6008 D_fake_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6008 D_tricked_loss= tensor(1.0912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6009 D_real_loss= tensor(0.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6009 D_fake_loss= tensor(0.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6009 D_tricked_loss= tensor(1.0768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6010 D_real_loss= tensor(0.6120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6010 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6010 D_tricked_loss= tensor(1.1071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6011 D_real_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6011 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6011 D_tricked_loss= tensor(1.1153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6012 D_real_loss= tensor(0.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6012 D_fake_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6012 D_tricked_loss= tensor(1.0892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6013 D_real_loss= tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6013 D_fake_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6013 D_tricked_loss= tensor(1.0663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6014 D_real_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6014 D_fake_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6014 D_tricked_loss= tensor(1.0631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6015 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6015 D_fake_loss= tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6015 D_tricked_loss= tensor(1.0279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6016 D_real_loss= tensor(0.6007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6016 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6016 D_tricked_loss= tensor(1.0398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6017 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6017 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6017 D_tricked_loss= tensor(1.0182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6018 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6018 D_fake_loss= tensor(0.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6018 D_tricked_loss= tensor(0.9792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6019 D_real_loss= tensor(0.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6019 D_fake_loss= tensor(0.5957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6019 D_tricked_loss= tensor(1.0327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6020 D_real_loss= tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6020 D_fake_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6020 D_tricked_loss= tensor(1.0036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6021 D_real_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6021 D_fake_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6021 D_tricked_loss= tensor(1.0546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6022 D_real_loss= tensor(0.6116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6022 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6022 D_tricked_loss= tensor(1.0242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6023 D_real_loss= tensor(0.6135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6023 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6023 D_tricked_loss= tensor(1.0772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6024 D_real_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6024 D_fake_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6024 D_tricked_loss= tensor(1.0606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6025 D_real_loss= tensor(0.6001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6025 D_fake_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6025 D_tricked_loss= tensor(1.0888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6026 D_real_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6026 D_fake_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6026 D_tricked_loss= tensor(1.0550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6027 D_real_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6027 D_fake_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6027 D_tricked_loss= tensor(1.0605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6028 D_real_loss= tensor(0.6264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6028 D_fake_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6028 D_tricked_loss= tensor(1.0845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6029 D_real_loss= tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6029 D_fake_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6029 D_tricked_loss= tensor(1.0375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6030 D_real_loss= tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6030 D_fake_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6030 D_tricked_loss= tensor(1.0509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6031 D_real_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6031 D_fake_loss= tensor(0.6262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6031 D_tricked_loss= tensor(1.0363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6032 D_real_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6032 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6032 D_tricked_loss= tensor(1.0643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6033 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6033 D_fake_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6033 D_tricked_loss= tensor(1.0614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6034 D_real_loss= tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6034 D_fake_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6034 D_tricked_loss= tensor(1.0909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6035 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6035 D_fake_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6035 D_tricked_loss= tensor(1.0240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6036 D_real_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6036 D_fake_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6036 D_tricked_loss= tensor(1.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6037 D_real_loss= tensor(0.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6037 D_fake_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6037 D_tricked_loss= tensor(1.1054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6038 D_real_loss= tensor(0.6112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6038 D_fake_loss= tensor(0.6068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6038 D_tricked_loss= tensor(1.0168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6039 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6039 D_fake_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6039 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6040 D_real_loss= tensor(0.6064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6040 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6040 D_tricked_loss= tensor(1.0350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6041 D_real_loss= tensor(0.6184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6041 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6041 D_tricked_loss= tensor(1.0527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6042 D_real_loss= tensor(0.6101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6042 D_fake_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6042 D_tricked_loss= tensor(0.9925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6043 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6043 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6043 D_tricked_loss= tensor(1.0496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6044 D_real_loss= tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6044 D_fake_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6044 D_tricked_loss= tensor(1.0411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6045 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6045 D_fake_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6045 D_tricked_loss= tensor(1.0319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6046 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6046 D_fake_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6046 D_tricked_loss= tensor(1.0083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6047 D_real_loss= tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6047 D_fake_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6047 D_tricked_loss= tensor(1.0123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6048 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6048 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6048 D_tricked_loss= tensor(1.0472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6049 D_real_loss= tensor(0.6094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6049 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6049 D_tricked_loss= tensor(1.0471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6050 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6050 D_fake_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6050 D_tricked_loss= tensor(1.0642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6051 D_real_loss= tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6051 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6051 D_tricked_loss= tensor(1.0548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6052 D_real_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6052 D_fake_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6052 D_tricked_loss= tensor(1.0391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6053 D_real_loss= tensor(0.6172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6053 D_fake_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6053 D_tricked_loss= tensor(1.0434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6054 D_real_loss= tensor(0.6179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6054 D_fake_loss= tensor(0.6044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6054 D_tricked_loss= tensor(0.9902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6055 D_real_loss= tensor(0.6190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6055 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6055 D_tricked_loss= tensor(1.0138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6056 D_real_loss= tensor(0.6163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6056 D_fake_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6056 D_tricked_loss= tensor(0.9993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6057 D_real_loss= tensor(0.6116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6057 D_fake_loss= tensor(0.6112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6057 D_tricked_loss= tensor(1.0427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6058 D_real_loss= tensor(0.6214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6058 D_fake_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6058 D_tricked_loss= tensor(1.0101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6059 D_real_loss= tensor(0.6145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6059 D_fake_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6059 D_tricked_loss= tensor(1.0152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6060 D_real_loss= tensor(0.6021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6060 D_fake_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6060 D_tricked_loss= tensor(1.0442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6061 D_real_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6061 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6061 D_tricked_loss= tensor(1.0569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6062 D_real_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6062 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6062 D_tricked_loss= tensor(1.0698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6063 D_real_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6063 D_fake_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6063 D_tricked_loss= tensor(1.0592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6064 D_real_loss= tensor(0.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6064 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6064 D_tricked_loss= tensor(1.0696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6065 D_real_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6065 D_fake_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6065 D_tricked_loss= tensor(1.0441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6066 D_real_loss= tensor(0.6136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6066 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6066 D_tricked_loss= tensor(1.0558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6067 D_real_loss= tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6067 D_fake_loss= tensor(0.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6067 D_tricked_loss= tensor(1.0114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6068 D_real_loss= tensor(0.6210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6068 D_fake_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6068 D_tricked_loss= tensor(1.0319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6069 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6069 D_fake_loss= tensor(0.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6069 D_tricked_loss= tensor(1.0474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6070 D_real_loss= tensor(0.6149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6070 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6070 D_tricked_loss= tensor(1.0207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6071 D_real_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6071 D_fake_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6071 D_tricked_loss= tensor(1.0172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6072 D_real_loss= tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6072 D_fake_loss= tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6072 D_tricked_loss= tensor(1.0267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6073 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6073 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6073 D_tricked_loss= tensor(1.0620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6074 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6074 D_fake_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6074 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6075 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6075 D_fake_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6075 D_tricked_loss= tensor(1.0771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6076 D_real_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6076 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6076 D_tricked_loss= tensor(1.0577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6077 D_real_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6077 D_fake_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6077 D_tricked_loss= tensor(1.0477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6078 D_real_loss= tensor(0.6063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6078 D_fake_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6078 D_tricked_loss= tensor(1.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6079 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6079 D_fake_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6079 D_tricked_loss= tensor(1.1247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6080 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6080 D_fake_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6080 D_tricked_loss= tensor(1.0741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6081 D_real_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6081 D_fake_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6081 D_tricked_loss= tensor(1.0678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6082 D_real_loss= tensor(0.6176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6082 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6082 D_tricked_loss= tensor(1.0798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6083 D_real_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6083 D_fake_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6083 D_tricked_loss= tensor(1.0245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6084 D_real_loss= tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6084 D_fake_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6084 D_tricked_loss= tensor(1.0340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6085 D_real_loss= tensor(0.6248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6085 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6085 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6086 D_real_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6086 D_fake_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6086 D_tricked_loss= tensor(1.0387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6087 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6087 D_fake_loss= tensor(0.6064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6087 D_tricked_loss= tensor(1.0533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6088 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6088 D_fake_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6088 D_tricked_loss= tensor(1.0542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6089 D_real_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6089 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6089 D_tricked_loss= tensor(1.0569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6090 D_real_loss= tensor(0.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6090 D_fake_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6090 D_tricked_loss= tensor(1.0534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6091 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6091 D_fake_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6091 D_tricked_loss= tensor(1.0772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6092 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6092 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6092 D_tricked_loss= tensor(1.0511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6093 D_real_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6093 D_fake_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6093 D_tricked_loss= tensor(1.0750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6094 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6094 D_fake_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6094 D_tricked_loss= tensor(1.0410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6095 D_real_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6095 D_fake_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6095 D_tricked_loss= tensor(1.0972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6096 D_real_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6096 D_fake_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6096 D_tricked_loss= tensor(1.0319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6097 D_real_loss= tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6097 D_fake_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6097 D_tricked_loss= tensor(1.0607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6098 D_real_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6098 D_fake_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6098 D_tricked_loss= tensor(1.0446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6099 D_real_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6099 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6099 D_tricked_loss= tensor(1.0441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6100 D_real_loss= tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6100 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6100 D_tricked_loss= tensor(1.0328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6101 D_real_loss= tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6101 D_fake_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6101 D_tricked_loss= tensor(1.0463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6102 D_real_loss= tensor(0.6064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6102 D_fake_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6102 D_tricked_loss= tensor(1.0655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6103 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6103 D_fake_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6103 D_tricked_loss= tensor(1.0113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6104 D_real_loss= tensor(0.6213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6104 D_fake_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6104 D_tricked_loss= tensor(1.0508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6105 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6105 D_fake_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6105 D_tricked_loss= tensor(1.0078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6106 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6106 D_fake_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6106 D_tricked_loss= tensor(1.0604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6107 D_real_loss= tensor(0.6003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6107 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6107 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6108 D_real_loss= tensor(0.6256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6108 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6108 D_tricked_loss= tensor(1.0428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6109 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6109 D_fake_loss= tensor(0.6222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6109 D_tricked_loss= tensor(0.9569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6110 D_real_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6110 D_fake_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6110 D_tricked_loss= tensor(0.9822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6111 D_real_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6111 D_fake_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6111 D_tricked_loss= tensor(1.0403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6112 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6112 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6112 D_tricked_loss= tensor(1.0129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6113 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6113 D_fake_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6113 D_tricked_loss= tensor(1.0297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6114 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6114 D_fake_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6114 D_tricked_loss= tensor(1.0741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6115 D_real_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6115 D_fake_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6115 D_tricked_loss= tensor(1.0556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6116 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6116 D_fake_loss= tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6116 D_tricked_loss= tensor(1.0659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6117 D_real_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6117 D_fake_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6117 D_tricked_loss= tensor(1.0691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6118 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6118 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6118 D_tricked_loss= tensor(1.0275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6119 D_real_loss= tensor(0.6110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6119 D_fake_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6119 D_tricked_loss= tensor(1.0136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6120 D_real_loss= tensor(0.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6120 D_fake_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6120 D_tricked_loss= tensor(1.0350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6121 D_real_loss= tensor(0.6241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6121 D_fake_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6121 D_tricked_loss= tensor(1.0387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6122 D_real_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6122 D_fake_loss= tensor(0.6167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6122 D_tricked_loss= tensor(0.9902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6123 D_real_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6123 D_fake_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6123 D_tricked_loss= tensor(1.0119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6124 D_real_loss= tensor(0.6070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6124 D_fake_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6124 D_tricked_loss= tensor(1.0184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6125 D_real_loss= tensor(0.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6125 D_fake_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6125 D_tricked_loss= tensor(1.0052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6126 D_real_loss= tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6126 D_fake_loss= tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6126 D_tricked_loss= tensor(1.0253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6127 D_real_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6127 D_fake_loss= tensor(0.6094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6127 D_tricked_loss= tensor(1.0015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6128 D_real_loss= tensor(0.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6128 D_fake_loss= tensor(0.6011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6128 D_tricked_loss= tensor(1.0305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6129 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6129 D_fake_loss= tensor(0.6151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6129 D_tricked_loss= tensor(1.0037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6130 D_real_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6130 D_fake_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6130 D_tricked_loss= tensor(1.0293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6131 D_real_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6131 D_fake_loss= tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6131 D_tricked_loss= tensor(1.0260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6132 D_real_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6132 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6132 D_tricked_loss= tensor(1.0887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6133 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6133 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6133 D_tricked_loss= tensor(1.0966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6134 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6134 D_fake_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6134 D_tricked_loss= tensor(1.0775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6135 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6135 D_fake_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6135 D_tricked_loss= tensor(1.1003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6136 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6136 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6136 D_tricked_loss= tensor(1.0862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6137 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6137 D_fake_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6137 D_tricked_loss= tensor(1.0982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6138 D_real_loss= tensor(0.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6138 D_fake_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6138 D_tricked_loss= tensor(1.0847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6139 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6139 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6139 D_tricked_loss= tensor(1.0663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6140 D_real_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6140 D_fake_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6140 D_tricked_loss= tensor(1.0225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6141 D_real_loss= tensor(0.6164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6141 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6141 D_tricked_loss= tensor(1.0220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6142 D_real_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6142 D_fake_loss= tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6142 D_tricked_loss= tensor(1.0360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6143 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6143 D_fake_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6143 D_tricked_loss= tensor(1.0213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6144 D_real_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6144 D_fake_loss= tensor(0.6100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6144 D_tricked_loss= tensor(1.0167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6145 D_real_loss= tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6145 D_fake_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6145 D_tricked_loss= tensor(1.0698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6146 D_real_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6146 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6146 D_tricked_loss= tensor(1.0528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6147 D_real_loss= tensor(0.6078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6147 D_fake_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6147 D_tricked_loss= tensor(1.0733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6148 D_real_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6148 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6148 D_tricked_loss= tensor(1.0316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6149 D_real_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6149 D_fake_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6149 D_tricked_loss= tensor(1.0142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6150 D_real_loss= tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6150 D_fake_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6150 D_tricked_loss= tensor(1.0236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6151 D_real_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6151 D_fake_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6151 D_tricked_loss= tensor(1.0375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6152 D_real_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6152 D_fake_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6152 D_tricked_loss= tensor(1.0513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6153 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6153 D_fake_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6153 D_tricked_loss= tensor(1.0394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6154 D_real_loss= tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6154 D_fake_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6154 D_tricked_loss= tensor(1.0996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6155 D_real_loss= tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6155 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6155 D_tricked_loss= tensor(1.0627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6156 D_real_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6156 D_fake_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6156 D_tricked_loss= tensor(1.0147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6157 D_real_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6157 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6157 D_tricked_loss= tensor(1.0206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6158 D_real_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6158 D_fake_loss= tensor(0.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6158 D_tricked_loss= tensor(0.9813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6159 D_real_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6159 D_fake_loss= tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6159 D_tricked_loss= tensor(0.9721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6160 D_real_loss= tensor(0.6131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6160 D_fake_loss= tensor(0.6092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6160 D_tricked_loss= tensor(1.0267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6161 D_real_loss= tensor(0.6079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6161 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6161 D_tricked_loss= tensor(1.0348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6162 D_real_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6162 D_fake_loss= tensor(0.6151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6162 D_tricked_loss= tensor(0.9963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6163 D_real_loss= tensor(0.6188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6163 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6163 D_tricked_loss= tensor(1.0181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6164 D_real_loss= tensor(0.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6164 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6164 D_tricked_loss= tensor(1.0411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6165 D_real_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6165 D_fake_loss= tensor(0.6126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6165 D_tricked_loss= tensor(1.0439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6166 D_real_loss= tensor(0.6215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6166 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6166 D_tricked_loss= tensor(1.0422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6167 D_real_loss= tensor(0.6129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6167 D_fake_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6167 D_tricked_loss= tensor(0.9945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6168 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6168 D_fake_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6168 D_tricked_loss= tensor(1.0415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6169 D_real_loss= tensor(0.6074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6169 D_fake_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6169 D_tricked_loss= tensor(1.0364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6170 D_real_loss= tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6170 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6170 D_tricked_loss= tensor(1.0324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6171 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6171 D_fake_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6171 D_tricked_loss= tensor(1.0459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6172 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6172 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6172 D_tricked_loss= tensor(1.1095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6173 D_real_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6173 D_fake_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6173 D_tricked_loss= tensor(1.0511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6174 D_real_loss= tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6174 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6174 D_tricked_loss= tensor(1.0658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6175 D_real_loss= tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6175 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6175 D_tricked_loss= tensor(1.0282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6176 D_real_loss= tensor(0.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6176 D_fake_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6176 D_tricked_loss= tensor(1.0397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6177 D_real_loss= tensor(0.6021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6177 D_fake_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6177 D_tricked_loss= tensor(1.0324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6178 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6178 D_fake_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6178 D_tricked_loss= tensor(1.0555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6179 D_real_loss= tensor(0.6128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6179 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6179 D_tricked_loss= tensor(1.0901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6180 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6180 D_fake_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6180 D_tricked_loss= tensor(1.0326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6181 D_real_loss= tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6181 D_fake_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6181 D_tricked_loss= tensor(1.0321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6182 D_real_loss= tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6182 D_fake_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6182 D_tricked_loss= tensor(1.0277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6183 D_real_loss= tensor(0.6118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6183 D_fake_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6183 D_tricked_loss= tensor(1.0402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6184 D_real_loss= tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6184 D_fake_loss= tensor(0.6114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6184 D_tricked_loss= tensor(0.9980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6185 D_real_loss= tensor(0.6046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6185 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6185 D_tricked_loss= tensor(1.0374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6186 D_real_loss= tensor(0.5903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6186 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6186 D_tricked_loss= tensor(1.0229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6187 D_real_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6187 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6187 D_tricked_loss= tensor(1.0336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6188 D_real_loss= tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6188 D_fake_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6188 D_tricked_loss= tensor(1.0223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6189 D_real_loss= tensor(0.6169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6189 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6189 D_tricked_loss= tensor(1.0429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6190 D_real_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6190 D_fake_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6190 D_tricked_loss= tensor(1.0486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6191 D_real_loss= tensor(0.6084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6191 D_fake_loss= tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6191 D_tricked_loss= tensor(1.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6192 D_real_loss= tensor(0.6234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6192 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6192 D_tricked_loss= tensor(1.0435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6193 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6193 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6193 D_tricked_loss= tensor(1.0311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6194 D_real_loss= tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6194 D_fake_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6194 D_tricked_loss= tensor(1.0311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6195 D_real_loss= tensor(0.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6195 D_fake_loss= tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6195 D_tricked_loss= tensor(1.0381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6196 D_real_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6196 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6196 D_tricked_loss= tensor(1.0637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6197 D_real_loss= tensor(0.6082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6197 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6197 D_tricked_loss= tensor(1.0727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6198 D_real_loss= tensor(0.6081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6198 D_fake_loss= tensor(0.5988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6198 D_tricked_loss= tensor(1.0329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6199 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6199 D_fake_loss= tensor(0.6138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6199 D_tricked_loss= tensor(1.0452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6200 D_real_loss= tensor(0.6254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6200 D_fake_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6200 D_tricked_loss= tensor(1.0229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6201 D_real_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6201 D_fake_loss= tensor(0.6278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6201 D_tricked_loss= tensor(1.0277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6202 D_real_loss= tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6202 D_fake_loss= tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6202 D_tricked_loss= tensor(1.0465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6203 D_real_loss= tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6203 D_fake_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6203 D_tricked_loss= tensor(1.0670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6204 D_real_loss= tensor(0.6257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6204 D_fake_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6204 D_tricked_loss= tensor(1.0162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6205 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6205 D_fake_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6205 D_tricked_loss= tensor(1.0119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6206 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6206 D_fake_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6206 D_tricked_loss= tensor(1.0198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6207 D_real_loss= tensor(0.6183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6207 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6207 D_tricked_loss= tensor(1.0573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6208 D_real_loss= tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6208 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6208 D_tricked_loss= tensor(1.0490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6209 D_real_loss= tensor(0.6291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6209 D_fake_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6209 D_tricked_loss= tensor(1.0467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6210 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6210 D_fake_loss= tensor(0.6040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6210 D_tricked_loss= tensor(1.0021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6211 D_real_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6211 D_fake_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6211 D_tricked_loss= tensor(1.0244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6212 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6212 D_fake_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6212 D_tricked_loss= tensor(1.0485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6213 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6213 D_fake_loss= tensor(0.6061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6213 D_tricked_loss= tensor(1.0381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6214 D_real_loss= tensor(0.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6214 D_fake_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6214 D_tricked_loss= tensor(1.0155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6215 D_real_loss= tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6215 D_fake_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6215 D_tricked_loss= tensor(1.0577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6216 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6216 D_fake_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6216 D_tricked_loss= tensor(1.0972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6217 D_real_loss= tensor(0.6088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6217 D_fake_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6217 D_tricked_loss= tensor(1.0494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6218 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6218 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6218 D_tricked_loss= tensor(1.0563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6219 D_real_loss= tensor(0.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6219 D_fake_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6219 D_tricked_loss= tensor(1.0255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6220 D_real_loss= tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6220 D_fake_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6220 D_tricked_loss= tensor(1.0129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6221 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6221 D_fake_loss= tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6221 D_tricked_loss= tensor(1.0034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6222 D_real_loss= tensor(0.6288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6222 D_fake_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6222 D_tricked_loss= tensor(1.0226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6223 D_real_loss= tensor(0.6138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6223 D_fake_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6223 D_tricked_loss= tensor(1.0011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6224 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6224 D_fake_loss= tensor(0.6369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6224 D_tricked_loss= tensor(0.9883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6225 D_real_loss= tensor(0.6280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6225 D_fake_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6225 D_tricked_loss= tensor(1.0115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6226 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6226 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6226 D_tricked_loss= tensor(1.0058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6227 D_real_loss= tensor(0.6032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6227 D_fake_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6227 D_tricked_loss= tensor(1.0604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6228 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6228 D_fake_loss= tensor(0.5983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6228 D_tricked_loss= tensor(1.0586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6229 D_real_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6229 D_fake_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6229 D_tricked_loss= tensor(1.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6230 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6230 D_fake_loss= tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6230 D_tricked_loss= tensor(1.0597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6231 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6231 D_fake_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6231 D_tricked_loss= tensor(1.0649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6232 D_real_loss= tensor(0.6082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6232 D_fake_loss= tensor(0.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6232 D_tricked_loss= tensor(1.0902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6233 D_real_loss= tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6233 D_fake_loss= tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6233 D_tricked_loss= tensor(1.0499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6234 D_real_loss= tensor(0.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6234 D_fake_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6234 D_tricked_loss= tensor(1.0393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6235 D_real_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6235 D_fake_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6235 D_tricked_loss= tensor(1.0317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6236 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6236 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6236 D_tricked_loss= tensor(1.0440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6237 D_real_loss= tensor(0.6152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6237 D_fake_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6237 D_tricked_loss= tensor(1.0421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6238 D_real_loss= tensor(0.6068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6238 D_fake_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6238 D_tricked_loss= tensor(1.0507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6239 D_real_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6239 D_fake_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6239 D_tricked_loss= tensor(1.0591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6240 D_real_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6240 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6240 D_tricked_loss= tensor(1.0560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6241 D_real_loss= tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6241 D_fake_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6241 D_tricked_loss= tensor(1.0679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6242 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6242 D_fake_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6242 D_tricked_loss= tensor(1.0767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6243 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6243 D_fake_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6243 D_tricked_loss= tensor(1.0538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6244 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6244 D_fake_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6244 D_tricked_loss= tensor(1.0936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6245 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6245 D_fake_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6245 D_tricked_loss= tensor(1.0416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6246 D_real_loss= tensor(0.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6246 D_fake_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6246 D_tricked_loss= tensor(1.0346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6247 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6247 D_fake_loss= tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6247 D_tricked_loss= tensor(1.0456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6248 D_real_loss= tensor(0.6150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6248 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6248 D_tricked_loss= tensor(1.0743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6249 D_real_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6249 D_fake_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6249 D_tricked_loss= tensor(1.0329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6250 D_real_loss= tensor(0.6118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6250 D_fake_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6250 D_tricked_loss= tensor(1.0415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6251 D_real_loss= tensor(0.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6251 D_fake_loss= tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6251 D_tricked_loss= tensor(1.0306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6252 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6252 D_fake_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6252 D_tricked_loss= tensor(0.9962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6253 D_real_loss= tensor(0.6205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6253 D_fake_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6253 D_tricked_loss= tensor(1.0396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6254 D_real_loss= tensor(0.6122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6254 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6254 D_tricked_loss= tensor(1.0214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6255 D_real_loss= tensor(0.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6255 D_fake_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6255 D_tricked_loss= tensor(1.0047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6256 D_real_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6256 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6256 D_tricked_loss= tensor(1.0473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6257 D_real_loss= tensor(0.6067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6257 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6257 D_tricked_loss= tensor(1.0043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6258 D_real_loss= tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6258 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6258 D_tricked_loss= tensor(1.0266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6259 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6259 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6259 D_tricked_loss= tensor(1.0198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6260 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6260 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6260 D_tricked_loss= tensor(1.0247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6261 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6261 D_fake_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6261 D_tricked_loss= tensor(1.0400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6262 D_real_loss= tensor(0.6248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6262 D_fake_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6262 D_tricked_loss= tensor(1.0109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6263 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6263 D_fake_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6263 D_tricked_loss= tensor(1.0460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6264 D_real_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6264 D_fake_loss= tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6264 D_tricked_loss= tensor(0.9923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6265 D_real_loss= tensor(0.6254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6265 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6265 D_tricked_loss= tensor(1.0106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6266 D_real_loss= tensor(0.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6266 D_fake_loss= tensor(0.6174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6266 D_tricked_loss= tensor(1.0066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6267 D_real_loss= tensor(0.6123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6267 D_fake_loss= tensor(0.5903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6267 D_tricked_loss= tensor(1.0489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6268 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6268 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6268 D_tricked_loss= tensor(1.0250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6269 D_real_loss= tensor(0.6141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6269 D_fake_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6269 D_tricked_loss= tensor(1.0615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6270 D_real_loss= tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6270 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6270 D_tricked_loss= tensor(1.0812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6271 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6271 D_fake_loss= tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6271 D_tricked_loss= tensor(1.0469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6272 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6272 D_fake_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6272 D_tricked_loss= tensor(1.0795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6273 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6273 D_fake_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6273 D_tricked_loss= tensor(1.0521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6274 D_real_loss= tensor(0.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6274 D_fake_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6274 D_tricked_loss= tensor(1.0555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6275 D_real_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6275 D_fake_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6275 D_tricked_loss= tensor(1.0355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6276 D_real_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6276 D_fake_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6276 D_tricked_loss= tensor(1.0391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6277 D_real_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6277 D_fake_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6277 D_tricked_loss= tensor(1.0615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6278 D_real_loss= tensor(0.6003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6278 D_fake_loss= tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6278 D_tricked_loss= tensor(1.0264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6279 D_real_loss= tensor(0.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6279 D_fake_loss= tensor(0.6024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6279 D_tricked_loss= tensor(1.0216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6280 D_real_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6280 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6280 D_tricked_loss= tensor(1.0530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6281 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6281 D_fake_loss= tensor(0.5972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6281 D_tricked_loss= tensor(1.0407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6282 D_real_loss= tensor(0.6128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6282 D_fake_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6282 D_tricked_loss= tensor(1.0307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6283 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6283 D_fake_loss= tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6283 D_tricked_loss= tensor(0.9863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6284 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6284 D_fake_loss= tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6284 D_tricked_loss= tensor(1.0133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6285 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6285 D_fake_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6285 D_tricked_loss= tensor(1.0132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6286 D_real_loss= tensor(0.6107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6286 D_fake_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6286 D_tricked_loss= tensor(1.0061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6287 D_real_loss= tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6287 D_fake_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6287 D_tricked_loss= tensor(1.0012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6288 D_real_loss= tensor(0.6007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6288 D_fake_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6288 D_tricked_loss= tensor(1.0233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6289 D_real_loss= tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6289 D_fake_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6289 D_tricked_loss= tensor(1.0185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6290 D_real_loss= tensor(0.6110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6290 D_fake_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6290 D_tricked_loss= tensor(1.0477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6291 D_real_loss= tensor(0.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6291 D_fake_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6291 D_tricked_loss= tensor(1.0088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6292 D_real_loss= tensor(0.6209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6292 D_fake_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6292 D_tricked_loss= tensor(1.0173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6293 D_real_loss= tensor(0.6137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6293 D_fake_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6293 D_tricked_loss= tensor(1.0034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6294 D_real_loss= tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6294 D_fake_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6294 D_tricked_loss= tensor(1.0138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6295 D_real_loss= tensor(0.6307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6295 D_fake_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6295 D_tricked_loss= tensor(0.9950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6296 D_real_loss= tensor(0.6046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6296 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6296 D_tricked_loss= tensor(1.0323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6297 D_real_loss= tensor(0.6001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6297 D_fake_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6297 D_tricked_loss= tensor(1.0249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6298 D_real_loss= tensor(0.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6298 D_fake_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6298 D_tricked_loss= tensor(1.0296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6299 D_real_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6299 D_fake_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6299 D_tricked_loss= tensor(1.0253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6300 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6300 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6300 D_tricked_loss= tensor(1.0839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6301 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6301 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6301 D_tricked_loss= tensor(1.0358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6302 D_real_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6302 D_fake_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6302 D_tricked_loss= tensor(1.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6303 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6303 D_fake_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6303 D_tricked_loss= tensor(1.0434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6304 D_real_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6304 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6304 D_tricked_loss= tensor(1.0848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6305 D_real_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6305 D_fake_loss= tensor(0.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6305 D_tricked_loss= tensor(1.0179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6306 D_real_loss= tensor(0.6177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6306 D_fake_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6306 D_tricked_loss= tensor(1.0453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6307 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6307 D_fake_loss= tensor(0.6187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6307 D_tricked_loss= tensor(1.0041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6308 D_real_loss= tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6308 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6308 D_tricked_loss= tensor(1.0337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6309 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6309 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6309 D_tricked_loss= tensor(0.9853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6310 D_real_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6310 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6310 D_tricked_loss= tensor(1.0265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6311 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6311 D_fake_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6311 D_tricked_loss= tensor(1.0278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6312 D_real_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6312 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6312 D_tricked_loss= tensor(1.0584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6313 D_real_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6313 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6313 D_tricked_loss= tensor(1.0500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6314 D_real_loss= tensor(0.6138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6314 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6314 D_tricked_loss= tensor(1.0550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6315 D_real_loss= tensor(0.6093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6315 D_fake_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6315 D_tricked_loss= tensor(1.0650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6316 D_real_loss= tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6316 D_fake_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6316 D_tricked_loss= tensor(1.0606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6317 D_real_loss= tensor(0.6205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6317 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6317 D_tricked_loss= tensor(1.0434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6318 D_real_loss= tensor(0.6008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6318 D_fake_loss= tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6318 D_tricked_loss= tensor(1.0333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6319 D_real_loss= tensor(0.6258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6319 D_fake_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6319 D_tricked_loss= tensor(1.0688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6320 D_real_loss= tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6320 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6320 D_tricked_loss= tensor(1.0593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6321 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6321 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6321 D_tricked_loss= tensor(1.0321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6322 D_real_loss= tensor(0.5978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6322 D_fake_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6322 D_tricked_loss= tensor(1.0354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6323 D_real_loss= tensor(0.6161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6323 D_fake_loss= tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6323 D_tricked_loss= tensor(1.0310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6324 D_real_loss= tensor(0.6088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6324 D_fake_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6324 D_tricked_loss= tensor(1.0085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6325 D_real_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6325 D_fake_loss= tensor(0.6088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6325 D_tricked_loss= tensor(0.9865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6326 D_real_loss= tensor(0.6066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6326 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6326 D_tricked_loss= tensor(1.0572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6327 D_real_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6327 D_fake_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6327 D_tricked_loss= tensor(0.9993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6328 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6328 D_fake_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6328 D_tricked_loss= tensor(1.0365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6329 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6329 D_fake_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6329 D_tricked_loss= tensor(1.0261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6330 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6330 D_fake_loss= tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6330 D_tricked_loss= tensor(1.0285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6331 D_real_loss= tensor(0.5966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6331 D_fake_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6331 D_tricked_loss= tensor(1.0531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6332 D_real_loss= tensor(0.6077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6332 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6332 D_tricked_loss= tensor(1.0717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6333 D_real_loss= tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6333 D_fake_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6333 D_tricked_loss= tensor(1.0665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6334 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6334 D_fake_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6334 D_tricked_loss= tensor(1.0134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6335 D_real_loss= tensor(0.5966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6335 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6335 D_tricked_loss= tensor(1.0637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6336 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6336 D_fake_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6336 D_tricked_loss= tensor(1.0387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6337 D_real_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6337 D_fake_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6337 D_tricked_loss= tensor(1.0445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6338 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6338 D_fake_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6338 D_tricked_loss= tensor(1.0264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6339 D_real_loss= tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6339 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6339 D_tricked_loss= tensor(1.0498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6340 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6340 D_fake_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6340 D_tricked_loss= tensor(1.0207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6341 D_real_loss= tensor(0.6156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6341 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6341 D_tricked_loss= tensor(1.0530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6342 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6342 D_fake_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6342 D_tricked_loss= tensor(1.0491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6343 D_real_loss= tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6343 D_fake_loss= tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6343 D_tricked_loss= tensor(1.0990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6344 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6344 D_fake_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6344 D_tricked_loss= tensor(1.0659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6345 D_real_loss= tensor(0.6203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6345 D_fake_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6345 D_tricked_loss= tensor(1.0428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6346 D_real_loss= tensor(0.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6346 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6346 D_tricked_loss= tensor(0.9991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6347 D_real_loss= tensor(0.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6347 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6347 D_tricked_loss= tensor(1.0165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6348 D_real_loss= tensor(0.6106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6348 D_fake_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6348 D_tricked_loss= tensor(1.0247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6349 D_real_loss= tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6349 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6349 D_tricked_loss= tensor(1.0109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6350 D_real_loss= tensor(0.6305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6350 D_fake_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6350 D_tricked_loss= tensor(1.0256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6351 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6351 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6351 D_tricked_loss= tensor(1.0514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6352 D_real_loss= tensor(0.6181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6352 D_fake_loss= tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6352 D_tricked_loss= tensor(1.0249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6353 D_real_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6353 D_fake_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6353 D_tricked_loss= tensor(1.0148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6354 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6354 D_fake_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6354 D_tricked_loss= tensor(0.9922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6355 D_real_loss= tensor(0.6111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6355 D_fake_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6355 D_tricked_loss= tensor(1.0573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6356 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6356 D_fake_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6356 D_tricked_loss= tensor(1.0610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6357 D_real_loss= tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6357 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6357 D_tricked_loss= tensor(1.0378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6358 D_real_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6358 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6358 D_tricked_loss= tensor(1.0324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6359 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6359 D_fake_loss= tensor(0.6130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6359 D_tricked_loss= tensor(1.0126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6360 D_real_loss= tensor(0.5957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6360 D_fake_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6360 D_tricked_loss= tensor(1.0720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6361 D_real_loss= tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6361 D_fake_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6361 D_tricked_loss= tensor(1.0636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6362 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6362 D_fake_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6362 D_tricked_loss= tensor(1.0121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6363 D_real_loss= tensor(0.6159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6363 D_fake_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6363 D_tricked_loss= tensor(1.0181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6364 D_real_loss= tensor(0.6008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6364 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6364 D_tricked_loss= tensor(0.9828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6365 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6365 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6365 D_tricked_loss= tensor(1.0382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6366 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6366 D_fake_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6366 D_tricked_loss= tensor(1.0508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6367 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6367 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6367 D_tricked_loss= tensor(1.0504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6368 D_real_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6368 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6368 D_tricked_loss= tensor(1.0406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6369 D_real_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6369 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6369 D_tricked_loss= tensor(1.0643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6370 D_real_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6370 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6370 D_tricked_loss= tensor(1.0454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6371 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6371 D_fake_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6371 D_tricked_loss= tensor(1.0307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6372 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6372 D_fake_loss= tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6372 D_tricked_loss= tensor(1.0540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6373 D_real_loss= tensor(0.5994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6373 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6373 D_tricked_loss= tensor(1.0992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6374 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6374 D_fake_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6374 D_tricked_loss= tensor(1.0809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6375 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6375 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6375 D_tricked_loss= tensor(1.1066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6376 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6376 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6376 D_tricked_loss= tensor(1.0851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6377 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6377 D_fake_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6377 D_tricked_loss= tensor(1.1185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6378 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6378 D_fake_loss= tensor(0.6104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6378 D_tricked_loss= tensor(1.0283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6379 D_real_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6379 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6379 D_tricked_loss= tensor(1.0898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6380 D_real_loss= tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6380 D_fake_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6380 D_tricked_loss= tensor(1.0495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6381 D_real_loss= tensor(0.6057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6381 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6381 D_tricked_loss= tensor(1.0657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6382 D_real_loss= tensor(0.6163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6382 D_fake_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6382 D_tricked_loss= tensor(1.0394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6383 D_real_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6383 D_fake_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6383 D_tricked_loss= tensor(1.0330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6384 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6384 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6384 D_tricked_loss= tensor(1.0231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6385 D_real_loss= tensor(0.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6385 D_fake_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6385 D_tricked_loss= tensor(1.0942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6386 D_real_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6386 D_fake_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6386 D_tricked_loss= tensor(1.0212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6387 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6387 D_fake_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6387 D_tricked_loss= tensor(1.0302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6388 D_real_loss= tensor(0.5994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6388 D_fake_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6388 D_tricked_loss= tensor(1.0390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6389 D_real_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6389 D_fake_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6389 D_tricked_loss= tensor(1.0476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6390 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6390 D_fake_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6390 D_tricked_loss= tensor(1.0491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6391 D_real_loss= tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6391 D_fake_loss= tensor(0.6099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6391 D_tricked_loss= tensor(1.0672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6392 D_real_loss= tensor(0.6112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6392 D_fake_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6392 D_tricked_loss= tensor(1.0725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6393 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6393 D_fake_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6393 D_tricked_loss= tensor(1.0311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6394 D_real_loss= tensor(0.6110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6394 D_fake_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6394 D_tricked_loss= tensor(1.0129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6395 D_real_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6395 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6395 D_tricked_loss= tensor(1.0121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6396 D_real_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6396 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6396 D_tricked_loss= tensor(1.0547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6397 D_real_loss= tensor(0.6123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6397 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6397 D_tricked_loss= tensor(1.0078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6398 D_real_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6398 D_fake_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6398 D_tricked_loss= tensor(1.0427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6399 D_real_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6399 D_fake_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6399 D_tricked_loss= tensor(1.0329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6400 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6400 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6400 D_tricked_loss= tensor(1.0633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6401 D_real_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6401 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6401 D_tricked_loss= tensor(1.0590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6402 D_real_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6402 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6402 D_tricked_loss= tensor(1.0345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6403 D_real_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6403 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6403 D_tricked_loss= tensor(1.0719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6404 D_real_loss= tensor(0.6090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6404 D_fake_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6404 D_tricked_loss= tensor(1.1108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6405 D_real_loss= tensor(0.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6405 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6405 D_tricked_loss= tensor(1.0581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6406 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6406 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6406 D_tricked_loss= tensor(1.0641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6407 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6407 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6407 D_tricked_loss= tensor(1.0701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6408 D_real_loss= tensor(0.6062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6408 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6408 D_tricked_loss= tensor(1.0741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6409 D_real_loss= tensor(0.6123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6409 D_fake_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6409 D_tricked_loss= tensor(1.0278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6410 D_real_loss= tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6410 D_fake_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6410 D_tricked_loss= tensor(1.0025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6411 D_real_loss= tensor(0.6224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6411 D_fake_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6411 D_tricked_loss= tensor(1.0277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6412 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6412 D_fake_loss= tensor(0.6115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6412 D_tricked_loss= tensor(1.0302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6413 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6413 D_fake_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6413 D_tricked_loss= tensor(0.9985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6414 D_real_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6414 D_fake_loss= tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6414 D_tricked_loss= tensor(1.0113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6415 D_real_loss= tensor(0.6151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6415 D_fake_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6415 D_tricked_loss= tensor(0.9977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6416 D_real_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6416 D_fake_loss= tensor(0.6120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6416 D_tricked_loss= tensor(0.9657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6417 D_real_loss= tensor(0.6120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6417 D_fake_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6417 D_tricked_loss= tensor(1.0164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6418 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6418 D_fake_loss= tensor(0.6161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6418 D_tricked_loss= tensor(0.9921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6419 D_real_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6419 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6419 D_tricked_loss= tensor(1.0178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6420 D_real_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6420 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6420 D_tricked_loss= tensor(0.9978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6421 D_real_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6421 D_fake_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6421 D_tricked_loss= tensor(1.0333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6422 D_real_loss= tensor(0.6109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6422 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6422 D_tricked_loss= tensor(1.0698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6423 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6423 D_fake_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6423 D_tricked_loss= tensor(1.0387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6424 D_real_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6424 D_fake_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6424 D_tricked_loss= tensor(1.0475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6425 D_real_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6425 D_fake_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6425 D_tricked_loss= tensor(1.0382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6426 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6426 D_fake_loss= tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6426 D_tricked_loss= tensor(1.0557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6427 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6427 D_fake_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6427 D_tricked_loss= tensor(1.0398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6428 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6428 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6428 D_tricked_loss= tensor(1.0498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6429 D_real_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6429 D_fake_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6429 D_tricked_loss= tensor(1.0306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6430 D_real_loss= tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6430 D_fake_loss= tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6430 D_tricked_loss= tensor(1.0477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6431 D_real_loss= tensor(0.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6431 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6431 D_tricked_loss= tensor(1.0510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6432 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6432 D_fake_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6432 D_tricked_loss= tensor(1.0324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6433 D_real_loss= tensor(0.6090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6433 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6433 D_tricked_loss= tensor(1.0250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6434 D_real_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6434 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6434 D_tricked_loss= tensor(1.0053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6435 D_real_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6435 D_fake_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6435 D_tricked_loss= tensor(1.0399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6436 D_real_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6436 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6436 D_tricked_loss= tensor(1.0497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6437 D_real_loss= tensor(0.6181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6437 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6437 D_tricked_loss= tensor(1.0574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6438 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6438 D_fake_loss= tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6438 D_tricked_loss= tensor(1.0159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6439 D_real_loss= tensor(0.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6439 D_fake_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6439 D_tricked_loss= tensor(1.0450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6440 D_real_loss= tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6440 D_fake_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6440 D_tricked_loss= tensor(1.0364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6441 D_real_loss= tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6441 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6441 D_tricked_loss= tensor(1.0628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6442 D_real_loss= tensor(0.6146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6442 D_fake_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6442 D_tricked_loss= tensor(1.0438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6443 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6443 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6443 D_tricked_loss= tensor(1.0436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6444 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6444 D_fake_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6444 D_tricked_loss= tensor(1.0311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6445 D_real_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6445 D_fake_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6445 D_tricked_loss= tensor(1.0420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6446 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6446 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6446 D_tricked_loss= tensor(1.0470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6447 D_real_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6447 D_fake_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6447 D_tricked_loss= tensor(1.0383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6448 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6448 D_fake_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6448 D_tricked_loss= tensor(1.0256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6449 D_real_loss= tensor(0.5976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6449 D_fake_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6449 D_tricked_loss= tensor(1.0739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6450 D_real_loss= tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6450 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6450 D_tricked_loss= tensor(1.0522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6451 D_real_loss= tensor(0.6079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6451 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6451 D_tricked_loss= tensor(1.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6452 D_real_loss= tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6452 D_fake_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6452 D_tricked_loss= tensor(1.0317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6453 D_real_loss= tensor(0.6261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6453 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6453 D_tricked_loss= tensor(1.0473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6454 D_real_loss= tensor(0.6040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6454 D_fake_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6454 D_tricked_loss= tensor(1.0039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6455 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6455 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6455 D_tricked_loss= tensor(1.0210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6456 D_real_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6456 D_fake_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6456 D_tricked_loss= tensor(1.0224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6457 D_real_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6457 D_fake_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6457 D_tricked_loss= tensor(1.0339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6458 D_real_loss= tensor(0.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6458 D_fake_loss= tensor(0.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6458 D_tricked_loss= tensor(1.0285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6459 D_real_loss= tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6459 D_fake_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6459 D_tricked_loss= tensor(1.0066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6460 D_real_loss= tensor(0.6067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6460 D_fake_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6460 D_tricked_loss= tensor(1.0230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6461 D_real_loss= tensor(0.6133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6461 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6461 D_tricked_loss= tensor(1.0324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6462 D_real_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6462 D_fake_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6462 D_tricked_loss= tensor(0.9979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6463 D_real_loss= tensor(0.6154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6463 D_fake_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6463 D_tricked_loss= tensor(1.0475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6464 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6464 D_fake_loss= tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6464 D_tricked_loss= tensor(1.0288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6465 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6465 D_fake_loss= tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6465 D_tricked_loss= tensor(0.9908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6466 D_real_loss= tensor(0.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6466 D_fake_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6466 D_tricked_loss= tensor(1.0368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6467 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6467 D_fake_loss= tensor(0.5978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6467 D_tricked_loss= tensor(1.0531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6468 D_real_loss= tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6468 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6468 D_tricked_loss= tensor(1.0478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6469 D_real_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6469 D_fake_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6469 D_tricked_loss= tensor(1.0086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6470 D_real_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6470 D_fake_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6470 D_tricked_loss= tensor(1.0537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6471 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6471 D_fake_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6471 D_tricked_loss= tensor(1.0526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6472 D_real_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6472 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6472 D_tricked_loss= tensor(1.1081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6473 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6473 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6473 D_tricked_loss= tensor(1.0491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6474 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6474 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6474 D_tricked_loss= tensor(1.0520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6475 D_real_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6475 D_fake_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6475 D_tricked_loss= tensor(1.0739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6476 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6476 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6476 D_tricked_loss= tensor(1.0296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6477 D_real_loss= tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6477 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6477 D_tricked_loss= tensor(1.1006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6478 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6478 D_fake_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6478 D_tricked_loss= tensor(1.0407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6479 D_real_loss= tensor(0.6143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6479 D_fake_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6479 D_tricked_loss= tensor(1.1113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6480 D_real_loss= tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6480 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6480 D_tricked_loss= tensor(1.0712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6481 D_real_loss= tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6481 D_fake_loss= tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6481 D_tricked_loss= tensor(1.0267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6482 D_real_loss= tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6482 D_fake_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6482 D_tricked_loss= tensor(1.0112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6483 D_real_loss= tensor(0.6087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6483 D_fake_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6483 D_tricked_loss= tensor(1.0370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6484 D_real_loss= tensor(0.6187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6484 D_fake_loss= tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6484 D_tricked_loss= tensor(1.0461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6485 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6485 D_fake_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6485 D_tricked_loss= tensor(1.0174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6486 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6486 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6486 D_tricked_loss= tensor(1.0235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6487 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6487 D_fake_loss= tensor(0.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6487 D_tricked_loss= tensor(1.0321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6488 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6488 D_fake_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6488 D_tricked_loss= tensor(1.0516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6489 D_real_loss= tensor(0.6124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6489 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6489 D_tricked_loss= tensor(1.0079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6490 D_real_loss= tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6490 D_fake_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6490 D_tricked_loss= tensor(1.0340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6491 D_real_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6491 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6491 D_tricked_loss= tensor(1.0452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6492 D_real_loss= tensor(0.6122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6492 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6492 D_tricked_loss= tensor(1.0338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6493 D_real_loss= tensor(0.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6493 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6493 D_tricked_loss= tensor(1.0224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6494 D_real_loss= tensor(0.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6494 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6494 D_tricked_loss= tensor(0.9937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6495 D_real_loss= tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6495 D_fake_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6495 D_tricked_loss= tensor(1.0123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6496 D_real_loss= tensor(0.6257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6496 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6496 D_tricked_loss= tensor(1.0149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6497 D_real_loss= tensor(0.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6497 D_fake_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6497 D_tricked_loss= tensor(1.0036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6498 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6498 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6498 D_tricked_loss= tensor(1.0262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6499 D_real_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6499 D_fake_loss= tensor(0.6187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6499 D_tricked_loss= tensor(1.0136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6500 D_real_loss= tensor(0.6063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6500 D_fake_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6500 D_tricked_loss= tensor(1.0204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6501 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6501 D_fake_loss= tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6501 D_tricked_loss= tensor(1.0396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6502 D_real_loss= tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6502 D_fake_loss= tensor(0.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6502 D_tricked_loss= tensor(0.9859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6503 D_real_loss= tensor(0.6141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6503 D_fake_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6503 D_tricked_loss= tensor(1.0382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6504 D_real_loss= tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6504 D_fake_loss= tensor(0.6228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6504 D_tricked_loss= tensor(0.9926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6505 D_real_loss= tensor(0.6154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6505 D_fake_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6505 D_tricked_loss= tensor(1.0280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6506 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6506 D_fake_loss= tensor(0.6105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6506 D_tricked_loss= tensor(0.9932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6507 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6507 D_fake_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6507 D_tricked_loss= tensor(1.0546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6508 D_real_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6508 D_fake_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6508 D_tricked_loss= tensor(1.0306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6509 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6509 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6509 D_tricked_loss= tensor(1.0544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6510 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6510 D_fake_loss= tensor(0.6087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6510 D_tricked_loss= tensor(1.0259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6511 D_real_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6511 D_fake_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6511 D_tricked_loss= tensor(1.0657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6512 D_real_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6512 D_fake_loss= tensor(0.6219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6512 D_tricked_loss= tensor(1.0284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6513 D_real_loss= tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6513 D_fake_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6513 D_tricked_loss= tensor(1.0561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6514 D_real_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6514 D_fake_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6514 D_tricked_loss= tensor(1.0251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6515 D_real_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6515 D_fake_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6515 D_tricked_loss= tensor(1.0343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6516 D_real_loss= tensor(0.6252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6516 D_fake_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6516 D_tricked_loss= tensor(1.0427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6517 D_real_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6517 D_fake_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6517 D_tricked_loss= tensor(1.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6518 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6518 D_fake_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6518 D_tricked_loss= tensor(1.0472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6519 D_real_loss= tensor(0.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6519 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6519 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6520 D_real_loss= tensor(0.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6520 D_fake_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6520 D_tricked_loss= tensor(1.0461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6521 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6521 D_fake_loss= tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6521 D_tricked_loss= tensor(1.0432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6522 D_real_loss= tensor(0.6218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6522 D_fake_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6522 D_tricked_loss= tensor(1.0489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6523 D_real_loss= tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6523 D_fake_loss= tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6523 D_tricked_loss= tensor(0.9936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6524 D_real_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6524 D_fake_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6524 D_tricked_loss= tensor(1.0247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6525 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6525 D_fake_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6525 D_tricked_loss= tensor(1.0263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6526 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6526 D_fake_loss= tensor(0.6137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6526 D_tricked_loss= tensor(0.9836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6527 D_real_loss= tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6527 D_fake_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6527 D_tricked_loss= tensor(1.0086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6528 D_real_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6528 D_fake_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6528 D_tricked_loss= tensor(1.0699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6529 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6529 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6529 D_tricked_loss= tensor(1.0115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6530 D_real_loss= tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6530 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6530 D_tricked_loss= tensor(1.0315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6531 D_real_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6531 D_fake_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6531 D_tricked_loss= tensor(1.0279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6532 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6532 D_fake_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6532 D_tricked_loss= tensor(1.0503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6533 D_real_loss= tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6533 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6533 D_tricked_loss= tensor(1.0620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6534 D_real_loss= tensor(0.6111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6534 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6534 D_tricked_loss= tensor(1.0715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6535 D_real_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6535 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6535 D_tricked_loss= tensor(1.0103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6536 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6536 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6536 D_tricked_loss= tensor(1.0340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6537 D_real_loss= tensor(0.6066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6537 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6537 D_tricked_loss= tensor(1.0648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6538 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6538 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6538 D_tricked_loss= tensor(1.0605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6539 D_real_loss= tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6539 D_fake_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6539 D_tricked_loss= tensor(1.0503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6540 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6540 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6540 D_tricked_loss= tensor(1.0503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6541 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6541 D_fake_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6541 D_tricked_loss= tensor(1.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6542 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6542 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6542 D_tricked_loss= tensor(1.0904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6543 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6543 D_fake_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6543 D_tricked_loss= tensor(1.0880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6544 D_real_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6544 D_fake_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6544 D_tricked_loss= tensor(1.0427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6545 D_real_loss= tensor(0.6067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6545 D_fake_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6545 D_tricked_loss= tensor(1.0324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6546 D_real_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6546 D_fake_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6546 D_tricked_loss= tensor(1.0284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6547 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6547 D_fake_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6547 D_tricked_loss= tensor(1.0158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6548 D_real_loss= tensor(0.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6548 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6548 D_tricked_loss= tensor(1.0553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6549 D_real_loss= tensor(0.6040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6549 D_fake_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6549 D_tricked_loss= tensor(1.0526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6550 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6550 D_fake_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6550 D_tricked_loss= tensor(1.0325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6551 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6551 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6551 D_tricked_loss= tensor(1.0194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6552 D_real_loss= tensor(0.6112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6552 D_fake_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6552 D_tricked_loss= tensor(1.0502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6553 D_real_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6553 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6553 D_tricked_loss= tensor(1.0106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6554 D_real_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6554 D_fake_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6554 D_tricked_loss= tensor(1.0657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6555 D_real_loss= tensor(0.6129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6555 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6555 D_tricked_loss= tensor(1.0053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6556 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6556 D_fake_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6556 D_tricked_loss= tensor(1.0082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6557 D_real_loss= tensor(0.6177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6557 D_fake_loss= tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6557 D_tricked_loss= tensor(1.0008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6558 D_real_loss= tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6558 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6558 D_tricked_loss= tensor(0.9933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6559 D_real_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6559 D_fake_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6559 D_tricked_loss= tensor(1.0337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6560 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6560 D_fake_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6560 D_tricked_loss= tensor(1.0510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6561 D_real_loss= tensor(0.5978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6561 D_fake_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6561 D_tricked_loss= tensor(1.0469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6562 D_real_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6562 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6562 D_tricked_loss= tensor(1.0512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6563 D_real_loss= tensor(0.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6563 D_fake_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6563 D_tricked_loss= tensor(1.0375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6564 D_real_loss= tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6564 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6564 D_tricked_loss= tensor(1.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6565 D_real_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6565 D_fake_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6565 D_tricked_loss= tensor(1.0619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6566 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6566 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6566 D_tricked_loss= tensor(1.0740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6567 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6567 D_fake_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6567 D_tricked_loss= tensor(1.0944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6568 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6568 D_fake_loss= tensor(0.5946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6568 D_tricked_loss= tensor(1.0312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6569 D_real_loss= tensor(0.6150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6569 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6569 D_tricked_loss= tensor(1.0410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6570 D_real_loss= tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6570 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6570 D_tricked_loss= tensor(1.0525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6571 D_real_loss= tensor(0.6310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6571 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6571 D_tricked_loss= tensor(1.0537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6572 D_real_loss= tensor(0.6021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6572 D_fake_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6572 D_tricked_loss= tensor(1.0127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6573 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6573 D_fake_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6573 D_tricked_loss= tensor(1.0272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6574 D_real_loss= tensor(0.6133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6574 D_fake_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6574 D_tricked_loss= tensor(1.0513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6575 D_real_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6575 D_fake_loss= tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6575 D_tricked_loss= tensor(1.0406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6576 D_real_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6576 D_fake_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6576 D_tricked_loss= tensor(1.0036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6577 D_real_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6577 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6577 D_tricked_loss= tensor(1.0537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6578 D_real_loss= tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6578 D_fake_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6578 D_tricked_loss= tensor(1.0297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6579 D_real_loss= tensor(0.6122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6579 D_fake_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6579 D_tricked_loss= tensor(1.0359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6580 D_real_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6580 D_fake_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6580 D_tricked_loss= tensor(0.9938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6581 D_real_loss= tensor(0.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6581 D_fake_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6581 D_tricked_loss= tensor(1.0426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6582 D_real_loss= tensor(0.6219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6582 D_fake_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6582 D_tricked_loss= tensor(1.0673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6583 D_real_loss= tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6583 D_fake_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6583 D_tricked_loss= tensor(1.0250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6584 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6584 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6584 D_tricked_loss= tensor(1.0325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6585 D_real_loss= tensor(0.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6585 D_fake_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6585 D_tricked_loss= tensor(1.0158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6586 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6586 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6586 D_tricked_loss= tensor(1.0163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6587 D_real_loss= tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6587 D_fake_loss= tensor(0.5999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6587 D_tricked_loss= tensor(1.0204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6588 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6588 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6588 D_tricked_loss= tensor(1.0458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6589 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6589 D_fake_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6589 D_tricked_loss= tensor(1.0410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6590 D_real_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6590 D_fake_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6590 D_tricked_loss= tensor(1.0590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6591 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6591 D_fake_loss= tensor(0.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6591 D_tricked_loss= tensor(1.0041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6592 D_real_loss= tensor(0.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6592 D_fake_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6592 D_tricked_loss= tensor(1.0263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6593 D_real_loss= tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6593 D_fake_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6593 D_tricked_loss= tensor(1.0471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6594 D_real_loss= tensor(0.6074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6594 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6594 D_tricked_loss= tensor(1.0867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6595 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6595 D_fake_loss= tensor(0.6226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6595 D_tricked_loss= tensor(1.0194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6596 D_real_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6596 D_fake_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6596 D_tricked_loss= tensor(1.0089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6597 D_real_loss= tensor(0.6135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6597 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6597 D_tricked_loss= tensor(1.0184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6598 D_real_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6598 D_fake_loss= tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6598 D_tricked_loss= tensor(1.0159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6599 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6599 D_fake_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6599 D_tricked_loss= tensor(1.0155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6600 D_real_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6600 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6600 D_tricked_loss= tensor(1.0590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6601 D_real_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6601 D_fake_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6601 D_tricked_loss= tensor(1.0265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6602 D_real_loss= tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6602 D_fake_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6602 D_tricked_loss= tensor(1.0303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6603 D_real_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6603 D_fake_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6603 D_tricked_loss= tensor(1.0579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6604 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6604 D_fake_loss= tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6604 D_tricked_loss= tensor(1.0534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6605 D_real_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6605 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6605 D_tricked_loss= tensor(1.0436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6606 D_real_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6606 D_fake_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6606 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6607 D_real_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6607 D_fake_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6607 D_tricked_loss= tensor(1.0455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6608 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6608 D_fake_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6608 D_tricked_loss= tensor(1.0986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6609 D_real_loss= tensor(0.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6609 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6609 D_tricked_loss= tensor(1.0598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6610 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6610 D_fake_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6610 D_tricked_loss= tensor(1.0265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6611 D_real_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6611 D_fake_loss= tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6611 D_tricked_loss= tensor(1.0821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6612 D_real_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6612 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6612 D_tricked_loss= tensor(1.0612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6613 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6613 D_fake_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6613 D_tricked_loss= tensor(1.0458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6614 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6614 D_fake_loss= tensor(0.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6614 D_tricked_loss= tensor(1.0222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6615 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6615 D_fake_loss= tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6615 D_tricked_loss= tensor(1.0651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6616 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6616 D_fake_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6616 D_tricked_loss= tensor(1.0490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6617 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6617 D_fake_loss= tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6617 D_tricked_loss= tensor(1.0525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6618 D_real_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6618 D_fake_loss= tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6618 D_tricked_loss= tensor(1.0277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6619 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6619 D_fake_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6619 D_tricked_loss= tensor(1.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6620 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6620 D_fake_loss= tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6620 D_tricked_loss= tensor(1.0383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6621 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6621 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6621 D_tricked_loss= tensor(1.0658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6622 D_real_loss= tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6622 D_fake_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6622 D_tricked_loss= tensor(1.0418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6623 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6623 D_fake_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6623 D_tricked_loss= tensor(1.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6624 D_real_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6624 D_fake_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6624 D_tricked_loss= tensor(1.0266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6625 D_real_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6625 D_fake_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6625 D_tricked_loss= tensor(1.0432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6626 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6626 D_fake_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6626 D_tricked_loss= tensor(1.0481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6627 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6627 D_fake_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6627 D_tricked_loss= tensor(1.0570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6628 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6628 D_fake_loss= tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6628 D_tricked_loss= tensor(1.0442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6629 D_real_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6629 D_fake_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6629 D_tricked_loss= tensor(1.0517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6630 D_real_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6630 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6630 D_tricked_loss= tensor(1.0401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6631 D_real_loss= tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6631 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6631 D_tricked_loss= tensor(1.0936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6632 D_real_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6632 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6632 D_tricked_loss= tensor(1.0075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6633 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6633 D_fake_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6633 D_tricked_loss= tensor(1.0048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6634 D_real_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6634 D_fake_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6634 D_tricked_loss= tensor(1.0451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6635 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6635 D_fake_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6635 D_tricked_loss= tensor(1.0465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6636 D_real_loss= tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6636 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6636 D_tricked_loss= tensor(1.0671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6637 D_real_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6637 D_fake_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6637 D_tricked_loss= tensor(1.0582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6638 D_real_loss= tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6638 D_fake_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6638 D_tricked_loss= tensor(1.0606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6639 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6639 D_fake_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6639 D_tricked_loss= tensor(1.0470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6640 D_real_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6640 D_fake_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6640 D_tricked_loss= tensor(1.0442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6641 D_real_loss= tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6641 D_fake_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6641 D_tricked_loss= tensor(1.0427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6642 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6642 D_fake_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6642 D_tricked_loss= tensor(1.0425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6643 D_real_loss= tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6643 D_fake_loss= tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6643 D_tricked_loss= tensor(1.0213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6644 D_real_loss= tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6644 D_fake_loss= tensor(0.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6644 D_tricked_loss= tensor(1.0449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6645 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6645 D_fake_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6645 D_tricked_loss= tensor(1.0166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6646 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6646 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6646 D_tricked_loss= tensor(1.0602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6647 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6647 D_fake_loss= tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6647 D_tricked_loss= tensor(1.0360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6648 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6648 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6648 D_tricked_loss= tensor(1.0604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6649 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6649 D_fake_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6649 D_tricked_loss= tensor(1.0550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6650 D_real_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6650 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6650 D_tricked_loss= tensor(1.0643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6651 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6651 D_fake_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6651 D_tricked_loss= tensor(1.0760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6652 D_real_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6652 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6652 D_tricked_loss= tensor(1.0617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6653 D_real_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6653 D_fake_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6653 D_tricked_loss= tensor(1.0971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6654 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6654 D_fake_loss= tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6654 D_tricked_loss= tensor(1.0961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6655 D_real_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6655 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6655 D_tricked_loss= tensor(1.0753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6656 D_real_loss= tensor(0.6001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6656 D_fake_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6656 D_tricked_loss= tensor(1.0435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6657 D_real_loss= tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6657 D_fake_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6657 D_tricked_loss= tensor(1.0417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6658 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6658 D_fake_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6658 D_tricked_loss= tensor(1.0036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6659 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6659 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6659 D_tricked_loss= tensor(1.0681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6660 D_real_loss= tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6660 D_fake_loss= tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6660 D_tricked_loss= tensor(1.0597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6661 D_real_loss= tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6661 D_fake_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6661 D_tricked_loss= tensor(1.0668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6662 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6662 D_fake_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6662 D_tricked_loss= tensor(1.0574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6663 D_real_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6663 D_fake_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6663 D_tricked_loss= tensor(1.0296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6664 D_real_loss= tensor(0.6003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6664 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6664 D_tricked_loss= tensor(1.0273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6665 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6665 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6665 D_tricked_loss= tensor(1.0538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6666 D_real_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6666 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6666 D_tricked_loss= tensor(1.0896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6667 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6667 D_fake_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6667 D_tricked_loss= tensor(1.0761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6668 D_real_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6668 D_fake_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6668 D_tricked_loss= tensor(1.0762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6669 D_real_loss= tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6669 D_fake_loss= tensor(0.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6669 D_tricked_loss= tensor(1.0735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6670 D_real_loss= tensor(0.6032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6670 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6670 D_tricked_loss= tensor(1.0794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6671 D_real_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6671 D_fake_loss= tensor(0.5972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6671 D_tricked_loss= tensor(1.0432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6672 D_real_loss= tensor(0.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6672 D_fake_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6672 D_tricked_loss= tensor(1.0513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6673 D_real_loss= tensor(0.5923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6673 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6673 D_tricked_loss= tensor(1.0147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6674 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6674 D_fake_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6674 D_tricked_loss= tensor(1.0518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6675 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6675 D_fake_loss= tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6675 D_tricked_loss= tensor(1.0197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6676 D_real_loss= tensor(0.6041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6676 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6676 D_tricked_loss= tensor(1.0676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6677 D_real_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6677 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6677 D_tricked_loss= tensor(1.0665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6678 D_real_loss= tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6678 D_fake_loss= tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6678 D_tricked_loss= tensor(1.0868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6679 D_real_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6679 D_fake_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6679 D_tricked_loss= tensor(1.0740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6680 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6680 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6680 D_tricked_loss= tensor(1.0410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6681 D_real_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6681 D_fake_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6681 D_tricked_loss= tensor(1.0799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6682 D_real_loss= tensor(0.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6682 D_fake_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6682 D_tricked_loss= tensor(1.0277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6683 D_real_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6683 D_fake_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6683 D_tricked_loss= tensor(1.0503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6684 D_real_loss= tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6684 D_fake_loss= tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6684 D_tricked_loss= tensor(1.0530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6685 D_real_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6685 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6685 D_tricked_loss= tensor(1.0723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6686 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6686 D_fake_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6686 D_tricked_loss= tensor(1.0060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6687 D_real_loss= tensor(0.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6687 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6687 D_tricked_loss= tensor(1.0441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6688 D_real_loss= tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6688 D_fake_loss= tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6688 D_tricked_loss= tensor(1.0352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6689 D_real_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6689 D_fake_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6689 D_tricked_loss= tensor(1.0626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6690 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6690 D_fake_loss= tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6690 D_tricked_loss= tensor(1.0606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6691 D_real_loss= tensor(0.6068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6691 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6691 D_tricked_loss= tensor(1.0187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6692 D_real_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6692 D_fake_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6692 D_tricked_loss= tensor(1.0043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6693 D_real_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6693 D_fake_loss= tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6693 D_tricked_loss= tensor(1.0515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6694 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6694 D_fake_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6694 D_tricked_loss= tensor(1.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6695 D_real_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6695 D_fake_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6695 D_tricked_loss= tensor(1.0342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6696 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6696 D_fake_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6696 D_tricked_loss= tensor(1.0173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6697 D_real_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6697 D_fake_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6697 D_tricked_loss= tensor(1.0383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6698 D_real_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6698 D_fake_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6698 D_tricked_loss= tensor(1.0321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6699 D_real_loss= tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6699 D_fake_loss= tensor(0.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6699 D_tricked_loss= tensor(1.0099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6700 D_real_loss= tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6700 D_fake_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6700 D_tricked_loss= tensor(1.0331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6701 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6701 D_fake_loss= tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6701 D_tricked_loss= tensor(1.0438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6702 D_real_loss= tensor(0.6171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6702 D_fake_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6702 D_tricked_loss= tensor(1.0790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6703 D_real_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6703 D_fake_loss= tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6703 D_tricked_loss= tensor(1.0414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6704 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6704 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6704 D_tricked_loss= tensor(1.0710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6705 D_real_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6705 D_fake_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6705 D_tricked_loss= tensor(1.0397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6706 D_real_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6706 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6706 D_tricked_loss= tensor(1.0415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6707 D_real_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6707 D_fake_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6707 D_tricked_loss= tensor(1.0159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6708 D_real_loss= tensor(0.6297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6708 D_fake_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6708 D_tricked_loss= tensor(1.0517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6709 D_real_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6709 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6709 D_tricked_loss= tensor(1.0558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6710 D_real_loss= tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6710 D_fake_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6710 D_tricked_loss= tensor(1.0611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6711 D_real_loss= tensor(0.6077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6711 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6711 D_tricked_loss= tensor(1.0534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6712 D_real_loss= tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6712 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6712 D_tricked_loss= tensor(1.0854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6713 D_real_loss= tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6713 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6713 D_tricked_loss= tensor(1.0628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6714 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6714 D_fake_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6714 D_tricked_loss= tensor(1.0351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6715 D_real_loss= tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6715 D_fake_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6715 D_tricked_loss= tensor(1.0491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6716 D_real_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6716 D_fake_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6716 D_tricked_loss= tensor(1.0307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6717 D_real_loss= tensor(0.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6717 D_fake_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6717 D_tricked_loss= tensor(1.0684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6718 D_real_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6718 D_fake_loss= tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6718 D_tricked_loss= tensor(1.0464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6719 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6719 D_fake_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6719 D_tricked_loss= tensor(1.0766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6720 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6720 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6720 D_tricked_loss= tensor(1.0520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6721 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6721 D_fake_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6721 D_tricked_loss= tensor(1.0634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6722 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6722 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6722 D_tricked_loss= tensor(1.0518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6723 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6723 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6723 D_tricked_loss= tensor(1.0775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6724 D_real_loss= tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6724 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6724 D_tricked_loss= tensor(1.0899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6725 D_real_loss= tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6725 D_fake_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6725 D_tricked_loss= tensor(1.0426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6726 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6726 D_fake_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6726 D_tricked_loss= tensor(1.0709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6727 D_real_loss= tensor(0.5956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6727 D_fake_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6727 D_tricked_loss= tensor(1.0606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6728 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6728 D_fake_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6728 D_tricked_loss= tensor(1.0667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6729 D_real_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6729 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6729 D_tricked_loss= tensor(1.0397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6730 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6730 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6730 D_tricked_loss= tensor(1.0799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6731 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6731 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6731 D_tricked_loss= tensor(1.0444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6732 D_real_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6732 D_fake_loss= tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6732 D_tricked_loss= tensor(1.0640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6733 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6733 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6733 D_tricked_loss= tensor(1.0521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6734 D_real_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6734 D_fake_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6734 D_tricked_loss= tensor(1.0560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6735 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6735 D_fake_loss= tensor(0.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6735 D_tricked_loss= tensor(1.0437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6736 D_real_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6736 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6736 D_tricked_loss= tensor(1.0873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6737 D_real_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6737 D_fake_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6737 D_tricked_loss= tensor(1.0492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6738 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6738 D_fake_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6738 D_tricked_loss= tensor(1.0659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6739 D_real_loss= tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6739 D_fake_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6739 D_tricked_loss= tensor(1.0264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6740 D_real_loss= tensor(0.6051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6740 D_fake_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6740 D_tricked_loss= tensor(1.0538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6741 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6741 D_fake_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6741 D_tricked_loss= tensor(1.0300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6742 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6742 D_fake_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6742 D_tricked_loss= tensor(1.0634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6743 D_real_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6743 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6743 D_tricked_loss= tensor(1.0321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6744 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6744 D_fake_loss= tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6744 D_tricked_loss= tensor(1.0635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6745 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6745 D_fake_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6745 D_tricked_loss= tensor(1.0365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6746 D_real_loss= tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6746 D_fake_loss= tensor(0.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6746 D_tricked_loss= tensor(1.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6747 D_real_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6747 D_fake_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6747 D_tricked_loss= tensor(1.0726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6748 D_real_loss= tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6748 D_fake_loss= tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6748 D_tricked_loss= tensor(1.0500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6749 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6749 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6749 D_tricked_loss= tensor(1.0396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6750 D_real_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6750 D_fake_loss= tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6750 D_tricked_loss= tensor(1.0244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6751 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6751 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6751 D_tricked_loss= tensor(1.0586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6752 D_real_loss= tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6752 D_fake_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6752 D_tricked_loss= tensor(1.0363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6753 D_real_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6753 D_fake_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6753 D_tricked_loss= tensor(1.0416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6754 D_real_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6754 D_fake_loss= tensor(0.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6754 D_tricked_loss= tensor(1.0723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6755 D_real_loss= tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6755 D_fake_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6755 D_tricked_loss= tensor(1.0635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6756 D_real_loss= tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6756 D_fake_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6756 D_tricked_loss= tensor(1.0525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6757 D_real_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6757 D_fake_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6757 D_tricked_loss= tensor(1.0389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6758 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6758 D_fake_loss= tensor(0.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6758 D_tricked_loss= tensor(1.0627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6759 D_real_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6759 D_fake_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6759 D_tricked_loss= tensor(1.0557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6760 D_real_loss= tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6760 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6760 D_tricked_loss= tensor(1.1389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6761 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6761 D_fake_loss= tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6761 D_tricked_loss= tensor(1.0749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6762 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6762 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6762 D_tricked_loss= tensor(1.0636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6763 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6763 D_fake_loss= tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6763 D_tricked_loss= tensor(1.0463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6764 D_real_loss= tensor(0.6048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6764 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6764 D_tricked_loss= tensor(1.0634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6765 D_real_loss= tensor(0.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6765 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6765 D_tricked_loss= tensor(1.0974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6766 D_real_loss= tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6766 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6766 D_tricked_loss= tensor(1.0573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6767 D_real_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6767 D_fake_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6767 D_tricked_loss= tensor(1.0710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6768 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6768 D_fake_loss= tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6768 D_tricked_loss= tensor(1.0568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6769 D_real_loss= tensor(0.5996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6769 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6769 D_tricked_loss= tensor(1.0654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6770 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6770 D_fake_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6770 D_tricked_loss= tensor(1.0493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6771 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6771 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6771 D_tricked_loss= tensor(1.0720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6772 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6772 D_fake_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6772 D_tricked_loss= tensor(1.0332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6773 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6773 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6773 D_tricked_loss= tensor(1.0534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6774 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6774 D_fake_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6774 D_tricked_loss= tensor(1.0920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6775 D_real_loss= tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6775 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6775 D_tricked_loss= tensor(1.1006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6776 D_real_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6776 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6776 D_tricked_loss= tensor(1.0769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6777 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6777 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6777 D_tricked_loss= tensor(1.1001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6778 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6778 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6778 D_tricked_loss= tensor(1.1130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6779 D_real_loss= tensor(0.6171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6779 D_fake_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6779 D_tricked_loss= tensor(1.0906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6780 D_real_loss= tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6780 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6780 D_tricked_loss= tensor(1.0704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6781 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6781 D_fake_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6781 D_tricked_loss= tensor(1.0770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6782 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6782 D_fake_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6782 D_tricked_loss= tensor(1.1343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6783 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6783 D_fake_loss= tensor(0.6049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6783 D_tricked_loss= tensor(1.0263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6784 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6784 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6784 D_tricked_loss= tensor(1.0560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6785 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6785 D_fake_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6785 D_tricked_loss= tensor(1.0208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6786 D_real_loss= tensor(0.6125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6786 D_fake_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6786 D_tricked_loss= tensor(1.0782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6787 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6787 D_fake_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6787 D_tricked_loss= tensor(1.0653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6788 D_real_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6788 D_fake_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6788 D_tricked_loss= tensor(1.0651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6789 D_real_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6789 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6789 D_tricked_loss= tensor(1.0517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6790 D_real_loss= tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6790 D_fake_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6790 D_tricked_loss= tensor(1.0481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6791 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6791 D_fake_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6791 D_tricked_loss= tensor(1.0315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6792 D_real_loss= tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6792 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6792 D_tricked_loss= tensor(1.0332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6793 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6793 D_fake_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6793 D_tricked_loss= tensor(1.0406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6794 D_real_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6794 D_fake_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6794 D_tricked_loss= tensor(1.0479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6795 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6795 D_fake_loss= tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6795 D_tricked_loss= tensor(1.0676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6796 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6796 D_fake_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6796 D_tricked_loss= tensor(1.0504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6797 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6797 D_fake_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6797 D_tricked_loss= tensor(1.0643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6798 D_real_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6798 D_fake_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6798 D_tricked_loss= tensor(1.0599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6799 D_real_loss= tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6799 D_fake_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6799 D_tricked_loss= tensor(1.0883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6800 D_real_loss= tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6800 D_fake_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6800 D_tricked_loss= tensor(1.0430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6801 D_real_loss= tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6801 D_fake_loss= tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6801 D_tricked_loss= tensor(1.0095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6802 D_real_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6802 D_fake_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6802 D_tricked_loss= tensor(1.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6803 D_real_loss= tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6803 D_fake_loss= tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6803 D_tricked_loss= tensor(1.0470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6804 D_real_loss= tensor(0.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6804 D_fake_loss= tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6804 D_tricked_loss= tensor(1.0365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6805 D_real_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6805 D_fake_loss= tensor(0.6143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6805 D_tricked_loss= tensor(0.9943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6806 D_real_loss= tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6806 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6806 D_tricked_loss= tensor(1.0438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6807 D_real_loss= tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6807 D_fake_loss= tensor(0.5966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6807 D_tricked_loss= tensor(1.0285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6808 D_real_loss= tensor(0.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6808 D_fake_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6808 D_tricked_loss= tensor(1.0746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6809 D_real_loss= tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6809 D_fake_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6809 D_tricked_loss= tensor(1.0386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6810 D_real_loss= tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6810 D_fake_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6810 D_tricked_loss= tensor(1.0565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6811 D_real_loss= tensor(0.6091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6811 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6811 D_tricked_loss= tensor(1.0502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6812 D_real_loss= tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6812 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6812 D_tricked_loss= tensor(1.0448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6813 D_real_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6813 D_fake_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6813 D_tricked_loss= tensor(1.0535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6814 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6814 D_fake_loss= tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6814 D_tricked_loss= tensor(1.0650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6815 D_real_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6815 D_fake_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6815 D_tricked_loss= tensor(1.0829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6816 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6816 D_fake_loss= tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6816 D_tricked_loss= tensor(1.0521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6817 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6817 D_fake_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6817 D_tricked_loss= tensor(1.0638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6818 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6818 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6818 D_tricked_loss= tensor(1.0745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6819 D_real_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6819 D_fake_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6819 D_tricked_loss= tensor(1.0627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6820 D_real_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6820 D_fake_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6820 D_tricked_loss= tensor(1.0702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6821 D_real_loss= tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6821 D_fake_loss= tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6821 D_tricked_loss= tensor(1.0764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6822 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6822 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6822 D_tricked_loss= tensor(1.0494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6823 D_real_loss= tensor(0.5986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6823 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6823 D_tricked_loss= tensor(1.0572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6824 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6824 D_fake_loss= tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6824 D_tricked_loss= tensor(1.0378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6825 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6825 D_fake_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6825 D_tricked_loss= tensor(1.0772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6826 D_real_loss= tensor(0.6105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6826 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6826 D_tricked_loss= tensor(1.0879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6827 D_real_loss= tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6827 D_fake_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6827 D_tricked_loss= tensor(1.0276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6828 D_real_loss= tensor(0.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6828 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6828 D_tricked_loss= tensor(1.1019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6829 D_real_loss= tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6829 D_fake_loss= tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6829 D_tricked_loss= tensor(1.0632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6830 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6830 D_fake_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6830 D_tricked_loss= tensor(1.0941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6831 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6831 D_fake_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6831 D_tricked_loss= tensor(1.0632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6832 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6832 D_fake_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6832 D_tricked_loss= tensor(1.0850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6833 D_real_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6833 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6833 D_tricked_loss= tensor(1.0681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6834 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6834 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6834 D_tricked_loss= tensor(1.0771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6835 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6835 D_fake_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6835 D_tricked_loss= tensor(1.0499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6836 D_real_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6836 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6836 D_tricked_loss= tensor(1.0689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6837 D_real_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6837 D_fake_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6837 D_tricked_loss= tensor(1.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6838 D_real_loss= tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6838 D_fake_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6838 D_tricked_loss= tensor(1.0552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6839 D_real_loss= tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6839 D_fake_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6839 D_tricked_loss= tensor(1.0740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6840 D_real_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6840 D_fake_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6840 D_tricked_loss= tensor(1.0777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6841 D_real_loss= tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6841 D_fake_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6841 D_tricked_loss= tensor(1.0671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6842 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6842 D_fake_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6842 D_tricked_loss= tensor(1.1053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6843 D_real_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6843 D_fake_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6843 D_tricked_loss= tensor(1.0953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6844 D_real_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6844 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6844 D_tricked_loss= tensor(1.0810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6845 D_real_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6845 D_fake_loss= tensor(0.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6845 D_tricked_loss= tensor(1.0610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6846 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6846 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6846 D_tricked_loss= tensor(1.0838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6847 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6847 D_fake_loss= tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6847 D_tricked_loss= tensor(1.0815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6848 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6848 D_fake_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6848 D_tricked_loss= tensor(1.1201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6849 D_real_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6849 D_fake_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6849 D_tricked_loss= tensor(1.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6850 D_real_loss= tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6850 D_fake_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6850 D_tricked_loss= tensor(1.0894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6851 D_real_loss= tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6851 D_fake_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6851 D_tricked_loss= tensor(1.1182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6852 D_real_loss= tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6852 D_fake_loss= tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6852 D_tricked_loss= tensor(1.0491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6853 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6853 D_fake_loss= tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6853 D_tricked_loss= tensor(1.0910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6854 D_real_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6854 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6854 D_tricked_loss= tensor(1.0608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6855 D_real_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6855 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6855 D_tricked_loss= tensor(1.0772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6856 D_real_loss= tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6856 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6856 D_tricked_loss= tensor(1.0844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6857 D_real_loss= tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6857 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6857 D_tricked_loss= tensor(1.0357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6858 D_real_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6858 D_fake_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6858 D_tricked_loss= tensor(1.0746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6859 D_real_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6859 D_fake_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6859 D_tricked_loss= tensor(1.0708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6860 D_real_loss= tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6860 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6860 D_tricked_loss= tensor(1.1033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6861 D_real_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6861 D_fake_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6861 D_tricked_loss= tensor(1.0516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6862 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6862 D_fake_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6862 D_tricked_loss= tensor(1.1131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6863 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6863 D_fake_loss= tensor(0.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6863 D_tricked_loss= tensor(1.0625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6864 D_real_loss= tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6864 D_fake_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6864 D_tricked_loss= tensor(1.0975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6865 D_real_loss= tensor(0.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6865 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6865 D_tricked_loss= tensor(1.0641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6866 D_real_loss= tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6866 D_fake_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6866 D_tricked_loss= tensor(1.0529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6867 D_real_loss= tensor(0.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6867 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6867 D_tricked_loss= tensor(1.1069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6868 D_real_loss= tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6868 D_fake_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6868 D_tricked_loss= tensor(1.0563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6869 D_real_loss= tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6869 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6869 D_tricked_loss= tensor(1.0647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6870 D_real_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6870 D_fake_loss= tensor(0.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6870 D_tricked_loss= tensor(1.0480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6871 D_real_loss= tensor(0.6136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6871 D_fake_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6871 D_tricked_loss= tensor(1.0798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6872 D_real_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6872 D_fake_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6872 D_tricked_loss= tensor(1.0414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6873 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6873 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6873 D_tricked_loss= tensor(1.1140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6874 D_real_loss= tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6874 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6874 D_tricked_loss= tensor(1.0603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6875 D_real_loss= tensor(0.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6875 D_fake_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6875 D_tricked_loss= tensor(1.0467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6876 D_real_loss= tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6876 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6876 D_tricked_loss= tensor(1.0641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6877 D_real_loss= tensor(0.6058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6877 D_fake_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6877 D_tricked_loss= tensor(1.0617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6878 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6878 D_fake_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6878 D_tricked_loss= tensor(1.0596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6879 D_real_loss= tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6879 D_fake_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6879 D_tricked_loss= tensor(1.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6880 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6880 D_fake_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6880 D_tricked_loss= tensor(1.0350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6881 D_real_loss= tensor(0.6136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6881 D_fake_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6881 D_tricked_loss= tensor(1.0863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6882 D_real_loss= tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6882 D_fake_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6882 D_tricked_loss= tensor(1.1022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6883 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6883 D_fake_loss= tensor(0.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6883 D_tricked_loss= tensor(1.0715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6884 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6884 D_fake_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6884 D_tricked_loss= tensor(1.0986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6885 D_real_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6885 D_fake_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6885 D_tricked_loss= tensor(1.0444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6886 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6886 D_fake_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6886 D_tricked_loss= tensor(1.1027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6887 D_real_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6887 D_fake_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6887 D_tricked_loss= tensor(1.0672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6888 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6888 D_fake_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6888 D_tricked_loss= tensor(1.0462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6889 D_real_loss= tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6889 D_fake_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6889 D_tricked_loss= tensor(1.0995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6890 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6890 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6890 D_tricked_loss= tensor(1.0714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6891 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6891 D_fake_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6891 D_tricked_loss= tensor(1.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6892 D_real_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6892 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6892 D_tricked_loss= tensor(1.0764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6893 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6893 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6893 D_tricked_loss= tensor(1.0785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6894 D_real_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6894 D_fake_loss= tensor(0.5849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6894 D_tricked_loss= tensor(1.0545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6895 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6895 D_fake_loss= tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6895 D_tricked_loss= tensor(1.0484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6896 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6896 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6896 D_tricked_loss= tensor(1.0684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6897 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6897 D_fake_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6897 D_tricked_loss= tensor(1.0560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6898 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6898 D_fake_loss= tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6898 D_tricked_loss= tensor(1.0741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6899 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6899 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6899 D_tricked_loss= tensor(1.0733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6900 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6900 D_fake_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6900 D_tricked_loss= tensor(1.0554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6901 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6901 D_fake_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6901 D_tricked_loss= tensor(1.0946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6902 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6902 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6902 D_tricked_loss= tensor(1.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6903 D_real_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6903 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6903 D_tricked_loss= tensor(1.0744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6904 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6904 D_fake_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6904 D_tricked_loss= tensor(1.1003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6905 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6905 D_fake_loss= tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6905 D_tricked_loss= tensor(1.0747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6906 D_real_loss= tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6906 D_fake_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6906 D_tricked_loss= tensor(1.0862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6907 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6907 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6907 D_tricked_loss= tensor(1.0694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6908 D_real_loss= tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6908 D_fake_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6908 D_tricked_loss= tensor(1.0736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6909 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6909 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6909 D_tricked_loss= tensor(1.0865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6910 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6910 D_fake_loss= tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6910 D_tricked_loss= tensor(1.0895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6911 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6911 D_fake_loss= tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6911 D_tricked_loss= tensor(1.0753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6912 D_real_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6912 D_fake_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6912 D_tricked_loss= tensor(1.0591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6913 D_real_loss= tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6913 D_fake_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6913 D_tricked_loss= tensor(1.0863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6914 D_real_loss= tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6914 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6914 D_tricked_loss= tensor(1.0735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6915 D_real_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6915 D_fake_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6915 D_tricked_loss= tensor(1.0843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6916 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6916 D_fake_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6916 D_tricked_loss= tensor(1.0647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6917 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6917 D_fake_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6917 D_tricked_loss= tensor(1.0909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6918 D_real_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6918 D_fake_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6918 D_tricked_loss= tensor(1.0672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6919 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6919 D_fake_loss= tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6919 D_tricked_loss= tensor(1.0450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6920 D_real_loss= tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6920 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6920 D_tricked_loss= tensor(1.1039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6921 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6921 D_fake_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6921 D_tricked_loss= tensor(1.0493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6922 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6922 D_fake_loss= tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6922 D_tricked_loss= tensor(1.0537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6923 D_real_loss= tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6923 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6923 D_tricked_loss= tensor(1.0972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6924 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6924 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6924 D_tricked_loss= tensor(1.0813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6925 D_real_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6925 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6925 D_tricked_loss= tensor(1.0616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6926 D_real_loss= tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6926 D_fake_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6926 D_tricked_loss= tensor(1.0763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6927 D_real_loss= tensor(0.5950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6927 D_fake_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6927 D_tricked_loss= tensor(1.0453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6928 D_real_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6928 D_fake_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6928 D_tricked_loss= tensor(1.0276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6929 D_real_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6929 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6929 D_tricked_loss= tensor(1.0448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6930 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6930 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6930 D_tricked_loss= tensor(1.0747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6931 D_real_loss= tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6931 D_fake_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6931 D_tricked_loss= tensor(1.0843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6932 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6932 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6932 D_tricked_loss= tensor(1.0873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6933 D_real_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6933 D_fake_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6933 D_tricked_loss= tensor(1.0519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6934 D_real_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6934 D_fake_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6934 D_tricked_loss= tensor(1.0694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6935 D_real_loss= tensor(0.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6935 D_fake_loss= tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6935 D_tricked_loss= tensor(1.0969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6936 D_real_loss= tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6936 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6936 D_tricked_loss= tensor(1.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6937 D_real_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6937 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6937 D_tricked_loss= tensor(1.0587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6938 D_real_loss= tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6938 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6938 D_tricked_loss= tensor(1.0762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6939 D_real_loss= tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6939 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6939 D_tricked_loss= tensor(1.0648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6940 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6940 D_fake_loss= tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6940 D_tricked_loss= tensor(1.0755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6941 D_real_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6941 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6941 D_tricked_loss= tensor(1.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6942 D_real_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6942 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6942 D_tricked_loss= tensor(1.1120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6943 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6943 D_fake_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6943 D_tricked_loss= tensor(1.0794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6944 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6944 D_fake_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6944 D_tricked_loss= tensor(1.0629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6945 D_real_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6945 D_fake_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6945 D_tricked_loss= tensor(1.0466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6946 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6946 D_fake_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6946 D_tricked_loss= tensor(1.0728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6947 D_real_loss= tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6947 D_fake_loss= tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6947 D_tricked_loss= tensor(1.0784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6948 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6948 D_fake_loss= tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6948 D_tricked_loss= tensor(1.0831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6949 D_real_loss= tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6949 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6949 D_tricked_loss= tensor(1.1009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6950 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6950 D_fake_loss= tensor(0.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6950 D_tricked_loss= tensor(1.0756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6951 D_real_loss= tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6951 D_fake_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6951 D_tricked_loss= tensor(1.0922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6952 D_real_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6952 D_fake_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6952 D_tricked_loss= tensor(1.0676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6953 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6953 D_fake_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6953 D_tricked_loss= tensor(1.0665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6954 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6954 D_fake_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6954 D_tricked_loss= tensor(1.1134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6955 D_real_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6955 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6955 D_tricked_loss= tensor(1.1433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6956 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6956 D_fake_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6956 D_tricked_loss= tensor(1.0783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6957 D_real_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6957 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6957 D_tricked_loss= tensor(1.0894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6958 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6958 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6958 D_tricked_loss= tensor(1.1212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6959 D_real_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6959 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6959 D_tricked_loss= tensor(1.1417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6960 D_real_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6960 D_fake_loss= tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6960 D_tricked_loss= tensor(1.0837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6961 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6961 D_fake_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6961 D_tricked_loss= tensor(1.1109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6962 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6962 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6962 D_tricked_loss= tensor(1.0762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6963 D_real_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6963 D_fake_loss= tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6963 D_tricked_loss= tensor(1.1027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6964 D_real_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6964 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6964 D_tricked_loss= tensor(1.0824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6965 D_real_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6965 D_fake_loss= tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6965 D_tricked_loss= tensor(1.0654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6966 D_real_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6966 D_fake_loss= tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6966 D_tricked_loss= tensor(1.1085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6967 D_real_loss= tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6967 D_fake_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6967 D_tricked_loss= tensor(1.0882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6968 D_real_loss= tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6968 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6968 D_tricked_loss= tensor(1.1031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6969 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6969 D_fake_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6969 D_tricked_loss= tensor(1.0859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6970 D_real_loss= tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6970 D_fake_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6970 D_tricked_loss= tensor(1.1138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6971 D_real_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6971 D_fake_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6971 D_tricked_loss= tensor(1.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6972 D_real_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6972 D_fake_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6972 D_tricked_loss= tensor(1.1062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6973 D_real_loss= tensor(0.6091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6973 D_fake_loss= tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6973 D_tricked_loss= tensor(1.0563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6974 D_real_loss= tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6974 D_fake_loss= tensor(0.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6974 D_tricked_loss= tensor(1.0354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6975 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6975 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6975 D_tricked_loss= tensor(1.0874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6976 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6976 D_fake_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6976 D_tricked_loss= tensor(1.0847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6977 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6977 D_fake_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6977 D_tricked_loss= tensor(1.0867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6978 D_real_loss= tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6978 D_fake_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6978 D_tricked_loss= tensor(1.1291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6979 D_real_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6979 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6979 D_tricked_loss= tensor(1.0628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6980 D_real_loss= tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6980 D_fake_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6980 D_tricked_loss= tensor(1.0771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6981 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6981 D_fake_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6981 D_tricked_loss= tensor(1.0671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6982 D_real_loss= tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6982 D_fake_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6982 D_tricked_loss= tensor(1.1154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6983 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6983 D_fake_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6983 D_tricked_loss= tensor(1.0475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6984 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6984 D_fake_loss= tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6984 D_tricked_loss= tensor(1.1302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6985 D_real_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6985 D_fake_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6985 D_tricked_loss= tensor(1.1231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6986 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6986 D_fake_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6986 D_tricked_loss= tensor(1.0592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6987 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6987 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6987 D_tricked_loss= tensor(1.0842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6988 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6988 D_fake_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6988 D_tricked_loss= tensor(1.1147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6989 D_real_loss= tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6989 D_fake_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6989 D_tricked_loss= tensor(1.0598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6990 D_real_loss= tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6990 D_fake_loss= tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6990 D_tricked_loss= tensor(1.1000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6991 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6991 D_fake_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6991 D_tricked_loss= tensor(1.0603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6992 D_real_loss= tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6992 D_fake_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6992 D_tricked_loss= tensor(1.0680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6993 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6993 D_fake_loss= tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6993 D_tricked_loss= tensor(1.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6994 D_real_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6994 D_fake_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6994 D_tricked_loss= tensor(1.0934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6995 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6995 D_fake_loss= tensor(0.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6995 D_tricked_loss= tensor(1.0748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6996 D_real_loss= tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6996 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6996 D_tricked_loss= tensor(1.0979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6997 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6997 D_fake_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6997 D_tricked_loss= tensor(1.0915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6998 D_real_loss= tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6998 D_fake_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6998 D_tricked_loss= tensor(1.1354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "6999 D_real_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6999 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6999 D_tricked_loss= tensor(1.0695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7000 D_real_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7000 D_fake_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7000 D_tricked_loss= tensor(1.1205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7001 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7001 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7001 D_tricked_loss= tensor(1.0943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7002 D_real_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7002 D_fake_loss= tensor(0.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7002 D_tricked_loss= tensor(1.0794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7003 D_real_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7003 D_fake_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7003 D_tricked_loss= tensor(1.0724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7004 D_real_loss= tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7004 D_fake_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7004 D_tricked_loss= tensor(1.0721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7005 D_real_loss= tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7005 D_fake_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7005 D_tricked_loss= tensor(1.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7006 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7006 D_fake_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7006 D_tricked_loss= tensor(1.0589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7007 D_real_loss= tensor(0.6137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7007 D_fake_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7007 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7008 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7008 D_fake_loss= tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7008 D_tricked_loss= tensor(1.0726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7009 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7009 D_fake_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7009 D_tricked_loss= tensor(1.0750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7010 D_real_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7010 D_fake_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7010 D_tricked_loss= tensor(1.0885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7011 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7011 D_fake_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7011 D_tricked_loss= tensor(1.0403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7012 D_real_loss= tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7012 D_fake_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7012 D_tricked_loss= tensor(1.0897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7013 D_real_loss= tensor(0.5935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7013 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7013 D_tricked_loss= tensor(1.0761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7014 D_real_loss= tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7014 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7014 D_tricked_loss= tensor(1.0841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7015 D_real_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7015 D_fake_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7015 D_tricked_loss= tensor(1.0566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7016 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7016 D_fake_loss= tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7016 D_tricked_loss= tensor(1.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7017 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7017 D_fake_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7017 D_tricked_loss= tensor(1.0929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7018 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7018 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7018 D_tricked_loss= tensor(1.0575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7019 D_real_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7019 D_fake_loss= tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7019 D_tricked_loss= tensor(1.0735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7020 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7020 D_fake_loss= tensor(0.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7020 D_tricked_loss= tensor(1.0631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7021 D_real_loss= tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7021 D_fake_loss= tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7021 D_tricked_loss= tensor(1.0322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7022 D_real_loss= tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7022 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7022 D_tricked_loss= tensor(1.0986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7023 D_real_loss= tensor(0.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7023 D_fake_loss= tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7023 D_tricked_loss= tensor(1.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7024 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7024 D_fake_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7024 D_tricked_loss= tensor(1.1053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7025 D_real_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7025 D_fake_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7025 D_tricked_loss= tensor(1.0951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7026 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7026 D_fake_loss= tensor(0.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7026 D_tricked_loss= tensor(1.0582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7027 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7027 D_fake_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7027 D_tricked_loss= tensor(1.0592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7028 D_real_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7028 D_fake_loss= tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7028 D_tricked_loss= tensor(1.0417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7029 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7029 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7029 D_tricked_loss= tensor(1.0856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7030 D_real_loss= tensor(0.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7030 D_fake_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7030 D_tricked_loss= tensor(1.1407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7031 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7031 D_fake_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7031 D_tricked_loss= tensor(1.1499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7032 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7032 D_fake_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7032 D_tricked_loss= tensor(1.0975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7033 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7033 D_fake_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7033 D_tricked_loss= tensor(1.0617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7034 D_real_loss= tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7034 D_fake_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7034 D_tricked_loss= tensor(1.0987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7035 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7035 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7035 D_tricked_loss= tensor(1.0780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7036 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7036 D_fake_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7036 D_tricked_loss= tensor(1.1457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7037 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7037 D_fake_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7037 D_tricked_loss= tensor(1.1261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7038 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7038 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7038 D_tricked_loss= tensor(1.0993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7039 D_real_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7039 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7039 D_tricked_loss= tensor(1.1077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7040 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7040 D_fake_loss= tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7040 D_tricked_loss= tensor(1.0856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7041 D_real_loss= tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7041 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7041 D_tricked_loss= tensor(1.1208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7042 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7042 D_fake_loss= tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7042 D_tricked_loss= tensor(1.0678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7043 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7043 D_fake_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7043 D_tricked_loss= tensor(1.0962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7044 D_real_loss= tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7044 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7044 D_tricked_loss= tensor(1.0782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7045 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7045 D_fake_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7045 D_tricked_loss= tensor(1.1039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7046 D_real_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7046 D_fake_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7046 D_tricked_loss= tensor(1.0967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7047 D_real_loss= tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7047 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7047 D_tricked_loss= tensor(1.1162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7048 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7048 D_fake_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7048 D_tricked_loss= tensor(1.1374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7049 D_real_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7049 D_fake_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7049 D_tricked_loss= tensor(1.1090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7050 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7050 D_fake_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7050 D_tricked_loss= tensor(1.1158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7051 D_real_loss= tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7051 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7051 D_tricked_loss= tensor(1.1437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7052 D_real_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7052 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7052 D_tricked_loss= tensor(1.0905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7053 D_real_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7053 D_fake_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7053 D_tricked_loss= tensor(1.0911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7054 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7054 D_fake_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7054 D_tricked_loss= tensor(1.0753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7055 D_real_loss= tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7055 D_fake_loss= tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7055 D_tricked_loss= tensor(1.0654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7056 D_real_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7056 D_fake_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7056 D_tricked_loss= tensor(1.0868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7057 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7057 D_fake_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7057 D_tricked_loss= tensor(1.0699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7058 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7058 D_fake_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7058 D_tricked_loss= tensor(1.1301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7059 D_real_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7059 D_fake_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7059 D_tricked_loss= tensor(1.0936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7060 D_real_loss= tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7060 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7060 D_tricked_loss= tensor(1.1502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7061 D_real_loss= tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7061 D_fake_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7061 D_tricked_loss= tensor(1.1090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7062 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7062 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7062 D_tricked_loss= tensor(1.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7063 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7063 D_fake_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7063 D_tricked_loss= tensor(1.1355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7064 D_real_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7064 D_fake_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7064 D_tricked_loss= tensor(1.0869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7065 D_real_loss= tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7065 D_fake_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7065 D_tricked_loss= tensor(1.1206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7066 D_real_loss= tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7066 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7066 D_tricked_loss= tensor(1.1074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7067 D_real_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7067 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7067 D_tricked_loss= tensor(1.1278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7068 D_real_loss= tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7068 D_fake_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7068 D_tricked_loss= tensor(1.1082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7069 D_real_loss= tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7069 D_fake_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7069 D_tricked_loss= tensor(1.0953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7070 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7070 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7070 D_tricked_loss= tensor(1.1122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7071 D_real_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7071 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7071 D_tricked_loss= tensor(1.0953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7072 D_real_loss= tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7072 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7072 D_tricked_loss= tensor(1.1256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7073 D_real_loss= tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7073 D_fake_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7073 D_tricked_loss= tensor(1.1394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7074 D_real_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7074 D_fake_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7074 D_tricked_loss= tensor(1.1228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7075 D_real_loss= tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7075 D_fake_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7075 D_tricked_loss= tensor(1.1614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7076 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7076 D_fake_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7076 D_tricked_loss= tensor(1.1125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7077 D_real_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7077 D_fake_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7077 D_tricked_loss= tensor(1.1094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7078 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7078 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7078 D_tricked_loss= tensor(1.1575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7079 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7079 D_fake_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7079 D_tricked_loss= tensor(1.1185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7080 D_real_loss= tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7080 D_fake_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7080 D_tricked_loss= tensor(1.1038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7081 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7081 D_fake_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7081 D_tricked_loss= tensor(1.1443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7082 D_real_loss= tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7082 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7082 D_tricked_loss= tensor(1.0938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7083 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7083 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7083 D_tricked_loss= tensor(1.0965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7084 D_real_loss= tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7084 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7084 D_tricked_loss= tensor(1.1114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7085 D_real_loss= tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7085 D_fake_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7085 D_tricked_loss= tensor(1.1023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7086 D_real_loss= tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7086 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7086 D_tricked_loss= tensor(1.1007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7087 D_real_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7087 D_fake_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7087 D_tricked_loss= tensor(1.0222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7088 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7088 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7088 D_tricked_loss= tensor(1.0794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7089 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7089 D_fake_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7089 D_tricked_loss= tensor(1.0985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7090 D_real_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7090 D_fake_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7090 D_tricked_loss= tensor(1.1187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7091 D_real_loss= tensor(0.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7091 D_fake_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7091 D_tricked_loss= tensor(1.1004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7092 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7092 D_fake_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7092 D_tricked_loss= tensor(1.1213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7093 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7093 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7093 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7094 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7094 D_fake_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7094 D_tricked_loss= tensor(1.1149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7095 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7095 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7095 D_tricked_loss= tensor(1.1002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7096 D_real_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7096 D_fake_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7096 D_tricked_loss= tensor(1.0961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7097 D_real_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7097 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7097 D_tricked_loss= tensor(1.1158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7098 D_real_loss= tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7098 D_fake_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7098 D_tricked_loss= tensor(1.1641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7099 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7099 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7099 D_tricked_loss= tensor(1.0982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7100 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7100 D_fake_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7100 D_tricked_loss= tensor(1.1114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7101 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7101 D_fake_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7101 D_tricked_loss= tensor(1.1304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7102 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7102 D_fake_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7102 D_tricked_loss= tensor(1.0946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7103 D_real_loss= tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7103 D_fake_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7103 D_tricked_loss= tensor(1.1241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7104 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7104 D_fake_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7104 D_tricked_loss= tensor(1.1108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7105 D_real_loss= tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7105 D_fake_loss= tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7105 D_tricked_loss= tensor(1.0832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7106 D_real_loss= tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7106 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7106 D_tricked_loss= tensor(1.0838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7107 D_real_loss= tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7107 D_fake_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7107 D_tricked_loss= tensor(1.0970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7108 D_real_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7108 D_fake_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7108 D_tricked_loss= tensor(1.1091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7109 D_real_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7109 D_fake_loss= tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7109 D_tricked_loss= tensor(1.0750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7110 D_real_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7110 D_fake_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7110 D_tricked_loss= tensor(1.1062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7111 D_real_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7111 D_fake_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7111 D_tricked_loss= tensor(1.0961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7112 D_real_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7112 D_fake_loss= tensor(0.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7112 D_tricked_loss= tensor(1.1286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7113 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7113 D_fake_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7113 D_tricked_loss= tensor(1.1817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7114 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7114 D_fake_loss= tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7114 D_tricked_loss= tensor(1.1446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7115 D_real_loss= tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7115 D_fake_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7115 D_tricked_loss= tensor(1.1480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7116 D_real_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7116 D_fake_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7116 D_tricked_loss= tensor(1.1207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7117 D_real_loss= tensor(0.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7117 D_fake_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7117 D_tricked_loss= tensor(1.1210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7118 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7118 D_fake_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7118 D_tricked_loss= tensor(1.0933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7119 D_real_loss= tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7119 D_fake_loss= tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7119 D_tricked_loss= tensor(1.0965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7120 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7120 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7120 D_tricked_loss= tensor(1.0838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7121 D_real_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7121 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7121 D_tricked_loss= tensor(1.0849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7122 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7122 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7122 D_tricked_loss= tensor(1.1020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7123 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7123 D_fake_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7123 D_tricked_loss= tensor(1.0946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7124 D_real_loss= tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7124 D_fake_loss= tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7124 D_tricked_loss= tensor(1.0945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7125 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7125 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7125 D_tricked_loss= tensor(1.1324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7126 D_real_loss= tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7126 D_fake_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7126 D_tricked_loss= tensor(1.1258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7127 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7127 D_fake_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7127 D_tricked_loss= tensor(1.0830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7128 D_real_loss= tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7128 D_fake_loss= tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7128 D_tricked_loss= tensor(1.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7129 D_real_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7129 D_fake_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7129 D_tricked_loss= tensor(1.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7130 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7130 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7130 D_tricked_loss= tensor(1.1538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7131 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7131 D_fake_loss= tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7131 D_tricked_loss= tensor(1.0960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7132 D_real_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7132 D_fake_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7132 D_tricked_loss= tensor(1.1210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7133 D_real_loss= tensor(0.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7133 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7133 D_tricked_loss= tensor(1.1271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7134 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7134 D_fake_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7134 D_tricked_loss= tensor(1.0874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7135 D_real_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7135 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7135 D_tricked_loss= tensor(1.0993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7136 D_real_loss= tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7136 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7136 D_tricked_loss= tensor(1.1394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7137 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7137 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7137 D_tricked_loss= tensor(1.1111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7138 D_real_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7138 D_fake_loss= tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7138 D_tricked_loss= tensor(1.0798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7139 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7139 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7139 D_tricked_loss= tensor(1.1103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7140 D_real_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7140 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7140 D_tricked_loss= tensor(1.1230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7141 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7141 D_fake_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7141 D_tricked_loss= tensor(1.1518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7142 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7142 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7142 D_tricked_loss= tensor(1.1399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7143 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7143 D_fake_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7143 D_tricked_loss= tensor(1.1934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7144 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7144 D_fake_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7144 D_tricked_loss= tensor(1.1351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7145 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7145 D_fake_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7145 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7146 D_real_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7146 D_fake_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7146 D_tricked_loss= tensor(1.1452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7147 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7147 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7147 D_tricked_loss= tensor(1.1122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7148 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7148 D_fake_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7148 D_tricked_loss= tensor(1.0951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7149 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7149 D_fake_loss= tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7149 D_tricked_loss= tensor(1.0904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7150 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7150 D_fake_loss= tensor(0.5832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7150 D_tricked_loss= tensor(1.0893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7151 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7151 D_fake_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7151 D_tricked_loss= tensor(1.0781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7152 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7152 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7152 D_tricked_loss= tensor(1.0513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7153 D_real_loss= tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7153 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7153 D_tricked_loss= tensor(1.1248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7154 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7154 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7154 D_tricked_loss= tensor(1.1410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7155 D_real_loss= tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7155 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7155 D_tricked_loss= tensor(1.1272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7156 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7156 D_fake_loss= tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7156 D_tricked_loss= tensor(1.1272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7157 D_real_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7157 D_fake_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7157 D_tricked_loss= tensor(1.1175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7158 D_real_loss= tensor(0.5798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7158 D_fake_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7158 D_tricked_loss= tensor(1.1292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7159 D_real_loss= tensor(0.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7159 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7159 D_tricked_loss= tensor(1.1027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7160 D_real_loss= tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7160 D_fake_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7160 D_tricked_loss= tensor(1.1030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7161 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7161 D_fake_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7161 D_tricked_loss= tensor(1.0986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7162 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7162 D_fake_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7162 D_tricked_loss= tensor(1.0824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7163 D_real_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7163 D_fake_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7163 D_tricked_loss= tensor(1.1238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7164 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7164 D_fake_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7164 D_tricked_loss= tensor(1.1176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7165 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7165 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7165 D_tricked_loss= tensor(1.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7166 D_real_loss= tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7166 D_fake_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7166 D_tricked_loss= tensor(1.1505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7167 D_real_loss= tensor(0.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7167 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7167 D_tricked_loss= tensor(1.1203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7168 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7168 D_fake_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7168 D_tricked_loss= tensor(1.1082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7169 D_real_loss= tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7169 D_fake_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7169 D_tricked_loss= tensor(1.0998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7170 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7170 D_fake_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7170 D_tricked_loss= tensor(1.1549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7171 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7171 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7171 D_tricked_loss= tensor(1.1172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7172 D_real_loss= tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7172 D_fake_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7172 D_tricked_loss= tensor(1.1059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7173 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7173 D_fake_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7173 D_tricked_loss= tensor(1.1039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7174 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7174 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7174 D_tricked_loss= tensor(1.1245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7175 D_real_loss= tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7175 D_fake_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7175 D_tricked_loss= tensor(1.1265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7176 D_real_loss= tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7176 D_fake_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7176 D_tricked_loss= tensor(1.1127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7177 D_real_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7177 D_fake_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7177 D_tricked_loss= tensor(1.1229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7178 D_real_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7178 D_fake_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7178 D_tricked_loss= tensor(1.1314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7179 D_real_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7179 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7179 D_tricked_loss= tensor(1.1201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7180 D_real_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7180 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7180 D_tricked_loss= tensor(1.1121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7181 D_real_loss= tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7181 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7181 D_tricked_loss= tensor(1.1176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7182 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7182 D_fake_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7182 D_tricked_loss= tensor(1.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7183 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7183 D_fake_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7183 D_tricked_loss= tensor(1.1083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7184 D_real_loss= tensor(0.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7184 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7184 D_tricked_loss= tensor(1.1485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7185 D_real_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7185 D_fake_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7185 D_tricked_loss= tensor(1.1323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7186 D_real_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7186 D_fake_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7186 D_tricked_loss= tensor(1.0975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7187 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7187 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7187 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7188 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7188 D_fake_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7188 D_tricked_loss= tensor(1.1146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7189 D_real_loss= tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7189 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7189 D_tricked_loss= tensor(1.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7190 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7190 D_fake_loss= tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7190 D_tricked_loss= tensor(1.1124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7191 D_real_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7191 D_fake_loss= tensor(0.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7191 D_tricked_loss= tensor(1.1049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7192 D_real_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7192 D_fake_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7192 D_tricked_loss= tensor(1.1447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7193 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7193 D_fake_loss= tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7193 D_tricked_loss= tensor(1.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7194 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7194 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7194 D_tricked_loss= tensor(1.1127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7195 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7195 D_fake_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7195 D_tricked_loss= tensor(1.1143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7196 D_real_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7196 D_fake_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7196 D_tricked_loss= tensor(1.1236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7197 D_real_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7197 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7197 D_tricked_loss= tensor(1.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7198 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7198 D_fake_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7198 D_tricked_loss= tensor(1.1337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7199 D_real_loss= tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7199 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7199 D_tricked_loss= tensor(1.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7200 D_real_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7200 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7200 D_tricked_loss= tensor(1.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7201 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7201 D_fake_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7201 D_tricked_loss= tensor(1.1183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7202 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7202 D_fake_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7202 D_tricked_loss= tensor(1.1204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7203 D_real_loss= tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7203 D_fake_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7203 D_tricked_loss= tensor(1.1570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7204 D_real_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7204 D_fake_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7204 D_tricked_loss= tensor(1.1139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7205 D_real_loss= tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7205 D_fake_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7205 D_tricked_loss= tensor(1.1492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7206 D_real_loss= tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7206 D_fake_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7206 D_tricked_loss= tensor(1.1619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7207 D_real_loss= tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7207 D_fake_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7207 D_tricked_loss= tensor(1.1162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7208 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7208 D_fake_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7208 D_tricked_loss= tensor(1.0858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7209 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7209 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7209 D_tricked_loss= tensor(1.0880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7210 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7210 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7210 D_tricked_loss= tensor(1.1368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7211 D_real_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7211 D_fake_loss= tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7211 D_tricked_loss= tensor(1.0914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7212 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7212 D_fake_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7212 D_tricked_loss= tensor(1.1492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7213 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7213 D_fake_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7213 D_tricked_loss= tensor(1.1148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7214 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7214 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7214 D_tricked_loss= tensor(1.1322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7215 D_real_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7215 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7215 D_tricked_loss= tensor(1.1373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7216 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7216 D_fake_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7216 D_tricked_loss= tensor(1.1084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7217 D_real_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7217 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7217 D_tricked_loss= tensor(1.1246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7218 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7218 D_fake_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7218 D_tricked_loss= tensor(1.1829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7219 D_real_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7219 D_fake_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7219 D_tricked_loss= tensor(1.1316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7220 D_real_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7220 D_fake_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7220 D_tricked_loss= tensor(1.1208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7221 D_real_loss= tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7221 D_fake_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7221 D_tricked_loss= tensor(1.1378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7222 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7222 D_fake_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7222 D_tricked_loss= tensor(1.1120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7223 D_real_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7223 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7223 D_tricked_loss= tensor(1.1982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7224 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7224 D_fake_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7224 D_tricked_loss= tensor(1.1534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7225 D_real_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7225 D_fake_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7225 D_tricked_loss= tensor(1.0995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7226 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7226 D_fake_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7226 D_tricked_loss= tensor(1.1587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7227 D_real_loss= tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7227 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7227 D_tricked_loss= tensor(1.1074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7228 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7228 D_fake_loss= tensor(0.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7228 D_tricked_loss= tensor(1.1364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7229 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7229 D_fake_loss= tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7229 D_tricked_loss= tensor(1.1348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7230 D_real_loss= tensor(0.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7230 D_fake_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7230 D_tricked_loss= tensor(1.1591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7231 D_real_loss= tensor(0.5773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7231 D_fake_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7231 D_tricked_loss= tensor(1.1353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7232 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7232 D_fake_loss= tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7232 D_tricked_loss= tensor(1.1187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7233 D_real_loss= tensor(0.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7233 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7233 D_tricked_loss= tensor(1.1203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7234 D_real_loss= tensor(0.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7234 D_fake_loss= tensor(0.5593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7234 D_tricked_loss= tensor(1.1067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7235 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7235 D_fake_loss= tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7235 D_tricked_loss= tensor(1.1037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7236 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7236 D_fake_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7236 D_tricked_loss= tensor(1.1484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7237 D_real_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7237 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7237 D_tricked_loss= tensor(1.1656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7238 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7238 D_fake_loss= tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7238 D_tricked_loss= tensor(1.1408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7239 D_real_loss= tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7239 D_fake_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7239 D_tricked_loss= tensor(1.1195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7240 D_real_loss= tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7240 D_fake_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7240 D_tricked_loss= tensor(1.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7241 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7241 D_fake_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7241 D_tricked_loss= tensor(1.1546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7242 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7242 D_fake_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7242 D_tricked_loss= tensor(1.0981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7243 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7243 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7243 D_tricked_loss= tensor(1.1179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7244 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7244 D_fake_loss= tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7244 D_tricked_loss= tensor(1.1286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7245 D_real_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7245 D_fake_loss= tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7245 D_tricked_loss= tensor(1.1090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7246 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7246 D_fake_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7246 D_tricked_loss= tensor(1.1582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7247 D_real_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7247 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7247 D_tricked_loss= tensor(1.1302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7248 D_real_loss= tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7248 D_fake_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7248 D_tricked_loss= tensor(1.1138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7249 D_real_loss= tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7249 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7249 D_tricked_loss= tensor(1.0958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7250 D_real_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7250 D_fake_loss= tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7250 D_tricked_loss= tensor(1.0934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7251 D_real_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7251 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7251 D_tricked_loss= tensor(1.1455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7252 D_real_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7252 D_fake_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7252 D_tricked_loss= tensor(1.0978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7253 D_real_loss= tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7253 D_fake_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7253 D_tricked_loss= tensor(1.1244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7254 D_real_loss= tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7254 D_fake_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7254 D_tricked_loss= tensor(1.1466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7255 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7255 D_fake_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7255 D_tricked_loss= tensor(1.1111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7256 D_real_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7256 D_fake_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7256 D_tricked_loss= tensor(1.1493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7257 D_real_loss= tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7257 D_fake_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7257 D_tricked_loss= tensor(1.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7258 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7258 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7258 D_tricked_loss= tensor(1.1123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7259 D_real_loss= tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7259 D_fake_loss= tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7259 D_tricked_loss= tensor(1.1347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7260 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7260 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7260 D_tricked_loss= tensor(1.1524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7261 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7261 D_fake_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7261 D_tricked_loss= tensor(1.1484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7262 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7262 D_fake_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7262 D_tricked_loss= tensor(1.1098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7263 D_real_loss= tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7263 D_fake_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7263 D_tricked_loss= tensor(1.1416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7264 D_real_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7264 D_fake_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7264 D_tricked_loss= tensor(1.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7265 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7265 D_fake_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7265 D_tricked_loss= tensor(1.1230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7266 D_real_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7266 D_fake_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7266 D_tricked_loss= tensor(1.1392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7267 D_real_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7267 D_fake_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7267 D_tricked_loss= tensor(1.1752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7268 D_real_loss= tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7268 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7268 D_tricked_loss= tensor(1.1402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7269 D_real_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7269 D_fake_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7269 D_tricked_loss= tensor(1.1238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7270 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7270 D_fake_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7270 D_tricked_loss= tensor(1.1268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7271 D_real_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7271 D_fake_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7271 D_tricked_loss= tensor(1.1371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7272 D_real_loss= tensor(0.5683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7272 D_fake_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7272 D_tricked_loss= tensor(1.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7273 D_real_loss= tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7273 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7273 D_tricked_loss= tensor(1.1243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7274 D_real_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7274 D_fake_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7274 D_tricked_loss= tensor(1.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7275 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7275 D_fake_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7275 D_tricked_loss= tensor(1.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7276 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7276 D_fake_loss= tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7276 D_tricked_loss= tensor(1.1391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7277 D_real_loss= tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7277 D_fake_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7277 D_tricked_loss= tensor(1.1020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7278 D_real_loss= tensor(0.5804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7278 D_fake_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7278 D_tricked_loss= tensor(1.1374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7279 D_real_loss= tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7279 D_fake_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7279 D_tricked_loss= tensor(1.1377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7280 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7280 D_fake_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7280 D_tricked_loss= tensor(1.0876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7281 D_real_loss= tensor(0.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7281 D_fake_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7281 D_tricked_loss= tensor(1.1214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7282 D_real_loss= tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7282 D_fake_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7282 D_tricked_loss= tensor(1.1421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7283 D_real_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7283 D_fake_loss= tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7283 D_tricked_loss= tensor(1.0949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7284 D_real_loss= tensor(0.5826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7284 D_fake_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7284 D_tricked_loss= tensor(1.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7285 D_real_loss= tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7285 D_fake_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7285 D_tricked_loss= tensor(1.1510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7286 D_real_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7286 D_fake_loss= tensor(0.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7286 D_tricked_loss= tensor(1.1226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7287 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7287 D_fake_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7287 D_tricked_loss= tensor(1.1727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7288 D_real_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7288 D_fake_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7288 D_tricked_loss= tensor(1.0998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7289 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7289 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7289 D_tricked_loss= tensor(1.1547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7290 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7290 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7290 D_tricked_loss= tensor(1.1858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7291 D_real_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7291 D_fake_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7291 D_tricked_loss= tensor(1.1366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7292 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7292 D_fake_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7292 D_tricked_loss= tensor(1.1375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7293 D_real_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7293 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7293 D_tricked_loss= tensor(1.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7294 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7294 D_fake_loss= tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7294 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7295 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7295 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7295 D_tricked_loss= tensor(1.1433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7296 D_real_loss= tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7296 D_fake_loss= tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7296 D_tricked_loss= tensor(1.1375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7297 D_real_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7297 D_fake_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7297 D_tricked_loss= tensor(1.1303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7298 D_real_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7298 D_fake_loss= tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7298 D_tricked_loss= tensor(1.1102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7299 D_real_loss= tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7299 D_fake_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7299 D_tricked_loss= tensor(1.1476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7300 D_real_loss= tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7300 D_fake_loss= tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7300 D_tricked_loss= tensor(1.1152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7301 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7301 D_fake_loss= tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7301 D_tricked_loss= tensor(1.1138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7302 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7302 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7302 D_tricked_loss= tensor(1.1497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7303 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7303 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7303 D_tricked_loss= tensor(1.1292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7304 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7304 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7304 D_tricked_loss= tensor(1.1269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7305 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7305 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7305 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7306 D_real_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7306 D_fake_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7306 D_tricked_loss= tensor(1.1281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7307 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7307 D_fake_loss= tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7307 D_tricked_loss= tensor(1.1066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7308 D_real_loss= tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7308 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7308 D_tricked_loss= tensor(1.1584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7309 D_real_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7309 D_fake_loss= tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7309 D_tricked_loss= tensor(1.1543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7310 D_real_loss= tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7310 D_fake_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7310 D_tricked_loss= tensor(1.1720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7311 D_real_loss= tensor(0.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7311 D_fake_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7311 D_tricked_loss= tensor(1.1597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7312 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7312 D_fake_loss= tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7312 D_tricked_loss= tensor(1.0969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7313 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7313 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7313 D_tricked_loss= tensor(1.1710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7314 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7314 D_fake_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7314 D_tricked_loss= tensor(1.1495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7315 D_real_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7315 D_fake_loss= tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7315 D_tricked_loss= tensor(1.1170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7316 D_real_loss= tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7316 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7316 D_tricked_loss= tensor(1.1112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7317 D_real_loss= tensor(0.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7317 D_fake_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7317 D_tricked_loss= tensor(1.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7318 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7318 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7318 D_tricked_loss= tensor(1.1693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7319 D_real_loss= tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7319 D_fake_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7319 D_tricked_loss= tensor(1.1859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7320 D_real_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7320 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7320 D_tricked_loss= tensor(1.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7321 D_real_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7321 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7321 D_tricked_loss= tensor(1.1329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7322 D_real_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7322 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7322 D_tricked_loss= tensor(1.1020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7323 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7323 D_fake_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7323 D_tricked_loss= tensor(1.1164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7324 D_real_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7324 D_fake_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7324 D_tricked_loss= tensor(1.1571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7325 D_real_loss= tensor(0.5372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7325 D_fake_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7325 D_tricked_loss= tensor(1.0755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7326 D_real_loss= tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7326 D_fake_loss= tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7326 D_tricked_loss= tensor(1.1562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7327 D_real_loss= tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7327 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7327 D_tricked_loss= tensor(1.1093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7328 D_real_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7328 D_fake_loss= tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7328 D_tricked_loss= tensor(1.1361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7329 D_real_loss= tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7329 D_fake_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7329 D_tricked_loss= tensor(1.1715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7330 D_real_loss= tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7330 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7330 D_tricked_loss= tensor(1.1590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7331 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7331 D_fake_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7331 D_tricked_loss= tensor(1.1308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7332 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7332 D_fake_loss= tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7332 D_tricked_loss= tensor(1.1037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7333 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7333 D_fake_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7333 D_tricked_loss= tensor(1.1056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7334 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7334 D_fake_loss= tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7334 D_tricked_loss= tensor(1.0961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7335 D_real_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7335 D_fake_loss= tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7335 D_tricked_loss= tensor(1.1026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7336 D_real_loss= tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7336 D_fake_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7336 D_tricked_loss= tensor(1.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7337 D_real_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7337 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7337 D_tricked_loss= tensor(1.1488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7338 D_real_loss= tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7338 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7338 D_tricked_loss= tensor(1.1593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7339 D_real_loss= tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7339 D_fake_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7339 D_tricked_loss= tensor(1.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7340 D_real_loss= tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7340 D_fake_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7340 D_tricked_loss= tensor(1.2018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7341 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7341 D_fake_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7341 D_tricked_loss= tensor(1.1475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7342 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7342 D_fake_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7342 D_tricked_loss= tensor(1.0786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7343 D_real_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7343 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7343 D_tricked_loss= tensor(1.1148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7344 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7344 D_fake_loss= tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7344 D_tricked_loss= tensor(1.1182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7345 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7345 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7345 D_tricked_loss= tensor(1.1605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7346 D_real_loss= tensor(0.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7346 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7346 D_tricked_loss= tensor(1.1655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7347 D_real_loss= tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7347 D_fake_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7347 D_tricked_loss= tensor(1.1517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7348 D_real_loss= tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7348 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7348 D_tricked_loss= tensor(1.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7349 D_real_loss= tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7349 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7349 D_tricked_loss= tensor(1.1445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7350 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7350 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7350 D_tricked_loss= tensor(1.1037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7351 D_real_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7351 D_fake_loss= tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7351 D_tricked_loss= tensor(1.1133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7352 D_real_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7352 D_fake_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7352 D_tricked_loss= tensor(1.1623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7353 D_real_loss= tensor(0.5506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7353 D_fake_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7353 D_tricked_loss= tensor(1.1499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7354 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7354 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7354 D_tricked_loss= tensor(1.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7355 D_real_loss= tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7355 D_fake_loss= tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7355 D_tricked_loss= tensor(1.1779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7356 D_real_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7356 D_fake_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7356 D_tricked_loss= tensor(1.1797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7357 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7357 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7357 D_tricked_loss= tensor(1.1261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7358 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7358 D_fake_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7358 D_tricked_loss= tensor(1.1382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7359 D_real_loss= tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7359 D_fake_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7359 D_tricked_loss= tensor(1.1239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7360 D_real_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7360 D_fake_loss= tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7360 D_tricked_loss= tensor(1.1046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7361 D_real_loss= tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7361 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7361 D_tricked_loss= tensor(1.1326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7362 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7362 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7362 D_tricked_loss= tensor(1.1720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7363 D_real_loss= tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7363 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7363 D_tricked_loss= tensor(1.1459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7364 D_real_loss= tensor(0.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7364 D_fake_loss= tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7364 D_tricked_loss= tensor(1.1889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7365 D_real_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7365 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7365 D_tricked_loss= tensor(1.1796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7366 D_real_loss= tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7366 D_fake_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7366 D_tricked_loss= tensor(1.1518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7367 D_real_loss= tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7367 D_fake_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7367 D_tricked_loss= tensor(1.1567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7368 D_real_loss= tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7368 D_fake_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7368 D_tricked_loss= tensor(1.1069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7369 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7369 D_fake_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7369 D_tricked_loss= tensor(1.1373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7370 D_real_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7370 D_fake_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7370 D_tricked_loss= tensor(1.0978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7371 D_real_loss= tensor(0.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7371 D_fake_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7371 D_tricked_loss= tensor(1.1774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7372 D_real_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7372 D_fake_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7372 D_tricked_loss= tensor(1.1531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7373 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7373 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7373 D_tricked_loss= tensor(1.1460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7374 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7374 D_fake_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7374 D_tricked_loss= tensor(1.1797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7375 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7375 D_fake_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7375 D_tricked_loss= tensor(1.1286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7376 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7376 D_fake_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7376 D_tricked_loss= tensor(1.1363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7377 D_real_loss= tensor(0.5372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7377 D_fake_loss= tensor(0.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7377 D_tricked_loss= tensor(1.1542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7378 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7378 D_fake_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7378 D_tricked_loss= tensor(1.1559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7379 D_real_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7379 D_fake_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7379 D_tricked_loss= tensor(1.1751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7380 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7380 D_fake_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7380 D_tricked_loss= tensor(1.1779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7381 D_real_loss= tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7381 D_fake_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7381 D_tricked_loss= tensor(1.1714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7382 D_real_loss= tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7382 D_fake_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7382 D_tricked_loss= tensor(1.1543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7383 D_real_loss= tensor(0.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7383 D_fake_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7383 D_tricked_loss= tensor(1.1210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7384 D_real_loss= tensor(0.5853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7384 D_fake_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7384 D_tricked_loss= tensor(1.1543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7385 D_real_loss= tensor(0.5560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7385 D_fake_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7385 D_tricked_loss= tensor(1.1170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7386 D_real_loss= tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7386 D_fake_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7386 D_tricked_loss= tensor(1.1731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7387 D_real_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7387 D_fake_loss= tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7387 D_tricked_loss= tensor(1.1077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7388 D_real_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7388 D_fake_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7388 D_tricked_loss= tensor(1.1621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7389 D_real_loss= tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7389 D_fake_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7389 D_tricked_loss= tensor(1.1331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7390 D_real_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7390 D_fake_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7390 D_tricked_loss= tensor(1.1622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7391 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7391 D_fake_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7391 D_tricked_loss= tensor(1.2006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7392 D_real_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7392 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7392 D_tricked_loss= tensor(1.1854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7393 D_real_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7393 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7393 D_tricked_loss= tensor(1.1790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7394 D_real_loss= tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7394 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7394 D_tricked_loss= tensor(1.1894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7395 D_real_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7395 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7395 D_tricked_loss= tensor(1.0884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7396 D_real_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7396 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7396 D_tricked_loss= tensor(1.1528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7397 D_real_loss= tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7397 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7397 D_tricked_loss= tensor(1.1567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7398 D_real_loss= tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7398 D_fake_loss= tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7398 D_tricked_loss= tensor(1.1574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7399 D_real_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7399 D_fake_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7399 D_tricked_loss= tensor(1.1345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7400 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7400 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7400 D_tricked_loss= tensor(1.1122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7401 D_real_loss= tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7401 D_fake_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7401 D_tricked_loss= tensor(1.1112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7402 D_real_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7402 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7402 D_tricked_loss= tensor(1.1345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7403 D_real_loss= tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7403 D_fake_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7403 D_tricked_loss= tensor(1.2039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7404 D_real_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7404 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7404 D_tricked_loss= tensor(1.1487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7405 D_real_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7405 D_fake_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7405 D_tricked_loss= tensor(1.2061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7406 D_real_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7406 D_fake_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7406 D_tricked_loss= tensor(1.1941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7407 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7407 D_fake_loss= tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7407 D_tricked_loss= tensor(1.1233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7408 D_real_loss= tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7408 D_fake_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7408 D_tricked_loss= tensor(1.1363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7409 D_real_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7409 D_fake_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7409 D_tricked_loss= tensor(1.1274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7410 D_real_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7410 D_fake_loss= tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7410 D_tricked_loss= tensor(1.1591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7411 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7411 D_fake_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7411 D_tricked_loss= tensor(1.1414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7412 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7412 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7412 D_tricked_loss= tensor(1.1309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7413 D_real_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7413 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7413 D_tricked_loss= tensor(1.1593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7414 D_real_loss= tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7414 D_fake_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7414 D_tricked_loss= tensor(1.1962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7415 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7415 D_fake_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7415 D_tricked_loss= tensor(1.1664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7416 D_real_loss= tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7416 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7416 D_tricked_loss= tensor(1.1460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7417 D_real_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7417 D_fake_loss= tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7417 D_tricked_loss= tensor(1.1168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7418 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7418 D_fake_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7418 D_tricked_loss= tensor(1.1607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7419 D_real_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7419 D_fake_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7419 D_tricked_loss= tensor(1.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7420 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7420 D_fake_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7420 D_tricked_loss= tensor(1.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7421 D_real_loss= tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7421 D_fake_loss= tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7421 D_tricked_loss= tensor(1.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7422 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7422 D_fake_loss= tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7422 D_tricked_loss= tensor(1.1390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7423 D_real_loss= tensor(0.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7423 D_fake_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7423 D_tricked_loss= tensor(1.1993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7424 D_real_loss= tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7424 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7424 D_tricked_loss= tensor(1.1737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7425 D_real_loss= tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7425 D_fake_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7425 D_tricked_loss= tensor(1.1403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7426 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7426 D_fake_loss= tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7426 D_tricked_loss= tensor(1.1204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7427 D_real_loss= tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7427 D_fake_loss= tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7427 D_tricked_loss= tensor(1.1451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7428 D_real_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7428 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7428 D_tricked_loss= tensor(1.1661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7429 D_real_loss= tensor(0.5606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7429 D_fake_loss= tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7429 D_tricked_loss= tensor(1.1820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7430 D_real_loss= tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7430 D_fake_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7430 D_tricked_loss= tensor(1.1149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7431 D_real_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7431 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7431 D_tricked_loss= tensor(1.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7432 D_real_loss= tensor(0.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7432 D_fake_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7432 D_tricked_loss= tensor(1.1439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7433 D_real_loss= tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7433 D_fake_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7433 D_tricked_loss= tensor(1.1301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7434 D_real_loss= tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7434 D_fake_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7434 D_tricked_loss= tensor(1.1336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7435 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7435 D_fake_loss= tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7435 D_tricked_loss= tensor(1.1407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7436 D_real_loss= tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7436 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7436 D_tricked_loss= tensor(1.1476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7437 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7437 D_fake_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7437 D_tricked_loss= tensor(1.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7438 D_real_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7438 D_fake_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7438 D_tricked_loss= tensor(1.1577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7439 D_real_loss= tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7439 D_fake_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7439 D_tricked_loss= tensor(1.1489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7440 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7440 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7440 D_tricked_loss= tensor(1.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7441 D_real_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7441 D_fake_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7441 D_tricked_loss= tensor(1.1628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7442 D_real_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7442 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7442 D_tricked_loss= tensor(1.1673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7443 D_real_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7443 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7443 D_tricked_loss= tensor(1.1965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7444 D_real_loss= tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7444 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7444 D_tricked_loss= tensor(1.1892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7445 D_real_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7445 D_fake_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7445 D_tricked_loss= tensor(1.1786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7446 D_real_loss= tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7446 D_fake_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7446 D_tricked_loss= tensor(1.1480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7447 D_real_loss= tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7447 D_fake_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7447 D_tricked_loss= tensor(1.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7448 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7448 D_fake_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7448 D_tricked_loss= tensor(1.1641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7449 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7449 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7449 D_tricked_loss= tensor(1.1481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7450 D_real_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7450 D_fake_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7450 D_tricked_loss= tensor(1.1287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7451 D_real_loss= tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7451 D_fake_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7451 D_tricked_loss= tensor(1.1793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7452 D_real_loss= tensor(0.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7452 D_fake_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7452 D_tricked_loss= tensor(1.2020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7453 D_real_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7453 D_fake_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7453 D_tricked_loss= tensor(1.1374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7454 D_real_loss= tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7454 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7454 D_tricked_loss= tensor(1.1340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7455 D_real_loss= tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7455 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7455 D_tricked_loss= tensor(1.1773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7456 D_real_loss= tensor(0.5303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7456 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7456 D_tricked_loss= tensor(1.1790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7457 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7457 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7457 D_tricked_loss= tensor(1.1546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7458 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7458 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7458 D_tricked_loss= tensor(1.1452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7459 D_real_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7459 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7459 D_tricked_loss= tensor(1.1145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7460 D_real_loss= tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7460 D_fake_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7460 D_tricked_loss= tensor(1.1586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7461 D_real_loss= tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7461 D_fake_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7461 D_tricked_loss= tensor(1.1586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7462 D_real_loss= tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7462 D_fake_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7462 D_tricked_loss= tensor(1.1272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7463 D_real_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7463 D_fake_loss= tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7463 D_tricked_loss= tensor(1.1220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7464 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7464 D_fake_loss= tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7464 D_tricked_loss= tensor(1.1211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7465 D_real_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7465 D_fake_loss= tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7465 D_tricked_loss= tensor(1.1347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7466 D_real_loss= tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7466 D_fake_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7466 D_tricked_loss= tensor(1.1582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7467 D_real_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7467 D_fake_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7467 D_tricked_loss= tensor(1.1444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7468 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7468 D_fake_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7468 D_tricked_loss= tensor(1.1131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7469 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7469 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7469 D_tricked_loss= tensor(1.1407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7470 D_real_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7470 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7470 D_tricked_loss= tensor(1.2235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7471 D_real_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7471 D_fake_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7471 D_tricked_loss= tensor(1.1828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7472 D_real_loss= tensor(0.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7472 D_fake_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7472 D_tricked_loss= tensor(1.1590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7473 D_real_loss= tensor(0.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7473 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7473 D_tricked_loss= tensor(1.1898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7474 D_real_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7474 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7474 D_tricked_loss= tensor(1.1768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7475 D_real_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7475 D_fake_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7475 D_tricked_loss= tensor(1.1300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7476 D_real_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7476 D_fake_loss= tensor(0.5131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7476 D_tricked_loss= tensor(1.1245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7477 D_real_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7477 D_fake_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7477 D_tricked_loss= tensor(1.1678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7478 D_real_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7478 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7478 D_tricked_loss= tensor(1.1913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7479 D_real_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7479 D_fake_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7479 D_tricked_loss= tensor(1.1658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7480 D_real_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7480 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7480 D_tricked_loss= tensor(1.1638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7481 D_real_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7481 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7481 D_tricked_loss= tensor(1.1996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7482 D_real_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7482 D_fake_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7482 D_tricked_loss= tensor(1.2159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7483 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7483 D_fake_loss= tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7483 D_tricked_loss= tensor(1.1506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7484 D_real_loss= tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7484 D_fake_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7484 D_tricked_loss= tensor(1.1789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7485 D_real_loss= tensor(0.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7485 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7485 D_tricked_loss= tensor(1.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7486 D_real_loss= tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7486 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7486 D_tricked_loss= tensor(1.1478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7487 D_real_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7487 D_fake_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7487 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7488 D_real_loss= tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7488 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7488 D_tricked_loss= tensor(1.1611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7489 D_real_loss= tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7489 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7489 D_tricked_loss= tensor(1.1795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7490 D_real_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7490 D_fake_loss= tensor(0.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7490 D_tricked_loss= tensor(1.1309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7491 D_real_loss= tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7491 D_fake_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7491 D_tricked_loss= tensor(1.2059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7492 D_real_loss= tensor(0.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7492 D_fake_loss= tensor(0.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7492 D_tricked_loss= tensor(1.1913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7493 D_real_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7493 D_fake_loss= tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7493 D_tricked_loss= tensor(1.2239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7494 D_real_loss= tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7494 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7494 D_tricked_loss= tensor(1.2030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7495 D_real_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7495 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7495 D_tricked_loss= tensor(1.1310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7496 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7496 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7496 D_tricked_loss= tensor(1.1939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7497 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7497 D_fake_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7497 D_tricked_loss= tensor(1.2149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7498 D_real_loss= tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7498 D_fake_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7498 D_tricked_loss= tensor(1.1571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7499 D_real_loss= tensor(0.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7499 D_fake_loss= tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7499 D_tricked_loss= tensor(1.2096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7500 D_real_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7500 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7500 D_tricked_loss= tensor(1.1725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7501 D_real_loss= tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7501 D_fake_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7501 D_tricked_loss= tensor(1.1150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7502 D_real_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7502 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7502 D_tricked_loss= tensor(1.1515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7503 D_real_loss= tensor(0.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7503 D_fake_loss= tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7503 D_tricked_loss= tensor(1.1470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7504 D_real_loss= tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7504 D_fake_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7504 D_tricked_loss= tensor(1.1677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7505 D_real_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7505 D_fake_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7505 D_tricked_loss= tensor(1.1400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7506 D_real_loss= tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7506 D_fake_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7506 D_tricked_loss= tensor(1.2123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7507 D_real_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7507 D_fake_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7507 D_tricked_loss= tensor(1.1964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7508 D_real_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7508 D_fake_loss= tensor(0.5491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7508 D_tricked_loss= tensor(1.2075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7509 D_real_loss= tensor(0.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7509 D_fake_loss= tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7509 D_tricked_loss= tensor(1.2069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7510 D_real_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7510 D_fake_loss= tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7510 D_tricked_loss= tensor(1.1713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7511 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7511 D_fake_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7511 D_tricked_loss= tensor(1.1818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7512 D_real_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7512 D_fake_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7512 D_tricked_loss= tensor(1.1298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7513 D_real_loss= tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7513 D_fake_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7513 D_tricked_loss= tensor(1.1530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7514 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7514 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7514 D_tricked_loss= tensor(1.1828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7515 D_real_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7515 D_fake_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7515 D_tricked_loss= tensor(1.2440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7516 D_real_loss= tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7516 D_fake_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7516 D_tricked_loss= tensor(1.1994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7517 D_real_loss= tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7517 D_fake_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7517 D_tricked_loss= tensor(1.1655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7518 D_real_loss= tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7518 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7518 D_tricked_loss= tensor(1.2415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7519 D_real_loss= tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7519 D_fake_loss= tensor(0.5155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7519 D_tricked_loss= tensor(1.2294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7520 D_real_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7520 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7520 D_tricked_loss= tensor(1.1630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7521 D_real_loss= tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7521 D_fake_loss= tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7521 D_tricked_loss= tensor(1.1317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7522 D_real_loss= tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7522 D_fake_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7522 D_tricked_loss= tensor(1.1783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7523 D_real_loss= tensor(0.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7523 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7523 D_tricked_loss= tensor(1.1515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7524 D_real_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7524 D_fake_loss= tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7524 D_tricked_loss= tensor(1.1569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7525 D_real_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7525 D_fake_loss= tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7525 D_tricked_loss= tensor(1.1745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7526 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7526 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7526 D_tricked_loss= tensor(1.1926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7527 D_real_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7527 D_fake_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7527 D_tricked_loss= tensor(1.2076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7528 D_real_loss= tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7528 D_fake_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7528 D_tricked_loss= tensor(1.1962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7529 D_real_loss= tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7529 D_fake_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7529 D_tricked_loss= tensor(1.1597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7530 D_real_loss= tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7530 D_fake_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7530 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7531 D_real_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7531 D_fake_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7531 D_tricked_loss= tensor(1.1686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7532 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7532 D_fake_loss= tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7532 D_tricked_loss= tensor(1.1291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7533 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7533 D_fake_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7533 D_tricked_loss= tensor(1.1685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7534 D_real_loss= tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7534 D_fake_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7534 D_tricked_loss= tensor(1.1732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7535 D_real_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7535 D_fake_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7535 D_tricked_loss= tensor(1.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7536 D_real_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7536 D_fake_loss= tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7536 D_tricked_loss= tensor(1.1951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7537 D_real_loss= tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7537 D_fake_loss= tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7537 D_tricked_loss= tensor(1.1640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7538 D_real_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7538 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7538 D_tricked_loss= tensor(1.1726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7539 D_real_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7539 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7539 D_tricked_loss= tensor(1.1411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7540 D_real_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7540 D_fake_loss= tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7540 D_tricked_loss= tensor(1.1471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7541 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7541 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7541 D_tricked_loss= tensor(1.1414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7542 D_real_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7542 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7542 D_tricked_loss= tensor(1.1409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7543 D_real_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7543 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7543 D_tricked_loss= tensor(1.1568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7544 D_real_loss= tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7544 D_fake_loss= tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7544 D_tricked_loss= tensor(1.1771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7545 D_real_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7545 D_fake_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7545 D_tricked_loss= tensor(1.1702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7546 D_real_loss= tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7546 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7546 D_tricked_loss= tensor(1.1890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7547 D_real_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7547 D_fake_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7547 D_tricked_loss= tensor(1.1479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7548 D_real_loss= tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7548 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7548 D_tricked_loss= tensor(1.1486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7549 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7549 D_fake_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7549 D_tricked_loss= tensor(1.1791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7550 D_real_loss= tensor(0.5486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7550 D_fake_loss= tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7550 D_tricked_loss= tensor(1.1384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7551 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7551 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7551 D_tricked_loss= tensor(1.2008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7552 D_real_loss= tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7552 D_fake_loss= tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7552 D_tricked_loss= tensor(1.1741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7553 D_real_loss= tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7553 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7553 D_tricked_loss= tensor(1.1994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7554 D_real_loss= tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7554 D_fake_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7554 D_tricked_loss= tensor(1.2348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7555 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7555 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7555 D_tricked_loss= tensor(1.2020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7556 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7556 D_fake_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7556 D_tricked_loss= tensor(1.1565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7557 D_real_loss= tensor(0.5392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7557 D_fake_loss= tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7557 D_tricked_loss= tensor(1.2052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7558 D_real_loss= tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7558 D_fake_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7558 D_tricked_loss= tensor(1.1681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7559 D_real_loss= tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7559 D_fake_loss= tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7559 D_tricked_loss= tensor(1.1544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7560 D_real_loss= tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7560 D_fake_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7560 D_tricked_loss= tensor(1.1657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7561 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7561 D_fake_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7561 D_tricked_loss= tensor(1.1908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7562 D_real_loss= tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7562 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7562 D_tricked_loss= tensor(1.2259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7563 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7563 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7563 D_tricked_loss= tensor(1.1663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7564 D_real_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7564 D_fake_loss= tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7564 D_tricked_loss= tensor(1.1689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7565 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7565 D_fake_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7565 D_tricked_loss= tensor(1.1375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7566 D_real_loss= tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7566 D_fake_loss= tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7566 D_tricked_loss= tensor(1.1423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7567 D_real_loss= tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7567 D_fake_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7567 D_tricked_loss= tensor(1.1515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7568 D_real_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7568 D_fake_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7568 D_tricked_loss= tensor(1.1447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7569 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7569 D_fake_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7569 D_tricked_loss= tensor(1.1792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7570 D_real_loss= tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7570 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7570 D_tricked_loss= tensor(1.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7571 D_real_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7571 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7571 D_tricked_loss= tensor(1.1825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7572 D_real_loss= tensor(0.5668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7572 D_fake_loss= tensor(0.5372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7572 D_tricked_loss= tensor(1.1988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7573 D_real_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7573 D_fake_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7573 D_tricked_loss= tensor(1.1703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7574 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7574 D_fake_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7574 D_tricked_loss= tensor(1.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7575 D_real_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7575 D_fake_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7575 D_tricked_loss= tensor(1.1351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7576 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7576 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7576 D_tricked_loss= tensor(1.1636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7577 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7577 D_fake_loss= tensor(0.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7577 D_tricked_loss= tensor(1.1857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7578 D_real_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7578 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7578 D_tricked_loss= tensor(1.2036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7579 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7579 D_fake_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7579 D_tricked_loss= tensor(1.2294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7580 D_real_loss= tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7580 D_fake_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7580 D_tricked_loss= tensor(1.2178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7581 D_real_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7581 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7581 D_tricked_loss= tensor(1.2009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7582 D_real_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7582 D_fake_loss= tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7582 D_tricked_loss= tensor(1.1644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7583 D_real_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7583 D_fake_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7583 D_tricked_loss= tensor(1.1952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7584 D_real_loss= tensor(0.5634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7584 D_fake_loss= tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7584 D_tricked_loss= tensor(1.1937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7585 D_real_loss= tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7585 D_fake_loss= tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7585 D_tricked_loss= tensor(1.1298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7586 D_real_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7586 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7586 D_tricked_loss= tensor(1.1436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7587 D_real_loss= tensor(0.5252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7587 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7587 D_tricked_loss= tensor(1.1961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7588 D_real_loss= tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7588 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7588 D_tricked_loss= tensor(1.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7589 D_real_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7589 D_fake_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7589 D_tricked_loss= tensor(1.1917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7590 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7590 D_fake_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7590 D_tricked_loss= tensor(1.1872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7591 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7591 D_fake_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7591 D_tricked_loss= tensor(1.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7592 D_real_loss= tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7592 D_fake_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7592 D_tricked_loss= tensor(1.1919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7593 D_real_loss= tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7593 D_fake_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7593 D_tricked_loss= tensor(1.2019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7594 D_real_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7594 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7594 D_tricked_loss= tensor(1.2032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7595 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7595 D_fake_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7595 D_tricked_loss= tensor(1.1876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7596 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7596 D_fake_loss= tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7596 D_tricked_loss= tensor(1.2086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7597 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7597 D_fake_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7597 D_tricked_loss= tensor(1.1792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7598 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7598 D_fake_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7598 D_tricked_loss= tensor(1.1826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7599 D_real_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7599 D_fake_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7599 D_tricked_loss= tensor(1.1819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7600 D_real_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7600 D_fake_loss= tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7600 D_tricked_loss= tensor(1.2040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7601 D_real_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7601 D_fake_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7601 D_tricked_loss= tensor(1.2224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7602 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7602 D_fake_loss= tensor(0.5131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7602 D_tricked_loss= tensor(1.1846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7603 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7603 D_fake_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7603 D_tricked_loss= tensor(1.1534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7604 D_real_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7604 D_fake_loss= tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7604 D_tricked_loss= tensor(1.1861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7605 D_real_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7605 D_fake_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7605 D_tricked_loss= tensor(1.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7606 D_real_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7606 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7606 D_tricked_loss= tensor(1.2189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7607 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7607 D_fake_loss= tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7607 D_tricked_loss= tensor(1.1802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7608 D_real_loss= tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7608 D_fake_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7608 D_tricked_loss= tensor(1.2033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7609 D_real_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7609 D_fake_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7609 D_tricked_loss= tensor(1.1645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7610 D_real_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7610 D_fake_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7610 D_tricked_loss= tensor(1.1685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7611 D_real_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7611 D_fake_loss= tensor(0.5100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7611 D_tricked_loss= tensor(1.1979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7612 D_real_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7612 D_fake_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7612 D_tricked_loss= tensor(1.1583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7613 D_real_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7613 D_fake_loss= tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7613 D_tricked_loss= tensor(1.1967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7614 D_real_loss= tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7614 D_fake_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7614 D_tricked_loss= tensor(1.2378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7615 D_real_loss= tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7615 D_fake_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7615 D_tricked_loss= tensor(1.1662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7616 D_real_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7616 D_fake_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7616 D_tricked_loss= tensor(1.1620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7617 D_real_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7617 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7617 D_tricked_loss= tensor(1.1760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7618 D_real_loss= tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7618 D_fake_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7618 D_tricked_loss= tensor(1.1743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7619 D_real_loss= tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7619 D_fake_loss= tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7619 D_tricked_loss= tensor(1.1995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7620 D_real_loss= tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7620 D_fake_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7620 D_tricked_loss= tensor(1.1899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7621 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7621 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7621 D_tricked_loss= tensor(1.2235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7622 D_real_loss= tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7622 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7622 D_tricked_loss= tensor(1.2152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7623 D_real_loss= tensor(0.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7623 D_fake_loss= tensor(0.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7623 D_tricked_loss= tensor(1.2067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7624 D_real_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7624 D_fake_loss= tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7624 D_tricked_loss= tensor(1.1717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7625 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7625 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7625 D_tricked_loss= tensor(1.1960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7626 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7626 D_fake_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7626 D_tricked_loss= tensor(1.1587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7627 D_real_loss= tensor(0.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7627 D_fake_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7627 D_tricked_loss= tensor(1.1452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7628 D_real_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7628 D_fake_loss= tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7628 D_tricked_loss= tensor(1.1519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7629 D_real_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7629 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7629 D_tricked_loss= tensor(1.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7630 D_real_loss= tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7630 D_fake_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7630 D_tricked_loss= tensor(1.2491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7631 D_real_loss= tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7631 D_fake_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7631 D_tricked_loss= tensor(1.2240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7632 D_real_loss= tensor(0.5734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7632 D_fake_loss= tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7632 D_tricked_loss= tensor(1.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7633 D_real_loss= tensor(0.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7633 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7633 D_tricked_loss= tensor(1.1931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7634 D_real_loss= tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7634 D_fake_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7634 D_tricked_loss= tensor(1.1824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7635 D_real_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7635 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7635 D_tricked_loss= tensor(1.1541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7636 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7636 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7636 D_tricked_loss= tensor(1.1849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7637 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7637 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7637 D_tricked_loss= tensor(1.1687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7638 D_real_loss= tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7638 D_fake_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7638 D_tricked_loss= tensor(1.2032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7639 D_real_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7639 D_fake_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7639 D_tricked_loss= tensor(1.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7640 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7640 D_fake_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7640 D_tricked_loss= tensor(1.2497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7641 D_real_loss= tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7641 D_fake_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7641 D_tricked_loss= tensor(1.2417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7642 D_real_loss= tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7642 D_fake_loss= tensor(0.5520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7642 D_tricked_loss= tensor(1.1596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7643 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7643 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7643 D_tricked_loss= tensor(1.1491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7644 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7644 D_fake_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7644 D_tricked_loss= tensor(1.2551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7645 D_real_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7645 D_fake_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7645 D_tricked_loss= tensor(1.2365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7646 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7646 D_fake_loss= tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7646 D_tricked_loss= tensor(1.1846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7647 D_real_loss= tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7647 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7647 D_tricked_loss= tensor(1.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7648 D_real_loss= tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7648 D_fake_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7648 D_tricked_loss= tensor(1.2009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7649 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7649 D_fake_loss= tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7649 D_tricked_loss= tensor(1.2022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7650 D_real_loss= tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7650 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7650 D_tricked_loss= tensor(1.2211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7651 D_real_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7651 D_fake_loss= tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7651 D_tricked_loss= tensor(1.2086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7652 D_real_loss= tensor(0.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7652 D_fake_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7652 D_tricked_loss= tensor(1.1401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7653 D_real_loss= tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7653 D_fake_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7653 D_tricked_loss= tensor(1.1688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7654 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7654 D_fake_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7654 D_tricked_loss= tensor(1.2042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7655 D_real_loss= tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7655 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7655 D_tricked_loss= tensor(1.2162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7656 D_real_loss= tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7656 D_fake_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7656 D_tricked_loss= tensor(1.1951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7657 D_real_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7657 D_fake_loss= tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7657 D_tricked_loss= tensor(1.1639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7658 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7658 D_fake_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7658 D_tricked_loss= tensor(1.2533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7659 D_real_loss= tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7659 D_fake_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7659 D_tricked_loss= tensor(1.2164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7660 D_real_loss= tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7660 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7660 D_tricked_loss= tensor(1.1950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7661 D_real_loss= tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7661 D_fake_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7661 D_tricked_loss= tensor(1.1626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7662 D_real_loss= tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7662 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7662 D_tricked_loss= tensor(1.1895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7663 D_real_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7663 D_fake_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7663 D_tricked_loss= tensor(1.2138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7664 D_real_loss= tensor(0.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7664 D_fake_loss= tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7664 D_tricked_loss= tensor(1.1980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7665 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7665 D_fake_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7665 D_tricked_loss= tensor(1.1579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7666 D_real_loss= tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7666 D_fake_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7666 D_tricked_loss= tensor(1.2232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7667 D_real_loss= tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7667 D_fake_loss= tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7667 D_tricked_loss= tensor(1.1471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7668 D_real_loss= tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7668 D_fake_loss= tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7668 D_tricked_loss= tensor(1.2004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7669 D_real_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7669 D_fake_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7669 D_tricked_loss= tensor(1.1691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7670 D_real_loss= tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7670 D_fake_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7670 D_tricked_loss= tensor(1.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7671 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7671 D_fake_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7671 D_tricked_loss= tensor(1.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7672 D_real_loss= tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7672 D_fake_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7672 D_tricked_loss= tensor(1.1868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7673 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7673 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7673 D_tricked_loss= tensor(1.1794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7674 D_real_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7674 D_fake_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7674 D_tricked_loss= tensor(1.2151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7675 D_real_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7675 D_fake_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7675 D_tricked_loss= tensor(1.2685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7676 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7676 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7676 D_tricked_loss= tensor(1.2011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7677 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7677 D_fake_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7677 D_tricked_loss= tensor(1.2112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7678 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7678 D_fake_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7678 D_tricked_loss= tensor(1.2191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7679 D_real_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7679 D_fake_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7679 D_tricked_loss= tensor(1.1894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7680 D_real_loss= tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7680 D_fake_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7680 D_tricked_loss= tensor(1.2174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7681 D_real_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7681 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7681 D_tricked_loss= tensor(1.2193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7682 D_real_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7682 D_fake_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7682 D_tricked_loss= tensor(1.1828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7683 D_real_loss= tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7683 D_fake_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7683 D_tricked_loss= tensor(1.2016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7684 D_real_loss= tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7684 D_fake_loss= tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7684 D_tricked_loss= tensor(1.2064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7685 D_real_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7685 D_fake_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7685 D_tricked_loss= tensor(1.1916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7686 D_real_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7686 D_fake_loss= tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7686 D_tricked_loss= tensor(1.2167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7687 D_real_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7687 D_fake_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7687 D_tricked_loss= tensor(1.1379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7688 D_real_loss= tensor(0.5414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7688 D_fake_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7688 D_tricked_loss= tensor(1.1838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7689 D_real_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7689 D_fake_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7689 D_tricked_loss= tensor(1.1943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7690 D_real_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7690 D_fake_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7690 D_tricked_loss= tensor(1.2481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7691 D_real_loss= tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7691 D_fake_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7691 D_tricked_loss= tensor(1.2063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7692 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7692 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7692 D_tricked_loss= tensor(1.2258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7693 D_real_loss= tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7693 D_fake_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7693 D_tricked_loss= tensor(1.2237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7694 D_real_loss= tensor(0.5553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7694 D_fake_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7694 D_tricked_loss= tensor(1.1866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7695 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7695 D_fake_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7695 D_tricked_loss= tensor(1.1864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7696 D_real_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7696 D_fake_loss= tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7696 D_tricked_loss= tensor(1.1603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7697 D_real_loss= tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7697 D_fake_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7697 D_tricked_loss= tensor(1.1924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7698 D_real_loss= tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7698 D_fake_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7698 D_tricked_loss= tensor(1.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7699 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7699 D_fake_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7699 D_tricked_loss= tensor(1.1917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7700 D_real_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7700 D_fake_loss= tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7700 D_tricked_loss= tensor(1.2117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7701 D_real_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7701 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7701 D_tricked_loss= tensor(1.2277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7702 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7702 D_fake_loss= tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7702 D_tricked_loss= tensor(1.1804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7703 D_real_loss= tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7703 D_fake_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7703 D_tricked_loss= tensor(1.2277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7704 D_real_loss= tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7704 D_fake_loss= tensor(0.5103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7704 D_tricked_loss= tensor(1.2102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7705 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7705 D_fake_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7705 D_tricked_loss= tensor(1.1966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7706 D_real_loss= tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7706 D_fake_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7706 D_tricked_loss= tensor(1.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7707 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7707 D_fake_loss= tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7707 D_tricked_loss= tensor(1.1925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7708 D_real_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7708 D_fake_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7708 D_tricked_loss= tensor(1.2221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7709 D_real_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7709 D_fake_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7709 D_tricked_loss= tensor(1.2391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7710 D_real_loss= tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7710 D_fake_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7710 D_tricked_loss= tensor(1.2179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7711 D_real_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7711 D_fake_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7711 D_tricked_loss= tensor(1.1978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7712 D_real_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7712 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7712 D_tricked_loss= tensor(1.1894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7713 D_real_loss= tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7713 D_fake_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7713 D_tricked_loss= tensor(1.1525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7714 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7714 D_fake_loss= tensor(0.5168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7714 D_tricked_loss= tensor(1.1974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7715 D_real_loss= tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7715 D_fake_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7715 D_tricked_loss= tensor(1.2157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7716 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7716 D_fake_loss= tensor(0.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7716 D_tricked_loss= tensor(1.2220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7717 D_real_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7717 D_fake_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7717 D_tricked_loss= tensor(1.2064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7718 D_real_loss= tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7718 D_fake_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7718 D_tricked_loss= tensor(1.2215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7719 D_real_loss= tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7719 D_fake_loss= tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7719 D_tricked_loss= tensor(1.1655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7720 D_real_loss= tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7720 D_fake_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7720 D_tricked_loss= tensor(1.1832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7721 D_real_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7721 D_fake_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7721 D_tricked_loss= tensor(1.1697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7722 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7722 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7722 D_tricked_loss= tensor(1.1891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7723 D_real_loss= tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7723 D_fake_loss= tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7723 D_tricked_loss= tensor(1.2135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7724 D_real_loss= tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7724 D_fake_loss= tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7724 D_tricked_loss= tensor(1.2458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7725 D_real_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7725 D_fake_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7725 D_tricked_loss= tensor(1.1711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7726 D_real_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7726 D_fake_loss= tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7726 D_tricked_loss= tensor(1.1789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7727 D_real_loss= tensor(0.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7727 D_fake_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7727 D_tricked_loss= tensor(1.2131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7728 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7728 D_fake_loss= tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7728 D_tricked_loss= tensor(1.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7729 D_real_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7729 D_fake_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7729 D_tricked_loss= tensor(1.1311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7730 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7730 D_fake_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7730 D_tricked_loss= tensor(1.1738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7731 D_real_loss= tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7731 D_fake_loss= tensor(0.4968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7731 D_tricked_loss= tensor(1.2121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7732 D_real_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7732 D_fake_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7732 D_tricked_loss= tensor(1.1427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7733 D_real_loss= tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7733 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7733 D_tricked_loss= tensor(1.2854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7734 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7734 D_fake_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7734 D_tricked_loss= tensor(1.2463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7735 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7735 D_fake_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7735 D_tricked_loss= tensor(1.2499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7736 D_real_loss= tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7736 D_fake_loss= tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7736 D_tricked_loss= tensor(1.2113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7737 D_real_loss= tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7737 D_fake_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7737 D_tricked_loss= tensor(1.1533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7738 D_real_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7738 D_fake_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7738 D_tricked_loss= tensor(1.1679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7739 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7739 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7739 D_tricked_loss= tensor(1.1626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7740 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7740 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7740 D_tricked_loss= tensor(1.2234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7741 D_real_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7741 D_fake_loss= tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7741 D_tricked_loss= tensor(1.2201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7742 D_real_loss= tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7742 D_fake_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7742 D_tricked_loss= tensor(1.2272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7743 D_real_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7743 D_fake_loss= tensor(0.5347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7743 D_tricked_loss= tensor(1.2298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7744 D_real_loss= tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7744 D_fake_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7744 D_tricked_loss= tensor(1.1926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7745 D_real_loss= tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7745 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7745 D_tricked_loss= tensor(1.1612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7746 D_real_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7746 D_fake_loss= tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7746 D_tricked_loss= tensor(1.1575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7747 D_real_loss= tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7747 D_fake_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7747 D_tricked_loss= tensor(1.1613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7748 D_real_loss= tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7748 D_fake_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7748 D_tricked_loss= tensor(1.1691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7749 D_real_loss= tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7749 D_fake_loss= tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7749 D_tricked_loss= tensor(1.2025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7750 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7750 D_fake_loss= tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7750 D_tricked_loss= tensor(1.2341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7751 D_real_loss= tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7751 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7751 D_tricked_loss= tensor(1.2673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7752 D_real_loss= tensor(0.5380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7752 D_fake_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7752 D_tricked_loss= tensor(1.2167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7753 D_real_loss= tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7753 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7753 D_tricked_loss= tensor(1.2283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7754 D_real_loss= tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7754 D_fake_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7754 D_tricked_loss= tensor(1.2038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7755 D_real_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7755 D_fake_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7755 D_tricked_loss= tensor(1.1594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7756 D_real_loss= tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7756 D_fake_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7756 D_tricked_loss= tensor(1.1751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7757 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7757 D_fake_loss= tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7757 D_tricked_loss= tensor(1.1984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7758 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7758 D_fake_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7758 D_tricked_loss= tensor(1.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7759 D_real_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7759 D_fake_loss= tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7759 D_tricked_loss= tensor(1.2692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7760 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7760 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7760 D_tricked_loss= tensor(1.2855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7761 D_real_loss= tensor(0.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7761 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7761 D_tricked_loss= tensor(1.2291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7762 D_real_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7762 D_fake_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7762 D_tricked_loss= tensor(1.2138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7763 D_real_loss= tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7763 D_fake_loss= tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7763 D_tricked_loss= tensor(1.1549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7764 D_real_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7764 D_fake_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7764 D_tricked_loss= tensor(1.2347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7765 D_real_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7765 D_fake_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7765 D_tricked_loss= tensor(1.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7766 D_real_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7766 D_fake_loss= tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7766 D_tricked_loss= tensor(1.1970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7767 D_real_loss= tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7767 D_fake_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7767 D_tricked_loss= tensor(1.2730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7768 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7768 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7768 D_tricked_loss= tensor(1.3093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7769 D_real_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7769 D_fake_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7769 D_tricked_loss= tensor(1.2895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7770 D_real_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7770 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7770 D_tricked_loss= tensor(1.2413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7771 D_real_loss= tensor(0.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7771 D_fake_loss= tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7771 D_tricked_loss= tensor(1.1814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7772 D_real_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7772 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7772 D_tricked_loss= tensor(1.2143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7773 D_real_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7773 D_fake_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7773 D_tricked_loss= tensor(1.1928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7774 D_real_loss= tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7774 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7774 D_tricked_loss= tensor(1.2223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7775 D_real_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7775 D_fake_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7775 D_tricked_loss= tensor(1.2423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7776 D_real_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7776 D_fake_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7776 D_tricked_loss= tensor(1.2560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7777 D_real_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7777 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7777 D_tricked_loss= tensor(1.2420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7778 D_real_loss= tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7778 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7778 D_tricked_loss= tensor(1.2710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7779 D_real_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7779 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7779 D_tricked_loss= tensor(1.2146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7780 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7780 D_fake_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7780 D_tricked_loss= tensor(1.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7781 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7781 D_fake_loss= tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7781 D_tricked_loss= tensor(1.1734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7782 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7782 D_fake_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7782 D_tricked_loss= tensor(1.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7783 D_real_loss= tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7783 D_fake_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7783 D_tricked_loss= tensor(1.2215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7784 D_real_loss= tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7784 D_fake_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7784 D_tricked_loss= tensor(1.2114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7785 D_real_loss= tensor(0.5482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7785 D_fake_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7785 D_tricked_loss= tensor(1.2759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7786 D_real_loss= tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7786 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7786 D_tricked_loss= tensor(1.2529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7787 D_real_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7787 D_fake_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7787 D_tricked_loss= tensor(1.2410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7788 D_real_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7788 D_fake_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7788 D_tricked_loss= tensor(1.2024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7789 D_real_loss= tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7789 D_fake_loss= tensor(0.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7789 D_tricked_loss= tensor(1.2142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7790 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7790 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7790 D_tricked_loss= tensor(1.2185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7791 D_real_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7791 D_fake_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7791 D_tricked_loss= tensor(1.1895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7792 D_real_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7792 D_fake_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7792 D_tricked_loss= tensor(1.1995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7793 D_real_loss= tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7793 D_fake_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7793 D_tricked_loss= tensor(1.2343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7794 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7794 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7794 D_tricked_loss= tensor(1.2851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7795 D_real_loss= tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7795 D_fake_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7795 D_tricked_loss= tensor(1.2663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7796 D_real_loss= tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7796 D_fake_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7796 D_tricked_loss= tensor(1.2195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7797 D_real_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7797 D_fake_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7797 D_tricked_loss= tensor(1.2088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7798 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7798 D_fake_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7798 D_tricked_loss= tensor(1.1930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7799 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7799 D_fake_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7799 D_tricked_loss= tensor(1.1620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7800 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7800 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7800 D_tricked_loss= tensor(1.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7801 D_real_loss= tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7801 D_fake_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7801 D_tricked_loss= tensor(1.2212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7802 D_real_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7802 D_fake_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7802 D_tricked_loss= tensor(1.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7803 D_real_loss= tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7803 D_fake_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7803 D_tricked_loss= tensor(1.2852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7804 D_real_loss= tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7804 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7804 D_tricked_loss= tensor(1.2796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7805 D_real_loss= tensor(0.5406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7805 D_fake_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7805 D_tricked_loss= tensor(1.2577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7806 D_real_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7806 D_fake_loss= tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7806 D_tricked_loss= tensor(1.1863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7807 D_real_loss= tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7807 D_fake_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7807 D_tricked_loss= tensor(1.2261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7808 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7808 D_fake_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7808 D_tricked_loss= tensor(1.2190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7809 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7809 D_fake_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7809 D_tricked_loss= tensor(1.2355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7810 D_real_loss= tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7810 D_fake_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7810 D_tricked_loss= tensor(1.2457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7811 D_real_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7811 D_fake_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7811 D_tricked_loss= tensor(1.2702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7812 D_real_loss= tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7812 D_fake_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7812 D_tricked_loss= tensor(1.2776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7813 D_real_loss= tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7813 D_fake_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7813 D_tricked_loss= tensor(1.2385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7814 D_real_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7814 D_fake_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7814 D_tricked_loss= tensor(1.2606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7815 D_real_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7815 D_fake_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7815 D_tricked_loss= tensor(1.2312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7816 D_real_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7816 D_fake_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7816 D_tricked_loss= tensor(1.2112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7817 D_real_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7817 D_fake_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7817 D_tricked_loss= tensor(1.2251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7818 D_real_loss= tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7818 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7818 D_tricked_loss= tensor(1.2307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7819 D_real_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7819 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7819 D_tricked_loss= tensor(1.2766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7820 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7820 D_fake_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7820 D_tricked_loss= tensor(1.2750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7821 D_real_loss= tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7821 D_fake_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7821 D_tricked_loss= tensor(1.2510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7822 D_real_loss= tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7822 D_fake_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7822 D_tricked_loss= tensor(1.2668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7823 D_real_loss= tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7823 D_fake_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7823 D_tricked_loss= tensor(1.2346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7824 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7824 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7824 D_tricked_loss= tensor(1.2097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7825 D_real_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7825 D_fake_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7825 D_tricked_loss= tensor(1.1556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7826 D_real_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7826 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7826 D_tricked_loss= tensor(1.1933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7827 D_real_loss= tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7827 D_fake_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7827 D_tricked_loss= tensor(1.2382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7828 D_real_loss= tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7828 D_fake_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7828 D_tricked_loss= tensor(1.2785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7829 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7829 D_fake_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7829 D_tricked_loss= tensor(1.2204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7830 D_real_loss= tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7830 D_fake_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7830 D_tricked_loss= tensor(1.2544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7831 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7831 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7831 D_tricked_loss= tensor(1.2119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7832 D_real_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7832 D_fake_loss= tensor(0.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7832 D_tricked_loss= tensor(1.1924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7833 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7833 D_fake_loss= tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7833 D_tricked_loss= tensor(1.2080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7834 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7834 D_fake_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7834 D_tricked_loss= tensor(1.2109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7835 D_real_loss= tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7835 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7835 D_tricked_loss= tensor(1.2350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7836 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7836 D_fake_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7836 D_tricked_loss= tensor(1.2402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7837 D_real_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7837 D_fake_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7837 D_tricked_loss= tensor(1.2871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7838 D_real_loss= tensor(0.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7838 D_fake_loss= tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7838 D_tricked_loss= tensor(1.2605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7839 D_real_loss= tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7839 D_fake_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7839 D_tricked_loss= tensor(1.2987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7840 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7840 D_fake_loss= tensor(0.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7840 D_tricked_loss= tensor(1.2451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7841 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7841 D_fake_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7841 D_tricked_loss= tensor(1.2389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7842 D_real_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7842 D_fake_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7842 D_tricked_loss= tensor(1.1990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7843 D_real_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7843 D_fake_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7843 D_tricked_loss= tensor(1.1916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7844 D_real_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7844 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7844 D_tricked_loss= tensor(1.2172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7845 D_real_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7845 D_fake_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7845 D_tricked_loss= tensor(1.2600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7846 D_real_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7846 D_fake_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7846 D_tricked_loss= tensor(1.2507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7847 D_real_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7847 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7847 D_tricked_loss= tensor(1.2728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7848 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7848 D_fake_loss= tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7848 D_tricked_loss= tensor(1.2263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7849 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7849 D_fake_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7849 D_tricked_loss= tensor(1.2711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7850 D_real_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7850 D_fake_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7850 D_tricked_loss= tensor(1.2214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7851 D_real_loss= tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7851 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7851 D_tricked_loss= tensor(1.2258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7852 D_real_loss= tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7852 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7852 D_tricked_loss= tensor(1.1787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7853 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7853 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7853 D_tricked_loss= tensor(1.2169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7854 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7854 D_fake_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7854 D_tricked_loss= tensor(1.2322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7855 D_real_loss= tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7855 D_fake_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7855 D_tricked_loss= tensor(1.2321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7856 D_real_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7856 D_fake_loss= tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7856 D_tricked_loss= tensor(1.2364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7857 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7857 D_fake_loss= tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7857 D_tricked_loss= tensor(1.2770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7858 D_real_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7858 D_fake_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7858 D_tricked_loss= tensor(1.2384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7859 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7859 D_fake_loss= tensor(0.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7859 D_tricked_loss= tensor(1.2228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7860 D_real_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7860 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7860 D_tricked_loss= tensor(1.2369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7861 D_real_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7861 D_fake_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7861 D_tricked_loss= tensor(1.2327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7862 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7862 D_fake_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7862 D_tricked_loss= tensor(1.2459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7863 D_real_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7863 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7863 D_tricked_loss= tensor(1.2448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7864 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7864 D_fake_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7864 D_tricked_loss= tensor(1.2959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7865 D_real_loss= tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7865 D_fake_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7865 D_tricked_loss= tensor(1.2814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7866 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7866 D_fake_loss= tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7866 D_tricked_loss= tensor(1.2723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7867 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7867 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7867 D_tricked_loss= tensor(1.2113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7868 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7868 D_fake_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7868 D_tricked_loss= tensor(1.2003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7869 D_real_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7869 D_fake_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7869 D_tricked_loss= tensor(1.2339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7870 D_real_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7870 D_fake_loss= tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7870 D_tricked_loss= tensor(1.2451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7871 D_real_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7871 D_fake_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7871 D_tricked_loss= tensor(1.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7872 D_real_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7872 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7872 D_tricked_loss= tensor(1.2868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7873 D_real_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7873 D_fake_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7873 D_tricked_loss= tensor(1.3027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7874 D_real_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7874 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7874 D_tricked_loss= tensor(1.2338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7875 D_real_loss= tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7875 D_fake_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7875 D_tricked_loss= tensor(1.2092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7876 D_real_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7876 D_fake_loss= tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7876 D_tricked_loss= tensor(1.2254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7877 D_real_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7877 D_fake_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7877 D_tricked_loss= tensor(1.1690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7878 D_real_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7878 D_fake_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7878 D_tricked_loss= tensor(1.2185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7879 D_real_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7879 D_fake_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7879 D_tricked_loss= tensor(1.2270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7880 D_real_loss= tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7880 D_fake_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7880 D_tricked_loss= tensor(1.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7881 D_real_loss= tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7881 D_fake_loss= tensor(0.5228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7881 D_tricked_loss= tensor(1.2950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7882 D_real_loss= tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7882 D_fake_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7882 D_tricked_loss= tensor(1.2827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7883 D_real_loss= tensor(0.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7883 D_fake_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7883 D_tricked_loss= tensor(1.1641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7884 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7884 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7884 D_tricked_loss= tensor(1.1590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7885 D_real_loss= tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7885 D_fake_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7885 D_tricked_loss= tensor(1.1660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7886 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7886 D_fake_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7886 D_tricked_loss= tensor(1.2509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7887 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7887 D_fake_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7887 D_tricked_loss= tensor(1.2688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7888 D_real_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7888 D_fake_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7888 D_tricked_loss= tensor(1.2757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7889 D_real_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7889 D_fake_loss= tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7889 D_tricked_loss= tensor(1.2682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7890 D_real_loss= tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7890 D_fake_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7890 D_tricked_loss= tensor(1.2855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7891 D_real_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7891 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7891 D_tricked_loss= tensor(1.2201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7892 D_real_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7892 D_fake_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7892 D_tricked_loss= tensor(1.2299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7893 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7893 D_fake_loss= tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7893 D_tricked_loss= tensor(1.2258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7894 D_real_loss= tensor(0.5131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7894 D_fake_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7894 D_tricked_loss= tensor(1.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7895 D_real_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7895 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7895 D_tricked_loss= tensor(1.2502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7896 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7896 D_fake_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7896 D_tricked_loss= tensor(1.2944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7897 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7897 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7897 D_tricked_loss= tensor(1.2925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7898 D_real_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7898 D_fake_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7898 D_tricked_loss= tensor(1.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7899 D_real_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7899 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7899 D_tricked_loss= tensor(1.2926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7900 D_real_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7900 D_fake_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7900 D_tricked_loss= tensor(1.2586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7901 D_real_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7901 D_fake_loss= tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7901 D_tricked_loss= tensor(1.2518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7902 D_real_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7902 D_fake_loss= tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7902 D_tricked_loss= tensor(1.2277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7903 D_real_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7903 D_fake_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7903 D_tricked_loss= tensor(1.2239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7904 D_real_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7904 D_fake_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7904 D_tricked_loss= tensor(1.2066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7905 D_real_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7905 D_fake_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7905 D_tricked_loss= tensor(1.2114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7906 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7906 D_fake_loss= tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7906 D_tricked_loss= tensor(1.2524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7907 D_real_loss= tensor(0.5472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7907 D_fake_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7907 D_tricked_loss= tensor(1.2511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7908 D_real_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7908 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7908 D_tricked_loss= tensor(1.2974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7909 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7909 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7909 D_tricked_loss= tensor(1.2137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7910 D_real_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7910 D_fake_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7910 D_tricked_loss= tensor(1.2556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7911 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7911 D_fake_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7911 D_tricked_loss= tensor(1.2127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7912 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7912 D_fake_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7912 D_tricked_loss= tensor(1.1838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7913 D_real_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7913 D_fake_loss= tensor(0.4850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7913 D_tricked_loss= tensor(1.2337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7914 D_real_loss= tensor(0.5345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7914 D_fake_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7914 D_tricked_loss= tensor(1.2239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7915 D_real_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7915 D_fake_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7915 D_tricked_loss= tensor(1.2603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7916 D_real_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7916 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7916 D_tricked_loss= tensor(1.2833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7917 D_real_loss= tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7917 D_fake_loss= tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7917 D_tricked_loss= tensor(1.2412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7918 D_real_loss= tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7918 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7918 D_tricked_loss= tensor(1.2182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7919 D_real_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7919 D_fake_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7919 D_tricked_loss= tensor(1.2698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7920 D_real_loss= tensor(0.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7920 D_fake_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7920 D_tricked_loss= tensor(1.2479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7921 D_real_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7921 D_fake_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7921 D_tricked_loss= tensor(1.2137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7922 D_real_loss= tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7922 D_fake_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7922 D_tricked_loss= tensor(1.1753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7923 D_real_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7923 D_fake_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7923 D_tricked_loss= tensor(1.2257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7924 D_real_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7924 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7924 D_tricked_loss= tensor(1.2281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7925 D_real_loss= tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7925 D_fake_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7925 D_tricked_loss= tensor(1.2768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7926 D_real_loss= tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7926 D_fake_loss= tensor(0.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7926 D_tricked_loss= tensor(1.2670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7927 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7927 D_fake_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7927 D_tricked_loss= tensor(1.2720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7928 D_real_loss= tensor(0.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7928 D_fake_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7928 D_tricked_loss= tensor(1.2986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7929 D_real_loss= tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7929 D_fake_loss= tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7929 D_tricked_loss= tensor(1.2293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7930 D_real_loss= tensor(0.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7930 D_fake_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7930 D_tricked_loss= tensor(1.2442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7931 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7931 D_fake_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7931 D_tricked_loss= tensor(1.2870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7932 D_real_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7932 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7932 D_tricked_loss= tensor(1.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7933 D_real_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7933 D_fake_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7933 D_tricked_loss= tensor(1.2815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7934 D_real_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7934 D_fake_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7934 D_tricked_loss= tensor(1.2648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7935 D_real_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7935 D_fake_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7935 D_tricked_loss= tensor(1.2803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7936 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7936 D_fake_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7936 D_tricked_loss= tensor(1.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7937 D_real_loss= tensor(0.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7937 D_fake_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7937 D_tricked_loss= tensor(1.2499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7938 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7938 D_fake_loss= tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7938 D_tricked_loss= tensor(1.1979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7939 D_real_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7939 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7939 D_tricked_loss= tensor(1.2183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7940 D_real_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7940 D_fake_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7940 D_tricked_loss= tensor(1.2098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7941 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7941 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7941 D_tricked_loss= tensor(1.2622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7942 D_real_loss= tensor(0.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7942 D_fake_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7942 D_tricked_loss= tensor(1.2789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7943 D_real_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7943 D_fake_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7943 D_tricked_loss= tensor(1.2928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7944 D_real_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7944 D_fake_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7944 D_tricked_loss= tensor(1.2365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7945 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7945 D_fake_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7945 D_tricked_loss= tensor(1.2852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7946 D_real_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7946 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7946 D_tricked_loss= tensor(1.2273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7947 D_real_loss= tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7947 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7947 D_tricked_loss= tensor(1.2555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7948 D_real_loss= tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7948 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7948 D_tricked_loss= tensor(1.2102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7949 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7949 D_fake_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7949 D_tricked_loss= tensor(1.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7950 D_real_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7950 D_fake_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7950 D_tricked_loss= tensor(1.2664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7951 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7951 D_fake_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7951 D_tricked_loss= tensor(1.2504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7952 D_real_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7952 D_fake_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7952 D_tricked_loss= tensor(1.2815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7953 D_real_loss= tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7953 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7953 D_tricked_loss= tensor(1.2741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7954 D_real_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7954 D_fake_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7954 D_tricked_loss= tensor(1.2204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7955 D_real_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7955 D_fake_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7955 D_tricked_loss= tensor(1.2568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7956 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7956 D_fake_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7956 D_tricked_loss= tensor(1.2176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7957 D_real_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7957 D_fake_loss= tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7957 D_tricked_loss= tensor(1.2671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7958 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7958 D_fake_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7958 D_tricked_loss= tensor(1.2833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7959 D_real_loss= tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7959 D_fake_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7959 D_tricked_loss= tensor(1.2822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7960 D_real_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7960 D_fake_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7960 D_tricked_loss= tensor(1.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7961 D_real_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7961 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7961 D_tricked_loss= tensor(1.2936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7962 D_real_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7962 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7962 D_tricked_loss= tensor(1.2527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7963 D_real_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7963 D_fake_loss= tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7963 D_tricked_loss= tensor(1.2197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7964 D_real_loss= tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7964 D_fake_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7964 D_tricked_loss= tensor(1.2477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7965 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7965 D_fake_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7965 D_tricked_loss= tensor(1.2360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7966 D_real_loss= tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7966 D_fake_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7966 D_tricked_loss= tensor(1.2420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7967 D_real_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7967 D_fake_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7967 D_tricked_loss= tensor(1.2533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7968 D_real_loss= tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7968 D_fake_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7968 D_tricked_loss= tensor(1.3141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7969 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7969 D_fake_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7969 D_tricked_loss= tensor(1.2325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7970 D_real_loss= tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7970 D_fake_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7970 D_tricked_loss= tensor(1.2245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7971 D_real_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7971 D_fake_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7971 D_tricked_loss= tensor(1.1983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7972 D_real_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7972 D_fake_loss= tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7972 D_tricked_loss= tensor(1.1864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7973 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7973 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7973 D_tricked_loss= tensor(1.2142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7974 D_real_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7974 D_fake_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7974 D_tricked_loss= tensor(1.2492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7975 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7975 D_fake_loss= tensor(0.5115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7975 D_tricked_loss= tensor(1.2911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7976 D_real_loss= tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7976 D_fake_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7976 D_tricked_loss= tensor(1.2813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7977 D_real_loss= tensor(0.5327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7977 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7977 D_tricked_loss= tensor(1.2984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7978 D_real_loss= tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7978 D_fake_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7978 D_tricked_loss= tensor(1.2592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7979 D_real_loss= tensor(0.5053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7979 D_fake_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7979 D_tricked_loss= tensor(1.2406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7980 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7980 D_fake_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7980 D_tricked_loss= tensor(1.2302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7981 D_real_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7981 D_fake_loss= tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7981 D_tricked_loss= tensor(1.2181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7982 D_real_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7982 D_fake_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7982 D_tricked_loss= tensor(1.2765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7983 D_real_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7983 D_fake_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7983 D_tricked_loss= tensor(1.2773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7984 D_real_loss= tensor(0.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7984 D_fake_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7984 D_tricked_loss= tensor(1.3039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7985 D_real_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7985 D_fake_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7985 D_tricked_loss= tensor(1.2919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7986 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7986 D_fake_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7986 D_tricked_loss= tensor(1.3268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7987 D_real_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7987 D_fake_loss= tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7987 D_tricked_loss= tensor(1.2259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7988 D_real_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7988 D_fake_loss= tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7988 D_tricked_loss= tensor(1.2148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7989 D_real_loss= tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7989 D_fake_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7989 D_tricked_loss= tensor(1.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7990 D_real_loss= tensor(0.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7990 D_fake_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7990 D_tricked_loss= tensor(1.2449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7991 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7991 D_fake_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7991 D_tricked_loss= tensor(1.2832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7992 D_real_loss= tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7992 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7992 D_tricked_loss= tensor(1.3238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7993 D_real_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7993 D_fake_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7993 D_tricked_loss= tensor(1.3055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7994 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7994 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7994 D_tricked_loss= tensor(1.2739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7995 D_real_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7995 D_fake_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7995 D_tricked_loss= tensor(1.2808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7996 D_real_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7996 D_fake_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7996 D_tricked_loss= tensor(1.2142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7997 D_real_loss= tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7997 D_fake_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7997 D_tricked_loss= tensor(1.1769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7998 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7998 D_fake_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7998 D_tricked_loss= tensor(1.2246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "7999 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7999 D_fake_loss= tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7999 D_tricked_loss= tensor(1.2293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8000 D_real_loss= tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8000 D_fake_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8000 D_tricked_loss= tensor(1.2902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8001 D_real_loss= tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8001 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8001 D_tricked_loss= tensor(1.3236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8002 D_real_loss= tensor(0.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8002 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8002 D_tricked_loss= tensor(1.2755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8003 D_real_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8003 D_fake_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8003 D_tricked_loss= tensor(1.2952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8004 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8004 D_fake_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8004 D_tricked_loss= tensor(1.2428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8005 D_real_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8005 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8005 D_tricked_loss= tensor(1.2288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8006 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8006 D_fake_loss= tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8006 D_tricked_loss= tensor(1.2119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8007 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8007 D_fake_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8007 D_tricked_loss= tensor(1.2187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8008 D_real_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8008 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8008 D_tricked_loss= tensor(1.2575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8009 D_real_loss= tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8009 D_fake_loss= tensor(0.4952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8009 D_tricked_loss= tensor(1.3574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8010 D_real_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8010 D_fake_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8010 D_tricked_loss= tensor(1.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8011 D_real_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8011 D_fake_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8011 D_tricked_loss= tensor(1.3594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8012 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8012 D_fake_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8012 D_tricked_loss= tensor(1.2812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8013 D_real_loss= tensor(0.4973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8013 D_fake_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8013 D_tricked_loss= tensor(1.2044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8014 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8014 D_fake_loss= tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8014 D_tricked_loss= tensor(1.2223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8015 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8015 D_fake_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8015 D_tricked_loss= tensor(1.2385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8016 D_real_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8016 D_fake_loss= tensor(0.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8016 D_tricked_loss= tensor(1.2764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8017 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8017 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8017 D_tricked_loss= tensor(1.3016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8018 D_real_loss= tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8018 D_fake_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8018 D_tricked_loss= tensor(1.3181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8019 D_real_loss= tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8019 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8019 D_tricked_loss= tensor(1.3202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8020 D_real_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8020 D_fake_loss= tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8020 D_tricked_loss= tensor(1.2504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8021 D_real_loss= tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8021 D_fake_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8021 D_tricked_loss= tensor(1.2177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8022 D_real_loss= tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8022 D_fake_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8022 D_tricked_loss= tensor(1.2027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8023 D_real_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8023 D_fake_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8023 D_tricked_loss= tensor(1.2055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8024 D_real_loss= tensor(0.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8024 D_fake_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8024 D_tricked_loss= tensor(1.2301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8025 D_real_loss= tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8025 D_fake_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8025 D_tricked_loss= tensor(1.2620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8026 D_real_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8026 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8026 D_tricked_loss= tensor(1.2783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8027 D_real_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8027 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8027 D_tricked_loss= tensor(1.3147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8028 D_real_loss= tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8028 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8028 D_tricked_loss= tensor(1.3438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8029 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8029 D_fake_loss= tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8029 D_tricked_loss= tensor(1.3245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8030 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8030 D_fake_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8030 D_tricked_loss= tensor(1.2435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8031 D_real_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8031 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8031 D_tricked_loss= tensor(1.2306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8032 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8032 D_fake_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8032 D_tricked_loss= tensor(1.2449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8033 D_real_loss= tensor(0.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8033 D_fake_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8033 D_tricked_loss= tensor(1.2776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8034 D_real_loss= tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8034 D_fake_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8034 D_tricked_loss= tensor(1.3166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8035 D_real_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8035 D_fake_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8035 D_tricked_loss= tensor(1.2491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8036 D_real_loss= tensor(0.5399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8036 D_fake_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8036 D_tricked_loss= tensor(1.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8037 D_real_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8037 D_fake_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8037 D_tricked_loss= tensor(1.3066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8038 D_real_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8038 D_fake_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8038 D_tricked_loss= tensor(1.2664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8039 D_real_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8039 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8039 D_tricked_loss= tensor(1.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8040 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8040 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8040 D_tricked_loss= tensor(1.1876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8041 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8041 D_fake_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8041 D_tricked_loss= tensor(1.2153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8042 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8042 D_fake_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8042 D_tricked_loss= tensor(1.2473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8043 D_real_loss= tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8043 D_fake_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8043 D_tricked_loss= tensor(1.3052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8044 D_real_loss= tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8044 D_fake_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8044 D_tricked_loss= tensor(1.3692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8045 D_real_loss= tensor(0.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8045 D_fake_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8045 D_tricked_loss= tensor(1.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8046 D_real_loss= tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8046 D_fake_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8046 D_tricked_loss= tensor(1.2834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8047 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8047 D_fake_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8047 D_tricked_loss= tensor(1.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8048 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8048 D_fake_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8048 D_tricked_loss= tensor(1.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8049 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8049 D_fake_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8049 D_tricked_loss= tensor(1.2470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8050 D_real_loss= tensor(0.5439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8050 D_fake_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8050 D_tricked_loss= tensor(1.2619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8051 D_real_loss= tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8051 D_fake_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8051 D_tricked_loss= tensor(1.3120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8052 D_real_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8052 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8052 D_tricked_loss= tensor(1.3325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8053 D_real_loss= tensor(0.5368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8053 D_fake_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8053 D_tricked_loss= tensor(1.3175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8054 D_real_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8054 D_fake_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8054 D_tricked_loss= tensor(1.2820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8055 D_real_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8055 D_fake_loss= tensor(0.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8055 D_tricked_loss= tensor(1.2514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8056 D_real_loss= tensor(0.4973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8056 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8056 D_tricked_loss= tensor(1.2094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8057 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8057 D_fake_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8057 D_tricked_loss= tensor(1.2381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8058 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8058 D_fake_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8058 D_tricked_loss= tensor(1.2139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8059 D_real_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8059 D_fake_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8059 D_tricked_loss= tensor(1.2571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8060 D_real_loss= tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8060 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8060 D_tricked_loss= tensor(1.3041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8061 D_real_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8061 D_fake_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8061 D_tricked_loss= tensor(1.3571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8062 D_real_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8062 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8062 D_tricked_loss= tensor(1.3449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8063 D_real_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8063 D_fake_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8063 D_tricked_loss= tensor(1.2995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8064 D_real_loss= tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8064 D_fake_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8064 D_tricked_loss= tensor(1.2340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8065 D_real_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8065 D_fake_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8065 D_tricked_loss= tensor(1.2238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8066 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8066 D_fake_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8066 D_tricked_loss= tensor(1.2366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8067 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8067 D_fake_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8067 D_tricked_loss= tensor(1.2359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8068 D_real_loss= tensor(0.5218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8068 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8068 D_tricked_loss= tensor(1.2904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8069 D_real_loss= tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8069 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8069 D_tricked_loss= tensor(1.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8070 D_real_loss= tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8070 D_fake_loss= tensor(0.4903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8070 D_tricked_loss= tensor(1.3526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8071 D_real_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8071 D_fake_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8071 D_tricked_loss= tensor(1.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8072 D_real_loss= tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8072 D_fake_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8072 D_tricked_loss= tensor(1.2453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8073 D_real_loss= tensor(0.4949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8073 D_fake_loss= tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8073 D_tricked_loss= tensor(1.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8074 D_real_loss= tensor(0.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8074 D_fake_loss= tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8074 D_tricked_loss= tensor(1.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8075 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8075 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8075 D_tricked_loss= tensor(1.2408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8076 D_real_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8076 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8076 D_tricked_loss= tensor(1.2433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8077 D_real_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8077 D_fake_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8077 D_tricked_loss= tensor(1.3101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8078 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8078 D_fake_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8078 D_tricked_loss= tensor(1.3315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8079 D_real_loss= tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8079 D_fake_loss= tensor(0.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8079 D_tricked_loss= tensor(1.2998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8080 D_real_loss= tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8080 D_fake_loss= tensor(0.5012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8080 D_tricked_loss= tensor(1.2687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8081 D_real_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8081 D_fake_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8081 D_tricked_loss= tensor(1.2853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8082 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8082 D_fake_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8082 D_tricked_loss= tensor(1.2357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8083 D_real_loss= tensor(0.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8083 D_fake_loss= tensor(0.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8083 D_tricked_loss= tensor(1.2298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8084 D_real_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8084 D_fake_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8084 D_tricked_loss= tensor(1.2505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8085 D_real_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8085 D_fake_loss= tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8085 D_tricked_loss= tensor(1.2590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8086 D_real_loss= tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8086 D_fake_loss= tensor(0.5115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8086 D_tricked_loss= tensor(1.2628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8087 D_real_loss= tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8087 D_fake_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8087 D_tricked_loss= tensor(1.3493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8088 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8088 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8088 D_tricked_loss= tensor(1.3163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8089 D_real_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8089 D_fake_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8089 D_tricked_loss= tensor(1.2666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8090 D_real_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8090 D_fake_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8090 D_tricked_loss= tensor(1.2333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8091 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8091 D_fake_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8091 D_tricked_loss= tensor(1.2004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8092 D_real_loss= tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8092 D_fake_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8092 D_tricked_loss= tensor(1.2386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8093 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8093 D_fake_loss= tensor(0.5103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8093 D_tricked_loss= tensor(1.2563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8094 D_real_loss= tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8094 D_fake_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8094 D_tricked_loss= tensor(1.3059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8095 D_real_loss= tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8095 D_fake_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8095 D_tricked_loss= tensor(1.3280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8096 D_real_loss= tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8096 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8096 D_tricked_loss= tensor(1.3961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8097 D_real_loss= tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8097 D_fake_loss= tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8097 D_tricked_loss= tensor(1.3394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8098 D_real_loss= tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8098 D_fake_loss= tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8098 D_tricked_loss= tensor(1.2412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8099 D_real_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8099 D_fake_loss= tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8099 D_tricked_loss= tensor(1.1883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8100 D_real_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8100 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8100 D_tricked_loss= tensor(1.2035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8101 D_real_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8101 D_fake_loss= tensor(0.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8101 D_tricked_loss= tensor(1.2699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8102 D_real_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8102 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8102 D_tricked_loss= tensor(1.2931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8103 D_real_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8103 D_fake_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8103 D_tricked_loss= tensor(1.3383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8104 D_real_loss= tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8104 D_fake_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8104 D_tricked_loss= tensor(1.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8105 D_real_loss= tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8105 D_fake_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8105 D_tricked_loss= tensor(1.3553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8106 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8106 D_fake_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8106 D_tricked_loss= tensor(1.2775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8107 D_real_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8107 D_fake_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8107 D_tricked_loss= tensor(1.2126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8108 D_real_loss= tensor(0.4968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8108 D_fake_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8108 D_tricked_loss= tensor(1.1918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8109 D_real_loss= tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8109 D_fake_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8109 D_tricked_loss= tensor(1.2816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8110 D_real_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8110 D_fake_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8110 D_tricked_loss= tensor(1.2462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8111 D_real_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8111 D_fake_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8111 D_tricked_loss= tensor(1.2946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8112 D_real_loss= tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8112 D_fake_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8112 D_tricked_loss= tensor(1.3681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8113 D_real_loss= tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8113 D_fake_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8113 D_tricked_loss= tensor(1.3554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8114 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8114 D_fake_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8114 D_tricked_loss= tensor(1.3507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8115 D_real_loss= tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8115 D_fake_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8115 D_tricked_loss= tensor(1.3074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8116 D_real_loss= tensor(0.4902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8116 D_fake_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8116 D_tricked_loss= tensor(1.2218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8117 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8117 D_fake_loss= tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8117 D_tricked_loss= tensor(1.2329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8118 D_real_loss= tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8118 D_fake_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8118 D_tricked_loss= tensor(1.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8119 D_real_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8119 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8119 D_tricked_loss= tensor(1.2679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8120 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8120 D_fake_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8120 D_tricked_loss= tensor(1.2943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8121 D_real_loss= tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8121 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8121 D_tricked_loss= tensor(1.3763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8122 D_real_loss= tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8122 D_fake_loss= tensor(0.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8122 D_tricked_loss= tensor(1.3563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8123 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8123 D_fake_loss= tensor(0.4950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8123 D_tricked_loss= tensor(1.3551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8124 D_real_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8124 D_fake_loss= tensor(0.5214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8124 D_tricked_loss= tensor(1.2777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8125 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8125 D_fake_loss= tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8125 D_tricked_loss= tensor(1.2365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8126 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8126 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8126 D_tricked_loss= tensor(1.2024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8127 D_real_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8127 D_fake_loss= tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8127 D_tricked_loss= tensor(1.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8128 D_real_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8128 D_fake_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8128 D_tricked_loss= tensor(1.2819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8129 D_real_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8129 D_fake_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8129 D_tricked_loss= tensor(1.3078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8130 D_real_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8130 D_fake_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8130 D_tricked_loss= tensor(1.3545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8131 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8131 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8131 D_tricked_loss= tensor(1.3506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8132 D_real_loss= tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8132 D_fake_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8132 D_tricked_loss= tensor(1.3827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8133 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8133 D_fake_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8133 D_tricked_loss= tensor(1.3503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8134 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8134 D_fake_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8134 D_tricked_loss= tensor(1.2807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8135 D_real_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8135 D_fake_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8135 D_tricked_loss= tensor(1.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8136 D_real_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8136 D_fake_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8136 D_tricked_loss= tensor(1.2204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8137 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8137 D_fake_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8137 D_tricked_loss= tensor(1.2424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8138 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8138 D_fake_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8138 D_tricked_loss= tensor(1.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8139 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8139 D_fake_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8139 D_tricked_loss= tensor(1.3068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8140 D_real_loss= tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8140 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8140 D_tricked_loss= tensor(1.3284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8141 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8141 D_fake_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8141 D_tricked_loss= tensor(1.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8142 D_real_loss= tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8142 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8142 D_tricked_loss= tensor(1.3163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8143 D_real_loss= tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8143 D_fake_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8143 D_tricked_loss= tensor(1.3358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8144 D_real_loss= tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8144 D_fake_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8144 D_tricked_loss= tensor(1.2668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8145 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8145 D_fake_loss= tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8145 D_tricked_loss= tensor(1.2544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8146 D_real_loss= tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8146 D_fake_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8146 D_tricked_loss= tensor(1.2729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8147 D_real_loss= tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8147 D_fake_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8147 D_tricked_loss= tensor(1.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8148 D_real_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8148 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8148 D_tricked_loss= tensor(1.3151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8149 D_real_loss= tensor(0.5228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8149 D_fake_loss= tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8149 D_tricked_loss= tensor(1.3317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8150 D_real_loss= tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8150 D_fake_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8150 D_tricked_loss= tensor(1.3453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8151 D_real_loss= tensor(0.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8151 D_fake_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8151 D_tricked_loss= tensor(1.3464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8152 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8152 D_fake_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8152 D_tricked_loss= tensor(1.2870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8153 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8153 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8153 D_tricked_loss= tensor(1.2948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8154 D_real_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8154 D_fake_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8154 D_tricked_loss= tensor(1.2614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8155 D_real_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8155 D_fake_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8155 D_tricked_loss= tensor(1.2934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8156 D_real_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8156 D_fake_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8156 D_tricked_loss= tensor(1.3132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8157 D_real_loss= tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8157 D_fake_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8157 D_tricked_loss= tensor(1.2922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8158 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8158 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8158 D_tricked_loss= tensor(1.3000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8159 D_real_loss= tensor(0.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8159 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8159 D_tricked_loss= tensor(1.3984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8160 D_real_loss= tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8160 D_fake_loss= tensor(0.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8160 D_tricked_loss= tensor(1.3221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8161 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8161 D_fake_loss= tensor(0.5012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8161 D_tricked_loss= tensor(1.3096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8162 D_real_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8162 D_fake_loss= tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8162 D_tricked_loss= tensor(1.2352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8163 D_real_loss= tensor(0.5073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8163 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8163 D_tricked_loss= tensor(1.2663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8164 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8164 D_fake_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8164 D_tricked_loss= tensor(1.2793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8165 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8165 D_fake_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8165 D_tricked_loss= tensor(1.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8166 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8166 D_fake_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8166 D_tricked_loss= tensor(1.3236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8167 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8167 D_fake_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8167 D_tricked_loss= tensor(1.3349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8168 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8168 D_fake_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8168 D_tricked_loss= tensor(1.3385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8169 D_real_loss= tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8169 D_fake_loss= tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8169 D_tricked_loss= tensor(1.3335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8170 D_real_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8170 D_fake_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8170 D_tricked_loss= tensor(1.2892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8171 D_real_loss= tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8171 D_fake_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8171 D_tricked_loss= tensor(1.2725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8172 D_real_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8172 D_fake_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8172 D_tricked_loss= tensor(1.2445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8173 D_real_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8173 D_fake_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8173 D_tricked_loss= tensor(1.2570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8174 D_real_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8174 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8174 D_tricked_loss= tensor(1.2896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8175 D_real_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8175 D_fake_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8175 D_tricked_loss= tensor(1.3147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8176 D_real_loss= tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8176 D_fake_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8176 D_tricked_loss= tensor(1.3186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8177 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8177 D_fake_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8177 D_tricked_loss= tensor(1.3124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8178 D_real_loss= tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8178 D_fake_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8178 D_tricked_loss= tensor(1.3077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8179 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8179 D_fake_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8179 D_tricked_loss= tensor(1.2947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8180 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8180 D_fake_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8180 D_tricked_loss= tensor(1.2807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8181 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8181 D_fake_loss= tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8181 D_tricked_loss= tensor(1.2526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8182 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8182 D_fake_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8182 D_tricked_loss= tensor(1.2862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8183 D_real_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8183 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8183 D_tricked_loss= tensor(1.2982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8184 D_real_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8184 D_fake_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8184 D_tricked_loss= tensor(1.3150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8185 D_real_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8185 D_fake_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8185 D_tricked_loss= tensor(1.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8186 D_real_loss= tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8186 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8186 D_tricked_loss= tensor(1.3518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8187 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8187 D_fake_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8187 D_tricked_loss= tensor(1.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8188 D_real_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8188 D_fake_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8188 D_tricked_loss= tensor(1.3630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8189 D_real_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8189 D_fake_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8189 D_tricked_loss= tensor(1.2863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8190 D_real_loss= tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8190 D_fake_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8190 D_tricked_loss= tensor(1.2620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8191 D_real_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8191 D_fake_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8191 D_tricked_loss= tensor(1.2664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8192 D_real_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8192 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8192 D_tricked_loss= tensor(1.2941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8193 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8193 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8193 D_tricked_loss= tensor(1.3206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8194 D_real_loss= tensor(0.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8194 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8194 D_tricked_loss= tensor(1.3685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8195 D_real_loss= tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8195 D_fake_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8195 D_tricked_loss= tensor(1.3327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8196 D_real_loss= tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8196 D_fake_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8196 D_tricked_loss= tensor(1.3380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8197 D_real_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8197 D_fake_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8197 D_tricked_loss= tensor(1.3309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8198 D_real_loss= tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8198 D_fake_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8198 D_tricked_loss= tensor(1.2847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8199 D_real_loss= tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8199 D_fake_loss= tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8199 D_tricked_loss= tensor(1.2901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8200 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8200 D_fake_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8200 D_tricked_loss= tensor(1.3063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8201 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8201 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8201 D_tricked_loss= tensor(1.3193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8202 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8202 D_fake_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8202 D_tricked_loss= tensor(1.3409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8203 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8203 D_fake_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8203 D_tricked_loss= tensor(1.3484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8204 D_real_loss= tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8204 D_fake_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8204 D_tricked_loss= tensor(1.3650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8205 D_real_loss= tensor(0.5155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8205 D_fake_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8205 D_tricked_loss= tensor(1.3272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8206 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8206 D_fake_loss= tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8206 D_tricked_loss= tensor(1.2929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8207 D_real_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8207 D_fake_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8207 D_tricked_loss= tensor(1.2814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8208 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8208 D_fake_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8208 D_tricked_loss= tensor(1.2776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8209 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8209 D_fake_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8209 D_tricked_loss= tensor(1.2624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8210 D_real_loss= tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8210 D_fake_loss= tensor(0.4778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8210 D_tricked_loss= tensor(1.2785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8211 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8211 D_fake_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8211 D_tricked_loss= tensor(1.2485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8212 D_real_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8212 D_fake_loss= tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8212 D_tricked_loss= tensor(1.3131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8213 D_real_loss= tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8213 D_fake_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8213 D_tricked_loss= tensor(1.2970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8214 D_real_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8214 D_fake_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8214 D_tricked_loss= tensor(1.2678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8215 D_real_loss= tensor(0.5225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8215 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8215 D_tricked_loss= tensor(1.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8216 D_real_loss= tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8216 D_fake_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8216 D_tricked_loss= tensor(1.2968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8217 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8217 D_fake_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8217 D_tricked_loss= tensor(1.3204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8218 D_real_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8218 D_fake_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8218 D_tricked_loss= tensor(1.3246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8219 D_real_loss= tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8219 D_fake_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8219 D_tricked_loss= tensor(1.2840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8220 D_real_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8220 D_fake_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8220 D_tricked_loss= tensor(1.3164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8221 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8221 D_fake_loss= tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8221 D_tricked_loss= tensor(1.3119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8222 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8222 D_fake_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8222 D_tricked_loss= tensor(1.3481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8223 D_real_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8223 D_fake_loss= tensor(0.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8223 D_tricked_loss= tensor(1.3353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8224 D_real_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8224 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8224 D_tricked_loss= tensor(1.2739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8225 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8225 D_fake_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8225 D_tricked_loss= tensor(1.2859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8226 D_real_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8226 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8226 D_tricked_loss= tensor(1.2673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8227 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8227 D_fake_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8227 D_tricked_loss= tensor(1.2722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8228 D_real_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8228 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8228 D_tricked_loss= tensor(1.2759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8229 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8229 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8229 D_tricked_loss= tensor(1.2472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8230 D_real_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8230 D_fake_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8230 D_tricked_loss= tensor(1.3006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8231 D_real_loss= tensor(0.5305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8231 D_fake_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8231 D_tricked_loss= tensor(1.3482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8232 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8232 D_fake_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8232 D_tricked_loss= tensor(1.3006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8233 D_real_loss= tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8233 D_fake_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8233 D_tricked_loss= tensor(1.3051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8234 D_real_loss= tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8234 D_fake_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8234 D_tricked_loss= tensor(1.3120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8235 D_real_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8235 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8235 D_tricked_loss= tensor(1.2622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8236 D_real_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8236 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8236 D_tricked_loss= tensor(1.2693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8237 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8237 D_fake_loss= tensor(0.4850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8237 D_tricked_loss= tensor(1.2892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8238 D_real_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8238 D_fake_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8238 D_tricked_loss= tensor(1.2990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8239 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8239 D_fake_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8239 D_tricked_loss= tensor(1.2700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8240 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8240 D_fake_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8240 D_tricked_loss= tensor(1.2972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8241 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8241 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8241 D_tricked_loss= tensor(1.3366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8242 D_real_loss= tensor(0.5303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8242 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8242 D_tricked_loss= tensor(1.3130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8243 D_real_loss= tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8243 D_fake_loss= tensor(0.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8243 D_tricked_loss= tensor(1.3235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8244 D_real_loss= tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8244 D_fake_loss= tensor(0.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8244 D_tricked_loss= tensor(1.3287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8245 D_real_loss= tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8245 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8245 D_tricked_loss= tensor(1.2633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8246 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8246 D_fake_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8246 D_tricked_loss= tensor(1.2783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8247 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8247 D_fake_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8247 D_tricked_loss= tensor(1.2927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8248 D_real_loss= tensor(0.5329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8248 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8248 D_tricked_loss= tensor(1.2529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8249 D_real_loss= tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8249 D_fake_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8249 D_tricked_loss= tensor(1.2689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8250 D_real_loss= tensor(0.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8250 D_fake_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8250 D_tricked_loss= tensor(1.3292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8251 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8251 D_fake_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8251 D_tricked_loss= tensor(1.2858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8252 D_real_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8252 D_fake_loss= tensor(0.5131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8252 D_tricked_loss= tensor(1.3410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8253 D_real_loss= tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8253 D_fake_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8253 D_tricked_loss= tensor(1.2893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8254 D_real_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8254 D_fake_loss= tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8254 D_tricked_loss= tensor(1.3052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8255 D_real_loss= tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8255 D_fake_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8255 D_tricked_loss= tensor(1.3306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8256 D_real_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8256 D_fake_loss= tensor(0.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8256 D_tricked_loss= tensor(1.2713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8257 D_real_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8257 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8257 D_tricked_loss= tensor(1.3129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8258 D_real_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8258 D_fake_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8258 D_tricked_loss= tensor(1.2673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8259 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8259 D_fake_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8259 D_tricked_loss= tensor(1.3086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8260 D_real_loss= tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8260 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8260 D_tricked_loss= tensor(1.3492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8261 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8261 D_fake_loss= tensor(0.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8261 D_tricked_loss= tensor(1.3228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8262 D_real_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8262 D_fake_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8262 D_tricked_loss= tensor(1.2423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8263 D_real_loss= tensor(0.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8263 D_fake_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8263 D_tricked_loss= tensor(1.2474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8264 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8264 D_fake_loss= tensor(0.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8264 D_tricked_loss= tensor(1.2961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8265 D_real_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8265 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8265 D_tricked_loss= tensor(1.2816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8266 D_real_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8266 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8266 D_tricked_loss= tensor(1.3161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8267 D_real_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8267 D_fake_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8267 D_tricked_loss= tensor(1.3046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8268 D_real_loss= tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8268 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8268 D_tricked_loss= tensor(1.3296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8269 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8269 D_fake_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8269 D_tricked_loss= tensor(1.3066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8270 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8270 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8270 D_tricked_loss= tensor(1.3399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8271 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8271 D_fake_loss= tensor(0.4902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8271 D_tricked_loss= tensor(1.3074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8272 D_real_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8272 D_fake_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8272 D_tricked_loss= tensor(1.2971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8273 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8273 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8273 D_tricked_loss= tensor(1.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8274 D_real_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8274 D_fake_loss= tensor(0.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8274 D_tricked_loss= tensor(1.2960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8275 D_real_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8275 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8275 D_tricked_loss= tensor(1.2447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8276 D_real_loss= tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8276 D_fake_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8276 D_tricked_loss= tensor(1.3278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8277 D_real_loss= tensor(0.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8277 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8277 D_tricked_loss= tensor(1.3188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8278 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8278 D_fake_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8278 D_tricked_loss= tensor(1.3236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8279 D_real_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8279 D_fake_loss= tensor(0.5012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8279 D_tricked_loss= tensor(1.2980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8280 D_real_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8280 D_fake_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8280 D_tricked_loss= tensor(1.3884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8281 D_real_loss= tensor(0.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8281 D_fake_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8281 D_tricked_loss= tensor(1.3606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8282 D_real_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8282 D_fake_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8282 D_tricked_loss= tensor(1.3013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8283 D_real_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8283 D_fake_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8283 D_tricked_loss= tensor(1.2995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8284 D_real_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8284 D_fake_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8284 D_tricked_loss= tensor(1.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8285 D_real_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8285 D_fake_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8285 D_tricked_loss= tensor(1.3192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8286 D_real_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8286 D_fake_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8286 D_tricked_loss= tensor(1.2936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8287 D_real_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8287 D_fake_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8287 D_tricked_loss= tensor(1.3481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8288 D_real_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8288 D_fake_loss= tensor(0.4997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8288 D_tricked_loss= tensor(1.3438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8289 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8289 D_fake_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8289 D_tricked_loss= tensor(1.3454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8290 D_real_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8290 D_fake_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8290 D_tricked_loss= tensor(1.3331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8291 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8291 D_fake_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8291 D_tricked_loss= tensor(1.3001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8292 D_real_loss= tensor(0.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8292 D_fake_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8292 D_tricked_loss= tensor(1.3293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8293 D_real_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8293 D_fake_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8293 D_tricked_loss= tensor(1.3083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8294 D_real_loss= tensor(0.5228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8294 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8294 D_tricked_loss= tensor(1.3221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8295 D_real_loss= tensor(0.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8295 D_fake_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8295 D_tricked_loss= tensor(1.3043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8296 D_real_loss= tensor(0.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8296 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8296 D_tricked_loss= tensor(1.3470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8297 D_real_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8297 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8297 D_tricked_loss= tensor(1.3420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8298 D_real_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8298 D_fake_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8298 D_tricked_loss= tensor(1.2911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8299 D_real_loss= tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8299 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8299 D_tricked_loss= tensor(1.2871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8300 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8300 D_fake_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8300 D_tricked_loss= tensor(1.2952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8301 D_real_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8301 D_fake_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8301 D_tricked_loss= tensor(1.3215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8302 D_real_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8302 D_fake_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8302 D_tricked_loss= tensor(1.2657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8303 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8303 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8303 D_tricked_loss= tensor(1.3112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8304 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8304 D_fake_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8304 D_tricked_loss= tensor(1.3293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8305 D_real_loss= tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8305 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8305 D_tricked_loss= tensor(1.3286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8306 D_real_loss= tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8306 D_fake_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8306 D_tricked_loss= tensor(1.3352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8307 D_real_loss= tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8307 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8307 D_tricked_loss= tensor(1.2926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8308 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8308 D_fake_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8308 D_tricked_loss= tensor(1.2881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8309 D_real_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8309 D_fake_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8309 D_tricked_loss= tensor(1.2806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8310 D_real_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8310 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8310 D_tricked_loss= tensor(1.2750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8311 D_real_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8311 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8311 D_tricked_loss= tensor(1.3407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8312 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8312 D_fake_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8312 D_tricked_loss= tensor(1.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8313 D_real_loss= tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8313 D_fake_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8313 D_tricked_loss= tensor(1.3502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8314 D_real_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8314 D_fake_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8314 D_tricked_loss= tensor(1.3200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8315 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8315 D_fake_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8315 D_tricked_loss= tensor(1.3160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8316 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8316 D_fake_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8316 D_tricked_loss= tensor(1.2879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8317 D_real_loss= tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8317 D_fake_loss= tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8317 D_tricked_loss= tensor(1.3064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8318 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8318 D_fake_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8318 D_tricked_loss= tensor(1.3234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8319 D_real_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8319 D_fake_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8319 D_tricked_loss= tensor(1.3198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8320 D_real_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8320 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8320 D_tricked_loss= tensor(1.3239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8321 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8321 D_fake_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8321 D_tricked_loss= tensor(1.3107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8322 D_real_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8322 D_fake_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8322 D_tricked_loss= tensor(1.3472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8323 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8323 D_fake_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8323 D_tricked_loss= tensor(1.3401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8324 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8324 D_fake_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8324 D_tricked_loss= tensor(1.3133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8325 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8325 D_fake_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8325 D_tricked_loss= tensor(1.3267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8326 D_real_loss= tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8326 D_fake_loss= tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8326 D_tricked_loss= tensor(1.2884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8327 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8327 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8327 D_tricked_loss= tensor(1.3059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8328 D_real_loss= tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8328 D_fake_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8328 D_tricked_loss= tensor(1.3231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8329 D_real_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8329 D_fake_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8329 D_tricked_loss= tensor(1.3691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8330 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8330 D_fake_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8330 D_tricked_loss= tensor(1.3421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8331 D_real_loss= tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8331 D_fake_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8331 D_tricked_loss= tensor(1.3294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8332 D_real_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8332 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8332 D_tricked_loss= tensor(1.3025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8333 D_real_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8333 D_fake_loss= tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8333 D_tricked_loss= tensor(1.2586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8334 D_real_loss= tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8334 D_fake_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8334 D_tricked_loss= tensor(1.3457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8335 D_real_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8335 D_fake_loss= tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8335 D_tricked_loss= tensor(1.3050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8336 D_real_loss= tensor(0.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8336 D_fake_loss= tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8336 D_tricked_loss= tensor(1.3150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8337 D_real_loss= tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8337 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8337 D_tricked_loss= tensor(1.3407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8338 D_real_loss= tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8338 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8338 D_tricked_loss= tensor(1.3394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8339 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8339 D_fake_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8339 D_tricked_loss= tensor(1.3097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8340 D_real_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8340 D_fake_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8340 D_tricked_loss= tensor(1.2822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8341 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8341 D_fake_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8341 D_tricked_loss= tensor(1.3160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8342 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8342 D_fake_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8342 D_tricked_loss= tensor(1.2807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8343 D_real_loss= tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8343 D_fake_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8343 D_tricked_loss= tensor(1.2938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8344 D_real_loss= tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8344 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8344 D_tricked_loss= tensor(1.3011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8345 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8345 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8345 D_tricked_loss= tensor(1.3040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8346 D_real_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8346 D_fake_loss= tensor(0.5025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8346 D_tricked_loss= tensor(1.2907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8347 D_real_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8347 D_fake_loss= tensor(0.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8347 D_tricked_loss= tensor(1.2775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8348 D_real_loss= tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8348 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8348 D_tricked_loss= tensor(1.3034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8349 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8349 D_fake_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8349 D_tricked_loss= tensor(1.2759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8350 D_real_loss= tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8350 D_fake_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8350 D_tricked_loss= tensor(1.3126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8351 D_real_loss= tensor(0.5243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8351 D_fake_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8351 D_tricked_loss= tensor(1.3134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8352 D_real_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8352 D_fake_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8352 D_tricked_loss= tensor(1.3215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8353 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8353 D_fake_loss= tensor(0.5053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8353 D_tricked_loss= tensor(1.3409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8354 D_real_loss= tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8354 D_fake_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8354 D_tricked_loss= tensor(1.2966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8355 D_real_loss= tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8355 D_fake_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8355 D_tricked_loss= tensor(1.3204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8356 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8356 D_fake_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8356 D_tricked_loss= tensor(1.3285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8357 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8357 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8357 D_tricked_loss= tensor(1.3113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8358 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8358 D_fake_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8358 D_tricked_loss= tensor(1.2870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8359 D_real_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8359 D_fake_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8359 D_tricked_loss= tensor(1.3434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8360 D_real_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8360 D_fake_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8360 D_tricked_loss= tensor(1.3332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8361 D_real_loss= tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8361 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8361 D_tricked_loss= tensor(1.3453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8362 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8362 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8362 D_tricked_loss= tensor(1.3321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8363 D_real_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8363 D_fake_loss= tensor(0.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8363 D_tricked_loss= tensor(1.3674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8364 D_real_loss= tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8364 D_fake_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8364 D_tricked_loss= tensor(1.3394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8365 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8365 D_fake_loss= tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8365 D_tricked_loss= tensor(1.3498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8366 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8366 D_fake_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8366 D_tricked_loss= tensor(1.3269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8367 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8367 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8367 D_tricked_loss= tensor(1.2966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8368 D_real_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8368 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8368 D_tricked_loss= tensor(1.3132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8369 D_real_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8369 D_fake_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8369 D_tricked_loss= tensor(1.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8370 D_real_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8370 D_fake_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8370 D_tricked_loss= tensor(1.3667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8371 D_real_loss= tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8371 D_fake_loss= tensor(0.4527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8371 D_tricked_loss= tensor(1.3199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8372 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8372 D_fake_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8372 D_tricked_loss= tensor(1.3459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8373 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8373 D_fake_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8373 D_tricked_loss= tensor(1.3551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8374 D_real_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8374 D_fake_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8374 D_tricked_loss= tensor(1.3397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8375 D_real_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8375 D_fake_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8375 D_tricked_loss= tensor(1.2474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8376 D_real_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8376 D_fake_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8376 D_tricked_loss= tensor(1.2990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8377 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8377 D_fake_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8377 D_tricked_loss= tensor(1.3336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8378 D_real_loss= tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8378 D_fake_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8378 D_tricked_loss= tensor(1.3768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8379 D_real_loss= tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8379 D_fake_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8379 D_tricked_loss= tensor(1.3467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8380 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8380 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8380 D_tricked_loss= tensor(1.3888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8381 D_real_loss= tensor(0.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8381 D_fake_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8381 D_tricked_loss= tensor(1.3256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8382 D_real_loss= tensor(0.5115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8382 D_fake_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8382 D_tricked_loss= tensor(1.2808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8383 D_real_loss= tensor(0.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8383 D_fake_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8383 D_tricked_loss= tensor(1.2451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8384 D_real_loss= tensor(0.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8384 D_fake_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8384 D_tricked_loss= tensor(1.2750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8385 D_real_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8385 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8385 D_tricked_loss= tensor(1.3177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8386 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8386 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8386 D_tricked_loss= tensor(1.3529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8387 D_real_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8387 D_fake_loss= tensor(0.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8387 D_tricked_loss= tensor(1.3536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8388 D_real_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8388 D_fake_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8388 D_tricked_loss= tensor(1.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8389 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8389 D_fake_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8389 D_tricked_loss= tensor(1.3335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8390 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8390 D_fake_loss= tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8390 D_tricked_loss= tensor(1.3333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8391 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8391 D_fake_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8391 D_tricked_loss= tensor(1.3030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8392 D_real_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8392 D_fake_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8392 D_tricked_loss= tensor(1.2724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8393 D_real_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8393 D_fake_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8393 D_tricked_loss= tensor(1.2861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8394 D_real_loss= tensor(0.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8394 D_fake_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8394 D_tricked_loss= tensor(1.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8395 D_real_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8395 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8395 D_tricked_loss= tensor(1.3292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8396 D_real_loss= tensor(0.5409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8396 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8396 D_tricked_loss= tensor(1.3493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8397 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8397 D_fake_loss= tensor(0.5053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8397 D_tricked_loss= tensor(1.3046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8398 D_real_loss= tensor(0.5087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8398 D_fake_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8398 D_tricked_loss= tensor(1.2943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8399 D_real_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8399 D_fake_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8399 D_tricked_loss= tensor(1.2802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8400 D_real_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8400 D_fake_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8400 D_tricked_loss= tensor(1.2508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8401 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8401 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8401 D_tricked_loss= tensor(1.3023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8402 D_real_loss= tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8402 D_fake_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8402 D_tricked_loss= tensor(1.3531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8403 D_real_loss= tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8403 D_fake_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8403 D_tricked_loss= tensor(1.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8404 D_real_loss= tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8404 D_fake_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8404 D_tricked_loss= tensor(1.3131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8405 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8405 D_fake_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8405 D_tricked_loss= tensor(1.3025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8406 D_real_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8406 D_fake_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8406 D_tricked_loss= tensor(1.3311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8407 D_real_loss= tensor(0.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8407 D_fake_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8407 D_tricked_loss= tensor(1.2746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8408 D_real_loss= tensor(0.4973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8408 D_fake_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8408 D_tricked_loss= tensor(1.2466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8409 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8409 D_fake_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8409 D_tricked_loss= tensor(1.3066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8410 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8410 D_fake_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8410 D_tricked_loss= tensor(1.3088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8411 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8411 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8411 D_tricked_loss= tensor(1.3586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8412 D_real_loss= tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8412 D_fake_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8412 D_tricked_loss= tensor(1.3771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8413 D_real_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8413 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8413 D_tricked_loss= tensor(1.3375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8414 D_real_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8414 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8414 D_tricked_loss= tensor(1.3436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8415 D_real_loss= tensor(0.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8415 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8415 D_tricked_loss= tensor(1.3942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8416 D_real_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8416 D_fake_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8416 D_tricked_loss= tensor(1.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8417 D_real_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8417 D_fake_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8417 D_tricked_loss= tensor(1.2440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8418 D_real_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8418 D_fake_loss= tensor(0.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8418 D_tricked_loss= tensor(1.3054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8419 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8419 D_fake_loss= tensor(0.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8419 D_tricked_loss= tensor(1.3374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8420 D_real_loss= tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8420 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8420 D_tricked_loss= tensor(1.3261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8421 D_real_loss= tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8421 D_fake_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8421 D_tricked_loss= tensor(1.3415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8422 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8422 D_fake_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8422 D_tricked_loss= tensor(1.3290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8423 D_real_loss= tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8423 D_fake_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8423 D_tricked_loss= tensor(1.3172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8424 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8424 D_fake_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8424 D_tricked_loss= tensor(1.3231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8425 D_real_loss= tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8425 D_fake_loss= tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8425 D_tricked_loss= tensor(1.3009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8426 D_real_loss= tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8426 D_fake_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8426 D_tricked_loss= tensor(1.3301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8427 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8427 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8427 D_tricked_loss= tensor(1.3502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8428 D_real_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8428 D_fake_loss= tensor(0.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8428 D_tricked_loss= tensor(1.3311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8429 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8429 D_fake_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8429 D_tricked_loss= tensor(1.3396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8430 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8430 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8430 D_tricked_loss= tensor(1.3810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8431 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8431 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8431 D_tricked_loss= tensor(1.3532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8432 D_real_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8432 D_fake_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8432 D_tricked_loss= tensor(1.2913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8433 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8433 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8433 D_tricked_loss= tensor(1.3389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8434 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8434 D_fake_loss= tensor(0.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8434 D_tricked_loss= tensor(1.3367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8435 D_real_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8435 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8435 D_tricked_loss= tensor(1.3106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8436 D_real_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8436 D_fake_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8436 D_tricked_loss= tensor(1.3422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8437 D_real_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8437 D_fake_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8437 D_tricked_loss= tensor(1.3045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8438 D_real_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8438 D_fake_loss= tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8438 D_tricked_loss= tensor(1.3038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8439 D_real_loss= tensor(0.4850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8439 D_fake_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8439 D_tricked_loss= tensor(1.3364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8440 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8440 D_fake_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8440 D_tricked_loss= tensor(1.3097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8441 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8441 D_fake_loss= tensor(0.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8441 D_tricked_loss= tensor(1.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8442 D_real_loss= tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8442 D_fake_loss= tensor(0.4922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8442 D_tricked_loss= tensor(1.3277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8443 D_real_loss= tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8443 D_fake_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8443 D_tricked_loss= tensor(1.2915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8444 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8444 D_fake_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8444 D_tricked_loss= tensor(1.3504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8445 D_real_loss= tensor(0.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8445 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8445 D_tricked_loss= tensor(1.3446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8446 D_real_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8446 D_fake_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8446 D_tricked_loss= tensor(1.3524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8447 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8447 D_fake_loss= tensor(0.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8447 D_tricked_loss= tensor(1.3524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8448 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8448 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8448 D_tricked_loss= tensor(1.3418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8449 D_real_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8449 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8449 D_tricked_loss= tensor(1.3370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8450 D_real_loss= tensor(0.5141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8450 D_fake_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8450 D_tricked_loss= tensor(1.3283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8451 D_real_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8451 D_fake_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8451 D_tricked_loss= tensor(1.3088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8452 D_real_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8452 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8452 D_tricked_loss= tensor(1.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8453 D_real_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8453 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8453 D_tricked_loss= tensor(1.3430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8454 D_real_loss= tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8454 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8454 D_tricked_loss= tensor(1.3771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8455 D_real_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8455 D_fake_loss= tensor(0.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8455 D_tricked_loss= tensor(1.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8456 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8456 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8456 D_tricked_loss= tensor(1.3099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8457 D_real_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8457 D_fake_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8457 D_tricked_loss= tensor(1.3377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8458 D_real_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8458 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8458 D_tricked_loss= tensor(1.3196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8459 D_real_loss= tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8459 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8459 D_tricked_loss= tensor(1.2989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8460 D_real_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8460 D_fake_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8460 D_tricked_loss= tensor(1.3189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8461 D_real_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8461 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8461 D_tricked_loss= tensor(1.3065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8462 D_real_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8462 D_fake_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8462 D_tricked_loss= tensor(1.3418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8463 D_real_loss= tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8463 D_fake_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8463 D_tricked_loss= tensor(1.4195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8464 D_real_loss= tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8464 D_fake_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8464 D_tricked_loss= tensor(1.3317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8465 D_real_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8465 D_fake_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8465 D_tricked_loss= tensor(1.3671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8466 D_real_loss= tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8466 D_fake_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8466 D_tricked_loss= tensor(1.3334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8467 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8467 D_fake_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8467 D_tricked_loss= tensor(1.2831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8468 D_real_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8468 D_fake_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8468 D_tricked_loss= tensor(1.3048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8469 D_real_loss= tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8469 D_fake_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8469 D_tricked_loss= tensor(1.3454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8470 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8470 D_fake_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8470 D_tricked_loss= tensor(1.3869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8471 D_real_loss= tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8471 D_fake_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8471 D_tricked_loss= tensor(1.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8472 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8472 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8472 D_tricked_loss= tensor(1.3886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8473 D_real_loss= tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8473 D_fake_loss= tensor(0.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8473 D_tricked_loss= tensor(1.3896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8474 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8474 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8474 D_tricked_loss= tensor(1.3442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8475 D_real_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8475 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8475 D_tricked_loss= tensor(1.3519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8476 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8476 D_fake_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8476 D_tricked_loss= tensor(1.3662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8477 D_real_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8477 D_fake_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8477 D_tricked_loss= tensor(1.3374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8478 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8478 D_fake_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8478 D_tricked_loss= tensor(1.3079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8479 D_real_loss= tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8479 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8479 D_tricked_loss= tensor(1.3780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8480 D_real_loss= tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8480 D_fake_loss= tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8480 D_tricked_loss= tensor(1.3498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8481 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8481 D_fake_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8481 D_tricked_loss= tensor(1.4168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8482 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8482 D_fake_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8482 D_tricked_loss= tensor(1.3326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8483 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8483 D_fake_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8483 D_tricked_loss= tensor(1.2593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8484 D_real_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8484 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8484 D_tricked_loss= tensor(1.3022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8485 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8485 D_fake_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8485 D_tricked_loss= tensor(1.2866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8486 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8486 D_fake_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8486 D_tricked_loss= tensor(1.3294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8487 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8487 D_fake_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8487 D_tricked_loss= tensor(1.3500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8488 D_real_loss= tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8488 D_fake_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8488 D_tricked_loss= tensor(1.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8489 D_real_loss= tensor(0.5160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8489 D_fake_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8489 D_tricked_loss= tensor(1.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8490 D_real_loss= tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8490 D_fake_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8490 D_tricked_loss= tensor(1.3466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8491 D_real_loss= tensor(0.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8491 D_fake_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8491 D_tricked_loss= tensor(1.3101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8492 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8492 D_fake_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8492 D_tricked_loss= tensor(1.2727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8493 D_real_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8493 D_fake_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8493 D_tricked_loss= tensor(1.2780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8494 D_real_loss= tensor(0.5100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8494 D_fake_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8494 D_tricked_loss= tensor(1.3222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8495 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8495 D_fake_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8495 D_tricked_loss= tensor(1.3518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8496 D_real_loss= tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8496 D_fake_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8496 D_tricked_loss= tensor(1.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8497 D_real_loss= tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8497 D_fake_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8497 D_tricked_loss= tensor(1.3816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8498 D_real_loss= tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8498 D_fake_loss= tensor(0.4858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8498 D_tricked_loss= tensor(1.3710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8499 D_real_loss= tensor(0.5100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8499 D_fake_loss= tensor(0.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8499 D_tricked_loss= tensor(1.2748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8500 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8500 D_fake_loss= tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8500 D_tricked_loss= tensor(1.2513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8501 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8501 D_fake_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8501 D_tricked_loss= tensor(1.2764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8502 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8502 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8502 D_tricked_loss= tensor(1.3296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8503 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8503 D_fake_loss= tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8503 D_tricked_loss= tensor(1.3349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8504 D_real_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8504 D_fake_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8504 D_tricked_loss= tensor(1.3903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8505 D_real_loss= tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8505 D_fake_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8505 D_tricked_loss= tensor(1.3750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8506 D_real_loss= tensor(0.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8506 D_fake_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8506 D_tricked_loss= tensor(1.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8507 D_real_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8507 D_fake_loss= tensor(0.4922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8507 D_tricked_loss= tensor(1.3327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8508 D_real_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8508 D_fake_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8508 D_tricked_loss= tensor(1.2508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8509 D_real_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8509 D_fake_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8509 D_tricked_loss= tensor(1.2666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8510 D_real_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8510 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8510 D_tricked_loss= tensor(1.3180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8511 D_real_loss= tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8511 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8511 D_tricked_loss= tensor(1.3395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8512 D_real_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8512 D_fake_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8512 D_tricked_loss= tensor(1.3689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8513 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8513 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8513 D_tricked_loss= tensor(1.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8514 D_real_loss= tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8514 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8514 D_tricked_loss= tensor(1.4128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8515 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8515 D_fake_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8515 D_tricked_loss= tensor(1.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8516 D_real_loss= tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8516 D_fake_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8516 D_tricked_loss= tensor(1.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8517 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8517 D_fake_loss= tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8517 D_tricked_loss= tensor(1.2776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8518 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8518 D_fake_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8518 D_tricked_loss= tensor(1.3250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8519 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8519 D_fake_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8519 D_tricked_loss= tensor(1.3161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8520 D_real_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8520 D_fake_loss= tensor(0.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8520 D_tricked_loss= tensor(1.3342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8521 D_real_loss= tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8521 D_fake_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8521 D_tricked_loss= tensor(1.3519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8522 D_real_loss= tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8522 D_fake_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8522 D_tricked_loss= tensor(1.3901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8523 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8523 D_fake_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8523 D_tricked_loss= tensor(1.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8524 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8524 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8524 D_tricked_loss= tensor(1.3683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8525 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8525 D_fake_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8525 D_tricked_loss= tensor(1.2978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8526 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8526 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8526 D_tricked_loss= tensor(1.2977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8527 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8527 D_fake_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8527 D_tricked_loss= tensor(1.3060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8528 D_real_loss= tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8528 D_fake_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8528 D_tricked_loss= tensor(1.3109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8529 D_real_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8529 D_fake_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8529 D_tricked_loss= tensor(1.3605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8530 D_real_loss= tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8530 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8530 D_tricked_loss= tensor(1.4518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8531 D_real_loss= tensor(0.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8531 D_fake_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8531 D_tricked_loss= tensor(1.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8532 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8532 D_fake_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8532 D_tricked_loss= tensor(1.4100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8533 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8533 D_fake_loss= tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8533 D_tricked_loss= tensor(1.3669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8534 D_real_loss= tensor(0.4885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8534 D_fake_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8534 D_tricked_loss= tensor(1.3372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8535 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8535 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8535 D_tricked_loss= tensor(1.2855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8536 D_real_loss= tensor(0.4660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8536 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8536 D_tricked_loss= tensor(1.3223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8537 D_real_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8537 D_fake_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8537 D_tricked_loss= tensor(1.3540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8538 D_real_loss= tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8538 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8538 D_tricked_loss= tensor(1.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8539 D_real_loss= tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8539 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8539 D_tricked_loss= tensor(1.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8540 D_real_loss= tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8540 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8540 D_tricked_loss= tensor(1.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8541 D_real_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8541 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8541 D_tricked_loss= tensor(1.4040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8542 D_real_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8542 D_fake_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8542 D_tricked_loss= tensor(1.3183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8543 D_real_loss= tensor(0.4713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8543 D_fake_loss= tensor(0.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8543 D_tricked_loss= tensor(1.2848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8544 D_real_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8544 D_fake_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8544 D_tricked_loss= tensor(1.3249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8545 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8545 D_fake_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8545 D_tricked_loss= tensor(1.3114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8546 D_real_loss= tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8546 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8546 D_tricked_loss= tensor(1.3756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8547 D_real_loss= tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8547 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8547 D_tricked_loss= tensor(1.4193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8548 D_real_loss= tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8548 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8548 D_tricked_loss= tensor(1.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8549 D_real_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8549 D_fake_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8549 D_tricked_loss= tensor(1.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8550 D_real_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8550 D_fake_loss= tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8550 D_tricked_loss= tensor(1.3565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8551 D_real_loss= tensor(0.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8551 D_fake_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8551 D_tricked_loss= tensor(1.2385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8552 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8552 D_fake_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8552 D_tricked_loss= tensor(1.2831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8553 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8553 D_fake_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8553 D_tricked_loss= tensor(1.3287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8554 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8554 D_fake_loss= tensor(0.4600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8554 D_tricked_loss= tensor(1.3570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8555 D_real_loss= tensor(0.5358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8555 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8555 D_tricked_loss= tensor(1.3633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8556 D_real_loss= tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8556 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8556 D_tricked_loss= tensor(1.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8557 D_real_loss= tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8557 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8557 D_tricked_loss= tensor(1.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8558 D_real_loss= tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8558 D_fake_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8558 D_tricked_loss= tensor(1.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8559 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8559 D_fake_loss= tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8559 D_tricked_loss= tensor(1.3260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8560 D_real_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8560 D_fake_loss= tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8560 D_tricked_loss= tensor(1.2711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8561 D_real_loss= tensor(0.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8561 D_fake_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8561 D_tricked_loss= tensor(1.2903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8562 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8562 D_fake_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8562 D_tricked_loss= tensor(1.2946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8563 D_real_loss= tensor(0.4957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8563 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8563 D_tricked_loss= tensor(1.3320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8564 D_real_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8564 D_fake_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8564 D_tricked_loss= tensor(1.3932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8565 D_real_loss= tensor(0.5103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8565 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8565 D_tricked_loss= tensor(1.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8566 D_real_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8566 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8566 D_tricked_loss= tensor(1.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8567 D_real_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8567 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8567 D_tricked_loss= tensor(1.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8568 D_real_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8568 D_fake_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8568 D_tricked_loss= tensor(1.3283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8569 D_real_loss= tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8569 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8569 D_tricked_loss= tensor(1.2758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8570 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8570 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8570 D_tricked_loss= tensor(1.2805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8571 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8571 D_fake_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8571 D_tricked_loss= tensor(1.3168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8572 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8572 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8572 D_tricked_loss= tensor(1.3532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8573 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8573 D_fake_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8573 D_tricked_loss= tensor(1.3673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8574 D_real_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8574 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8574 D_tricked_loss= tensor(1.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8575 D_real_loss= tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8575 D_fake_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8575 D_tricked_loss= tensor(1.4517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8576 D_real_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8576 D_fake_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8576 D_tricked_loss= tensor(1.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8577 D_real_loss= tensor(0.5073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8577 D_fake_loss= tensor(0.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8577 D_tricked_loss= tensor(1.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8578 D_real_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8578 D_fake_loss= tensor(0.4778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8578 D_tricked_loss= tensor(1.2713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8579 D_real_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8579 D_fake_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8579 D_tricked_loss= tensor(1.2758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8580 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8580 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8580 D_tricked_loss= tensor(1.3216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8581 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8581 D_fake_loss= tensor(0.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8581 D_tricked_loss= tensor(1.3463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8582 D_real_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8582 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8582 D_tricked_loss= tensor(1.4081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8583 D_real_loss= tensor(0.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8583 D_fake_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8583 D_tricked_loss= tensor(1.4060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8584 D_real_loss= tensor(0.5100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8584 D_fake_loss= tensor(0.4730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8584 D_tricked_loss= tensor(1.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8585 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8585 D_fake_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8585 D_tricked_loss= tensor(1.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8586 D_real_loss= tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8586 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8586 D_tricked_loss= tensor(1.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8587 D_real_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8587 D_fake_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8587 D_tricked_loss= tensor(1.3049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8588 D_real_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8588 D_fake_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8588 D_tricked_loss= tensor(1.3514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8589 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8589 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8589 D_tricked_loss= tensor(1.3222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8590 D_real_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8590 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8590 D_tricked_loss= tensor(1.3580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8591 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8591 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8591 D_tricked_loss= tensor(1.3721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8592 D_real_loss= tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8592 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8592 D_tricked_loss= tensor(1.4097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8593 D_real_loss= tensor(0.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8593 D_fake_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8593 D_tricked_loss= tensor(1.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8594 D_real_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8594 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8594 D_tricked_loss= tensor(1.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8595 D_real_loss= tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8595 D_fake_loss= tensor(0.4902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8595 D_tricked_loss= tensor(1.3834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8596 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8596 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8596 D_tricked_loss= tensor(1.3349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8597 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8597 D_fake_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8597 D_tricked_loss= tensor(1.3149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8598 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8598 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8598 D_tricked_loss= tensor(1.3432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8599 D_real_loss= tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8599 D_fake_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8599 D_tricked_loss= tensor(1.3467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8600 D_real_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8600 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8600 D_tricked_loss= tensor(1.3926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8601 D_real_loss= tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8601 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8601 D_tricked_loss= tensor(1.3964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8602 D_real_loss= tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8602 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8602 D_tricked_loss= tensor(1.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8603 D_real_loss= tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8603 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8603 D_tricked_loss= tensor(1.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8604 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8604 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8604 D_tricked_loss= tensor(1.3762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8605 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8605 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8605 D_tricked_loss= tensor(1.3425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8606 D_real_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8606 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8606 D_tricked_loss= tensor(1.3493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8607 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8607 D_fake_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8607 D_tricked_loss= tensor(1.3685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8608 D_real_loss= tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8608 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8608 D_tricked_loss= tensor(1.3558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8609 D_real_loss= tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8609 D_fake_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8609 D_tricked_loss= tensor(1.4525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8610 D_real_loss= tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8610 D_fake_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8610 D_tricked_loss= tensor(1.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8611 D_real_loss= tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8611 D_fake_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8611 D_tricked_loss= tensor(1.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8612 D_real_loss= tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8612 D_fake_loss= tensor(0.4783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8612 D_tricked_loss= tensor(1.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8613 D_real_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8613 D_fake_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8613 D_tricked_loss= tensor(1.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8614 D_real_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8614 D_fake_loss= tensor(0.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8614 D_tricked_loss= tensor(1.3770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8615 D_real_loss= tensor(0.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8615 D_fake_loss= tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8615 D_tricked_loss= tensor(1.2989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8616 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8616 D_fake_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8616 D_tricked_loss= tensor(1.3185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8617 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8617 D_fake_loss= tensor(0.4681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8617 D_tricked_loss= tensor(1.4023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8618 D_real_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8618 D_fake_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8618 D_tricked_loss= tensor(1.3613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8619 D_real_loss= tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8619 D_fake_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8619 D_tricked_loss= tensor(1.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8620 D_real_loss= tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8620 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8620 D_tricked_loss= tensor(1.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8621 D_real_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8621 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8621 D_tricked_loss= tensor(1.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8622 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8622 D_fake_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8622 D_tricked_loss= tensor(1.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8623 D_real_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8623 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8623 D_tricked_loss= tensor(1.3126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8624 D_real_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8624 D_fake_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8624 D_tricked_loss= tensor(1.2860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8625 D_real_loss= tensor(0.4806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8625 D_fake_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8625 D_tricked_loss= tensor(1.3121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8626 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8626 D_fake_loss= tensor(0.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8626 D_tricked_loss= tensor(1.3298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8627 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8627 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8627 D_tricked_loss= tensor(1.3248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8628 D_real_loss= tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8628 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8628 D_tricked_loss= tensor(1.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8629 D_real_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8629 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8629 D_tricked_loss= tensor(1.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8630 D_real_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8630 D_fake_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8630 D_tricked_loss= tensor(1.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8631 D_real_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8631 D_fake_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8631 D_tricked_loss= tensor(1.3681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8632 D_real_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8632 D_fake_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8632 D_tricked_loss= tensor(1.3407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8633 D_real_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8633 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8633 D_tricked_loss= tensor(1.3118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8634 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8634 D_fake_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8634 D_tricked_loss= tensor(1.3093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8635 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8635 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8635 D_tricked_loss= tensor(1.3345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8636 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8636 D_fake_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8636 D_tricked_loss= tensor(1.3178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8637 D_real_loss= tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8637 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8637 D_tricked_loss= tensor(1.3858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8638 D_real_loss= tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8638 D_fake_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8638 D_tricked_loss= tensor(1.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8639 D_real_loss= tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8639 D_fake_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8639 D_tricked_loss= tensor(1.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8640 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8640 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8640 D_tricked_loss= tensor(1.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8641 D_real_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8641 D_fake_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8641 D_tricked_loss= tensor(1.3942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8642 D_real_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8642 D_fake_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8642 D_tricked_loss= tensor(1.3600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8643 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8643 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8643 D_tricked_loss= tensor(1.3512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8644 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8644 D_fake_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8644 D_tricked_loss= tensor(1.3653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8645 D_real_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8645 D_fake_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8645 D_tricked_loss= tensor(1.3495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8646 D_real_loss= tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8646 D_fake_loss= tensor(0.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8646 D_tricked_loss= tensor(1.3845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8647 D_real_loss= tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8647 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8647 D_tricked_loss= tensor(1.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8648 D_real_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8648 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8648 D_tricked_loss= tensor(1.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8649 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8649 D_fake_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8649 D_tricked_loss= tensor(1.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8650 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8650 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8650 D_tricked_loss= tensor(1.3873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8651 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8651 D_fake_loss= tensor(0.4786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8651 D_tricked_loss= tensor(1.3018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8652 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8652 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8652 D_tricked_loss= tensor(1.3366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8653 D_real_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8653 D_fake_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8653 D_tricked_loss= tensor(1.3422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8654 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8654 D_fake_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8654 D_tricked_loss= tensor(1.3685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8655 D_real_loss= tensor(0.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8655 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8655 D_tricked_loss= tensor(1.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8656 D_real_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8656 D_fake_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8656 D_tricked_loss= tensor(1.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8657 D_real_loss= tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8657 D_fake_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8657 D_tricked_loss= tensor(1.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8658 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8658 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8658 D_tricked_loss= tensor(1.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8659 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8659 D_fake_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8659 D_tricked_loss= tensor(1.4017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8660 D_real_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8660 D_fake_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8660 D_tricked_loss= tensor(1.3322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8661 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8661 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8661 D_tricked_loss= tensor(1.3590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8662 D_real_loss= tensor(0.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8662 D_fake_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8662 D_tricked_loss= tensor(1.3194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8663 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8663 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8663 D_tricked_loss= tensor(1.3393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8664 D_real_loss= tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8664 D_fake_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8664 D_tricked_loss= tensor(1.3899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8665 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8665 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8665 D_tricked_loss= tensor(1.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8666 D_real_loss= tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8666 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8666 D_tricked_loss= tensor(1.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8667 D_real_loss= tensor(0.5180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8667 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8667 D_tricked_loss= tensor(1.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8668 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8668 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8668 D_tricked_loss= tensor(1.3885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8669 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8669 D_fake_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8669 D_tricked_loss= tensor(1.4183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8670 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8670 D_fake_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8670 D_tricked_loss= tensor(1.3339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8671 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8671 D_fake_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8671 D_tricked_loss= tensor(1.3010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8672 D_real_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8672 D_fake_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8672 D_tricked_loss= tensor(1.3391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8673 D_real_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8673 D_fake_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8673 D_tricked_loss= tensor(1.3880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8674 D_real_loss= tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8674 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8674 D_tricked_loss= tensor(1.4193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8675 D_real_loss= tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8675 D_fake_loss= tensor(0.4600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8675 D_tricked_loss= tensor(1.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8676 D_real_loss= tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8676 D_fake_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8676 D_tricked_loss= tensor(1.4003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8677 D_real_loss= tensor(0.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8677 D_fake_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8677 D_tricked_loss= tensor(1.3543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8678 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8678 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8678 D_tricked_loss= tensor(1.3611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8679 D_real_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8679 D_fake_loss= tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8679 D_tricked_loss= tensor(1.3331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8680 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8680 D_fake_loss= tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8680 D_tricked_loss= tensor(1.3141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8681 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8681 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8681 D_tricked_loss= tensor(1.3320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8682 D_real_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8682 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8682 D_tricked_loss= tensor(1.3622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8683 D_real_loss= tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8683 D_fake_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8683 D_tricked_loss= tensor(1.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8684 D_real_loss= tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8684 D_fake_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8684 D_tricked_loss= tensor(1.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8685 D_real_loss= tensor(0.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8685 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8685 D_tricked_loss= tensor(1.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8686 D_real_loss= tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8686 D_fake_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8686 D_tricked_loss= tensor(1.3930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8687 D_real_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8687 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8687 D_tricked_loss= tensor(1.3653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8688 D_real_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8688 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8688 D_tricked_loss= tensor(1.3502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8689 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8689 D_fake_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8689 D_tricked_loss= tensor(1.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8690 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8690 D_fake_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8690 D_tricked_loss= tensor(1.3964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8691 D_real_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8691 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8691 D_tricked_loss= tensor(1.3789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8692 D_real_loss= tensor(0.5168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8692 D_fake_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8692 D_tricked_loss= tensor(1.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8693 D_real_loss= tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8693 D_fake_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8693 D_tricked_loss= tensor(1.4210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8694 D_real_loss= tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8694 D_fake_loss= tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8694 D_tricked_loss= tensor(1.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8695 D_real_loss= tensor(0.5247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8695 D_fake_loss= tensor(0.4681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8695 D_tricked_loss= tensor(1.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8696 D_real_loss= tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8696 D_fake_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8696 D_tricked_loss= tensor(1.3995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8697 D_real_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8697 D_fake_loss= tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8697 D_tricked_loss= tensor(1.3349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8698 D_real_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8698 D_fake_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8698 D_tricked_loss= tensor(1.3479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8699 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8699 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8699 D_tricked_loss= tensor(1.3665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8700 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8700 D_fake_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8700 D_tricked_loss= tensor(1.3529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8701 D_real_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8701 D_fake_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8701 D_tricked_loss= tensor(1.3377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8702 D_real_loss= tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8702 D_fake_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8702 D_tricked_loss= tensor(1.3907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8703 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8703 D_fake_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8703 D_tricked_loss= tensor(1.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8704 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8704 D_fake_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8704 D_tricked_loss= tensor(1.3830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8705 D_real_loss= tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8705 D_fake_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8705 D_tricked_loss= tensor(1.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8706 D_real_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8706 D_fake_loss= tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8706 D_tricked_loss= tensor(1.3668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8707 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8707 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8707 D_tricked_loss= tensor(1.3264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8708 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8708 D_fake_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8708 D_tricked_loss= tensor(1.3607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8709 D_real_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8709 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8709 D_tricked_loss= tensor(1.3563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8710 D_real_loss= tensor(0.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8710 D_fake_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8710 D_tricked_loss= tensor(1.3691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8711 D_real_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8711 D_fake_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8711 D_tricked_loss= tensor(1.3882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8712 D_real_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8712 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8712 D_tricked_loss= tensor(1.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8713 D_real_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8713 D_fake_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8713 D_tricked_loss= tensor(1.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8714 D_real_loss= tensor(0.5098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8714 D_fake_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8714 D_tricked_loss= tensor(1.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8715 D_real_loss= tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8715 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8715 D_tricked_loss= tensor(1.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8716 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8716 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8716 D_tricked_loss= tensor(1.3233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8717 D_real_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8717 D_fake_loss= tensor(0.4952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8717 D_tricked_loss= tensor(1.3246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8718 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8718 D_fake_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8718 D_tricked_loss= tensor(1.3748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8719 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8719 D_fake_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8719 D_tricked_loss= tensor(1.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8720 D_real_loss= tensor(0.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8720 D_fake_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8720 D_tricked_loss= tensor(1.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8721 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8721 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8721 D_tricked_loss= tensor(1.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8722 D_real_loss= tensor(0.4850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8722 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8722 D_tricked_loss= tensor(1.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8723 D_real_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8723 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8723 D_tricked_loss= tensor(1.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8724 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8724 D_fake_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8724 D_tricked_loss= tensor(1.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8725 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8725 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8725 D_tricked_loss= tensor(1.3510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8726 D_real_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8726 D_fake_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8726 D_tricked_loss= tensor(1.3464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8727 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8727 D_fake_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8727 D_tricked_loss= tensor(1.3577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8728 D_real_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8728 D_fake_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8728 D_tricked_loss= tensor(1.3784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8729 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8729 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8729 D_tricked_loss= tensor(1.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8730 D_real_loss= tensor(0.5182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8730 D_fake_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8730 D_tricked_loss= tensor(1.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8731 D_real_loss= tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8731 D_fake_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8731 D_tricked_loss= tensor(1.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8732 D_real_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8732 D_fake_loss= tensor(0.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8732 D_tricked_loss= tensor(1.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8733 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8733 D_fake_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8733 D_tricked_loss= tensor(1.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8734 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8734 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8734 D_tricked_loss= tensor(1.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8735 D_real_loss= tensor(0.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8735 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8735 D_tricked_loss= tensor(1.3431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8736 D_real_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8736 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8736 D_tricked_loss= tensor(1.3602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8737 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8737 D_fake_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8737 D_tricked_loss= tensor(1.3430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8738 D_real_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8738 D_fake_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8738 D_tricked_loss= tensor(1.3804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8739 D_real_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8739 D_fake_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8739 D_tricked_loss= tensor(1.3942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8740 D_real_loss= tensor(0.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8740 D_fake_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8740 D_tricked_loss= tensor(1.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8741 D_real_loss= tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8741 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8741 D_tricked_loss= tensor(1.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8742 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8742 D_fake_loss= tensor(0.4713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8742 D_tricked_loss= tensor(1.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8743 D_real_loss= tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8743 D_fake_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8743 D_tricked_loss= tensor(1.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8744 D_real_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8744 D_fake_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8744 D_tricked_loss= tensor(1.3482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8745 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8745 D_fake_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8745 D_tricked_loss= tensor(1.3512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8746 D_real_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8746 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8746 D_tricked_loss= tensor(1.3667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8747 D_real_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8747 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8747 D_tricked_loss= tensor(1.3909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8748 D_real_loss= tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8748 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8748 D_tricked_loss= tensor(1.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8749 D_real_loss= tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8749 D_fake_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8749 D_tricked_loss= tensor(1.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8750 D_real_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8750 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8750 D_tricked_loss= tensor(1.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8751 D_real_loss= tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8751 D_fake_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8751 D_tricked_loss= tensor(1.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8752 D_real_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8752 D_fake_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8752 D_tricked_loss= tensor(1.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8753 D_real_loss= tensor(0.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8753 D_fake_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8753 D_tricked_loss= tensor(1.3590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8754 D_real_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8754 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8754 D_tricked_loss= tensor(1.3416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8755 D_real_loss= tensor(0.4681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8755 D_fake_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8755 D_tricked_loss= tensor(1.3823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8756 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8756 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8756 D_tricked_loss= tensor(1.3781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8757 D_real_loss= tensor(0.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8757 D_fake_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8757 D_tricked_loss= tensor(1.3750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8758 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8758 D_fake_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8758 D_tricked_loss= tensor(1.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8759 D_real_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8759 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8759 D_tricked_loss= tensor(1.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8760 D_real_loss= tensor(0.5025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8760 D_fake_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8760 D_tricked_loss= tensor(1.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8761 D_real_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8761 D_fake_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8761 D_tricked_loss= tensor(1.4136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8762 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8762 D_fake_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8762 D_tricked_loss= tensor(1.3839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8763 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8763 D_fake_loss= tensor(0.4620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8763 D_tricked_loss= tensor(1.3234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8764 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8764 D_fake_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8764 D_tricked_loss= tensor(1.3707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8765 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8765 D_fake_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8765 D_tricked_loss= tensor(1.3806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8766 D_real_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8766 D_fake_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8766 D_tricked_loss= tensor(1.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8767 D_real_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8767 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8767 D_tricked_loss= tensor(1.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8768 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8768 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8768 D_tricked_loss= tensor(1.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8769 D_real_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8769 D_fake_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8769 D_tricked_loss= tensor(1.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8770 D_real_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8770 D_fake_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8770 D_tricked_loss= tensor(1.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8771 D_real_loss= tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8771 D_fake_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8771 D_tricked_loss= tensor(1.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8772 D_real_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8772 D_fake_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8772 D_tricked_loss= tensor(1.3176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8773 D_real_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8773 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8773 D_tricked_loss= tensor(1.3672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8774 D_real_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8774 D_fake_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8774 D_tricked_loss= tensor(1.3865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8775 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8775 D_fake_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8775 D_tricked_loss= tensor(1.3538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8776 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8776 D_fake_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8776 D_tricked_loss= tensor(1.3691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8777 D_real_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8777 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8777 D_tricked_loss= tensor(1.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8778 D_real_loss= tensor(0.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8778 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8778 D_tricked_loss= tensor(1.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8779 D_real_loss= tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8779 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8779 D_tricked_loss= tensor(1.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8780 D_real_loss= tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8780 D_fake_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8780 D_tricked_loss= tensor(1.3741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8781 D_real_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8781 D_fake_loss= tensor(0.4858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8781 D_tricked_loss= tensor(1.3500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8782 D_real_loss= tensor(0.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8782 D_fake_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8782 D_tricked_loss= tensor(1.3208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8783 D_real_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8783 D_fake_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8783 D_tricked_loss= tensor(1.3593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8784 D_real_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8784 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8784 D_tricked_loss= tensor(1.3967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8785 D_real_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8785 D_fake_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8785 D_tricked_loss= tensor(1.4048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8786 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8786 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8786 D_tricked_loss= tensor(1.4023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8787 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8787 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8787 D_tricked_loss= tensor(1.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8788 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8788 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8788 D_tricked_loss= tensor(1.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8789 D_real_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8789 D_fake_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8789 D_tricked_loss= tensor(1.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8790 D_real_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8790 D_fake_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8790 D_tricked_loss= tensor(1.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8791 D_real_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8791 D_fake_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8791 D_tricked_loss= tensor(1.3713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8792 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8792 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8792 D_tricked_loss= tensor(1.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8793 D_real_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8793 D_fake_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8793 D_tricked_loss= tensor(1.3882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8794 D_real_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8794 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8794 D_tricked_loss= tensor(1.3752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8795 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8795 D_fake_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8795 D_tricked_loss= tensor(1.4135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8796 D_real_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8796 D_fake_loss= tensor(0.4620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8796 D_tricked_loss= tensor(1.3981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8797 D_real_loss= tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8797 D_fake_loss= tensor(0.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8797 D_tricked_loss= tensor(1.3601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8798 D_real_loss= tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8798 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8798 D_tricked_loss= tensor(1.3705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8799 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8799 D_fake_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8799 D_tricked_loss= tensor(1.3574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8800 D_real_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8800 D_fake_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8800 D_tricked_loss= tensor(1.3782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8801 D_real_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8801 D_fake_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8801 D_tricked_loss= tensor(1.3266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8802 D_real_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8802 D_fake_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8802 D_tricked_loss= tensor(1.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8803 D_real_loss= tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8803 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8803 D_tricked_loss= tensor(1.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8804 D_real_loss= tensor(0.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8804 D_fake_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8804 D_tricked_loss= tensor(1.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8805 D_real_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8805 D_fake_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8805 D_tricked_loss= tensor(1.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8806 D_real_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8806 D_fake_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8806 D_tricked_loss= tensor(1.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8807 D_real_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8807 D_fake_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8807 D_tricked_loss= tensor(1.3955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8808 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8808 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8808 D_tricked_loss= tensor(1.3824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8809 D_real_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8809 D_fake_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8809 D_tricked_loss= tensor(1.3415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8810 D_real_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8810 D_fake_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8810 D_tricked_loss= tensor(1.3687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8811 D_real_loss= tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8811 D_fake_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8811 D_tricked_loss= tensor(1.3515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8812 D_real_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8812 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8812 D_tricked_loss= tensor(1.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8813 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8813 D_fake_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8813 D_tricked_loss= tensor(1.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8814 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8814 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8814 D_tricked_loss= tensor(1.4074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8815 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8815 D_fake_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8815 D_tricked_loss= tensor(1.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8816 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8816 D_fake_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8816 D_tricked_loss= tensor(1.3874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8817 D_real_loss= tensor(0.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8817 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8817 D_tricked_loss= tensor(1.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8818 D_real_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8818 D_fake_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8818 D_tricked_loss= tensor(1.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8819 D_real_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8819 D_fake_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8819 D_tricked_loss= tensor(1.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8820 D_real_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8820 D_fake_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8820 D_tricked_loss= tensor(1.4295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8821 D_real_loss= tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8821 D_fake_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8821 D_tricked_loss= tensor(1.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8822 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8822 D_fake_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8822 D_tricked_loss= tensor(1.4178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8823 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8823 D_fake_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8823 D_tricked_loss= tensor(1.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8824 D_real_loss= tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8824 D_fake_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8824 D_tricked_loss= tensor(1.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8825 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8825 D_fake_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8825 D_tricked_loss= tensor(1.3207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8826 D_real_loss= tensor(0.4944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8826 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8826 D_tricked_loss= tensor(1.3957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8827 D_real_loss= tensor(0.5029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8827 D_fake_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8827 D_tricked_loss= tensor(1.3757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8828 D_real_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8828 D_fake_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8828 D_tricked_loss= tensor(1.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8829 D_real_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8829 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8829 D_tricked_loss= tensor(1.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8830 D_real_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8830 D_fake_loss= tensor(0.4783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8830 D_tricked_loss= tensor(1.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8831 D_real_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8831 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8831 D_tricked_loss= tensor(1.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8832 D_real_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8832 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8832 D_tricked_loss= tensor(1.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8833 D_real_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8833 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8833 D_tricked_loss= tensor(1.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8834 D_real_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8834 D_fake_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8834 D_tricked_loss= tensor(1.3678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8835 D_real_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8835 D_fake_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8835 D_tricked_loss= tensor(1.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8836 D_real_loss= tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8836 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8836 D_tricked_loss= tensor(1.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8837 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8837 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8837 D_tricked_loss= tensor(1.4034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8838 D_real_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8838 D_fake_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8838 D_tricked_loss= tensor(1.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8839 D_real_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8839 D_fake_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8839 D_tricked_loss= tensor(1.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8840 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8840 D_fake_loss= tensor(0.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8840 D_tricked_loss= tensor(1.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8841 D_real_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8841 D_fake_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8841 D_tricked_loss= tensor(1.3955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8842 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8842 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8842 D_tricked_loss= tensor(1.3951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8843 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8843 D_fake_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8843 D_tricked_loss= tensor(1.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8844 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8844 D_fake_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8844 D_tricked_loss= tensor(1.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8845 D_real_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8845 D_fake_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8845 D_tricked_loss= tensor(1.3835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8846 D_real_loss= tensor(0.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8846 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8846 D_tricked_loss= tensor(1.4108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8847 D_real_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8847 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8847 D_tricked_loss= tensor(1.4165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8848 D_real_loss= tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8848 D_fake_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8848 D_tricked_loss= tensor(1.4059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8849 D_real_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8849 D_fake_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8849 D_tricked_loss= tensor(1.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8850 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8850 D_fake_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8850 D_tricked_loss= tensor(1.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8851 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8851 D_fake_loss= tensor(0.4556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8851 D_tricked_loss= tensor(1.3896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8852 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8852 D_fake_loss= tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8852 D_tricked_loss= tensor(1.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8853 D_real_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8853 D_fake_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8853 D_tricked_loss= tensor(1.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8854 D_real_loss= tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8854 D_fake_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8854 D_tricked_loss= tensor(1.4057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8855 D_real_loss= tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8855 D_fake_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8855 D_tricked_loss= tensor(1.4019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8856 D_real_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8856 D_fake_loss= tensor(0.4744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8856 D_tricked_loss= tensor(1.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8857 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8857 D_fake_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8857 D_tricked_loss= tensor(1.4180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8858 D_real_loss= tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8858 D_fake_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8858 D_tricked_loss= tensor(1.3807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8859 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8859 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8859 D_tricked_loss= tensor(1.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8860 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8860 D_fake_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8860 D_tricked_loss= tensor(1.3500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8861 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8861 D_fake_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8861 D_tricked_loss= tensor(1.3556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8862 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8862 D_fake_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8862 D_tricked_loss= tensor(1.3777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8863 D_real_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8863 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8863 D_tricked_loss= tensor(1.4138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8864 D_real_loss= tensor(0.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8864 D_fake_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8864 D_tricked_loss= tensor(1.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8865 D_real_loss= tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8865 D_fake_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8865 D_tricked_loss= tensor(1.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8866 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8866 D_fake_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8866 D_tricked_loss= tensor(1.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8867 D_real_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8867 D_fake_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8867 D_tricked_loss= tensor(1.3885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8868 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8868 D_fake_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8868 D_tricked_loss= tensor(1.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8869 D_real_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8869 D_fake_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8869 D_tricked_loss= tensor(1.3764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8870 D_real_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8870 D_fake_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8870 D_tricked_loss= tensor(1.3921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8871 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8871 D_fake_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8871 D_tricked_loss= tensor(1.3923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8872 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8872 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8872 D_tricked_loss= tensor(1.3963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8873 D_real_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8873 D_fake_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8873 D_tricked_loss= tensor(1.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8874 D_real_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8874 D_fake_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8874 D_tricked_loss= tensor(1.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8875 D_real_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8875 D_fake_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8875 D_tricked_loss= tensor(1.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8876 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8876 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8876 D_tricked_loss= tensor(1.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8877 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8877 D_fake_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8877 D_tricked_loss= tensor(1.3871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8878 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8878 D_fake_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8878 D_tricked_loss= tensor(1.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8879 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8879 D_fake_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8879 D_tricked_loss= tensor(1.3521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8880 D_real_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8880 D_fake_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8880 D_tricked_loss= tensor(1.3625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8881 D_real_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8881 D_fake_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8881 D_tricked_loss= tensor(1.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8882 D_real_loss= tensor(0.5001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8882 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8882 D_tricked_loss= tensor(1.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8883 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8883 D_fake_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8883 D_tricked_loss= tensor(1.3963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8884 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8884 D_fake_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8884 D_tricked_loss= tensor(1.4029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8885 D_real_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8885 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8885 D_tricked_loss= tensor(1.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8886 D_real_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8886 D_fake_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8886 D_tricked_loss= tensor(1.3976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8887 D_real_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8887 D_fake_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8887 D_tricked_loss= tensor(1.4005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8888 D_real_loss= tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8888 D_fake_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8888 D_tricked_loss= tensor(1.3858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8889 D_real_loss= tensor(0.5032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8889 D_fake_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8889 D_tricked_loss= tensor(1.3525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8890 D_real_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8890 D_fake_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8890 D_tricked_loss= tensor(1.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8891 D_real_loss= tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8891 D_fake_loss= tensor(0.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8891 D_tricked_loss= tensor(1.3767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8892 D_real_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8892 D_fake_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8892 D_tricked_loss= tensor(1.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8893 D_real_loss= tensor(0.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8893 D_fake_loss= tensor(0.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8893 D_tricked_loss= tensor(1.4053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8894 D_real_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8894 D_fake_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8894 D_tricked_loss= tensor(1.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8895 D_real_loss= tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8895 D_fake_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8895 D_tricked_loss= tensor(1.3995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8896 D_real_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8896 D_fake_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8896 D_tricked_loss= tensor(1.3697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8897 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8897 D_fake_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8897 D_tricked_loss= tensor(1.3907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8898 D_real_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8898 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8898 D_tricked_loss= tensor(1.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8899 D_real_loss= tensor(0.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8899 D_fake_loss= tensor(0.4525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8899 D_tricked_loss= tensor(1.4049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8900 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8900 D_fake_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8900 D_tricked_loss= tensor(1.4145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8901 D_real_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8901 D_fake_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8901 D_tricked_loss= tensor(1.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8902 D_real_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8902 D_fake_loss= tensor(0.4730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8902 D_tricked_loss= tensor(1.3955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8903 D_real_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8903 D_fake_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8903 D_tricked_loss= tensor(1.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8904 D_real_loss= tensor(0.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8904 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8904 D_tricked_loss= tensor(1.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8905 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8905 D_fake_loss= tensor(0.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8905 D_tricked_loss= tensor(1.3738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8906 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8906 D_fake_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8906 D_tricked_loss= tensor(1.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8907 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8907 D_fake_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8907 D_tricked_loss= tensor(1.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8908 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8908 D_fake_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8908 D_tricked_loss= tensor(1.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8909 D_real_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8909 D_fake_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8909 D_tricked_loss= tensor(1.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8910 D_real_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8910 D_fake_loss= tensor(0.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8910 D_tricked_loss= tensor(1.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8911 D_real_loss= tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8911 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8911 D_tricked_loss= tensor(1.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8912 D_real_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8912 D_fake_loss= tensor(0.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8912 D_tricked_loss= tensor(1.4395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8913 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8913 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8913 D_tricked_loss= tensor(1.3974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8914 D_real_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8914 D_fake_loss= tensor(0.4556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8914 D_tricked_loss= tensor(1.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8915 D_real_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8915 D_fake_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8915 D_tricked_loss= tensor(1.3809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8916 D_real_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8916 D_fake_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8916 D_tricked_loss= tensor(1.4133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8917 D_real_loss= tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8917 D_fake_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8917 D_tricked_loss= tensor(1.3769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8918 D_real_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8918 D_fake_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8918 D_tricked_loss= tensor(1.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8919 D_real_loss= tensor(0.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8919 D_fake_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8919 D_tricked_loss= tensor(1.3578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8920 D_real_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8920 D_fake_loss= tensor(0.4413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8920 D_tricked_loss= tensor(1.3947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8921 D_real_loss= tensor(0.4837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8921 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8921 D_tricked_loss= tensor(1.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8922 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8922 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8922 D_tricked_loss= tensor(1.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8923 D_real_loss= tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8923 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8923 D_tricked_loss= tensor(1.3848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8924 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8924 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8924 D_tricked_loss= tensor(1.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8925 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8925 D_fake_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8925 D_tricked_loss= tensor(1.4095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8926 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8926 D_fake_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8926 D_tricked_loss= tensor(1.3892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8927 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8927 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8927 D_tricked_loss= tensor(1.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8928 D_real_loss= tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8928 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8928 D_tricked_loss= tensor(1.4259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8929 D_real_loss= tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8929 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8929 D_tricked_loss= tensor(1.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8930 D_real_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8930 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8930 D_tricked_loss= tensor(1.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8931 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8931 D_fake_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8931 D_tricked_loss= tensor(1.4065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8932 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8932 D_fake_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8932 D_tricked_loss= tensor(1.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8933 D_real_loss= tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8933 D_fake_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8933 D_tricked_loss= tensor(1.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8934 D_real_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8934 D_fake_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8934 D_tricked_loss= tensor(1.3606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8935 D_real_loss= tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8935 D_fake_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8935 D_tricked_loss= tensor(1.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8936 D_real_loss= tensor(0.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8936 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8936 D_tricked_loss= tensor(1.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8937 D_real_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8937 D_fake_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8937 D_tricked_loss= tensor(1.4481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8938 D_real_loss= tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8938 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8938 D_tricked_loss= tensor(1.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8939 D_real_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8939 D_fake_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8939 D_tricked_loss= tensor(1.3935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8940 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8940 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8940 D_tricked_loss= tensor(1.3764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8941 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8941 D_fake_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8941 D_tricked_loss= tensor(1.3739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8942 D_real_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8942 D_fake_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8942 D_tricked_loss= tensor(1.3684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8943 D_real_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8943 D_fake_loss= tensor(0.4440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8943 D_tricked_loss= tensor(1.3974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8944 D_real_loss= tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8944 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8944 D_tricked_loss= tensor(1.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8945 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8945 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8945 D_tricked_loss= tensor(1.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8946 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8946 D_fake_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8946 D_tricked_loss= tensor(1.4249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8947 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8947 D_fake_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8947 D_tricked_loss= tensor(1.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8948 D_real_loss= tensor(0.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8948 D_fake_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8948 D_tricked_loss= tensor(1.3979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8949 D_real_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8949 D_fake_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8949 D_tricked_loss= tensor(1.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8950 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8950 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8950 D_tricked_loss= tensor(1.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8951 D_real_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8951 D_fake_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8951 D_tricked_loss= tensor(1.3683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8952 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8952 D_fake_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8952 D_tricked_loss= tensor(1.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8953 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8953 D_fake_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8953 D_tricked_loss= tensor(1.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8954 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8954 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8954 D_tricked_loss= tensor(1.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8955 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8955 D_fake_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8955 D_tricked_loss= tensor(1.3842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8956 D_real_loss= tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8956 D_fake_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8956 D_tricked_loss= tensor(1.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8957 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8957 D_fake_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8957 D_tricked_loss= tensor(1.3927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8958 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8958 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8958 D_tricked_loss= tensor(1.3847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8959 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8959 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8959 D_tricked_loss= tensor(1.4041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8960 D_real_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8960 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8960 D_tricked_loss= tensor(1.3761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8961 D_real_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8961 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8961 D_tricked_loss= tensor(1.3932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8962 D_real_loss= tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8962 D_fake_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8962 D_tricked_loss= tensor(1.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8963 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8963 D_fake_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8963 D_tricked_loss= tensor(1.3872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8964 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8964 D_fake_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8964 D_tricked_loss= tensor(1.4225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8965 D_real_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8965 D_fake_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8965 D_tricked_loss= tensor(1.3999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8966 D_real_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8966 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8966 D_tricked_loss= tensor(1.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8967 D_real_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8967 D_fake_loss= tensor(0.4643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8967 D_tricked_loss= tensor(1.4141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8968 D_real_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8968 D_fake_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8968 D_tricked_loss= tensor(1.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8969 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8969 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8969 D_tricked_loss= tensor(1.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8970 D_real_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8970 D_fake_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8970 D_tricked_loss= tensor(1.3988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8971 D_real_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8971 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8971 D_tricked_loss= tensor(1.3816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8972 D_real_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8972 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8972 D_tricked_loss= tensor(1.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8973 D_real_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8973 D_fake_loss= tensor(0.4577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8973 D_tricked_loss= tensor(1.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8974 D_real_loss= tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8974 D_fake_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8974 D_tricked_loss= tensor(1.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8975 D_real_loss= tensor(0.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8975 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8975 D_tricked_loss= tensor(1.3948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8976 D_real_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8976 D_fake_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8976 D_tricked_loss= tensor(1.3738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8977 D_real_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8977 D_fake_loss= tensor(0.4377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8977 D_tricked_loss= tensor(1.4145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8978 D_real_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8978 D_fake_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8978 D_tricked_loss= tensor(1.4050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8979 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8979 D_fake_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8979 D_tricked_loss= tensor(1.4172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8980 D_real_loss= tensor(0.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8980 D_fake_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8980 D_tricked_loss= tensor(1.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8981 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8981 D_fake_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8981 D_tricked_loss= tensor(1.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8982 D_real_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8982 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8982 D_tricked_loss= tensor(1.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8983 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8983 D_fake_loss= tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8983 D_tricked_loss= tensor(1.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8984 D_real_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8984 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8984 D_tricked_loss= tensor(1.4130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8985 D_real_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8985 D_fake_loss= tensor(0.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8985 D_tricked_loss= tensor(1.4007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8986 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8986 D_fake_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8986 D_tricked_loss= tensor(1.4013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8987 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8987 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8987 D_tricked_loss= tensor(1.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8988 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8988 D_fake_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8988 D_tricked_loss= tensor(1.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8989 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8989 D_fake_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8989 D_tricked_loss= tensor(1.3853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8990 D_real_loss= tensor(0.4971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8990 D_fake_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8990 D_tricked_loss= tensor(1.4047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8991 D_real_loss= tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8991 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8991 D_tricked_loss= tensor(1.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8992 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8992 D_fake_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8992 D_tricked_loss= tensor(1.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8993 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8993 D_fake_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8993 D_tricked_loss= tensor(1.4057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8994 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8994 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8994 D_tricked_loss= tensor(1.4106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8995 D_real_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8995 D_fake_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8995 D_tricked_loss= tensor(1.3910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8996 D_real_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8996 D_fake_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8996 D_tricked_loss= tensor(1.3952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8997 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8997 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8997 D_tricked_loss= tensor(1.4056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8998 D_real_loss= tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8998 D_fake_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8998 D_tricked_loss= tensor(1.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "8999 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8999 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8999 D_tricked_loss= tensor(1.3716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9000 D_real_loss= tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9000 D_fake_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9000 D_tricked_loss= tensor(1.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9001 D_real_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9001 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9001 D_tricked_loss= tensor(1.3970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9002 D_real_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9002 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9002 D_tricked_loss= tensor(1.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9003 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9003 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9003 D_tricked_loss= tensor(1.4306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9004 D_real_loss= tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9004 D_fake_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9004 D_tricked_loss= tensor(1.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9005 D_real_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9005 D_fake_loss= tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9005 D_tricked_loss= tensor(1.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9006 D_real_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9006 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9006 D_tricked_loss= tensor(1.3799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9007 D_real_loss= tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9007 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9007 D_tricked_loss= tensor(1.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9008 D_real_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9008 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9008 D_tricked_loss= tensor(1.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9009 D_real_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9009 D_fake_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9009 D_tricked_loss= tensor(1.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9010 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9010 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9010 D_tricked_loss= tensor(1.4299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9011 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9011 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9011 D_tricked_loss= tensor(1.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9012 D_real_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9012 D_fake_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9012 D_tricked_loss= tensor(1.4074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9013 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9013 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9013 D_tricked_loss= tensor(1.4068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9014 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9014 D_fake_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9014 D_tricked_loss= tensor(1.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9015 D_real_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9015 D_fake_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9015 D_tricked_loss= tensor(1.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9016 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9016 D_fake_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9016 D_tricked_loss= tensor(1.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9017 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9017 D_fake_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9017 D_tricked_loss= tensor(1.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9018 D_real_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9018 D_fake_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9018 D_tricked_loss= tensor(1.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9019 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9019 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9019 D_tricked_loss= tensor(1.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9020 D_real_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9020 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9020 D_tricked_loss= tensor(1.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9021 D_real_loss= tensor(0.4648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9021 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9021 D_tricked_loss= tensor(1.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9022 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9022 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9022 D_tricked_loss= tensor(1.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9023 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9023 D_fake_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9023 D_tricked_loss= tensor(1.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9024 D_real_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9024 D_fake_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9024 D_tricked_loss= tensor(1.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9025 D_real_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9025 D_fake_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9025 D_tricked_loss= tensor(1.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9026 D_real_loss= tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9026 D_fake_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9026 D_tricked_loss= tensor(1.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9027 D_real_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9027 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9027 D_tricked_loss= tensor(1.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9028 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9028 D_fake_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9028 D_tricked_loss= tensor(1.4259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9029 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9029 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9029 D_tricked_loss= tensor(1.4197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9030 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9030 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9030 D_tricked_loss= tensor(1.4051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9031 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9031 D_fake_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9031 D_tricked_loss= tensor(1.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9032 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9032 D_fake_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9032 D_tricked_loss= tensor(1.4237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9033 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9033 D_fake_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9033 D_tricked_loss= tensor(1.3632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9034 D_real_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9034 D_fake_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9034 D_tricked_loss= tensor(1.3948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9035 D_real_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9035 D_fake_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9035 D_tricked_loss= tensor(1.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9036 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9036 D_fake_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9036 D_tricked_loss= tensor(1.4088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9037 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9037 D_fake_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9037 D_tricked_loss= tensor(1.4275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9038 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9038 D_fake_loss= tensor(0.4738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9038 D_tricked_loss= tensor(1.4262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9039 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9039 D_fake_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9039 D_tricked_loss= tensor(1.4037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9040 D_real_loss= tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9040 D_fake_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9040 D_tricked_loss= tensor(1.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9041 D_real_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9041 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9041 D_tricked_loss= tensor(1.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9042 D_real_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9042 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9042 D_tricked_loss= tensor(1.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9043 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9043 D_fake_loss= tensor(0.4783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9043 D_tricked_loss= tensor(1.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9044 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9044 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9044 D_tricked_loss= tensor(1.4018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9045 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9045 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9045 D_tricked_loss= tensor(1.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9046 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9046 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9046 D_tricked_loss= tensor(1.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9047 D_real_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9047 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9047 D_tricked_loss= tensor(1.3884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9048 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9048 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9048 D_tricked_loss= tensor(1.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9049 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9049 D_fake_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9049 D_tricked_loss= tensor(1.4139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9050 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9050 D_fake_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9050 D_tricked_loss= tensor(1.4040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9051 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9051 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9051 D_tricked_loss= tensor(1.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9052 D_real_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9052 D_fake_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9052 D_tricked_loss= tensor(1.4133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9053 D_real_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9053 D_fake_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9053 D_tricked_loss= tensor(1.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9054 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9054 D_fake_loss= tensor(0.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9054 D_tricked_loss= tensor(1.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9055 D_real_loss= tensor(0.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9055 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9055 D_tricked_loss= tensor(1.4132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9056 D_real_loss= tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9056 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9056 D_tricked_loss= tensor(1.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9057 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9057 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9057 D_tricked_loss= tensor(1.4041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9058 D_real_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9058 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9058 D_tricked_loss= tensor(1.3958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9059 D_real_loss= tensor(0.5118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9059 D_fake_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9059 D_tricked_loss= tensor(1.4129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9060 D_real_loss= tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9060 D_fake_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9060 D_tricked_loss= tensor(1.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9061 D_real_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9061 D_fake_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9061 D_tricked_loss= tensor(1.3869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9062 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9062 D_fake_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9062 D_tricked_loss= tensor(1.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9063 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9063 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9063 D_tricked_loss= tensor(1.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9064 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9064 D_fake_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9064 D_tricked_loss= tensor(1.3616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9065 D_real_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9065 D_fake_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9065 D_tricked_loss= tensor(1.4147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9066 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9066 D_fake_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9066 D_tricked_loss= tensor(1.4178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9067 D_real_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9067 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9067 D_tricked_loss= tensor(1.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9068 D_real_loss= tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9068 D_fake_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9068 D_tricked_loss= tensor(1.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9069 D_real_loss= tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9069 D_fake_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9069 D_tricked_loss= tensor(1.4082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9070 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9070 D_fake_loss= tensor(0.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9070 D_tricked_loss= tensor(1.3940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9071 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9071 D_fake_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9071 D_tricked_loss= tensor(1.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9072 D_real_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9072 D_fake_loss= tensor(0.4333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9072 D_tricked_loss= tensor(1.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9073 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9073 D_fake_loss= tensor(0.4903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9073 D_tricked_loss= tensor(1.4029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9074 D_real_loss= tensor(0.5025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9074 D_fake_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9074 D_tricked_loss= tensor(1.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9075 D_real_loss= tensor(0.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9075 D_fake_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9075 D_tricked_loss= tensor(1.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9076 D_real_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9076 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9076 D_tricked_loss= tensor(1.3902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9077 D_real_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9077 D_fake_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9077 D_tricked_loss= tensor(1.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9078 D_real_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9078 D_fake_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9078 D_tricked_loss= tensor(1.4241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9079 D_real_loss= tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9079 D_fake_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9079 D_tricked_loss= tensor(1.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9080 D_real_loss= tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9080 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9080 D_tricked_loss= tensor(1.4023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9081 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9081 D_fake_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9081 D_tricked_loss= tensor(1.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9082 D_real_loss= tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9082 D_fake_loss= tensor(0.4404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9082 D_tricked_loss= tensor(1.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9083 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9083 D_fake_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9083 D_tricked_loss= tensor(1.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9084 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9084 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9084 D_tricked_loss= tensor(1.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9085 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9085 D_fake_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9085 D_tricked_loss= tensor(1.4118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9086 D_real_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9086 D_fake_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9086 D_tricked_loss= tensor(1.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9087 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9087 D_fake_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9087 D_tricked_loss= tensor(1.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9088 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9088 D_fake_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9088 D_tricked_loss= tensor(1.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9089 D_real_loss= tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9089 D_fake_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9089 D_tricked_loss= tensor(1.3947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9090 D_real_loss= tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9090 D_fake_loss= tensor(0.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9090 D_tricked_loss= tensor(1.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9091 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9091 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9091 D_tricked_loss= tensor(1.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9092 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9092 D_fake_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9092 D_tricked_loss= tensor(1.3616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9093 D_real_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9093 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9093 D_tricked_loss= tensor(1.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9094 D_real_loss= tensor(0.5087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9094 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9094 D_tricked_loss= tensor(1.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9095 D_real_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9095 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9095 D_tricked_loss= tensor(1.3816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9096 D_real_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9096 D_fake_loss= tensor(0.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9096 D_tricked_loss= tensor(1.4137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9097 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9097 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9097 D_tricked_loss= tensor(1.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9098 D_real_loss= tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9098 D_fake_loss= tensor(0.4285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9098 D_tricked_loss= tensor(1.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9099 D_real_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9099 D_fake_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9099 D_tricked_loss= tensor(1.3756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9100 D_real_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9100 D_fake_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9100 D_tricked_loss= tensor(1.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9101 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9101 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9101 D_tricked_loss= tensor(1.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9102 D_real_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9102 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9102 D_tricked_loss= tensor(1.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9103 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9103 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9103 D_tricked_loss= tensor(1.4062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9104 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9104 D_fake_loss= tensor(0.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9104 D_tricked_loss= tensor(1.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9105 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9105 D_fake_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9105 D_tricked_loss= tensor(1.3857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9106 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9106 D_fake_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9106 D_tricked_loss= tensor(1.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9107 D_real_loss= tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9107 D_fake_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9107 D_tricked_loss= tensor(1.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9108 D_real_loss= tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9108 D_fake_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9108 D_tricked_loss= tensor(1.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9109 D_real_loss= tensor(0.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9109 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9109 D_tricked_loss= tensor(1.3737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9110 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9110 D_fake_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9110 D_tricked_loss= tensor(1.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9111 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9111 D_fake_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9111 D_tricked_loss= tensor(1.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9112 D_real_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9112 D_fake_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9112 D_tricked_loss= tensor(1.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9113 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9113 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9113 D_tricked_loss= tensor(1.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9114 D_real_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9114 D_fake_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9114 D_tricked_loss= tensor(1.4413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9115 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9115 D_fake_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9115 D_tricked_loss= tensor(1.4102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9116 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9116 D_fake_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9116 D_tricked_loss= tensor(1.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9117 D_real_loss= tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9117 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9117 D_tricked_loss= tensor(1.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9118 D_real_loss= tensor(0.4936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9118 D_fake_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9118 D_tricked_loss= tensor(1.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9119 D_real_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9119 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9119 D_tricked_loss= tensor(1.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9120 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9120 D_fake_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9120 D_tricked_loss= tensor(1.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9121 D_real_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9121 D_fake_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9121 D_tricked_loss= tensor(1.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9122 D_real_loss= tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9122 D_fake_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9122 D_tricked_loss= tensor(1.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9123 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9123 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9123 D_tricked_loss= tensor(1.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9124 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9124 D_fake_loss= tensor(0.4482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9124 D_tricked_loss= tensor(1.4336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9125 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9125 D_fake_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9125 D_tricked_loss= tensor(1.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9126 D_real_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9126 D_fake_loss= tensor(0.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9126 D_tricked_loss= tensor(1.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9127 D_real_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9127 D_fake_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9127 D_tricked_loss= tensor(1.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9128 D_real_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9128 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9128 D_tricked_loss= tensor(1.4600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9129 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9129 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9129 D_tricked_loss= tensor(1.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9130 D_real_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9130 D_fake_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9130 D_tricked_loss= tensor(1.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9131 D_real_loss= tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9131 D_fake_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9131 D_tricked_loss= tensor(1.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9132 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9132 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9132 D_tricked_loss= tensor(1.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9133 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9133 D_fake_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9133 D_tricked_loss= tensor(1.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9134 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9134 D_fake_loss= tensor(0.4643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9134 D_tricked_loss= tensor(1.4055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9135 D_real_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9135 D_fake_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9135 D_tricked_loss= tensor(1.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9136 D_real_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9136 D_fake_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9136 D_tricked_loss= tensor(1.3976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9137 D_real_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9137 D_fake_loss= tensor(0.4577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9137 D_tricked_loss= tensor(1.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9138 D_real_loss= tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9138 D_fake_loss= tensor(0.4306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9138 D_tricked_loss= tensor(1.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9139 D_real_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9139 D_fake_loss= tensor(0.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9139 D_tricked_loss= tensor(1.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9140 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9140 D_fake_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9140 D_tricked_loss= tensor(1.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9141 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9141 D_fake_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9141 D_tricked_loss= tensor(1.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9142 D_real_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9142 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9142 D_tricked_loss= tensor(1.3782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9143 D_real_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9143 D_fake_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9143 D_tricked_loss= tensor(1.4139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9144 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9144 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9144 D_tricked_loss= tensor(1.4162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9145 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9145 D_fake_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9145 D_tricked_loss= tensor(1.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9146 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9146 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9146 D_tricked_loss= tensor(1.4010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9147 D_real_loss= tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9147 D_fake_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9147 D_tricked_loss= tensor(1.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9148 D_real_loss= tensor(0.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9148 D_fake_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9148 D_tricked_loss= tensor(1.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9149 D_real_loss= tensor(0.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9149 D_fake_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9149 D_tricked_loss= tensor(1.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9150 D_real_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9150 D_fake_loss= tensor(0.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9150 D_tricked_loss= tensor(1.3970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9151 D_real_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9151 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9151 D_tricked_loss= tensor(1.3874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9152 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9152 D_fake_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9152 D_tricked_loss= tensor(1.3708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9153 D_real_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9153 D_fake_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9153 D_tricked_loss= tensor(1.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9154 D_real_loss= tensor(0.4892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9154 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9154 D_tricked_loss= tensor(1.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9155 D_real_loss= tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9155 D_fake_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9155 D_tricked_loss= tensor(1.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9156 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9156 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9156 D_tricked_loss= tensor(1.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9157 D_real_loss= tensor(0.5131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9157 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9157 D_tricked_loss= tensor(1.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9158 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9158 D_fake_loss= tensor(0.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9158 D_tricked_loss= tensor(1.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9159 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9159 D_fake_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9159 D_tricked_loss= tensor(1.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9160 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9160 D_fake_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9160 D_tricked_loss= tensor(1.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9161 D_real_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9161 D_fake_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9161 D_tricked_loss= tensor(1.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9162 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9162 D_fake_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9162 D_tricked_loss= tensor(1.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9163 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9163 D_fake_loss= tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9163 D_tricked_loss= tensor(1.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9164 D_real_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9164 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9164 D_tricked_loss= tensor(1.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9165 D_real_loss= tensor(0.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9165 D_fake_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9165 D_tricked_loss= tensor(1.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9166 D_real_loss= tensor(0.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9166 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9166 D_tricked_loss= tensor(1.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9167 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9167 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9167 D_tricked_loss= tensor(1.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9168 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9168 D_fake_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9168 D_tricked_loss= tensor(1.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9169 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9169 D_fake_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9169 D_tricked_loss= tensor(1.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9170 D_real_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9170 D_fake_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9170 D_tricked_loss= tensor(1.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9171 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9171 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9171 D_tricked_loss= tensor(1.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9172 D_real_loss= tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9172 D_fake_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9172 D_tricked_loss= tensor(1.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9173 D_real_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9173 D_fake_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9173 D_tricked_loss= tensor(1.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9174 D_real_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9174 D_fake_loss= tensor(0.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9174 D_tricked_loss= tensor(1.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9175 D_real_loss= tensor(0.4648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9175 D_fake_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9175 D_tricked_loss= tensor(1.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9176 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9176 D_fake_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9176 D_tricked_loss= tensor(1.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9177 D_real_loss= tensor(0.4968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9177 D_fake_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9177 D_tricked_loss= tensor(1.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9178 D_real_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9178 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9178 D_tricked_loss= tensor(1.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9179 D_real_loss= tensor(0.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9179 D_fake_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9179 D_tricked_loss= tensor(1.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9180 D_real_loss= tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9180 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9180 D_tricked_loss= tensor(1.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9181 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9181 D_fake_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9181 D_tricked_loss= tensor(1.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9182 D_real_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9182 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9182 D_tricked_loss= tensor(1.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9183 D_real_loss= tensor(0.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9183 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9183 D_tricked_loss= tensor(1.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9184 D_real_loss= tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9184 D_fake_loss= tensor(0.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9184 D_tricked_loss= tensor(1.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9185 D_real_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9185 D_fake_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9185 D_tricked_loss= tensor(1.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9186 D_real_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9186 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9186 D_tricked_loss= tensor(1.4014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9187 D_real_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9187 D_fake_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9187 D_tricked_loss= tensor(1.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9188 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9188 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9188 D_tricked_loss= tensor(1.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9189 D_real_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9189 D_fake_loss= tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9189 D_tricked_loss= tensor(1.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9190 D_real_loss= tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9190 D_fake_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9190 D_tricked_loss= tensor(1.3925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9191 D_real_loss= tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9191 D_fake_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9191 D_tricked_loss= tensor(1.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9192 D_real_loss= tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9192 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9192 D_tricked_loss= tensor(1.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9193 D_real_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9193 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9193 D_tricked_loss= tensor(1.4156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9194 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9194 D_fake_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9194 D_tricked_loss= tensor(1.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9195 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9195 D_fake_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9195 D_tricked_loss= tensor(1.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9196 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9196 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9196 D_tricked_loss= tensor(1.4035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9197 D_real_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9197 D_fake_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9197 D_tricked_loss= tensor(1.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9198 D_real_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9198 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9198 D_tricked_loss= tensor(1.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9199 D_real_loss= tensor(0.5130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9199 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9199 D_tricked_loss= tensor(1.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9200 D_real_loss= tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9200 D_fake_loss= tensor(0.4495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9200 D_tricked_loss= tensor(1.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9201 D_real_loss= tensor(0.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9201 D_fake_loss= tensor(0.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9201 D_tricked_loss= tensor(1.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9202 D_real_loss= tensor(0.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9202 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9202 D_tricked_loss= tensor(1.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9203 D_real_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9203 D_fake_loss= tensor(0.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9203 D_tricked_loss= tensor(1.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9204 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9204 D_fake_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9204 D_tricked_loss= tensor(1.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9205 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9205 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9205 D_tricked_loss= tensor(1.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9206 D_real_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9206 D_fake_loss= tensor(0.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9206 D_tricked_loss= tensor(1.3914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9207 D_real_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9207 D_fake_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9207 D_tricked_loss= tensor(1.4019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9208 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9208 D_fake_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9208 D_tricked_loss= tensor(1.4172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9209 D_real_loss= tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9209 D_fake_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9209 D_tricked_loss= tensor(1.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9210 D_real_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9210 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9210 D_tricked_loss= tensor(1.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9211 D_real_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9211 D_fake_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9211 D_tricked_loss= tensor(1.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9212 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9212 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9212 D_tricked_loss= tensor(1.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9213 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9213 D_fake_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9213 D_tricked_loss= tensor(1.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9214 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9214 D_fake_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9214 D_tricked_loss= tensor(1.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9215 D_real_loss= tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9215 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9215 D_tricked_loss= tensor(1.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9216 D_real_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9216 D_fake_loss= tensor(0.4600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9216 D_tricked_loss= tensor(1.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9217 D_real_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9217 D_fake_loss= tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9217 D_tricked_loss= tensor(1.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9218 D_real_loss= tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9218 D_fake_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9218 D_tricked_loss= tensor(1.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9219 D_real_loss= tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9219 D_fake_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9219 D_tricked_loss= tensor(1.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9220 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9220 D_fake_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9220 D_tricked_loss= tensor(1.5167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9221 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9221 D_fake_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9221 D_tricked_loss= tensor(1.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9222 D_real_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9222 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9222 D_tricked_loss= tensor(1.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9223 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9223 D_fake_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9223 D_tricked_loss= tensor(1.3710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9224 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9224 D_fake_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9224 D_tricked_loss= tensor(1.3967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9225 D_real_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9225 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9225 D_tricked_loss= tensor(1.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9226 D_real_loss= tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9226 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9226 D_tricked_loss= tensor(1.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9227 D_real_loss= tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9227 D_fake_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9227 D_tricked_loss= tensor(1.5021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9228 D_real_loss= tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9228 D_fake_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9228 D_tricked_loss= tensor(1.5194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9229 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9229 D_fake_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9229 D_tricked_loss= tensor(1.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9230 D_real_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9230 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9230 D_tricked_loss= tensor(1.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9231 D_real_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9231 D_fake_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9231 D_tricked_loss= tensor(1.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9232 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9232 D_fake_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9232 D_tricked_loss= tensor(1.3901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9233 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9233 D_fake_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9233 D_tricked_loss= tensor(1.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9234 D_real_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9234 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9234 D_tricked_loss= tensor(1.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9235 D_real_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9235 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9235 D_tricked_loss= tensor(1.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9236 D_real_loss= tensor(0.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9236 D_fake_loss= tensor(0.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9236 D_tricked_loss= tensor(1.4912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9237 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9237 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9237 D_tricked_loss= tensor(1.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9238 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9238 D_fake_loss= tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9238 D_tricked_loss= tensor(1.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9239 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9239 D_fake_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9239 D_tricked_loss= tensor(1.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9240 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9240 D_fake_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9240 D_tricked_loss= tensor(1.3863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9241 D_real_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9241 D_fake_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9241 D_tricked_loss= tensor(1.3695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9242 D_real_loss= tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9242 D_fake_loss= tensor(0.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9242 D_tricked_loss= tensor(1.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9243 D_real_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9243 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9243 D_tricked_loss= tensor(1.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9244 D_real_loss= tensor(0.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9244 D_fake_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9244 D_tricked_loss= tensor(1.5302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9245 D_real_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9245 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9245 D_tricked_loss= tensor(1.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9246 D_real_loss= tensor(0.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9246 D_fake_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9246 D_tricked_loss= tensor(1.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9247 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9247 D_fake_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9247 D_tricked_loss= tensor(1.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9248 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9248 D_fake_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9248 D_tricked_loss= tensor(1.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9249 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9249 D_fake_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9249 D_tricked_loss= tensor(1.4251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9250 D_real_loss= tensor(0.4620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9250 D_fake_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9250 D_tricked_loss= tensor(1.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9251 D_real_loss= tensor(0.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9251 D_fake_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9251 D_tricked_loss= tensor(1.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9252 D_real_loss= tensor(0.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9252 D_fake_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9252 D_tricked_loss= tensor(1.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9253 D_real_loss= tensor(0.4837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9253 D_fake_loss= tensor(0.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9253 D_tricked_loss= tensor(1.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9254 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9254 D_fake_loss= tensor(0.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9254 D_tricked_loss= tensor(1.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9255 D_real_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9255 D_fake_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9255 D_tricked_loss= tensor(1.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9256 D_real_loss= tensor(0.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9256 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9256 D_tricked_loss= tensor(1.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9257 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9257 D_fake_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9257 D_tricked_loss= tensor(1.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9258 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9258 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9258 D_tricked_loss= tensor(1.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9259 D_real_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9259 D_fake_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9259 D_tricked_loss= tensor(1.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9260 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9260 D_fake_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9260 D_tricked_loss= tensor(1.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9261 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9261 D_fake_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9261 D_tricked_loss= tensor(1.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9262 D_real_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9262 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9262 D_tricked_loss= tensor(1.4577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9263 D_real_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9263 D_fake_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9263 D_tricked_loss= tensor(1.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9264 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9264 D_fake_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9264 D_tricked_loss= tensor(1.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9265 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9265 D_fake_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9265 D_tricked_loss= tensor(1.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9266 D_real_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9266 D_fake_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9266 D_tricked_loss= tensor(1.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9267 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9267 D_fake_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9267 D_tricked_loss= tensor(1.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9268 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9268 D_fake_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9268 D_tricked_loss= tensor(1.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9269 D_real_loss= tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9269 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9269 D_tricked_loss= tensor(1.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9270 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9270 D_fake_loss= tensor(0.4395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9270 D_tricked_loss= tensor(1.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9271 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9271 D_fake_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9271 D_tricked_loss= tensor(1.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9272 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9272 D_fake_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9272 D_tricked_loss= tensor(1.4937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9273 D_real_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9273 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9273 D_tricked_loss= tensor(1.5089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9274 D_real_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9274 D_fake_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9274 D_tricked_loss= tensor(1.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9275 D_real_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9275 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9275 D_tricked_loss= tensor(1.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9276 D_real_loss= tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9276 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9276 D_tricked_loss= tensor(1.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9277 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9277 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9277 D_tricked_loss= tensor(1.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9278 D_real_loss= tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9278 D_fake_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9278 D_tricked_loss= tensor(1.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9279 D_real_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9279 D_fake_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9279 D_tricked_loss= tensor(1.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9280 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9280 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9280 D_tricked_loss= tensor(1.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9281 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9281 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9281 D_tricked_loss= tensor(1.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9282 D_real_loss= tensor(0.4843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9282 D_fake_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9282 D_tricked_loss= tensor(1.4069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9283 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9283 D_fake_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9283 D_tricked_loss= tensor(1.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9284 D_real_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9284 D_fake_loss= tensor(0.4761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9284 D_tricked_loss= tensor(1.3740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9285 D_real_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9285 D_fake_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9285 D_tricked_loss= tensor(1.3900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9286 D_real_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9286 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9286 D_tricked_loss= tensor(1.3958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9287 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9287 D_fake_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9287 D_tricked_loss= tensor(1.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9288 D_real_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9288 D_fake_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9288 D_tricked_loss= tensor(1.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9289 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9289 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9289 D_tricked_loss= tensor(1.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9290 D_real_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9290 D_fake_loss= tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9290 D_tricked_loss= tensor(1.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9291 D_real_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9291 D_fake_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9291 D_tricked_loss= tensor(1.4167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9292 D_real_loss= tensor(0.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9292 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9292 D_tricked_loss= tensor(1.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9293 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9293 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9293 D_tricked_loss= tensor(1.4078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9294 D_real_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9294 D_fake_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9294 D_tricked_loss= tensor(1.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9295 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9295 D_fake_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9295 D_tricked_loss= tensor(1.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9296 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9296 D_fake_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9296 D_tricked_loss= tensor(1.4603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9297 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9297 D_fake_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9297 D_tricked_loss= tensor(1.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9298 D_real_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9298 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9298 D_tricked_loss= tensor(1.5267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9299 D_real_loss= tensor(0.5012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9299 D_fake_loss= tensor(0.4333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9299 D_tricked_loss= tensor(1.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9300 D_real_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9300 D_fake_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9300 D_tricked_loss= tensor(1.4643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9301 D_real_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9301 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9301 D_tricked_loss= tensor(1.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9302 D_real_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9302 D_fake_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9302 D_tricked_loss= tensor(1.3846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9303 D_real_loss= tensor(0.5024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9303 D_fake_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9303 D_tricked_loss= tensor(1.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9304 D_real_loss= tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9304 D_fake_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9304 D_tricked_loss= tensor(1.4922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9305 D_real_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9305 D_fake_loss= tensor(0.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9305 D_tricked_loss= tensor(1.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9306 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9306 D_fake_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9306 D_tricked_loss= tensor(1.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9307 D_real_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9307 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9307 D_tricked_loss= tensor(1.4050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9308 D_real_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9308 D_fake_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9308 D_tricked_loss= tensor(1.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9309 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9309 D_fake_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9309 D_tricked_loss= tensor(1.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9310 D_real_loss= tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9310 D_fake_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9310 D_tricked_loss= tensor(1.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9311 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9311 D_fake_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9311 D_tricked_loss= tensor(1.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9312 D_real_loss= tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9312 D_fake_loss= tensor(0.4783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9312 D_tricked_loss= tensor(1.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9313 D_real_loss= tensor(0.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9313 D_fake_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9313 D_tricked_loss= tensor(1.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9314 D_real_loss= tensor(0.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9314 D_fake_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9314 D_tricked_loss= tensor(1.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9315 D_real_loss= tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9315 D_fake_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9315 D_tricked_loss= tensor(1.5053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9316 D_real_loss= tensor(0.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9316 D_fake_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9316 D_tricked_loss= tensor(1.3898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9317 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9317 D_fake_loss= tensor(0.4858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9317 D_tricked_loss= tensor(1.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9318 D_real_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9318 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9318 D_tricked_loss= tensor(1.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9319 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9319 D_fake_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9319 D_tricked_loss= tensor(1.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9320 D_real_loss= tensor(0.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9320 D_fake_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9320 D_tricked_loss= tensor(1.4083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9321 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9321 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9321 D_tricked_loss= tensor(1.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9322 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9322 D_fake_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9322 D_tricked_loss= tensor(1.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9323 D_real_loss= tensor(0.5087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9323 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9323 D_tricked_loss= tensor(1.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9324 D_real_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9324 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9324 D_tricked_loss= tensor(1.4074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9325 D_real_loss= tensor(0.4806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9325 D_fake_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9325 D_tricked_loss= tensor(1.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9326 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9326 D_fake_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9326 D_tricked_loss= tensor(1.4286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9327 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9327 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9327 D_tricked_loss= tensor(1.3939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9328 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9328 D_fake_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9328 D_tricked_loss= tensor(1.4156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9329 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9329 D_fake_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9329 D_tricked_loss= tensor(1.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9330 D_real_loss= tensor(0.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9330 D_fake_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9330 D_tricked_loss= tensor(1.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9331 D_real_loss= tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9331 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9331 D_tricked_loss= tensor(1.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9332 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9332 D_fake_loss= tensor(0.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9332 D_tricked_loss= tensor(1.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9333 D_real_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9333 D_fake_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9333 D_tricked_loss= tensor(1.4115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9334 D_real_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9334 D_fake_loss= tensor(0.4699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9334 D_tricked_loss= tensor(1.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9335 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9335 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9335 D_tricked_loss= tensor(1.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9336 D_real_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9336 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9336 D_tricked_loss= tensor(1.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9337 D_real_loss= tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9337 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9337 D_tricked_loss= tensor(1.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9338 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9338 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9338 D_tricked_loss= tensor(1.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9339 D_real_loss= tensor(0.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9339 D_fake_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9339 D_tricked_loss= tensor(1.4319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9340 D_real_loss= tensor(0.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9340 D_fake_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9340 D_tricked_loss= tensor(1.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9341 D_real_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9341 D_fake_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9341 D_tricked_loss= tensor(1.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9342 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9342 D_fake_loss= tensor(0.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9342 D_tricked_loss= tensor(1.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9343 D_real_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9343 D_fake_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9343 D_tricked_loss= tensor(1.4087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9344 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9344 D_fake_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9344 D_tricked_loss= tensor(1.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9345 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9345 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9345 D_tricked_loss= tensor(1.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9346 D_real_loss= tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9346 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9346 D_tricked_loss= tensor(1.5025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9347 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9347 D_fake_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9347 D_tricked_loss= tensor(1.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9348 D_real_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9348 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9348 D_tricked_loss= tensor(1.4949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9349 D_real_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9349 D_fake_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9349 D_tricked_loss= tensor(1.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9350 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9350 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9350 D_tricked_loss= tensor(1.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9351 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9351 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9351 D_tricked_loss= tensor(1.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9352 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9352 D_fake_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9352 D_tricked_loss= tensor(1.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9353 D_real_loss= tensor(0.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9353 D_fake_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9353 D_tricked_loss= tensor(1.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9354 D_real_loss= tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9354 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9354 D_tricked_loss= tensor(1.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9355 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9355 D_fake_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9355 D_tricked_loss= tensor(1.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9356 D_real_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9356 D_fake_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9356 D_tricked_loss= tensor(1.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9357 D_real_loss= tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9357 D_fake_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9357 D_tricked_loss= tensor(1.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9358 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9358 D_fake_loss= tensor(0.4704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9358 D_tricked_loss= tensor(1.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9359 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9359 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9359 D_tricked_loss= tensor(1.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9360 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9360 D_fake_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9360 D_tricked_loss= tensor(1.4139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9361 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9361 D_fake_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9361 D_tricked_loss= tensor(1.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9362 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9362 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9362 D_tricked_loss= tensor(1.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9363 D_real_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9363 D_fake_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9363 D_tricked_loss= tensor(1.4082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9364 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9364 D_fake_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9364 D_tricked_loss= tensor(1.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9365 D_real_loss= tensor(0.4786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9365 D_fake_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9365 D_tricked_loss= tensor(1.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9366 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9366 D_fake_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9366 D_tricked_loss= tensor(1.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9367 D_real_loss= tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9367 D_fake_loss= tensor(0.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9367 D_tricked_loss= tensor(1.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9368 D_real_loss= tensor(0.4995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9368 D_fake_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9368 D_tricked_loss= tensor(1.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9369 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9369 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9369 D_tricked_loss= tensor(1.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9370 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9370 D_fake_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9370 D_tricked_loss= tensor(1.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9371 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9371 D_fake_loss= tensor(0.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9371 D_tricked_loss= tensor(1.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9372 D_real_loss= tensor(0.4556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9372 D_fake_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9372 D_tricked_loss= tensor(1.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9373 D_real_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9373 D_fake_loss= tensor(0.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9373 D_tricked_loss= tensor(1.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9374 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9374 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9374 D_tricked_loss= tensor(1.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9375 D_real_loss= tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9375 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9375 D_tricked_loss= tensor(1.4943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9376 D_real_loss= tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9376 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9376 D_tricked_loss= tensor(1.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9377 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9377 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9377 D_tricked_loss= tensor(1.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9378 D_real_loss= tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9378 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9378 D_tricked_loss= tensor(1.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9379 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9379 D_fake_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9379 D_tricked_loss= tensor(1.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9380 D_real_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9380 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9380 D_tricked_loss= tensor(1.4257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9381 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9381 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9381 D_tricked_loss= tensor(1.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9382 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9382 D_fake_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9382 D_tricked_loss= tensor(1.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9383 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9383 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9383 D_tricked_loss= tensor(1.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9384 D_real_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9384 D_fake_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9384 D_tricked_loss= tensor(1.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9385 D_real_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9385 D_fake_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9385 D_tricked_loss= tensor(1.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9386 D_real_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9386 D_fake_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9386 D_tricked_loss= tensor(1.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9387 D_real_loss= tensor(0.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9387 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9387 D_tricked_loss= tensor(1.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9388 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9388 D_fake_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9388 D_tricked_loss= tensor(1.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9389 D_real_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9389 D_fake_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9389 D_tricked_loss= tensor(1.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9390 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9390 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9390 D_tricked_loss= tensor(1.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9391 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9391 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9391 D_tricked_loss= tensor(1.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9392 D_real_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9392 D_fake_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9392 D_tricked_loss= tensor(1.4400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9393 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9393 D_fake_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9393 D_tricked_loss= tensor(1.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9394 D_real_loss= tensor(0.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9394 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9394 D_tricked_loss= tensor(1.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9395 D_real_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9395 D_fake_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9395 D_tricked_loss= tensor(1.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9396 D_real_loss= tensor(0.4973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9396 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9396 D_tricked_loss= tensor(1.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9397 D_real_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9397 D_fake_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9397 D_tricked_loss= tensor(1.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9398 D_real_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9398 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9398 D_tricked_loss= tensor(1.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9399 D_real_loss= tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9399 D_fake_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9399 D_tricked_loss= tensor(1.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9400 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9400 D_fake_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9400 D_tricked_loss= tensor(1.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9401 D_real_loss= tensor(0.4851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9401 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9401 D_tricked_loss= tensor(1.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9402 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9402 D_fake_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9402 D_tricked_loss= tensor(1.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9403 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9403 D_fake_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9403 D_tricked_loss= tensor(1.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9404 D_real_loss= tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9404 D_fake_loss= tensor(0.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9404 D_tricked_loss= tensor(1.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9405 D_real_loss= tensor(0.4741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9405 D_fake_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9405 D_tricked_loss= tensor(1.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9406 D_real_loss= tensor(0.4806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9406 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9406 D_tricked_loss= tensor(1.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9407 D_real_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9407 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9407 D_tricked_loss= tensor(1.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9408 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9408 D_fake_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9408 D_tricked_loss= tensor(1.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9409 D_real_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9409 D_fake_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9409 D_tricked_loss= tensor(1.3973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9410 D_real_loss= tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9410 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9410 D_tricked_loss= tensor(1.4896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9411 D_real_loss= tensor(0.4858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9411 D_fake_loss= tensor(0.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9411 D_tricked_loss= tensor(1.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9412 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9412 D_fake_loss= tensor(0.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9412 D_tricked_loss= tensor(1.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9413 D_real_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9413 D_fake_loss= tensor(0.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9413 D_tricked_loss= tensor(1.5564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9414 D_real_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9414 D_fake_loss= tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9414 D_tricked_loss= tensor(1.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9415 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9415 D_fake_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9415 D_tricked_loss= tensor(1.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9416 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9416 D_fake_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9416 D_tricked_loss= tensor(1.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9417 D_real_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9417 D_fake_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9417 D_tricked_loss= tensor(1.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9418 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9418 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9418 D_tricked_loss= tensor(1.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9419 D_real_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9419 D_fake_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9419 D_tricked_loss= tensor(1.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9420 D_real_loss= tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9420 D_fake_loss= tensor(0.4440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9420 D_tricked_loss= tensor(1.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9421 D_real_loss= tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9421 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9421 D_tricked_loss= tensor(1.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9422 D_real_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9422 D_fake_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9422 D_tricked_loss= tensor(1.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9423 D_real_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9423 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9423 D_tricked_loss= tensor(1.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9424 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9424 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9424 D_tricked_loss= tensor(1.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9425 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9425 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9425 D_tricked_loss= tensor(1.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9426 D_real_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9426 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9426 D_tricked_loss= tensor(1.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9427 D_real_loss= tensor(0.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9427 D_fake_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9427 D_tricked_loss= tensor(1.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9428 D_real_loss= tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9428 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9428 D_tricked_loss= tensor(1.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9429 D_real_loss= tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9429 D_fake_loss= tensor(0.4620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9429 D_tricked_loss= tensor(1.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9430 D_real_loss= tensor(0.5098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9430 D_fake_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9430 D_tricked_loss= tensor(1.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9431 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9431 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9431 D_tricked_loss= tensor(1.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9432 D_real_loss= tensor(0.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9432 D_fake_loss= tensor(0.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9432 D_tricked_loss= tensor(1.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9433 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9433 D_fake_loss= tensor(0.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9433 D_tricked_loss= tensor(1.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9434 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9434 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9434 D_tricked_loss= tensor(1.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9435 D_real_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9435 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9435 D_tricked_loss= tensor(1.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9436 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9436 D_fake_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9436 D_tricked_loss= tensor(1.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9437 D_real_loss= tensor(0.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9437 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9437 D_tricked_loss= tensor(1.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9438 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9438 D_fake_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9438 D_tricked_loss= tensor(1.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9439 D_real_loss= tensor(0.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9439 D_fake_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9439 D_tricked_loss= tensor(1.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9440 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9440 D_fake_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9440 D_tricked_loss= tensor(1.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9441 D_real_loss= tensor(0.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9441 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9441 D_tricked_loss= tensor(1.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9442 D_real_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9442 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9442 D_tricked_loss= tensor(1.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9443 D_real_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9443 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9443 D_tricked_loss= tensor(1.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9444 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9444 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9444 D_tricked_loss= tensor(1.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9445 D_real_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9445 D_fake_loss= tensor(0.4365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9445 D_tricked_loss= tensor(1.4299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9446 D_real_loss= tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9446 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9446 D_tricked_loss= tensor(1.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9447 D_real_loss= tensor(0.4835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9447 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9447 D_tricked_loss= tensor(1.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9448 D_real_loss= tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9448 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9448 D_tricked_loss= tensor(1.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9449 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9449 D_fake_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9449 D_tricked_loss= tensor(1.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9450 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9450 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9450 D_tricked_loss= tensor(1.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9451 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9451 D_fake_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9451 D_tricked_loss= tensor(1.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9452 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9452 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9452 D_tricked_loss= tensor(1.4251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9453 D_real_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9453 D_fake_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9453 D_tricked_loss= tensor(1.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9454 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9454 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9454 D_tricked_loss= tensor(1.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9455 D_real_loss= tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9455 D_fake_loss= tensor(0.4225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9455 D_tricked_loss= tensor(1.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9456 D_real_loss= tensor(0.4954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9456 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9456 D_tricked_loss= tensor(1.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9457 D_real_loss= tensor(0.4906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9457 D_fake_loss= tensor(0.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9457 D_tricked_loss= tensor(1.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9458 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9458 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9458 D_tricked_loss= tensor(1.5513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9459 D_real_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9459 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9459 D_tricked_loss= tensor(1.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9460 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9460 D_fake_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9460 D_tricked_loss= tensor(1.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9461 D_real_loss= tensor(0.4778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9461 D_fake_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9461 D_tricked_loss= tensor(1.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9462 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9462 D_fake_loss= tensor(0.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9462 D_tricked_loss= tensor(1.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9463 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9463 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9463 D_tricked_loss= tensor(1.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9464 D_real_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9464 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9464 D_tricked_loss= tensor(1.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9465 D_real_loss= tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9465 D_fake_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9465 D_tricked_loss= tensor(1.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9466 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9466 D_fake_loss= tensor(0.4335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9466 D_tricked_loss= tensor(1.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9467 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9467 D_fake_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9467 D_tricked_loss= tensor(1.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9468 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9468 D_fake_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9468 D_tricked_loss= tensor(1.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9469 D_real_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9469 D_fake_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9469 D_tricked_loss= tensor(1.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9470 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9470 D_fake_loss= tensor(0.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9470 D_tricked_loss= tensor(1.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9471 D_real_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9471 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9471 D_tricked_loss= tensor(1.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9472 D_real_loss= tensor(0.4525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9472 D_fake_loss= tensor(0.4335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9472 D_tricked_loss= tensor(1.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9473 D_real_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9473 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9473 D_tricked_loss= tensor(1.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9474 D_real_loss= tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9474 D_fake_loss= tensor(0.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9474 D_tricked_loss= tensor(1.5031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9475 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9475 D_fake_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9475 D_tricked_loss= tensor(1.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9476 D_real_loss= tensor(0.4747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9476 D_fake_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9476 D_tricked_loss= tensor(1.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9477 D_real_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9477 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9477 D_tricked_loss= tensor(1.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9478 D_real_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9478 D_fake_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9478 D_tricked_loss= tensor(1.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9479 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9479 D_fake_loss= tensor(0.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9479 D_tricked_loss= tensor(1.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9480 D_real_loss= tensor(0.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9480 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9480 D_tricked_loss= tensor(1.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9481 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9481 D_fake_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9481 D_tricked_loss= tensor(1.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9482 D_real_loss= tensor(0.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9482 D_fake_loss= tensor(0.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9482 D_tricked_loss= tensor(1.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9483 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9483 D_fake_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9483 D_tricked_loss= tensor(1.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9484 D_real_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9484 D_fake_loss= tensor(0.4250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9484 D_tricked_loss= tensor(1.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9485 D_real_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9485 D_fake_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9485 D_tricked_loss= tensor(1.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9486 D_real_loss= tensor(0.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9486 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9486 D_tricked_loss= tensor(1.5291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9487 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9487 D_fake_loss= tensor(0.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9487 D_tricked_loss= tensor(1.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9488 D_real_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9488 D_fake_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9488 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9489 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9489 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9489 D_tricked_loss= tensor(1.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9490 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9490 D_fake_loss= tensor(0.4335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9490 D_tricked_loss= tensor(1.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9491 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9491 D_fake_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9491 D_tricked_loss= tensor(1.5209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9492 D_real_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9492 D_fake_loss= tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9492 D_tricked_loss= tensor(1.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9493 D_real_loss= tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9493 D_fake_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9493 D_tricked_loss= tensor(1.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9494 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9494 D_fake_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9494 D_tricked_loss= tensor(1.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9495 D_real_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9495 D_fake_loss= tensor(0.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9495 D_tricked_loss= tensor(1.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9496 D_real_loss= tensor(0.4377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9496 D_fake_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9496 D_tricked_loss= tensor(1.4165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9497 D_real_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9497 D_fake_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9497 D_tricked_loss= tensor(1.4928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9498 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9498 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9498 D_tricked_loss= tensor(1.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9499 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9499 D_fake_loss= tensor(0.4556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9499 D_tricked_loss= tensor(1.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9500 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9500 D_fake_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9500 D_tricked_loss= tensor(1.5164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9501 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9501 D_fake_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9501 D_tricked_loss= tensor(1.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9502 D_real_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9502 D_fake_loss= tensor(0.4444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9502 D_tricked_loss= tensor(1.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9503 D_real_loss= tensor(0.4920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9503 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9503 D_tricked_loss= tensor(1.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9504 D_real_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9504 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9504 D_tricked_loss= tensor(1.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9505 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9505 D_fake_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9505 D_tricked_loss= tensor(1.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9506 D_real_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9506 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9506 D_tricked_loss= tensor(1.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9507 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9507 D_fake_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9507 D_tricked_loss= tensor(1.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9508 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9508 D_fake_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9508 D_tricked_loss= tensor(1.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9509 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9509 D_fake_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9509 D_tricked_loss= tensor(1.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9510 D_real_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9510 D_fake_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9510 D_tricked_loss= tensor(1.5315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9511 D_real_loss= tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9511 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9511 D_tricked_loss= tensor(1.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9512 D_real_loss= tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9512 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9512 D_tricked_loss= tensor(1.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9513 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9513 D_fake_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9513 D_tricked_loss= tensor(1.4747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9514 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9514 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9514 D_tricked_loss= tensor(1.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9515 D_real_loss= tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9515 D_fake_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9515 D_tricked_loss= tensor(1.4881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9516 D_real_loss= tensor(0.4968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9516 D_fake_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9516 D_tricked_loss= tensor(1.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9517 D_real_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9517 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9517 D_tricked_loss= tensor(1.4882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9518 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9518 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9518 D_tricked_loss= tensor(1.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9519 D_real_loss= tensor(0.4604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9519 D_fake_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9519 D_tricked_loss= tensor(1.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9520 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9520 D_fake_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9520 D_tricked_loss= tensor(1.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9521 D_real_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9521 D_fake_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9521 D_tricked_loss= tensor(1.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9522 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9522 D_fake_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9522 D_tricked_loss= tensor(1.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9523 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9523 D_fake_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9523 D_tricked_loss= tensor(1.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9524 D_real_loss= tensor(0.4681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9524 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9524 D_tricked_loss= tensor(1.4121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9525 D_real_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9525 D_fake_loss= tensor(0.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9525 D_tricked_loss= tensor(1.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9526 D_real_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9526 D_fake_loss= tensor(0.4517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9526 D_tricked_loss= tensor(1.4455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9527 D_real_loss= tensor(0.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9527 D_fake_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9527 D_tricked_loss= tensor(1.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9528 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9528 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9528 D_tricked_loss= tensor(1.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9529 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9529 D_fake_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9529 D_tricked_loss= tensor(1.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9530 D_real_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9530 D_fake_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9530 D_tricked_loss= tensor(1.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9531 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9531 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9531 D_tricked_loss= tensor(1.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9532 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9532 D_fake_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9532 D_tricked_loss= tensor(1.4837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9533 D_real_loss= tensor(0.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9533 D_fake_loss= tensor(0.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9533 D_tricked_loss= tensor(1.4563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9534 D_real_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9534 D_fake_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9534 D_tricked_loss= tensor(1.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9535 D_real_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9535 D_fake_loss= tensor(0.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9535 D_tricked_loss= tensor(1.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9536 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9536 D_fake_loss= tensor(0.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9536 D_tricked_loss= tensor(1.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9537 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9537 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9537 D_tricked_loss= tensor(1.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9538 D_real_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9538 D_fake_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9538 D_tricked_loss= tensor(1.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9539 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9539 D_fake_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9539 D_tricked_loss= tensor(1.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9540 D_real_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9540 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9540 D_tricked_loss= tensor(1.5180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9541 D_real_loss= tensor(0.4927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9541 D_fake_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9541 D_tricked_loss= tensor(1.5099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9542 D_real_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9542 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9542 D_tricked_loss= tensor(1.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9543 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9543 D_fake_loss= tensor(0.4648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9543 D_tricked_loss= tensor(1.5303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9544 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9544 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9544 D_tricked_loss= tensor(1.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9545 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9545 D_fake_loss= tensor(0.4421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9545 D_tricked_loss= tensor(1.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9546 D_real_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9546 D_fake_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9546 D_tricked_loss= tensor(1.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9547 D_real_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9547 D_fake_loss= tensor(0.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9547 D_tricked_loss= tensor(1.4905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9548 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9548 D_fake_loss= tensor(0.4517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9548 D_tricked_loss= tensor(1.4060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9549 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9549 D_fake_loss= tensor(0.4825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9549 D_tricked_loss= tensor(1.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9550 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9550 D_fake_loss= tensor(0.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9550 D_tricked_loss= tensor(1.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9551 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9551 D_fake_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9551 D_tricked_loss= tensor(1.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9552 D_real_loss= tensor(0.4900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9552 D_fake_loss= tensor(0.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9552 D_tricked_loss= tensor(1.5312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9553 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9553 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9553 D_tricked_loss= tensor(1.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9554 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9554 D_fake_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9554 D_tricked_loss= tensor(1.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9555 D_real_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9555 D_fake_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9555 D_tricked_loss= tensor(1.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9556 D_real_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9556 D_fake_loss= tensor(0.4240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9556 D_tricked_loss= tensor(1.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9557 D_real_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9557 D_fake_loss= tensor(0.4660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9557 D_tricked_loss= tensor(1.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9558 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9558 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9558 D_tricked_loss= tensor(1.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9559 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9559 D_fake_loss= tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9559 D_tricked_loss= tensor(1.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9560 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9560 D_fake_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9560 D_tricked_loss= tensor(1.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9561 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9561 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9561 D_tricked_loss= tensor(1.5065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9562 D_real_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9562 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9562 D_tricked_loss= tensor(1.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9563 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9563 D_fake_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9563 D_tricked_loss= tensor(1.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9564 D_real_loss= tensor(0.4556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9564 D_fake_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9564 D_tricked_loss= tensor(1.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9565 D_real_loss= tensor(0.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9565 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9565 D_tricked_loss= tensor(1.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9566 D_real_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9566 D_fake_loss= tensor(0.4233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9566 D_tricked_loss= tensor(1.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9567 D_real_loss= tensor(0.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9567 D_fake_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9567 D_tricked_loss= tensor(1.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9568 D_real_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9568 D_fake_loss= tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9568 D_tricked_loss= tensor(1.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9569 D_real_loss= tensor(0.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9569 D_fake_loss= tensor(0.4408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9569 D_tricked_loss= tensor(1.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9570 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9570 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9570 D_tricked_loss= tensor(1.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9571 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9571 D_fake_loss= tensor(0.4379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9571 D_tricked_loss= tensor(1.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9572 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9572 D_fake_loss= tensor(0.4391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9572 D_tricked_loss= tensor(1.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9573 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9573 D_fake_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9573 D_tricked_loss= tensor(1.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9574 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9574 D_fake_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9574 D_tricked_loss= tensor(1.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9575 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9575 D_fake_loss= tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9575 D_tricked_loss= tensor(1.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9576 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9576 D_fake_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9576 D_tricked_loss= tensor(1.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9577 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9577 D_fake_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9577 D_tricked_loss= tensor(1.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9578 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9578 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9578 D_tricked_loss= tensor(1.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9579 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9579 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9579 D_tricked_loss= tensor(1.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9580 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9580 D_fake_loss= tensor(0.4410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9580 D_tricked_loss= tensor(1.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9581 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9581 D_fake_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9581 D_tricked_loss= tensor(1.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9582 D_real_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9582 D_fake_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9582 D_tricked_loss= tensor(1.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9583 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9583 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9583 D_tricked_loss= tensor(1.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9584 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9584 D_fake_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9584 D_tricked_loss= tensor(1.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9585 D_real_loss= tensor(0.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9585 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9585 D_tricked_loss= tensor(1.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9586 D_real_loss= tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9586 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9586 D_tricked_loss= tensor(1.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9587 D_real_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9587 D_fake_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9587 D_tricked_loss= tensor(1.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9588 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9588 D_fake_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9588 D_tricked_loss= tensor(1.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9589 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9589 D_fake_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9589 D_tricked_loss= tensor(1.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9590 D_real_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9590 D_fake_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9590 D_tricked_loss= tensor(1.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9591 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9591 D_fake_loss= tensor(0.4400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9591 D_tricked_loss= tensor(1.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9592 D_real_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9592 D_fake_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9592 D_tricked_loss= tensor(1.5064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9593 D_real_loss= tensor(0.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9593 D_fake_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9593 D_tricked_loss= tensor(1.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9594 D_real_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9594 D_fake_loss= tensor(0.4319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9594 D_tricked_loss= tensor(1.4977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9595 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9595 D_fake_loss= tensor(0.4237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9595 D_tricked_loss= tensor(1.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9596 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9596 D_fake_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9596 D_tricked_loss= tensor(1.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9597 D_real_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9597 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9597 D_tricked_loss= tensor(1.5106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9598 D_real_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9598 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9598 D_tricked_loss= tensor(1.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9599 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9599 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9599 D_tricked_loss= tensor(1.5201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9600 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9600 D_fake_loss= tensor(0.4421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9600 D_tricked_loss= tensor(1.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9601 D_real_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9601 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9601 D_tricked_loss= tensor(1.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9602 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9602 D_fake_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9602 D_tricked_loss= tensor(1.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9603 D_real_loss= tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9603 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9603 D_tricked_loss= tensor(1.5111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9604 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9604 D_fake_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9604 D_tricked_loss= tensor(1.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9605 D_real_loss= tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9605 D_fake_loss= tensor(0.4344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9605 D_tricked_loss= tensor(1.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9606 D_real_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9606 D_fake_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9606 D_tricked_loss= tensor(1.5470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9607 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9607 D_fake_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9607 D_tricked_loss= tensor(1.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9608 D_real_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9608 D_fake_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9608 D_tricked_loss= tensor(1.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9609 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9609 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9609 D_tricked_loss= tensor(1.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9610 D_real_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9610 D_fake_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9610 D_tricked_loss= tensor(1.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9611 D_real_loss= tensor(0.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9611 D_fake_loss= tensor(0.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9611 D_tricked_loss= tensor(1.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9612 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9612 D_fake_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9612 D_tricked_loss= tensor(1.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9613 D_real_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9613 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9613 D_tricked_loss= tensor(1.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9614 D_real_loss= tensor(0.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9614 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9614 D_tricked_loss= tensor(1.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9615 D_real_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9615 D_fake_loss= tensor(0.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9615 D_tricked_loss= tensor(1.4964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9616 D_real_loss= tensor(0.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9616 D_fake_loss= tensor(0.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9616 D_tricked_loss= tensor(1.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9617 D_real_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9617 D_fake_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9617 D_tricked_loss= tensor(1.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9618 D_real_loss= tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9618 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9618 D_tricked_loss= tensor(1.5107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9619 D_real_loss= tensor(0.4525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9619 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9619 D_tricked_loss= tensor(1.4845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9620 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9620 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9620 D_tricked_loss= tensor(1.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9621 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9621 D_fake_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9621 D_tricked_loss= tensor(1.4865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9622 D_real_loss= tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9622 D_fake_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9622 D_tricked_loss= tensor(1.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9623 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9623 D_fake_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9623 D_tricked_loss= tensor(1.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9624 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9624 D_fake_loss= tensor(0.4621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9624 D_tricked_loss= tensor(1.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9625 D_real_loss= tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9625 D_fake_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9625 D_tricked_loss= tensor(1.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9626 D_real_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9626 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9626 D_tricked_loss= tensor(1.5231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9627 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9627 D_fake_loss= tensor(0.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9627 D_tricked_loss= tensor(1.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9628 D_real_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9628 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9628 D_tricked_loss= tensor(1.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9629 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9629 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9629 D_tricked_loss= tensor(1.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9630 D_real_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9630 D_fake_loss= tensor(0.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9630 D_tricked_loss= tensor(1.5015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9631 D_real_loss= tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9631 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9631 D_tricked_loss= tensor(1.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9632 D_real_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9632 D_fake_loss= tensor(0.4145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9632 D_tricked_loss= tensor(1.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9633 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9633 D_fake_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9633 D_tricked_loss= tensor(1.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9634 D_real_loss= tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9634 D_fake_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9634 D_tricked_loss= tensor(1.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9635 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9635 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9635 D_tricked_loss= tensor(1.4870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9636 D_real_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9636 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9636 D_tricked_loss= tensor(1.5262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9637 D_real_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9637 D_fake_loss= tensor(0.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9637 D_tricked_loss= tensor(1.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9638 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9638 D_fake_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9638 D_tricked_loss= tensor(1.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9639 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9639 D_fake_loss= tensor(0.4138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9639 D_tricked_loss= tensor(1.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9640 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9640 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9640 D_tricked_loss= tensor(1.4911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9641 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9641 D_fake_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9641 D_tricked_loss= tensor(1.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9642 D_real_loss= tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9642 D_fake_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9642 D_tricked_loss= tensor(1.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9643 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9643 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9643 D_tricked_loss= tensor(1.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9644 D_real_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9644 D_fake_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9644 D_tricked_loss= tensor(1.4802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9645 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9645 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9645 D_tricked_loss= tensor(1.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9646 D_real_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9646 D_fake_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9646 D_tricked_loss= tensor(1.4983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9647 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9647 D_fake_loss= tensor(0.4392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9647 D_tricked_loss= tensor(1.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9648 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9648 D_fake_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9648 D_tricked_loss= tensor(1.5068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9649 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9649 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9649 D_tricked_loss= tensor(1.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9650 D_real_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9650 D_fake_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9650 D_tricked_loss= tensor(1.4754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9651 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9651 D_fake_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9651 D_tricked_loss= tensor(1.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9652 D_real_loss= tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9652 D_fake_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9652 D_tricked_loss= tensor(1.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9653 D_real_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9653 D_fake_loss= tensor(0.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9653 D_tricked_loss= tensor(1.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9654 D_real_loss= tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9654 D_fake_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9654 D_tricked_loss= tensor(1.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9655 D_real_loss= tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9655 D_fake_loss= tensor(0.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9655 D_tricked_loss= tensor(1.5088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9656 D_real_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9656 D_fake_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9656 D_tricked_loss= tensor(1.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9657 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9657 D_fake_loss= tensor(0.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9657 D_tricked_loss= tensor(1.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9658 D_real_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9658 D_fake_loss= tensor(0.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9658 D_tricked_loss= tensor(1.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9659 D_real_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9659 D_fake_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9659 D_tricked_loss= tensor(1.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9660 D_real_loss= tensor(0.4976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9660 D_fake_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9660 D_tricked_loss= tensor(1.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9661 D_real_loss= tensor(0.4921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9661 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9661 D_tricked_loss= tensor(1.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9662 D_real_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9662 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9662 D_tricked_loss= tensor(1.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9663 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9663 D_fake_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9663 D_tricked_loss= tensor(1.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9664 D_real_loss= tensor(0.4899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9664 D_fake_loss= tensor(0.4279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9664 D_tricked_loss= tensor(1.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9665 D_real_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9665 D_fake_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9665 D_tricked_loss= tensor(1.5151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9666 D_real_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9666 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9666 D_tricked_loss= tensor(1.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9667 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9667 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9667 D_tricked_loss= tensor(1.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9668 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9668 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9668 D_tricked_loss= tensor(1.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9669 D_real_loss= tensor(0.4855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9669 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9669 D_tricked_loss= tensor(1.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9670 D_real_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9670 D_fake_loss= tensor(0.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9670 D_tricked_loss= tensor(1.5184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9671 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9671 D_fake_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9671 D_tricked_loss= tensor(1.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9672 D_real_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9672 D_fake_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9672 D_tricked_loss= tensor(1.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9673 D_real_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9673 D_fake_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9673 D_tricked_loss= tensor(1.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9674 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9674 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9674 D_tricked_loss= tensor(1.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9675 D_real_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9675 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9675 D_tricked_loss= tensor(1.4901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9676 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9676 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9676 D_tricked_loss= tensor(1.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9677 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9677 D_fake_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9677 D_tricked_loss= tensor(1.5042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9678 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9678 D_fake_loss= tensor(0.4395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9678 D_tricked_loss= tensor(1.5132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9679 D_real_loss= tensor(0.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9679 D_fake_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9679 D_tricked_loss= tensor(1.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9680 D_real_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9680 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9680 D_tricked_loss= tensor(1.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9681 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9681 D_fake_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9681 D_tricked_loss= tensor(1.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9682 D_real_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9682 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9682 D_tricked_loss= tensor(1.5060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9683 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9683 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9683 D_tricked_loss= tensor(1.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9684 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9684 D_fake_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9684 D_tricked_loss= tensor(1.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9685 D_real_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9685 D_fake_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9685 D_tricked_loss= tensor(1.5241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9686 D_real_loss= tensor(0.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9686 D_fake_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9686 D_tricked_loss= tensor(1.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9687 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9687 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9687 D_tricked_loss= tensor(1.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9688 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9688 D_fake_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9688 D_tricked_loss= tensor(1.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9689 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9689 D_fake_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9689 D_tricked_loss= tensor(1.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9690 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9690 D_fake_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9690 D_tricked_loss= tensor(1.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9691 D_real_loss= tensor(0.4655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9691 D_fake_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9691 D_tricked_loss= tensor(1.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9692 D_real_loss= tensor(0.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9692 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9692 D_tricked_loss= tensor(1.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9693 D_real_loss= tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9693 D_fake_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9693 D_tricked_loss= tensor(1.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9694 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9694 D_fake_loss= tensor(0.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9694 D_tricked_loss= tensor(1.5155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9695 D_real_loss= tensor(0.4830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9695 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9695 D_tricked_loss= tensor(1.5350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9696 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9696 D_fake_loss= tensor(0.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9696 D_tricked_loss= tensor(1.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9697 D_real_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9697 D_fake_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9697 D_tricked_loss= tensor(1.5047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9698 D_real_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9698 D_fake_loss= tensor(0.4237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9698 D_tricked_loss= tensor(1.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9699 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9699 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9699 D_tricked_loss= tensor(1.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9700 D_real_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9700 D_fake_loss= tensor(0.4365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9700 D_tricked_loss= tensor(1.5308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9701 D_real_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9701 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9701 D_tricked_loss= tensor(1.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9702 D_real_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9702 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9702 D_tricked_loss= tensor(1.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9703 D_real_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9703 D_fake_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9703 D_tricked_loss= tensor(1.4787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9704 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9704 D_fake_loss= tensor(0.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9704 D_tricked_loss= tensor(1.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9705 D_real_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9705 D_fake_loss= tensor(0.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9705 D_tricked_loss= tensor(1.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9706 D_real_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9706 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9706 D_tricked_loss= tensor(1.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9707 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9707 D_fake_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9707 D_tricked_loss= tensor(1.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9708 D_real_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9708 D_fake_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9708 D_tricked_loss= tensor(1.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9709 D_real_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9709 D_fake_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9709 D_tricked_loss= tensor(1.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9710 D_real_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9710 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9710 D_tricked_loss= tensor(1.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9711 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9711 D_fake_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9711 D_tricked_loss= tensor(1.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9712 D_real_loss= tensor(0.4745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9712 D_fake_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9712 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9713 D_real_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9713 D_fake_loss= tensor(0.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9713 D_tricked_loss= tensor(1.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9714 D_real_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9714 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9714 D_tricked_loss= tensor(1.4860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9715 D_real_loss= tensor(0.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9715 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9715 D_tricked_loss= tensor(1.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9716 D_real_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9716 D_fake_loss= tensor(0.4114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9716 D_tricked_loss= tensor(1.4788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9717 D_real_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9717 D_fake_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9717 D_tricked_loss= tensor(1.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9718 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9718 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9718 D_tricked_loss= tensor(1.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9719 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9719 D_fake_loss= tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9719 D_tricked_loss= tensor(1.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9720 D_real_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9720 D_fake_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9720 D_tricked_loss= tensor(1.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9721 D_real_loss= tensor(0.4758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9721 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9721 D_tricked_loss= tensor(1.5027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9722 D_real_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9722 D_fake_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9722 D_tricked_loss= tensor(1.4744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9723 D_real_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9723 D_fake_loss= tensor(0.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9723 D_tricked_loss= tensor(1.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9724 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9724 D_fake_loss= tensor(0.4502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9724 D_tricked_loss= tensor(1.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9725 D_real_loss= tensor(0.4846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9725 D_fake_loss= tensor(0.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9725 D_tricked_loss= tensor(1.5232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9726 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9726 D_fake_loss= tensor(0.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9726 D_tricked_loss= tensor(1.4913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9727 D_real_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9727 D_fake_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9727 D_tricked_loss= tensor(1.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9728 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9728 D_fake_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9728 D_tricked_loss= tensor(1.5393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9729 D_real_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9729 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9729 D_tricked_loss= tensor(1.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9730 D_real_loss= tensor(0.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9730 D_fake_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9730 D_tricked_loss= tensor(1.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9731 D_real_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9731 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9731 D_tricked_loss= tensor(1.5147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9732 D_real_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9732 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9732 D_tricked_loss= tensor(1.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9733 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9733 D_fake_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9733 D_tricked_loss= tensor(1.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9734 D_real_loss= tensor(0.5051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9734 D_fake_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9734 D_tricked_loss= tensor(1.5195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9735 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9735 D_fake_loss= tensor(0.4181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9735 D_tricked_loss= tensor(1.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9736 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9736 D_fake_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9736 D_tricked_loss= tensor(1.5313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9737 D_real_loss= tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9737 D_fake_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9737 D_tricked_loss= tensor(1.5337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9738 D_real_loss= tensor(0.4803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9738 D_fake_loss= tensor(0.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9738 D_tricked_loss= tensor(1.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9739 D_real_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9739 D_fake_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9739 D_tricked_loss= tensor(1.5502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9740 D_real_loss= tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9740 D_fake_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9740 D_tricked_loss= tensor(1.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9741 D_real_loss= tensor(0.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9741 D_fake_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9741 D_tricked_loss= tensor(1.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9742 D_real_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9742 D_fake_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9742 D_tricked_loss= tensor(1.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9743 D_real_loss= tensor(0.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9743 D_fake_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9743 D_tricked_loss= tensor(1.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9744 D_real_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9744 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9744 D_tricked_loss= tensor(1.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9745 D_real_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9745 D_fake_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9745 D_tricked_loss= tensor(1.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9746 D_real_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9746 D_fake_loss= tensor(0.4386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9746 D_tricked_loss= tensor(1.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9747 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9747 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9747 D_tricked_loss= tensor(1.4941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9748 D_real_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9748 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9748 D_tricked_loss= tensor(1.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9749 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9749 D_fake_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9749 D_tricked_loss= tensor(1.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9750 D_real_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9750 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9750 D_tricked_loss= tensor(1.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9751 D_real_loss= tensor(0.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9751 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9751 D_tricked_loss= tensor(1.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9752 D_real_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9752 D_fake_loss= tensor(0.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9752 D_tricked_loss= tensor(1.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9753 D_real_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9753 D_fake_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9753 D_tricked_loss= tensor(1.5140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9754 D_real_loss= tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9754 D_fake_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9754 D_tricked_loss= tensor(1.5187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9755 D_real_loss= tensor(0.4973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9755 D_fake_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9755 D_tricked_loss= tensor(1.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9756 D_real_loss= tensor(0.4762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9756 D_fake_loss= tensor(0.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9756 D_tricked_loss= tensor(1.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9757 D_real_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9757 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9757 D_tricked_loss= tensor(1.5153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9758 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9758 D_fake_loss= tensor(0.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9758 D_tricked_loss= tensor(1.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9759 D_real_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9759 D_fake_loss= tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9759 D_tricked_loss= tensor(1.5500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9760 D_real_loss= tensor(0.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9760 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9760 D_tricked_loss= tensor(1.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9761 D_real_loss= tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9761 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9761 D_tricked_loss= tensor(1.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9762 D_real_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9762 D_fake_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9762 D_tricked_loss= tensor(1.4713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9763 D_real_loss= tensor(0.4948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9763 D_fake_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9763 D_tricked_loss= tensor(1.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9764 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9764 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9764 D_tricked_loss= tensor(1.6196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9765 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9765 D_fake_loss= tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9765 D_tricked_loss= tensor(1.5249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9766 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9766 D_fake_loss= tensor(0.4306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9766 D_tricked_loss= tensor(1.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9767 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9767 D_fake_loss= tensor(0.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9767 D_tricked_loss= tensor(1.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9768 D_real_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9768 D_fake_loss= tensor(0.4312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9768 D_tricked_loss= tensor(1.5049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9769 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9769 D_fake_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9769 D_tricked_loss= tensor(1.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9770 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9770 D_fake_loss= tensor(0.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9770 D_tricked_loss= tensor(1.4992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9771 D_real_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9771 D_fake_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9771 D_tricked_loss= tensor(1.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9772 D_real_loss= tensor(0.4887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9772 D_fake_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9772 D_tricked_loss= tensor(1.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9773 D_real_loss= tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9773 D_fake_loss= tensor(0.4410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9773 D_tricked_loss= tensor(1.5711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9774 D_real_loss= tensor(0.4929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9774 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9774 D_tricked_loss= tensor(1.5769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9775 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9775 D_fake_loss= tensor(0.4249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9775 D_tricked_loss= tensor(1.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9776 D_real_loss= tensor(0.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9776 D_fake_loss= tensor(0.4430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9776 D_tricked_loss= tensor(1.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9777 D_real_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9777 D_fake_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9777 D_tricked_loss= tensor(1.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9778 D_real_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9778 D_fake_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9778 D_tricked_loss= tensor(1.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9779 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9779 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9779 D_tricked_loss= tensor(1.5246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9780 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9780 D_fake_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9780 D_tricked_loss= tensor(1.4993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9781 D_real_loss= tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9781 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9781 D_tricked_loss= tensor(1.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9782 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9782 D_fake_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9782 D_tricked_loss= tensor(1.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9783 D_real_loss= tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9783 D_fake_loss= tensor(0.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9783 D_tricked_loss= tensor(1.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9784 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9784 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9784 D_tricked_loss= tensor(1.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9785 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9785 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9785 D_tricked_loss= tensor(1.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9786 D_real_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9786 D_fake_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9786 D_tricked_loss= tensor(1.4095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9787 D_real_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9787 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9787 D_tricked_loss= tensor(1.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9788 D_real_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9788 D_fake_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9788 D_tricked_loss= tensor(1.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9789 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9789 D_fake_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9789 D_tricked_loss= tensor(1.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9790 D_real_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9790 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9790 D_tricked_loss= tensor(1.5043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9791 D_real_loss= tensor(0.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9791 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9791 D_tricked_loss= tensor(1.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9792 D_real_loss= tensor(0.4786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9792 D_fake_loss= tensor(0.4141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9792 D_tricked_loss= tensor(1.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9793 D_real_loss= tensor(0.5006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9793 D_fake_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9793 D_tricked_loss= tensor(1.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9794 D_real_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9794 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9794 D_tricked_loss= tensor(1.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9795 D_real_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9795 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9795 D_tricked_loss= tensor(1.5074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9796 D_real_loss= tensor(0.4556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9796 D_fake_loss= tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9796 D_tricked_loss= tensor(1.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9797 D_real_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9797 D_fake_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9797 D_tricked_loss= tensor(1.4989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9798 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9798 D_fake_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9798 D_tricked_loss= tensor(1.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9799 D_real_loss= tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9799 D_fake_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9799 D_tricked_loss= tensor(1.5165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9800 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9800 D_fake_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9800 D_tricked_loss= tensor(1.5260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9801 D_real_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9801 D_fake_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9801 D_tricked_loss= tensor(1.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9802 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9802 D_fake_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9802 D_tricked_loss= tensor(1.5273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9803 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9803 D_fake_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9803 D_tricked_loss= tensor(1.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9804 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9804 D_fake_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9804 D_tricked_loss= tensor(1.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9805 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9805 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9805 D_tricked_loss= tensor(1.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9806 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9806 D_fake_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9806 D_tricked_loss= tensor(1.5142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9807 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9807 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9807 D_tricked_loss= tensor(1.5322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9808 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9808 D_fake_loss= tensor(0.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9808 D_tricked_loss= tensor(1.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9809 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9809 D_fake_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9809 D_tricked_loss= tensor(1.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9810 D_real_loss= tensor(0.4858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9810 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9810 D_tricked_loss= tensor(1.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9811 D_real_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9811 D_fake_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9811 D_tricked_loss= tensor(1.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9812 D_real_loss= tensor(0.4839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9812 D_fake_loss= tensor(0.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9812 D_tricked_loss= tensor(1.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9813 D_real_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9813 D_fake_loss= tensor(0.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9813 D_tricked_loss= tensor(1.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9814 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9814 D_fake_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9814 D_tricked_loss= tensor(1.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9815 D_real_loss= tensor(0.4832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9815 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9815 D_tricked_loss= tensor(1.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9816 D_real_loss= tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9816 D_fake_loss= tensor(0.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9816 D_tricked_loss= tensor(1.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9817 D_real_loss= tensor(0.4903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9817 D_fake_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9817 D_tricked_loss= tensor(1.6011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9818 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9818 D_fake_loss= tensor(0.4482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9818 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9819 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9819 D_fake_loss= tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9819 D_tricked_loss= tensor(1.5468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9820 D_real_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9820 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9820 D_tricked_loss= tensor(1.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9821 D_real_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9821 D_fake_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9821 D_tricked_loss= tensor(1.5109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9822 D_real_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9822 D_fake_loss= tensor(0.4875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9822 D_tricked_loss= tensor(1.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9823 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9823 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9823 D_tricked_loss= tensor(1.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9824 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9824 D_fake_loss= tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9824 D_tricked_loss= tensor(1.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9825 D_real_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9825 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9825 D_tricked_loss= tensor(1.5394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9826 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9826 D_fake_loss= tensor(0.4495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9826 D_tricked_loss= tensor(1.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9827 D_real_loss= tensor(0.4807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9827 D_fake_loss= tensor(0.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9827 D_tricked_loss= tensor(1.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9828 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9828 D_fake_loss= tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9828 D_tricked_loss= tensor(1.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9829 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9829 D_fake_loss= tensor(0.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9829 D_tricked_loss= tensor(1.5224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9830 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9830 D_fake_loss= tensor(0.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9830 D_tricked_loss= tensor(1.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9831 D_real_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9831 D_fake_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9831 D_tricked_loss= tensor(1.5048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9832 D_real_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9832 D_fake_loss= tensor(0.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9832 D_tricked_loss= tensor(1.5396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9833 D_real_loss= tensor(0.4898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9833 D_fake_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9833 D_tricked_loss= tensor(1.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9834 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9834 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9834 D_tricked_loss= tensor(1.5066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9835 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9835 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9835 D_tricked_loss= tensor(1.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9836 D_real_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9836 D_fake_loss= tensor(0.4263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9836 D_tricked_loss= tensor(1.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9837 D_real_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9837 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9837 D_tricked_loss= tensor(1.5327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9838 D_real_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9838 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9838 D_tricked_loss= tensor(1.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9839 D_real_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9839 D_fake_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9839 D_tricked_loss= tensor(1.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9840 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9840 D_fake_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9840 D_tricked_loss= tensor(1.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9841 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9841 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9841 D_tricked_loss= tensor(1.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9842 D_real_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9842 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9842 D_tricked_loss= tensor(1.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9843 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9843 D_fake_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9843 D_tricked_loss= tensor(1.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9844 D_real_loss= tensor(0.4961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9844 D_fake_loss= tensor(0.4049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9844 D_tricked_loss= tensor(1.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9845 D_real_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9845 D_fake_loss= tensor(0.4299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9845 D_tricked_loss= tensor(1.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9846 D_real_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9846 D_fake_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9846 D_tricked_loss= tensor(1.5096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9847 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9847 D_fake_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9847 D_tricked_loss= tensor(1.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9848 D_real_loss= tensor(0.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9848 D_fake_loss= tensor(0.4664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9848 D_tricked_loss= tensor(1.4116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9849 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9849 D_fake_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9849 D_tricked_loss= tensor(1.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9850 D_real_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9850 D_fake_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9850 D_tricked_loss= tensor(1.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9851 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9851 D_fake_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9851 D_tricked_loss= tensor(1.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9852 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9852 D_fake_loss= tensor(0.4212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9852 D_tricked_loss= tensor(1.5061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9853 D_real_loss= tensor(0.4847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9853 D_fake_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9853 D_tricked_loss= tensor(1.5653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9854 D_real_loss= tensor(0.4692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9854 D_fake_loss= tensor(0.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9854 D_tricked_loss= tensor(1.5765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9855 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9855 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9855 D_tricked_loss= tensor(1.4988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9856 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9856 D_fake_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9856 D_tricked_loss= tensor(1.5542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9857 D_real_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9857 D_fake_loss= tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9857 D_tricked_loss= tensor(1.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9858 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9858 D_fake_loss= tensor(0.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9858 D_tricked_loss= tensor(1.4994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9859 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9859 D_fake_loss= tensor(0.4474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9859 D_tricked_loss= tensor(1.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9860 D_real_loss= tensor(0.4697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9860 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9860 D_tricked_loss= tensor(1.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9861 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9861 D_fake_loss= tensor(0.4448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9861 D_tricked_loss= tensor(1.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9862 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9862 D_fake_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9862 D_tricked_loss= tensor(1.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9863 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9863 D_fake_loss= tensor(0.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9863 D_tricked_loss= tensor(1.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9864 D_real_loss= tensor(0.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9864 D_fake_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9864 D_tricked_loss= tensor(1.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9865 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9865 D_fake_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9865 D_tricked_loss= tensor(1.4821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9866 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9866 D_fake_loss= tensor(0.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9866 D_tricked_loss= tensor(1.5410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9867 D_real_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9867 D_fake_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9867 D_tricked_loss= tensor(1.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9868 D_real_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9868 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9868 D_tricked_loss= tensor(1.5200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9869 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9869 D_fake_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9869 D_tricked_loss= tensor(1.4942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9870 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9870 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9870 D_tricked_loss= tensor(1.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9871 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9871 D_fake_loss= tensor(0.4404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9871 D_tricked_loss= tensor(1.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9872 D_real_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9872 D_fake_loss= tensor(0.4390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9872 D_tricked_loss= tensor(1.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9873 D_real_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9873 D_fake_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9873 D_tricked_loss= tensor(1.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9874 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9874 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9874 D_tricked_loss= tensor(1.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9875 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9875 D_fake_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9875 D_tricked_loss= tensor(1.5289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9876 D_real_loss= tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9876 D_fake_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9876 D_tricked_loss= tensor(1.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9877 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9877 D_fake_loss= tensor(0.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9877 D_tricked_loss= tensor(1.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9878 D_real_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9878 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9878 D_tricked_loss= tensor(1.4786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9879 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9879 D_fake_loss= tensor(0.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9879 D_tricked_loss= tensor(1.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9880 D_real_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9880 D_fake_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9880 D_tricked_loss= tensor(1.5123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9881 D_real_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9881 D_fake_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9881 D_tricked_loss= tensor(1.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9882 D_real_loss= tensor(0.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9882 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9882 D_tricked_loss= tensor(1.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9883 D_real_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9883 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9883 D_tricked_loss= tensor(1.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9884 D_real_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9884 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9884 D_tricked_loss= tensor(1.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9885 D_real_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9885 D_fake_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9885 D_tricked_loss= tensor(1.5086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9886 D_real_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9886 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9886 D_tricked_loss= tensor(1.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9887 D_real_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9887 D_fake_loss= tensor(0.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9887 D_tricked_loss= tensor(1.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9888 D_real_loss= tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9888 D_fake_loss= tensor(0.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9888 D_tricked_loss= tensor(1.4888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9889 D_real_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9889 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9889 D_tricked_loss= tensor(1.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9890 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9890 D_fake_loss= tensor(0.4232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9890 D_tricked_loss= tensor(1.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9891 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9891 D_fake_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9891 D_tricked_loss= tensor(1.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9892 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9892 D_fake_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9892 D_tricked_loss= tensor(1.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9893 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9893 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9893 D_tricked_loss= tensor(1.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9894 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9894 D_fake_loss= tensor(0.4358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9894 D_tricked_loss= tensor(1.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9895 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9895 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9895 D_tricked_loss= tensor(1.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9896 D_real_loss= tensor(0.4620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9896 D_fake_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9896 D_tricked_loss= tensor(1.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9897 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9897 D_fake_loss= tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9897 D_tricked_loss= tensor(1.4690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9898 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9898 D_fake_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9898 D_tricked_loss= tensor(1.4861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9899 D_real_loss= tensor(0.4746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9899 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9899 D_tricked_loss= tensor(1.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9900 D_real_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9900 D_fake_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9900 D_tricked_loss= tensor(1.4951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9901 D_real_loss= tensor(0.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9901 D_fake_loss= tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9901 D_tricked_loss= tensor(1.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9902 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9902 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9902 D_tricked_loss= tensor(1.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9903 D_real_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9903 D_fake_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9903 D_tricked_loss= tensor(1.5996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9904 D_real_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9904 D_fake_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9904 D_tricked_loss= tensor(1.5139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9905 D_real_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9905 D_fake_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9905 D_tricked_loss= tensor(1.5178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9906 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9906 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9906 D_tricked_loss= tensor(1.5097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9907 D_real_loss= tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9907 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9907 D_tricked_loss= tensor(1.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9908 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9908 D_fake_loss= tensor(0.4286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9908 D_tricked_loss= tensor(1.5033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9909 D_real_loss= tensor(0.4939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9909 D_fake_loss= tensor(0.4263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9909 D_tricked_loss= tensor(1.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9910 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9910 D_fake_loss= tensor(0.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9910 D_tricked_loss= tensor(1.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9911 D_real_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9911 D_fake_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9911 D_tricked_loss= tensor(1.5135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9912 D_real_loss= tensor(0.4590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9912 D_fake_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9912 D_tricked_loss= tensor(1.4965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9913 D_real_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9913 D_fake_loss= tensor(0.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9913 D_tricked_loss= tensor(1.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9914 D_real_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9914 D_fake_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9914 D_tricked_loss= tensor(1.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9915 D_real_loss= tensor(0.4707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9915 D_fake_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9915 D_tricked_loss= tensor(1.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9916 D_real_loss= tensor(0.5052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9916 D_fake_loss= tensor(0.4195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9916 D_tricked_loss= tensor(1.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9917 D_real_loss= tensor(0.4779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9917 D_fake_loss= tensor(0.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9917 D_tricked_loss= tensor(1.5452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9918 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9918 D_fake_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9918 D_tricked_loss= tensor(1.5294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9919 D_real_loss= tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9919 D_fake_loss= tensor(0.4118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9919 D_tricked_loss= tensor(1.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9920 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9920 D_fake_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9920 D_tricked_loss= tensor(1.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9921 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9921 D_fake_loss= tensor(0.4299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9921 D_tricked_loss= tensor(1.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9922 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9922 D_fake_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9922 D_tricked_loss= tensor(1.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9923 D_real_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9923 D_fake_loss= tensor(0.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9923 D_tricked_loss= tensor(1.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9924 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9924 D_fake_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9924 D_tricked_loss= tensor(1.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9925 D_real_loss= tensor(0.4838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9925 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9925 D_tricked_loss= tensor(1.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9926 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9926 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9926 D_tricked_loss= tensor(1.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9927 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9927 D_fake_loss= tensor(0.4444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9927 D_tricked_loss= tensor(1.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9928 D_real_loss= tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9928 D_fake_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9928 D_tricked_loss= tensor(1.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9929 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9929 D_fake_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9929 D_tricked_loss= tensor(1.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9930 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9930 D_fake_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9930 D_tricked_loss= tensor(1.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9931 D_real_loss= tensor(0.4460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9931 D_fake_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9931 D_tricked_loss= tensor(1.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9932 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9932 D_fake_loss= tensor(0.4286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9932 D_tricked_loss= tensor(1.5102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9933 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9933 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9933 D_tricked_loss= tensor(1.5566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9934 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9934 D_fake_loss= tensor(0.4422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9934 D_tricked_loss= tensor(1.5277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9935 D_real_loss= tensor(0.4747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9935 D_fake_loss= tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9935 D_tricked_loss= tensor(1.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9936 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9936 D_fake_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9936 D_tricked_loss= tensor(1.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9937 D_real_loss= tensor(0.4849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9937 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9937 D_tricked_loss= tensor(1.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9938 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9938 D_fake_loss= tensor(0.4361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9938 D_tricked_loss= tensor(1.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9939 D_real_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9939 D_fake_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9939 D_tricked_loss= tensor(1.5333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9940 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9940 D_fake_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9940 D_tricked_loss= tensor(1.5229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9941 D_real_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9941 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9941 D_tricked_loss= tensor(1.4938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9942 D_real_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9942 D_fake_loss= tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9942 D_tricked_loss= tensor(1.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9943 D_real_loss= tensor(0.4823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9943 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9943 D_tricked_loss= tensor(1.5354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9944 D_real_loss= tensor(0.4933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9944 D_fake_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9944 D_tricked_loss= tensor(1.5025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9945 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9945 D_fake_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9945 D_tricked_loss= tensor(1.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9946 D_real_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9946 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9946 D_tricked_loss= tensor(1.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9947 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9947 D_fake_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9947 D_tricked_loss= tensor(1.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9948 D_real_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9948 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9948 D_tricked_loss= tensor(1.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9949 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9949 D_fake_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9949 D_tricked_loss= tensor(1.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9950 D_real_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9950 D_fake_loss= tensor(0.4126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9950 D_tricked_loss= tensor(1.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9951 D_real_loss= tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9951 D_fake_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9951 D_tricked_loss= tensor(1.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9952 D_real_loss= tensor(0.4908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9952 D_fake_loss= tensor(0.4259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9952 D_tricked_loss= tensor(1.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9953 D_real_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9953 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9953 D_tricked_loss= tensor(1.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9954 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9954 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9954 D_tricked_loss= tensor(1.5359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9955 D_real_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9955 D_fake_loss= tensor(0.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9955 D_tricked_loss= tensor(1.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9956 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9956 D_fake_loss= tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9956 D_tricked_loss= tensor(1.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9957 D_real_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9957 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9957 D_tricked_loss= tensor(1.5407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9958 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9958 D_fake_loss= tensor(0.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9958 D_tricked_loss= tensor(1.5019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9959 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9959 D_fake_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9959 D_tricked_loss= tensor(1.4785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9960 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9960 D_fake_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9960 D_tricked_loss= tensor(1.4872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9961 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9961 D_fake_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9961 D_tricked_loss= tensor(1.5115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9962 D_real_loss= tensor(0.4970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9962 D_fake_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9962 D_tricked_loss= tensor(1.5242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9963 D_real_loss= tensor(0.4786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9963 D_fake_loss= tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9963 D_tricked_loss= tensor(1.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9964 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9964 D_fake_loss= tensor(0.4104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9964 D_tricked_loss= tensor(1.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9965 D_real_loss= tensor(0.4930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9965 D_fake_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9965 D_tricked_loss= tensor(1.6242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9966 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9966 D_fake_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9966 D_tricked_loss= tensor(1.5137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9967 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9967 D_fake_loss= tensor(0.4418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9967 D_tricked_loss= tensor(1.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9968 D_real_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9968 D_fake_loss= tensor(0.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9968 D_tricked_loss= tensor(1.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9969 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9969 D_fake_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9969 D_tricked_loss= tensor(1.4962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9970 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9970 D_fake_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9970 D_tricked_loss= tensor(1.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9971 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9971 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9971 D_tricked_loss= tensor(1.5440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9972 D_real_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9972 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9972 D_tricked_loss= tensor(1.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9973 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9973 D_fake_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9973 D_tricked_loss= tensor(1.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9974 D_real_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9974 D_fake_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9974 D_tricked_loss= tensor(1.5020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9975 D_real_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9975 D_fake_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9975 D_tricked_loss= tensor(1.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9976 D_real_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9976 D_fake_loss= tensor(0.4395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9976 D_tricked_loss= tensor(1.5244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9977 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9977 D_fake_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9977 D_tricked_loss= tensor(1.5264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9978 D_real_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9978 D_fake_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9978 D_tricked_loss= tensor(1.5081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9979 D_real_loss= tensor(0.4543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9979 D_fake_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9979 D_tricked_loss= tensor(1.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9980 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9980 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9980 D_tricked_loss= tensor(1.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9981 D_real_loss= tensor(0.4867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9981 D_fake_loss= tensor(0.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9981 D_tricked_loss= tensor(1.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9982 D_real_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9982 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9982 D_tricked_loss= tensor(1.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9983 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9983 D_fake_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9983 D_tricked_loss= tensor(1.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9984 D_real_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9984 D_fake_loss= tensor(0.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9984 D_tricked_loss= tensor(1.5323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9985 D_real_loss= tensor(0.4956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9985 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9985 D_tricked_loss= tensor(1.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9986 D_real_loss= tensor(0.4748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9986 D_fake_loss= tensor(0.4404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9986 D_tricked_loss= tensor(1.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9987 D_real_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9987 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9987 D_tricked_loss= tensor(1.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9988 D_real_loss= tensor(0.4796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9988 D_fake_loss= tensor(0.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9988 D_tricked_loss= tensor(1.5067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9989 D_real_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9989 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9989 D_tricked_loss= tensor(1.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9990 D_real_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9990 D_fake_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9990 D_tricked_loss= tensor(1.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9991 D_real_loss= tensor(0.4837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9991 D_fake_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9991 D_tricked_loss= tensor(1.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9992 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9992 D_fake_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9992 D_tricked_loss= tensor(1.5379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9993 D_real_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9993 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9993 D_tricked_loss= tensor(1.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9994 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9994 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9994 D_tricked_loss= tensor(1.5334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9995 D_real_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9995 D_fake_loss= tensor(0.4391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9995 D_tricked_loss= tensor(1.4884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9996 D_real_loss= tensor(0.4760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9996 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9996 D_tricked_loss= tensor(1.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9997 D_real_loss= tensor(0.4671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9997 D_fake_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9997 D_tricked_loss= tensor(1.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9998 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9998 D_fake_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9998 D_tricked_loss= tensor(1.5436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "9999 D_real_loss= tensor(0.4795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9999 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9999 D_tricked_loss= tensor(1.5993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10000 D_real_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10000 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10000 D_tricked_loss= tensor(1.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10001 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10001 D_fake_loss= tensor(0.4032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10001 D_tricked_loss= tensor(1.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10002 D_real_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10002 D_fake_loss= tensor(0.4604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10002 D_tricked_loss= tensor(1.5012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10003 D_real_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10003 D_fake_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10003 D_tricked_loss= tensor(1.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10004 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10004 D_fake_loss= tensor(0.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10004 D_tricked_loss= tensor(1.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10005 D_real_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10005 D_fake_loss= tensor(0.4418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10005 D_tricked_loss= tensor(1.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10006 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10006 D_fake_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10006 D_tricked_loss= tensor(1.5166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10007 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10007 D_fake_loss= tensor(0.4275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10007 D_tricked_loss= tensor(1.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10008 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10008 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10008 D_tricked_loss= tensor(1.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10009 D_real_loss= tensor(0.4766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10009 D_fake_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10009 D_tricked_loss= tensor(1.6494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10010 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10010 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10010 D_tricked_loss= tensor(1.5544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10011 D_real_loss= tensor(0.4438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10011 D_fake_loss= tensor(0.3967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10011 D_tricked_loss= tensor(1.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10012 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10012 D_fake_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10012 D_tricked_loss= tensor(1.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10013 D_real_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10013 D_fake_loss= tensor(0.4156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10013 D_tricked_loss= tensor(1.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10014 D_real_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10014 D_fake_loss= tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10014 D_tricked_loss= tensor(1.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10015 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10015 D_fake_loss= tensor(0.4254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10015 D_tricked_loss= tensor(1.6260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10016 D_real_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10016 D_fake_loss= tensor(0.4358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10016 D_tricked_loss= tensor(1.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10017 D_real_loss= tensor(0.4731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10017 D_fake_loss= tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10017 D_tricked_loss= tensor(1.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10018 D_real_loss= tensor(0.4914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10018 D_fake_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10018 D_tricked_loss= tensor(1.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10019 D_real_loss= tensor(0.4828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10019 D_fake_loss= tensor(0.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10019 D_tricked_loss= tensor(1.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10020 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10020 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10020 D_tricked_loss= tensor(1.5010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10021 D_real_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10021 D_fake_loss= tensor(0.4421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10021 D_tricked_loss= tensor(1.5055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10022 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10022 D_fake_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10022 D_tricked_loss= tensor(1.5095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10023 D_real_loss= tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10023 D_fake_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10023 D_tricked_loss= tensor(1.5361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10024 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10024 D_fake_loss= tensor(0.4109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10024 D_tricked_loss= tensor(1.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10025 D_real_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10025 D_fake_loss= tensor(0.4183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10025 D_tricked_loss= tensor(1.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10026 D_real_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10026 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10026 D_tricked_loss= tensor(1.5405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10027 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10027 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10027 D_tricked_loss= tensor(1.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10028 D_real_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10028 D_fake_loss= tensor(0.4117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10028 D_tricked_loss= tensor(1.5230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10029 D_real_loss= tensor(0.4550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10029 D_fake_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10029 D_tricked_loss= tensor(1.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10030 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10030 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10030 D_tricked_loss= tensor(1.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10031 D_real_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10031 D_fake_loss= tensor(0.4211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10031 D_tricked_loss= tensor(1.5258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10032 D_real_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10032 D_fake_loss= tensor(0.4153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10032 D_tricked_loss= tensor(1.5434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10033 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10033 D_fake_loss= tensor(0.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10033 D_tricked_loss= tensor(1.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10034 D_real_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10034 D_fake_loss= tensor(0.4184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10034 D_tricked_loss= tensor(1.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10035 D_real_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10035 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10035 D_tricked_loss= tensor(1.5360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10036 D_real_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10036 D_fake_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10036 D_tricked_loss= tensor(1.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10037 D_real_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10037 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10037 D_tricked_loss= tensor(1.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10038 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10038 D_fake_loss= tensor(0.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10038 D_tricked_loss= tensor(1.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10039 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10039 D_fake_loss= tensor(0.4278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10039 D_tricked_loss= tensor(1.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10040 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10040 D_fake_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10040 D_tricked_loss= tensor(1.5076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10041 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10041 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10041 D_tricked_loss= tensor(1.5101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10042 D_real_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10042 D_fake_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10042 D_tricked_loss= tensor(1.5175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10043 D_real_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10043 D_fake_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10043 D_tricked_loss= tensor(1.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10044 D_real_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10044 D_fake_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10044 D_tricked_loss= tensor(1.5112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10045 D_real_loss= tensor(0.4878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10045 D_fake_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10045 D_tricked_loss= tensor(1.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10046 D_real_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10046 D_fake_loss= tensor(0.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10046 D_tricked_loss= tensor(1.5226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10047 D_real_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10047 D_fake_loss= tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10047 D_tricked_loss= tensor(1.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10048 D_real_loss= tensor(0.4674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10048 D_fake_loss= tensor(0.4046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10048 D_tricked_loss= tensor(1.5533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10049 D_real_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10049 D_fake_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10049 D_tricked_loss= tensor(1.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10050 D_real_loss= tensor(0.4631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10050 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10050 D_tricked_loss= tensor(1.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10051 D_real_loss= tensor(0.4694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10051 D_fake_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10051 D_tricked_loss= tensor(1.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10052 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10052 D_fake_loss= tensor(0.4301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10052 D_tricked_loss= tensor(1.5623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10053 D_real_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10053 D_fake_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10053 D_tricked_loss= tensor(1.5296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10054 D_real_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10054 D_fake_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10054 D_tricked_loss= tensor(1.5083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10055 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10055 D_fake_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10055 D_tricked_loss= tensor(1.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10056 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10056 D_fake_loss= tensor(0.4259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10056 D_tricked_loss= tensor(1.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10057 D_real_loss= tensor(0.4793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10057 D_fake_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10057 D_tricked_loss= tensor(1.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10058 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10058 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10058 D_tricked_loss= tensor(1.5245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10059 D_real_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10059 D_fake_loss= tensor(0.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10059 D_tricked_loss= tensor(1.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10060 D_real_loss= tensor(0.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10060 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10060 D_tricked_loss= tensor(1.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10061 D_real_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10061 D_fake_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10061 D_tricked_loss= tensor(1.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10062 D_real_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10062 D_fake_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10062 D_tricked_loss= tensor(1.5272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10063 D_real_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10063 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10063 D_tricked_loss= tensor(1.5343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10064 D_real_loss= tensor(0.4506, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10064 D_fake_loss= tensor(0.4178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10064 D_tricked_loss= tensor(1.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10065 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10065 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10065 D_tricked_loss= tensor(1.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10066 D_real_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10066 D_fake_loss= tensor(0.4141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10066 D_tricked_loss= tensor(1.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10067 D_real_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10067 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10067 D_tricked_loss= tensor(1.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10068 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10068 D_fake_loss= tensor(0.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10068 D_tricked_loss= tensor(1.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10069 D_real_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10069 D_fake_loss= tensor(0.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10069 D_tricked_loss= tensor(1.5004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10070 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10070 D_fake_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10070 D_tricked_loss= tensor(1.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10071 D_real_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10071 D_fake_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10071 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10072 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10072 D_fake_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10072 D_tricked_loss= tensor(1.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10073 D_real_loss= tensor(0.4782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10073 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10073 D_tricked_loss= tensor(1.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10074 D_real_loss= tensor(0.4720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10074 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10074 D_tricked_loss= tensor(1.5148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10075 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10075 D_fake_loss= tensor(0.4365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10075 D_tricked_loss= tensor(1.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10076 D_real_loss= tensor(0.4455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10076 D_fake_loss= tensor(0.4150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10076 D_tricked_loss= tensor(1.5426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10077 D_real_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10077 D_fake_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10077 D_tricked_loss= tensor(1.5085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10078 D_real_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10078 D_fake_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10078 D_tricked_loss= tensor(1.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10079 D_real_loss= tensor(0.4789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10079 D_fake_loss= tensor(0.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10079 D_tricked_loss= tensor(1.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10080 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10080 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10080 D_tricked_loss= tensor(1.5427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10081 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10081 D_fake_loss= tensor(0.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10081 D_tricked_loss= tensor(1.5286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10082 D_real_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10082 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10082 D_tricked_loss= tensor(1.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10083 D_real_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10083 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10083 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10084 D_real_loss= tensor(0.4714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10084 D_fake_loss= tensor(0.4141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10084 D_tricked_loss= tensor(1.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10085 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10085 D_fake_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10085 D_tricked_loss= tensor(1.5401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10086 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10086 D_fake_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10086 D_tricked_loss= tensor(1.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10087 D_real_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10087 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10087 D_tricked_loss= tensor(1.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10088 D_real_loss= tensor(0.4607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10088 D_fake_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10088 D_tricked_loss= tensor(1.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10089 D_real_loss= tensor(0.4453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10089 D_fake_loss= tensor(0.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10089 D_tricked_loss= tensor(1.5381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10090 D_real_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10090 D_fake_loss= tensor(0.4251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10090 D_tricked_loss= tensor(1.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10091 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10091 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10091 D_tricked_loss= tensor(1.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10092 D_real_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10092 D_fake_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10092 D_tricked_loss= tensor(1.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10093 D_real_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10093 D_fake_loss= tensor(0.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10093 D_tricked_loss= tensor(1.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10094 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10094 D_fake_loss= tensor(0.4120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10094 D_tricked_loss= tensor(1.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10095 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10095 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10095 D_tricked_loss= tensor(1.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10096 D_real_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10096 D_fake_loss= tensor(0.4172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10096 D_tricked_loss= tensor(1.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10097 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10097 D_fake_loss= tensor(0.4518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10097 D_tricked_loss= tensor(1.5163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10098 D_real_loss= tensor(0.4768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10098 D_fake_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10098 D_tricked_loss= tensor(1.5255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10099 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10099 D_fake_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10099 D_tricked_loss= tensor(1.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10100 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10100 D_fake_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10100 D_tricked_loss= tensor(1.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10101 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10101 D_fake_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10101 D_tricked_loss= tensor(1.5136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10102 D_real_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10102 D_fake_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10102 D_tricked_loss= tensor(1.4981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10103 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10103 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10103 D_tricked_loss= tensor(1.5138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10104 D_real_loss= tensor(0.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10104 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10104 D_tricked_loss= tensor(1.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10105 D_real_loss= tensor(0.4890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10105 D_fake_loss= tensor(0.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10105 D_tricked_loss= tensor(1.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10106 D_real_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10106 D_fake_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10106 D_tricked_loss= tensor(1.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10107 D_real_loss= tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10107 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10107 D_tricked_loss= tensor(1.6163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10108 D_real_loss= tensor(0.4891, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10108 D_fake_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10108 D_tricked_loss= tensor(1.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10109 D_real_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10109 D_fake_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10109 D_tricked_loss= tensor(1.5274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10110 D_real_loss= tensor(0.4654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10110 D_fake_loss= tensor(0.4304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10110 D_tricked_loss= tensor(1.5044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10111 D_real_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10111 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10111 D_tricked_loss= tensor(1.5388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10112 D_real_loss= tensor(0.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10112 D_fake_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10112 D_tricked_loss= tensor(1.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10113 D_real_loss= tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10113 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10113 D_tricked_loss= tensor(1.5268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10114 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10114 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10114 D_tricked_loss= tensor(1.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10115 D_real_loss= tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10115 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10115 D_tricked_loss= tensor(1.4960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10116 D_real_loss= tensor(0.4827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10116 D_fake_loss= tensor(0.4083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10116 D_tricked_loss= tensor(1.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10117 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10117 D_fake_loss= tensor(0.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10117 D_tricked_loss= tensor(1.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10118 D_real_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10118 D_fake_loss= tensor(0.3919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10118 D_tricked_loss= tensor(1.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10119 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10119 D_fake_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10119 D_tricked_loss= tensor(1.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10120 D_real_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10120 D_fake_loss= tensor(0.4232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10120 D_tricked_loss= tensor(1.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10121 D_real_loss= tensor(0.4742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10121 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10121 D_tricked_loss= tensor(1.6101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10122 D_real_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10122 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10122 D_tricked_loss= tensor(1.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10123 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10123 D_fake_loss= tensor(0.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10123 D_tricked_loss= tensor(1.5775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10124 D_real_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10124 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10124 D_tricked_loss= tensor(1.6537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10125 D_real_loss= tensor(0.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10125 D_fake_loss= tensor(0.4165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10125 D_tricked_loss= tensor(1.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10126 D_real_loss= tensor(0.4833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10126 D_fake_loss= tensor(0.4301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10126 D_tricked_loss= tensor(1.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10127 D_real_loss= tensor(0.4427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10127 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10127 D_tricked_loss= tensor(1.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10128 D_real_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10128 D_fake_loss= tensor(0.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10128 D_tricked_loss= tensor(1.5419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10129 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10129 D_fake_loss= tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10129 D_tricked_loss= tensor(1.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10130 D_real_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10130 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10130 D_tricked_loss= tensor(1.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10131 D_real_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10131 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10131 D_tricked_loss= tensor(1.5895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10132 D_real_loss= tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10132 D_fake_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10132 D_tricked_loss= tensor(1.5820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10133 D_real_loss= tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10133 D_fake_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10133 D_tricked_loss= tensor(1.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10134 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10134 D_fake_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10134 D_tricked_loss= tensor(1.5221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10135 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10135 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10135 D_tricked_loss= tensor(1.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10136 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10136 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10136 D_tricked_loss= tensor(1.5365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10137 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10137 D_fake_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10137 D_tricked_loss= tensor(1.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10138 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10138 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10138 D_tricked_loss= tensor(1.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10139 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10139 D_fake_loss= tensor(0.4126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10139 D_tricked_loss= tensor(1.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10140 D_real_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10140 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10140 D_tricked_loss= tensor(1.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10141 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10141 D_fake_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10141 D_tricked_loss= tensor(1.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10142 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10142 D_fake_loss= tensor(0.4284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10142 D_tricked_loss= tensor(1.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10143 D_real_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10143 D_fake_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10143 D_tricked_loss= tensor(1.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10144 D_real_loss= tensor(0.4982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10144 D_fake_loss= tensor(0.4259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10144 D_tricked_loss= tensor(1.6061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10145 D_real_loss= tensor(0.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10145 D_fake_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10145 D_tricked_loss= tensor(1.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10146 D_real_loss= tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10146 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10146 D_tricked_loss= tensor(1.5681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10147 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10147 D_fake_loss= tensor(0.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10147 D_tricked_loss= tensor(1.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10148 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10148 D_fake_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10148 D_tricked_loss= tensor(1.5005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10149 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10149 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10149 D_tricked_loss= tensor(1.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10150 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10150 D_fake_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10150 D_tricked_loss= tensor(1.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10151 D_real_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10151 D_fake_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10151 D_tricked_loss= tensor(1.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10152 D_real_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10152 D_fake_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10152 D_tricked_loss= tensor(1.5364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10153 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10153 D_fake_loss= tensor(0.4147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10153 D_tricked_loss= tensor(1.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10154 D_real_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10154 D_fake_loss= tensor(0.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10154 D_tricked_loss= tensor(1.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10155 D_real_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10155 D_fake_loss= tensor(0.4527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10155 D_tricked_loss= tensor(1.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10156 D_real_loss= tensor(0.4826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10156 D_fake_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10156 D_tricked_loss= tensor(1.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10157 D_real_loss= tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10157 D_fake_loss= tensor(0.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10157 D_tricked_loss= tensor(1.5179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10158 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10158 D_fake_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10158 D_tricked_loss= tensor(1.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10159 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10159 D_fake_loss= tensor(0.4390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10159 D_tricked_loss= tensor(1.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10160 D_real_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10160 D_fake_loss= tensor(0.4410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10160 D_tricked_loss= tensor(1.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10161 D_real_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10161 D_fake_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10161 D_tricked_loss= tensor(1.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10162 D_real_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10162 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10162 D_tricked_loss= tensor(1.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10163 D_real_loss= tensor(0.4652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10163 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10163 D_tricked_loss= tensor(1.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10164 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10164 D_fake_loss= tensor(0.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10164 D_tricked_loss= tensor(1.5372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10165 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10165 D_fake_loss= tensor(0.3910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10165 D_tricked_loss= tensor(1.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10166 D_real_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10166 D_fake_loss= tensor(0.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10166 D_tricked_loss= tensor(1.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10167 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10167 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10167 D_tricked_loss= tensor(1.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10168 D_real_loss= tensor(0.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10168 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10168 D_tricked_loss= tensor(1.5649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10169 D_real_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10169 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10169 D_tricked_loss= tensor(1.5309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10170 D_real_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10170 D_fake_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10170 D_tricked_loss= tensor(1.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10171 D_real_loss= tensor(0.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10171 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10171 D_tricked_loss= tensor(1.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10172 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10172 D_fake_loss= tensor(0.4103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10172 D_tricked_loss= tensor(1.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10173 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10173 D_fake_loss= tensor(0.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10173 D_tricked_loss= tensor(1.6053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10174 D_real_loss= tensor(0.4481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10174 D_fake_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10174 D_tricked_loss= tensor(1.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10175 D_real_loss= tensor(0.4740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10175 D_fake_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10175 D_tricked_loss= tensor(1.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10176 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10176 D_fake_loss= tensor(0.4184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10176 D_tricked_loss= tensor(1.6171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10177 D_real_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10177 D_fake_loss= tensor(0.4147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10177 D_tricked_loss= tensor(1.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10178 D_real_loss= tensor(0.4628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10178 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10178 D_tricked_loss= tensor(1.6017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10179 D_real_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10179 D_fake_loss= tensor(0.4019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10179 D_tricked_loss= tensor(1.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10180 D_real_loss= tensor(0.4518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10180 D_fake_loss= tensor(0.4095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10180 D_tricked_loss= tensor(1.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10181 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10181 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10181 D_tricked_loss= tensor(1.6003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10182 D_real_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10182 D_fake_loss= tensor(0.4232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10182 D_tricked_loss= tensor(1.5295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10183 D_real_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10183 D_fake_loss= tensor(0.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10183 D_tricked_loss= tensor(1.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10184 D_real_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10184 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10184 D_tricked_loss= tensor(1.5299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10185 D_real_loss= tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10185 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10185 D_tricked_loss= tensor(1.5976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10186 D_real_loss= tensor(0.4715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10186 D_fake_loss= tensor(0.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10186 D_tricked_loss= tensor(1.5326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10187 D_real_loss= tensor(0.5091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10187 D_fake_loss= tensor(0.4241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10187 D_tricked_loss= tensor(1.5810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10188 D_real_loss= tensor(0.4926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10188 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10188 D_tricked_loss= tensor(1.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10189 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10189 D_fake_loss= tensor(0.4386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10189 D_tricked_loss= tensor(1.5432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10190 D_real_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10190 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10190 D_tricked_loss= tensor(1.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10191 D_real_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10191 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10191 D_tricked_loss= tensor(1.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10192 D_real_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10192 D_fake_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10192 D_tricked_loss= tensor(1.5377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10193 D_real_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10193 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10193 D_tricked_loss= tensor(1.5311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10194 D_real_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10194 D_fake_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10194 D_tricked_loss= tensor(1.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10195 D_real_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10195 D_fake_loss= tensor(0.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10195 D_tricked_loss= tensor(1.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10196 D_real_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10196 D_fake_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10196 D_tricked_loss= tensor(1.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10197 D_real_loss= tensor(0.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10197 D_fake_loss= tensor(0.4333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10197 D_tricked_loss= tensor(1.5461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10198 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10198 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10198 D_tricked_loss= tensor(1.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10199 D_real_loss= tensor(0.4924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10199 D_fake_loss= tensor(0.4115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10199 D_tricked_loss= tensor(1.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10200 D_real_loss= tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10200 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10200 D_tricked_loss= tensor(1.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10201 D_real_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10201 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10201 D_tricked_loss= tensor(1.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10202 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10202 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10202 D_tricked_loss= tensor(1.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10203 D_real_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10203 D_fake_loss= tensor(0.4419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10203 D_tricked_loss= tensor(1.4959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10204 D_real_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10204 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10204 D_tricked_loss= tensor(1.4967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10205 D_real_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10205 D_fake_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10205 D_tricked_loss= tensor(1.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10206 D_real_loss= tensor(0.4684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10206 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10206 D_tricked_loss= tensor(1.5181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10207 D_real_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10207 D_fake_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10207 D_tricked_loss= tensor(1.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10208 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10208 D_fake_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10208 D_tricked_loss= tensor(1.5386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10209 D_real_loss= tensor(0.4874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10209 D_fake_loss= tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10209 D_tricked_loss= tensor(1.5675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10210 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10210 D_fake_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10210 D_tricked_loss= tensor(1.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10211 D_real_loss= tensor(0.4909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10211 D_fake_loss= tensor(0.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10211 D_tricked_loss= tensor(1.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10212 D_real_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10212 D_fake_loss= tensor(0.4299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10212 D_tricked_loss= tensor(1.5269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10213 D_real_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10213 D_fake_loss= tensor(0.4284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10213 D_tricked_loss= tensor(1.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10214 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10214 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10214 D_tricked_loss= tensor(1.5397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10215 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10215 D_fake_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10215 D_tricked_loss= tensor(1.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10216 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10216 D_fake_loss= tensor(0.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10216 D_tricked_loss= tensor(1.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10217 D_real_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10217 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10217 D_tricked_loss= tensor(1.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10218 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10218 D_fake_loss= tensor(0.4220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10218 D_tricked_loss= tensor(1.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10219 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10219 D_fake_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10219 D_tricked_loss= tensor(1.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10220 D_real_loss= tensor(0.4594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10220 D_fake_loss= tensor(0.4284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10220 D_tricked_loss= tensor(1.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10221 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10221 D_fake_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10221 D_tricked_loss= tensor(1.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10222 D_real_loss= tensor(0.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10222 D_fake_loss= tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10222 D_tricked_loss= tensor(1.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10223 D_real_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10223 D_fake_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10223 D_tricked_loss= tensor(1.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10224 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10224 D_fake_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10224 D_tricked_loss= tensor(1.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10225 D_real_loss= tensor(0.4949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10225 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10225 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10226 D_real_loss= tensor(0.4773, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10226 D_fake_loss= tensor(0.4210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10226 D_tricked_loss= tensor(1.5524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10227 D_real_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10227 D_fake_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10227 D_tricked_loss= tensor(1.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10228 D_real_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10228 D_fake_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10228 D_tricked_loss= tensor(1.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10229 D_real_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10229 D_fake_loss= tensor(0.4272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10229 D_tricked_loss= tensor(1.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10230 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10230 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10230 D_tricked_loss= tensor(1.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10231 D_real_loss= tensor(0.4661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10231 D_fake_loss= tensor(0.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10231 D_tricked_loss= tensor(1.5216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10232 D_real_loss= tensor(0.4743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10232 D_fake_loss= tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10232 D_tricked_loss= tensor(1.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10233 D_real_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10233 D_fake_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10233 D_tricked_loss= tensor(1.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10234 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10234 D_fake_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10234 D_tricked_loss= tensor(1.5463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10235 D_real_loss= tensor(0.4707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10235 D_fake_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10235 D_tricked_loss= tensor(1.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10236 D_real_loss= tensor(0.4864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10236 D_fake_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10236 D_tricked_loss= tensor(1.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10237 D_real_loss= tensor(0.4735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10237 D_fake_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10237 D_tricked_loss= tensor(1.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10238 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10238 D_fake_loss= tensor(0.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10238 D_tricked_loss= tensor(1.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10239 D_real_loss= tensor(0.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10239 D_fake_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10239 D_tricked_loss= tensor(1.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10240 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10240 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10240 D_tricked_loss= tensor(1.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10241 D_real_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10241 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10241 D_tricked_loss= tensor(1.5110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10242 D_real_loss= tensor(0.4840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10242 D_fake_loss= tensor(0.4282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10242 D_tricked_loss= tensor(1.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10243 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10243 D_fake_loss= tensor(0.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10243 D_tricked_loss= tensor(1.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10244 D_real_loss= tensor(0.4876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10244 D_fake_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10244 D_tricked_loss= tensor(1.6191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10245 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10245 D_fake_loss= tensor(0.4295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10245 D_tricked_loss= tensor(1.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10246 D_real_loss= tensor(0.4709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10246 D_fake_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10246 D_tricked_loss= tensor(1.5375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10247 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10247 D_fake_loss= tensor(0.4340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10247 D_tricked_loss= tensor(1.5003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10248 D_real_loss= tensor(0.4656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10248 D_fake_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10248 D_tricked_loss= tensor(1.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10249 D_real_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10249 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10249 D_tricked_loss= tensor(1.4925, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10250 D_real_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10250 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10250 D_tricked_loss= tensor(1.6151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10251 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10251 D_fake_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10251 D_tricked_loss= tensor(1.5348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10252 D_real_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10252 D_fake_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10252 D_tricked_loss= tensor(1.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10253 D_real_loss= tensor(0.4834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10253 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10253 D_tricked_loss= tensor(1.5704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10254 D_real_loss= tensor(0.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10254 D_fake_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10254 D_tricked_loss= tensor(1.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10255 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10255 D_fake_loss= tensor(0.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10255 D_tricked_loss= tensor(1.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10256 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10256 D_fake_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10256 D_tricked_loss= tensor(1.5234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10257 D_real_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10257 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10257 D_tricked_loss= tensor(1.5053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10258 D_real_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10258 D_fake_loss= tensor(0.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10258 D_tricked_loss= tensor(1.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10259 D_real_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10259 D_fake_loss= tensor(0.4195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10259 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10260 D_real_loss= tensor(0.4790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10260 D_fake_loss= tensor(0.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10260 D_tricked_loss= tensor(1.5812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10261 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10261 D_fake_loss= tensor(0.4205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10261 D_tricked_loss= tensor(1.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10262 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10262 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10262 D_tricked_loss= tensor(1.6128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10263 D_real_loss= tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10263 D_fake_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10263 D_tricked_loss= tensor(1.5946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10264 D_real_loss= tensor(0.4804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10264 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10264 D_tricked_loss= tensor(1.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10265 D_real_loss= tensor(0.4533, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10265 D_fake_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10265 D_tricked_loss= tensor(1.5438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10266 D_real_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10266 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10266 D_tricked_loss= tensor(1.5196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10267 D_real_loss= tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10267 D_fake_loss= tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10267 D_tricked_loss= tensor(1.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10268 D_real_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10268 D_fake_loss= tensor(0.4147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10268 D_tricked_loss= tensor(1.5389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10269 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10269 D_fake_loss= tensor(0.4232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10269 D_tricked_loss= tensor(1.5430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10270 D_real_loss= tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10270 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10270 D_tricked_loss= tensor(1.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10271 D_real_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10271 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10271 D_tricked_loss= tensor(1.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10272 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10272 D_fake_loss= tensor(0.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10272 D_tricked_loss= tensor(1.6692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10273 D_real_loss= tensor(0.4829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10273 D_fake_loss= tensor(0.4034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10273 D_tricked_loss= tensor(1.6590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10274 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10274 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10274 D_tricked_loss= tensor(1.5562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10275 D_real_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10275 D_fake_loss= tensor(0.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10275 D_tricked_loss= tensor(1.5443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10276 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10276 D_fake_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10276 D_tricked_loss= tensor(1.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10277 D_real_loss= tensor(0.4485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10277 D_fake_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10277 D_tricked_loss= tensor(1.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10278 D_real_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10278 D_fake_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10278 D_tricked_loss= tensor(1.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10279 D_real_loss= tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10279 D_fake_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10279 D_tricked_loss= tensor(1.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10280 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10280 D_fake_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10280 D_tricked_loss= tensor(1.6091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10281 D_real_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10281 D_fake_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10281 D_tricked_loss= tensor(1.6095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10282 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10282 D_fake_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10282 D_tricked_loss= tensor(1.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10283 D_real_loss= tensor(0.4539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10283 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10283 D_tricked_loss= tensor(1.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10284 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10284 D_fake_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10284 D_tricked_loss= tensor(1.5692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10285 D_real_loss= tensor(0.4801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10285 D_fake_loss= tensor(0.4295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10285 D_tricked_loss= tensor(1.6099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10286 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10286 D_fake_loss= tensor(0.4176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10286 D_tricked_loss= tensor(1.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10287 D_real_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10287 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10287 D_tricked_loss= tensor(1.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10288 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10288 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10288 D_tricked_loss= tensor(1.4935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10289 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10289 D_fake_loss= tensor(0.3987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10289 D_tricked_loss= tensor(1.5595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10290 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10290 D_fake_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10290 D_tricked_loss= tensor(1.6308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10291 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10291 D_fake_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10291 D_tricked_loss= tensor(1.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10292 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10292 D_fake_loss= tensor(0.4331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10292 D_tricked_loss= tensor(1.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10293 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10293 D_fake_loss= tensor(0.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10293 D_tricked_loss= tensor(1.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10294 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10294 D_fake_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10294 D_tricked_loss= tensor(1.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10295 D_real_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10295 D_fake_loss= tensor(0.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10295 D_tricked_loss= tensor(1.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10296 D_real_loss= tensor(0.4233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10296 D_fake_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10296 D_tricked_loss= tensor(1.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10297 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10297 D_fake_loss= tensor(0.4053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10297 D_tricked_loss= tensor(1.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10298 D_real_loss= tensor(0.4455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10298 D_fake_loss= tensor(0.4400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10298 D_tricked_loss= tensor(1.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10299 D_real_loss= tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10299 D_fake_loss= tensor(0.4189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10299 D_tricked_loss= tensor(1.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10300 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10300 D_fake_loss= tensor(0.3942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10300 D_tricked_loss= tensor(1.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10301 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10301 D_fake_loss= tensor(0.4153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10301 D_tricked_loss= tensor(1.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10302 D_real_loss= tensor(0.4822, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10302 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10302 D_tricked_loss= tensor(1.5588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10303 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10303 D_fake_loss= tensor(0.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10303 D_tricked_loss= tensor(1.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10304 D_real_loss= tensor(0.4854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10304 D_fake_loss= tensor(0.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10304 D_tricked_loss= tensor(1.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10305 D_real_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10305 D_fake_loss= tensor(0.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10305 D_tricked_loss= tensor(1.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10306 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10306 D_fake_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10306 D_tricked_loss= tensor(1.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10307 D_real_loss= tensor(0.4645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10307 D_fake_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10307 D_tricked_loss= tensor(1.5424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10308 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10308 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10308 D_tricked_loss= tensor(1.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10309 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10309 D_fake_loss= tensor(0.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10309 D_tricked_loss= tensor(1.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10310 D_real_loss= tensor(0.4670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10310 D_fake_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10310 D_tricked_loss= tensor(1.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10311 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10311 D_fake_loss= tensor(0.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10311 D_tricked_loss= tensor(1.5104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10312 D_real_loss= tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10312 D_fake_loss= tensor(0.4301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10312 D_tricked_loss= tensor(1.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10313 D_real_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10313 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10313 D_tricked_loss= tensor(1.5183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10314 D_real_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10314 D_fake_loss= tensor(0.4223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10314 D_tricked_loss= tensor(1.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10315 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10315 D_fake_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10315 D_tricked_loss= tensor(1.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10316 D_real_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10316 D_fake_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10316 D_tricked_loss= tensor(1.5126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10317 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10317 D_fake_loss= tensor(0.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10317 D_tricked_loss= tensor(1.5382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10318 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10318 D_fake_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10318 D_tricked_loss= tensor(1.5341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10319 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10319 D_fake_loss= tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10319 D_tricked_loss= tensor(1.5838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10320 D_real_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10320 D_fake_loss= tensor(0.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10320 D_tricked_loss= tensor(1.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10321 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10321 D_fake_loss= tensor(0.4428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10321 D_tricked_loss= tensor(1.5991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10322 D_real_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10322 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10322 D_tricked_loss= tensor(1.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10323 D_real_loss= tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10323 D_fake_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10323 D_tricked_loss= tensor(1.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10324 D_real_loss= tensor(0.4678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10324 D_fake_loss= tensor(0.4005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10324 D_tricked_loss= tensor(1.6991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10325 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10325 D_fake_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10325 D_tricked_loss= tensor(1.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10326 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10326 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10326 D_tricked_loss= tensor(1.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10327 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10327 D_fake_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10327 D_tricked_loss= tensor(1.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10328 D_real_loss= tensor(0.4685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10328 D_fake_loss= tensor(0.4121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10328 D_tricked_loss= tensor(1.5281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10329 D_real_loss= tensor(0.4711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10329 D_fake_loss= tensor(0.4162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10329 D_tricked_loss= tensor(1.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10330 D_real_loss= tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10330 D_fake_loss= tensor(0.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10330 D_tricked_loss= tensor(1.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10331 D_real_loss= tensor(0.4792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10331 D_fake_loss= tensor(0.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10331 D_tricked_loss= tensor(1.5385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10332 D_real_loss= tensor(0.4919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10332 D_fake_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10332 D_tricked_loss= tensor(1.6226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10333 D_real_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10333 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10333 D_tricked_loss= tensor(1.5292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10334 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10334 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10334 D_tricked_loss= tensor(1.5495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10335 D_real_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10335 D_fake_loss= tensor(0.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10335 D_tricked_loss= tensor(1.5314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10336 D_real_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10336 D_fake_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10336 D_tricked_loss= tensor(1.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10337 D_real_loss= tensor(0.4604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10337 D_fake_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10337 D_tricked_loss= tensor(1.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10338 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10338 D_fake_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10338 D_tricked_loss= tensor(1.5319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10339 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10339 D_fake_loss= tensor(0.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10339 D_tricked_loss= tensor(1.5415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10340 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10340 D_fake_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10340 D_tricked_loss= tensor(1.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10341 D_real_loss= tensor(0.4765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10341 D_fake_loss= tensor(0.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10341 D_tricked_loss= tensor(1.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10342 D_real_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10342 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10342 D_tricked_loss= tensor(1.5437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10343 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10343 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10343 D_tricked_loss= tensor(1.5208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10344 D_real_loss= tensor(0.4857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10344 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10344 D_tricked_loss= tensor(1.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10345 D_real_loss= tensor(0.4707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10345 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10345 D_tricked_loss= tensor(1.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10346 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10346 D_fake_loss= tensor(0.4251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10346 D_tricked_loss= tensor(1.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10347 D_real_loss= tensor(0.4614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10347 D_fake_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10347 D_tricked_loss= tensor(1.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10348 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10348 D_fake_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10348 D_tricked_loss= tensor(1.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10349 D_real_loss= tensor(0.4561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10349 D_fake_loss= tensor(0.4282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10349 D_tricked_loss= tensor(1.5725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10350 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10350 D_fake_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10350 D_tricked_loss= tensor(1.5617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10351 D_real_loss= tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10351 D_fake_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10351 D_tricked_loss= tensor(1.5670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10352 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10352 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10352 D_tricked_loss= tensor(1.5228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10353 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10353 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10353 D_tricked_loss= tensor(1.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10354 D_real_loss= tensor(0.4927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10354 D_fake_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10354 D_tricked_loss= tensor(1.5643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10355 D_real_loss= tensor(0.4772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10355 D_fake_loss= tensor(0.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10355 D_tricked_loss= tensor(1.5059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10356 D_real_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10356 D_fake_loss= tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10356 D_tricked_loss= tensor(1.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10357 D_real_loss= tensor(0.4669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10357 D_fake_loss= tensor(0.4151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10357 D_tricked_loss= tensor(1.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10358 D_real_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10358 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10358 D_tricked_loss= tensor(1.5433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10359 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10359 D_fake_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10359 D_tricked_loss= tensor(1.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10360 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10360 D_fake_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10360 D_tricked_loss= tensor(1.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10361 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10361 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10361 D_tricked_loss= tensor(1.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10362 D_real_loss= tensor(0.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10362 D_fake_loss= tensor(0.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10362 D_tricked_loss= tensor(1.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10363 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10363 D_fake_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10363 D_tricked_loss= tensor(1.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10364 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10364 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10364 D_tricked_loss= tensor(1.5879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10365 D_real_loss= tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10365 D_fake_loss= tensor(0.3992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10365 D_tricked_loss= tensor(1.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10366 D_real_loss= tensor(0.4641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10366 D_fake_loss= tensor(0.4134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10366 D_tricked_loss= tensor(1.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10367 D_real_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10367 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10367 D_tricked_loss= tensor(1.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10368 D_real_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10368 D_fake_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10368 D_tricked_loss= tensor(1.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10369 D_real_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10369 D_fake_loss= tensor(0.4116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10369 D_tricked_loss= tensor(1.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10370 D_real_loss= tensor(0.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10370 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10370 D_tricked_loss= tensor(1.5204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10371 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10371 D_fake_loss= tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10371 D_tricked_loss= tensor(1.6262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10372 D_real_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10372 D_fake_loss= tensor(0.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10372 D_tricked_loss= tensor(1.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10373 D_real_loss= tensor(0.4879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10373 D_fake_loss= tensor(0.4084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10373 D_tricked_loss= tensor(1.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10374 D_real_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10374 D_fake_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10374 D_tricked_loss= tensor(1.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10375 D_real_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10375 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10375 D_tricked_loss= tensor(1.5284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10376 D_real_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10376 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10376 D_tricked_loss= tensor(1.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10377 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10377 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10377 D_tricked_loss= tensor(1.5119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10378 D_real_loss= tensor(0.4495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10378 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10378 D_tricked_loss= tensor(1.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10379 D_real_loss= tensor(0.4325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10379 D_fake_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10379 D_tricked_loss= tensor(1.5744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10380 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10380 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10380 D_tricked_loss= tensor(1.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10381 D_real_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10381 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10381 D_tricked_loss= tensor(1.5447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10382 D_real_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10382 D_fake_loss= tensor(0.4251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10382 D_tricked_loss= tensor(1.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10383 D_real_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10383 D_fake_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10383 D_tricked_loss= tensor(1.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10384 D_real_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10384 D_fake_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10384 D_tricked_loss= tensor(1.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10385 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10385 D_fake_loss= tensor(0.3880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10385 D_tricked_loss= tensor(1.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10386 D_real_loss= tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10386 D_fake_loss= tensor(0.4142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10386 D_tricked_loss= tensor(1.5529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10387 D_real_loss= tensor(0.4602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10387 D_fake_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10387 D_tricked_loss= tensor(1.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10388 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10388 D_fake_loss= tensor(0.4122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10388 D_tricked_loss= tensor(1.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10389 D_real_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10389 D_fake_loss= tensor(0.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10389 D_tricked_loss= tensor(1.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10390 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10390 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10390 D_tricked_loss= tensor(1.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10391 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10391 D_fake_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10391 D_tricked_loss= tensor(1.5771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10392 D_real_loss= tensor(0.4780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10392 D_fake_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10392 D_tricked_loss= tensor(1.5445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10393 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10393 D_fake_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10393 D_tricked_loss= tensor(1.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10394 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10394 D_fake_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10394 D_tricked_loss= tensor(1.5549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10395 D_real_loss= tensor(0.4451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10395 D_fake_loss= tensor(0.4166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10395 D_tricked_loss= tensor(1.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10396 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10396 D_fake_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10396 D_tricked_loss= tensor(1.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10397 D_real_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10397 D_fake_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10397 D_tricked_loss= tensor(1.6099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10398 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10398 D_fake_loss= tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10398 D_tricked_loss= tensor(1.5293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10399 D_real_loss= tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10399 D_fake_loss= tensor(0.4093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10399 D_tricked_loss= tensor(1.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10400 D_real_loss= tensor(0.4917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10400 D_fake_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10400 D_tricked_loss= tensor(1.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10401 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10401 D_fake_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10401 D_tricked_loss= tensor(1.5324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10402 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10402 D_fake_loss= tensor(0.4662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10402 D_tricked_loss= tensor(1.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10403 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10403 D_fake_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10403 D_tricked_loss= tensor(1.5402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10404 D_real_loss= tensor(0.4555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10404 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10404 D_tricked_loss= tensor(1.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10405 D_real_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10405 D_fake_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10405 D_tricked_loss= tensor(1.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10406 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10406 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10406 D_tricked_loss= tensor(1.5339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10407 D_real_loss= tensor(0.4747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10407 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10407 D_tricked_loss= tensor(1.5168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10408 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10408 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10408 D_tricked_loss= tensor(1.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10409 D_real_loss= tensor(0.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10409 D_fake_loss= tensor(0.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10409 D_tricked_loss= tensor(1.5203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10410 D_real_loss= tensor(0.4897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10410 D_fake_loss= tensor(0.4195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10410 D_tricked_loss= tensor(1.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10411 D_real_loss= tensor(0.4810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10411 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10411 D_tricked_loss= tensor(1.5421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10412 D_real_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10412 D_fake_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10412 D_tricked_loss= tensor(1.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10413 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10413 D_fake_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10413 D_tricked_loss= tensor(1.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10414 D_real_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10414 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10414 D_tricked_loss= tensor(1.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10415 D_real_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10415 D_fake_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10415 D_tricked_loss= tensor(1.5395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10416 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10416 D_fake_loss= tensor(0.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10416 D_tricked_loss= tensor(1.5253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10417 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10417 D_fake_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10417 D_tricked_loss= tensor(1.4927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10418 D_real_loss= tensor(0.4683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10418 D_fake_loss= tensor(0.3963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10418 D_tricked_loss= tensor(1.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10419 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10419 D_fake_loss= tensor(0.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10419 D_tricked_loss= tensor(1.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10420 D_real_loss= tensor(0.4734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10420 D_fake_loss= tensor(0.4386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10420 D_tricked_loss= tensor(1.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10421 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10421 D_fake_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10421 D_tricked_loss= tensor(1.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10422 D_real_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10422 D_fake_loss= tensor(0.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10422 D_tricked_loss= tensor(1.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10423 D_real_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10423 D_fake_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10423 D_tricked_loss= tensor(1.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10424 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10424 D_fake_loss= tensor(0.4210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10424 D_tricked_loss= tensor(1.5390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10425 D_real_loss= tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10425 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10425 D_tricked_loss= tensor(1.5189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10426 D_real_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10426 D_fake_loss= tensor(0.4320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10426 D_tricked_loss= tensor(1.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10427 D_real_loss= tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10427 D_fake_loss= tensor(0.4312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10427 D_tricked_loss= tensor(1.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10428 D_real_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10428 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10428 D_tricked_loss= tensor(1.5125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10429 D_real_loss= tensor(0.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10429 D_fake_loss= tensor(0.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10429 D_tricked_loss= tensor(1.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10430 D_real_loss= tensor(0.4866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10430 D_fake_loss= tensor(0.4189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10430 D_tricked_loss= tensor(1.5783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10431 D_real_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10431 D_fake_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10431 D_tricked_loss= tensor(1.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10432 D_real_loss= tensor(0.4776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10432 D_fake_loss= tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10432 D_tricked_loss= tensor(1.6392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10433 D_real_loss= tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10433 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10433 D_tricked_loss= tensor(1.5263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10434 D_real_loss= tensor(0.4940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10434 D_fake_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10434 D_tricked_loss= tensor(1.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10435 D_real_loss= tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10435 D_fake_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10435 D_tricked_loss= tensor(1.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10436 D_real_loss= tensor(0.4812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10436 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10436 D_tricked_loss= tensor(1.5569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10437 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10437 D_fake_loss= tensor(0.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10437 D_tricked_loss= tensor(1.6206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10438 D_real_loss= tensor(0.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10438 D_fake_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10438 D_tricked_loss= tensor(1.5265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10439 D_real_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10439 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10439 D_tricked_loss= tensor(1.5331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10440 D_real_loss= tensor(0.4512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10440 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10440 D_tricked_loss= tensor(1.6026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10441 D_real_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10441 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10441 D_tricked_loss= tensor(1.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10442 D_real_loss= tensor(0.4633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10442 D_fake_loss= tensor(0.4353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10442 D_tricked_loss= tensor(1.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10443 D_real_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10443 D_fake_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10443 D_tricked_loss= tensor(1.6092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10444 D_real_loss= tensor(0.4871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10444 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10444 D_tricked_loss= tensor(1.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10445 D_real_loss= tensor(0.4798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10445 D_fake_loss= tensor(0.3952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10445 D_tricked_loss= tensor(1.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10446 D_real_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10446 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10446 D_tricked_loss= tensor(1.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10447 D_real_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10447 D_fake_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10447 D_tricked_loss= tensor(1.5479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10448 D_real_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10448 D_fake_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10448 D_tricked_loss= tensor(1.5261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10449 D_real_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10449 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10449 D_tricked_loss= tensor(1.5220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10450 D_real_loss= tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10450 D_fake_loss= tensor(0.4408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10450 D_tricked_loss= tensor(1.5251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10451 D_real_loss= tensor(0.4622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10451 D_fake_loss= tensor(0.4085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10451 D_tricked_loss= tensor(1.5271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10452 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10452 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10452 D_tricked_loss= tensor(1.5177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10453 D_real_loss= tensor(0.4848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10453 D_fake_loss= tensor(0.4463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10453 D_tricked_loss= tensor(1.5370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10454 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10454 D_fake_loss= tensor(0.4414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10454 D_tricked_loss= tensor(1.5808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10455 D_real_loss= tensor(0.4725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10455 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10455 D_tricked_loss= tensor(1.5404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10456 D_real_loss= tensor(0.4750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10456 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10456 D_tricked_loss= tensor(1.5372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10457 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10457 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10457 D_tricked_loss= tensor(1.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10458 D_real_loss= tensor(0.4333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10458 D_fake_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10458 D_tricked_loss= tensor(1.4996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10459 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10459 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10459 D_tricked_loss= tensor(1.5215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10460 D_real_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10460 D_fake_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10460 D_tricked_loss= tensor(1.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10461 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10461 D_fake_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10461 D_tricked_loss= tensor(1.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10462 D_real_loss= tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10462 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10462 D_tricked_loss= tensor(1.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10463 D_real_loss= tensor(0.4916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10463 D_fake_loss= tensor(0.4125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10463 D_tricked_loss= tensor(1.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10464 D_real_loss= tensor(0.4396, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10464 D_fake_loss= tensor(0.4152, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10464 D_tricked_loss= tensor(1.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10465 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10465 D_fake_loss= tensor(0.4263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10465 D_tricked_loss= tensor(1.5997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10466 D_real_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10466 D_fake_loss= tensor(0.4380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10466 D_tricked_loss= tensor(1.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10467 D_real_loss= tensor(0.4327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10467 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10467 D_tricked_loss= tensor(1.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10468 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10468 D_fake_loss= tensor(0.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10468 D_tricked_loss= tensor(1.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10469 D_real_loss= tensor(0.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10469 D_fake_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10469 D_tricked_loss= tensor(1.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10470 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10470 D_fake_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10470 D_tricked_loss= tensor(1.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10471 D_real_loss= tensor(0.4710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10471 D_fake_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10471 D_tricked_loss= tensor(1.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10472 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10472 D_fake_loss= tensor(0.4355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10472 D_tricked_loss= tensor(1.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10473 D_real_loss= tensor(0.4546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10473 D_fake_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10473 D_tricked_loss= tensor(1.5017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10474 D_real_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10474 D_fake_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10474 D_tricked_loss= tensor(1.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10475 D_real_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10475 D_fake_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10475 D_tricked_loss= tensor(1.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10476 D_real_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10476 D_fake_loss= tensor(0.4457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10476 D_tricked_loss= tensor(1.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10477 D_real_loss= tensor(0.4498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10477 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10477 D_tricked_loss= tensor(1.5540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10478 D_real_loss= tensor(0.4527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10478 D_fake_loss= tensor(0.4370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10478 D_tricked_loss= tensor(1.5442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10479 D_real_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10479 D_fake_loss= tensor(0.3923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10479 D_tricked_loss= tensor(1.5176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10480 D_real_loss= tensor(0.4518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10480 D_fake_loss= tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10480 D_tricked_loss= tensor(1.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10481 D_real_loss= tensor(0.4727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10481 D_fake_loss= tensor(0.4189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10481 D_tricked_loss= tensor(1.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10482 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10482 D_fake_loss= tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10482 D_tricked_loss= tensor(1.5911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10483 D_real_loss= tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10483 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10483 D_tricked_loss= tensor(1.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10484 D_real_loss= tensor(0.4862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10484 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10484 D_tricked_loss= tensor(1.5636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10485 D_real_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10485 D_fake_loss= tensor(0.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10485 D_tricked_loss= tensor(1.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10486 D_real_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10486 D_fake_loss= tensor(0.4173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10486 D_tricked_loss= tensor(1.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10487 D_real_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10487 D_fake_loss= tensor(0.4166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10487 D_tricked_loss= tensor(1.5457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10488 D_real_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10488 D_fake_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10488 D_tricked_loss= tensor(1.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10489 D_real_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10489 D_fake_loss= tensor(0.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10489 D_tricked_loss= tensor(1.5169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10490 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10490 D_fake_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10490 D_tricked_loss= tensor(1.5363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10491 D_real_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10491 D_fake_loss= tensor(0.4138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10491 D_tricked_loss= tensor(1.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10492 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10492 D_fake_loss= tensor(0.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10492 D_tricked_loss= tensor(1.5921, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10493 D_real_loss= tensor(0.4726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10493 D_fake_loss= tensor(0.4173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10493 D_tricked_loss= tensor(1.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10494 D_real_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10494 D_fake_loss= tensor(0.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10494 D_tricked_loss= tensor(1.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10495 D_real_loss= tensor(0.4947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10495 D_fake_loss= tensor(0.4141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10495 D_tricked_loss= tensor(1.5816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10496 D_real_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10496 D_fake_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10496 D_tricked_loss= tensor(1.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10497 D_real_loss= tensor(0.4791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10497 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10497 D_tricked_loss= tensor(1.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10498 D_real_loss= tensor(0.4466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10498 D_fake_loss= tensor(0.4063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10498 D_tricked_loss= tensor(1.5116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10499 D_real_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10499 D_fake_loss= tensor(0.4240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10499 D_tricked_loss= tensor(1.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10500 D_real_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10500 D_fake_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10500 D_tricked_loss= tensor(1.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10501 D_real_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10501 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10501 D_tricked_loss= tensor(1.5477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10502 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10502 D_fake_loss= tensor(0.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10502 D_tricked_loss= tensor(1.5310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10503 D_real_loss= tensor(0.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10503 D_fake_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10503 D_tricked_loss= tensor(1.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10504 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10504 D_fake_loss= tensor(0.4302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10504 D_tricked_loss= tensor(1.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10505 D_real_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10505 D_fake_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10505 D_tricked_loss= tensor(1.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10506 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10506 D_fake_loss= tensor(0.4240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10506 D_tricked_loss= tensor(1.5909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10507 D_real_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10507 D_fake_loss= tensor(0.4488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10507 D_tricked_loss= tensor(1.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10508 D_real_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10508 D_fake_loss= tensor(0.4031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10508 D_tricked_loss= tensor(1.6323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10509 D_real_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10509 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10509 D_tricked_loss= tensor(1.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10510 D_real_loss= tensor(0.4424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10510 D_fake_loss= tensor(0.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10510 D_tricked_loss= tensor(1.6081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10511 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10511 D_fake_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10511 D_tricked_loss= tensor(1.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10512 D_real_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10512 D_fake_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10512 D_tricked_loss= tensor(1.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10513 D_real_loss= tensor(0.4425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10513 D_fake_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10513 D_tricked_loss= tensor(1.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10514 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10514 D_fake_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10514 D_tricked_loss= tensor(1.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10515 D_real_loss= tensor(0.4712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10515 D_fake_loss= tensor(0.4319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10515 D_tricked_loss= tensor(1.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10516 D_real_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10516 D_fake_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10516 D_tricked_loss= tensor(1.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10517 D_real_loss= tensor(0.4554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10517 D_fake_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10517 D_tricked_loss= tensor(1.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10518 D_real_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10518 D_fake_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10518 D_tricked_loss= tensor(1.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10519 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10519 D_fake_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10519 D_tricked_loss= tensor(1.6275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10520 D_real_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10520 D_fake_loss= tensor(0.4191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10520 D_tricked_loss= tensor(1.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10521 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10521 D_fake_loss= tensor(0.4108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10521 D_tricked_loss= tensor(1.6124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10522 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10522 D_fake_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10522 D_tricked_loss= tensor(1.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10523 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10523 D_fake_loss= tensor(0.4115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10523 D_tricked_loss= tensor(1.6329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10524 D_real_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10524 D_fake_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10524 D_tricked_loss= tensor(1.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10525 D_real_loss= tensor(0.4732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10525 D_fake_loss= tensor(0.4106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10525 D_tricked_loss= tensor(1.6071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10526 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10526 D_fake_loss= tensor(0.4240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10526 D_tricked_loss= tensor(1.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10527 D_real_loss= tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10527 D_fake_loss= tensor(0.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10527 D_tricked_loss= tensor(1.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10528 D_real_loss= tensor(0.4476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10528 D_fake_loss= tensor(0.4112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10528 D_tricked_loss= tensor(1.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10529 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10529 D_fake_loss= tensor(0.4008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10529 D_tricked_loss= tensor(1.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10530 D_real_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10530 D_fake_loss= tensor(0.4073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10530 D_tricked_loss= tensor(1.6348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10531 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10531 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10531 D_tricked_loss= tensor(1.6068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10532 D_real_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10532 D_fake_loss= tensor(0.4217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10532 D_tricked_loss= tensor(1.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10533 D_real_loss= tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10533 D_fake_loss= tensor(0.4174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10533 D_tricked_loss= tensor(1.5376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10534 D_real_loss= tensor(0.4805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10534 D_fake_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10534 D_tricked_loss= tensor(1.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10535 D_real_loss= tensor(0.4601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10535 D_fake_loss= tensor(0.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10535 D_tricked_loss= tensor(1.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10536 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10536 D_fake_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10536 D_tricked_loss= tensor(1.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10537 D_real_loss= tensor(0.4752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10537 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10537 D_tricked_loss= tensor(1.6262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10538 D_real_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10538 D_fake_loss= tensor(0.4199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10538 D_tricked_loss= tensor(1.5655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10539 D_real_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10539 D_fake_loss= tensor(0.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10539 D_tricked_loss= tensor(1.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10540 D_real_loss= tensor(0.4564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10540 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10540 D_tricked_loss= tensor(1.5536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10541 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10541 D_fake_loss= tensor(0.4243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10541 D_tricked_loss= tensor(1.5610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10542 D_real_loss= tensor(0.4465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10542 D_fake_loss= tensor(0.4193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10542 D_tricked_loss= tensor(1.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10543 D_real_loss= tensor(0.4433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10543 D_fake_loss= tensor(0.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10543 D_tricked_loss= tensor(1.6182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10544 D_real_loss= tensor(0.4719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10544 D_fake_loss= tensor(0.4146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10544 D_tricked_loss= tensor(1.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10545 D_real_loss= tensor(0.4568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10545 D_fake_loss= tensor(0.4044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10545 D_tricked_loss= tensor(1.6173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10546 D_real_loss= tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10546 D_fake_loss= tensor(0.4156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10546 D_tricked_loss= tensor(1.5729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10547 D_real_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10547 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10547 D_tricked_loss= tensor(1.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10548 D_real_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10548 D_fake_loss= tensor(0.4046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10548 D_tricked_loss= tensor(1.6126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10549 D_real_loss= tensor(0.4604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10549 D_fake_loss= tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10549 D_tricked_loss= tensor(1.5330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10550 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10550 D_fake_loss= tensor(0.4197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10550 D_tricked_loss= tensor(1.5290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10551 D_real_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10551 D_fake_loss= tensor(0.4211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10551 D_tricked_loss= tensor(1.6091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10552 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10552 D_fake_loss= tensor(0.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10552 D_tricked_loss= tensor(1.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10553 D_real_loss= tensor(0.4774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10553 D_fake_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10553 D_tricked_loss= tensor(1.5942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10554 D_real_loss= tensor(0.4487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10554 D_fake_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10554 D_tricked_loss= tensor(1.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10555 D_real_loss= tensor(0.4815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10555 D_fake_loss= tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10555 D_tricked_loss= tensor(1.6459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10556 D_real_loss= tensor(0.4651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10556 D_fake_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10556 D_tricked_loss= tensor(1.6100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10557 D_real_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10557 D_fake_loss= tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10557 D_tricked_loss= tensor(1.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10558 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10558 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10558 D_tricked_loss= tensor(1.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10559 D_real_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10559 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10559 D_tricked_loss= tensor(1.5666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10560 D_real_loss= tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10560 D_fake_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10560 D_tricked_loss= tensor(1.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10561 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10561 D_fake_loss= tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10561 D_tricked_loss= tensor(1.6238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10562 D_real_loss= tensor(0.4893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10562 D_fake_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10562 D_tricked_loss= tensor(1.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10563 D_real_loss= tensor(0.4425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10563 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10563 D_tricked_loss= tensor(1.6183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10564 D_real_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10564 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10564 D_tricked_loss= tensor(1.6164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10565 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10565 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10565 D_tricked_loss= tensor(1.5651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10566 D_real_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10566 D_fake_loss= tensor(0.4075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10566 D_tricked_loss= tensor(1.5571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10567 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10567 D_fake_loss= tensor(0.4280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10567 D_tricked_loss= tensor(1.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10568 D_real_loss= tensor(0.4478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10568 D_fake_loss= tensor(0.4009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10568 D_tricked_loss= tensor(1.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10569 D_real_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10569 D_fake_loss= tensor(0.4088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10569 D_tricked_loss= tensor(1.6340, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10570 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10570 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10570 D_tricked_loss= tensor(1.5591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10571 D_real_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10571 D_fake_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10571 D_tricked_loss= tensor(1.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10572 D_real_loss= tensor(0.4759, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10572 D_fake_loss= tensor(0.4287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10572 D_tricked_loss= tensor(1.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10573 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10573 D_fake_loss= tensor(0.4197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10573 D_tricked_loss= tensor(1.5767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10574 D_real_loss= tensor(0.4492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10574 D_fake_loss= tensor(0.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10574 D_tricked_loss= tensor(1.5679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10575 D_real_loss= tensor(0.4538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10575 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10575 D_tricked_loss= tensor(1.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10576 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10576 D_fake_loss= tensor(0.4106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10576 D_tricked_loss= tensor(1.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10577 D_real_loss= tensor(0.4528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10577 D_fake_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10577 D_tricked_loss= tensor(1.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10578 D_real_loss= tensor(0.4680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10578 D_fake_loss= tensor(0.4292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10578 D_tricked_loss= tensor(1.5411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10579 D_real_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10579 D_fake_loss= tensor(0.4009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10579 D_tricked_loss= tensor(1.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10580 D_real_loss= tensor(0.4706, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10580 D_fake_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10580 D_tricked_loss= tensor(1.5612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10581 D_real_loss= tensor(0.4405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10581 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10581 D_tricked_loss= tensor(1.5647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10582 D_real_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10582 D_fake_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10582 D_tricked_loss= tensor(1.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10583 D_real_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10583 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10583 D_tricked_loss= tensor(1.5349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10584 D_real_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10584 D_fake_loss= tensor(0.4226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10584 D_tricked_loss= tensor(1.5790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10585 D_real_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10585 D_fake_loss= tensor(0.4307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10585 D_tricked_loss= tensor(1.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10586 D_real_loss= tensor(0.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10586 D_fake_loss= tensor(0.4110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10586 D_tricked_loss= tensor(1.6209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10587 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10587 D_fake_loss= tensor(0.3870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10587 D_tricked_loss= tensor(1.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10588 D_real_loss= tensor(0.4647, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10588 D_fake_loss= tensor(0.4352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10588 D_tricked_loss= tensor(1.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10589 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10589 D_fake_loss= tensor(0.3975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10589 D_tricked_loss= tensor(1.6225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10590 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10590 D_fake_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10590 D_tricked_loss= tensor(1.6603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10591 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10591 D_fake_loss= tensor(0.4294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10591 D_tricked_loss= tensor(1.5929, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10592 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10592 D_fake_loss= tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10592 D_tricked_loss= tensor(1.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10593 D_real_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10593 D_fake_loss= tensor(0.4237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10593 D_tricked_loss= tensor(1.5316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10594 D_real_loss= tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10594 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10594 D_tricked_loss= tensor(1.5677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10595 D_real_loss= tensor(0.4469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10595 D_fake_loss= tensor(0.3935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10595 D_tricked_loss= tensor(1.5608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10596 D_real_loss= tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10596 D_fake_loss= tensor(0.4336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10596 D_tricked_loss= tensor(1.5306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10597 D_real_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10597 D_fake_loss= tensor(0.4214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10597 D_tricked_loss= tensor(1.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10598 D_real_loss= tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10598 D_fake_loss= tensor(0.4091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10598 D_tricked_loss= tensor(1.6579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10599 D_real_loss= tensor(0.4511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10599 D_fake_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10599 D_tricked_loss= tensor(1.6065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10600 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10600 D_fake_loss= tensor(0.4010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10600 D_tricked_loss= tensor(1.6156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10601 D_real_loss= tensor(0.4417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10601 D_fake_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10601 D_tricked_loss= tensor(1.6422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10602 D_real_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10602 D_fake_loss= tensor(0.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10602 D_tricked_loss= tensor(1.6295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10603 D_real_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10603 D_fake_loss= tensor(0.4199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10603 D_tricked_loss= tensor(1.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10604 D_real_loss= tensor(0.4371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10604 D_fake_loss= tensor(0.3836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10604 D_tricked_loss= tensor(1.6605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10605 D_real_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10605 D_fake_loss= tensor(0.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10605 D_tricked_loss= tensor(1.6320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10606 D_real_loss= tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10606 D_fake_loss= tensor(0.4161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10606 D_tricked_loss= tensor(1.6131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10607 D_real_loss= tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10607 D_fake_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10607 D_tricked_loss= tensor(1.6470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10608 D_real_loss= tensor(0.4626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10608 D_fake_loss= tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10608 D_tricked_loss= tensor(1.6157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10609 D_real_loss= tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10609 D_fake_loss= tensor(0.4212, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10609 D_tricked_loss= tensor(1.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10610 D_real_loss= tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10610 D_fake_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10610 D_tricked_loss= tensor(1.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10611 D_real_loss= tensor(0.4708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10611 D_fake_loss= tensor(0.4181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10611 D_tricked_loss= tensor(1.6167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10612 D_real_loss= tensor(0.4584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10612 D_fake_loss= tensor(0.4198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10612 D_tricked_loss= tensor(1.5980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10613 D_real_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10613 D_fake_loss= tensor(0.4034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10613 D_tricked_loss= tensor(1.6433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10614 D_real_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10614 D_fake_loss= tensor(0.4024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10614 D_tricked_loss= tensor(1.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10615 D_real_loss= tensor(0.4477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10615 D_fake_loss= tensor(0.4211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10615 D_tricked_loss= tensor(1.6293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10616 D_real_loss= tensor(0.4724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10616 D_fake_loss= tensor(0.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10616 D_tricked_loss= tensor(1.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10617 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10617 D_fake_loss= tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10617 D_tricked_loss= tensor(1.5531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10618 D_real_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10618 D_fake_loss= tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10618 D_tricked_loss= tensor(1.6226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10619 D_real_loss= tensor(0.4598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10619 D_fake_loss= tensor(0.4407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10619 D_tricked_loss= tensor(1.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10620 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10620 D_fake_loss= tensor(0.4258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10620 D_tricked_loss= tensor(1.6453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10621 D_real_loss= tensor(0.4673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10621 D_fake_loss= tensor(0.3898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10621 D_tricked_loss= tensor(1.6421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10622 D_real_loss= tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10622 D_fake_loss= tensor(0.4002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10622 D_tricked_loss= tensor(1.5901, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10623 D_real_loss= tensor(0.4526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10623 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10623 D_tricked_loss= tensor(1.6280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10624 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10624 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10624 D_tricked_loss= tensor(1.6013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10625 D_real_loss= tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10625 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10625 D_tricked_loss= tensor(1.5431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10626 D_real_loss= tensor(0.4412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10626 D_fake_loss= tensor(0.4088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10626 D_tricked_loss= tensor(1.5222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10627 D_real_loss= tensor(0.4721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10627 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10627 D_tricked_loss= tensor(1.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10628 D_real_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10628 D_fake_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10628 D_tricked_loss= tensor(1.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10629 D_real_loss= tensor(0.4744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10629 D_fake_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10629 D_tricked_loss= tensor(1.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10630 D_real_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10630 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10630 D_tricked_loss= tensor(1.6149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10631 D_real_loss= tensor(0.4736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10631 D_fake_loss= tensor(0.4015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10631 D_tricked_loss= tensor(1.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10632 D_real_loss= tensor(0.4755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10632 D_fake_loss= tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10632 D_tricked_loss= tensor(1.6180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10633 D_real_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10633 D_fake_loss= tensor(0.4179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10633 D_tricked_loss= tensor(1.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10634 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10634 D_fake_loss= tensor(0.4008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10634 D_tricked_loss= tensor(1.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10635 D_real_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10635 D_fake_loss= tensor(0.3969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10635 D_tricked_loss= tensor(1.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10636 D_real_loss= tensor(0.4547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10636 D_fake_loss= tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10636 D_tricked_loss= tensor(1.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10637 D_real_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10637 D_fake_loss= tensor(0.4044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10637 D_tricked_loss= tensor(1.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10638 D_real_loss= tensor(0.4764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10638 D_fake_loss= tensor(0.4190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10638 D_tricked_loss= tensor(1.6372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10639 D_real_loss= tensor(0.4767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10639 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10639 D_tricked_loss= tensor(1.5859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10640 D_real_loss= tensor(0.4609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10640 D_fake_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10640 D_tricked_loss= tensor(1.6119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10641 D_real_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10641 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10641 D_tricked_loss= tensor(1.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10642 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10642 D_fake_loss= tensor(0.4362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10642 D_tricked_loss= tensor(1.5927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10643 D_real_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10643 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10643 D_tricked_loss= tensor(1.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10644 D_real_loss= tensor(0.4646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10644 D_fake_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10644 D_tricked_loss= tensor(1.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10645 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10645 D_fake_loss= tensor(0.4406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10645 D_tricked_loss= tensor(1.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10646 D_real_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10646 D_fake_loss= tensor(0.4159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10646 D_tricked_loss= tensor(1.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10647 D_real_loss= tensor(0.4679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10647 D_fake_loss= tensor(0.4065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10647 D_tricked_loss= tensor(1.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10648 D_real_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10648 D_fake_loss= tensor(0.4323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10648 D_tricked_loss= tensor(1.5373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10649 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10649 D_fake_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10649 D_tricked_loss= tensor(1.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10650 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10650 D_fake_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10650 D_tricked_loss= tensor(1.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10651 D_real_loss= tensor(0.4814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10651 D_fake_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10651 D_tricked_loss= tensor(1.6252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10652 D_real_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10652 D_fake_loss= tensor(0.4216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10652 D_tricked_loss= tensor(1.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10653 D_real_loss= tensor(0.4499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10653 D_fake_loss= tensor(0.4282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10653 D_tricked_loss= tensor(1.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10654 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10654 D_fake_loss= tensor(0.4014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10654 D_tricked_loss= tensor(1.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10655 D_real_loss= tensor(0.4440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10655 D_fake_loss= tensor(0.4173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10655 D_tricked_loss= tensor(1.5367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10656 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10656 D_fake_loss= tensor(0.4100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10656 D_tricked_loss= tensor(1.6323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10657 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10657 D_fake_loss= tensor(0.4071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10657 D_tricked_loss= tensor(1.5731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10658 D_real_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10658 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10658 D_tricked_loss= tensor(1.6141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10659 D_real_loss= tensor(0.4634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10659 D_fake_loss= tensor(0.4086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10659 D_tricked_loss= tensor(1.6046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10660 D_real_loss= tensor(0.4441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10660 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10660 D_tricked_loss= tensor(1.5328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10661 D_real_loss= tensor(0.4522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10661 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10661 D_tricked_loss= tensor(1.5551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10662 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10662 D_fake_loss= tensor(0.4378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10662 D_tricked_loss= tensor(1.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10663 D_real_loss= tensor(0.4616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10663 D_fake_loss= tensor(0.4209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10663 D_tricked_loss= tensor(1.5683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10664 D_real_loss= tensor(0.4520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10664 D_fake_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10664 D_tricked_loss= tensor(1.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10665 D_real_loss= tensor(0.4818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10665 D_fake_loss= tensor(0.4504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10665 D_tricked_loss= tensor(1.5696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10666 D_real_loss= tensor(0.4923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10666 D_fake_loss= tensor(0.4225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10666 D_tricked_loss= tensor(1.6362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10667 D_real_loss= tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10667 D_fake_loss= tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10667 D_tricked_loss= tensor(1.5387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10668 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10668 D_fake_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10668 D_tricked_loss= tensor(1.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10669 D_real_loss= tensor(0.4600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10669 D_fake_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10669 D_tricked_loss= tensor(1.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10670 D_real_loss= tensor(0.4648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10670 D_fake_loss= tensor(0.4394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10670 D_tricked_loss= tensor(1.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10671 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10671 D_fake_loss= tensor(0.3963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10671 D_tricked_loss= tensor(1.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10672 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10672 D_fake_loss= tensor(0.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10672 D_tricked_loss= tensor(1.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10673 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10673 D_fake_loss= tensor(0.3940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10673 D_tricked_loss= tensor(1.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10674 D_real_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10674 D_fake_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10674 D_tricked_loss= tensor(1.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10675 D_real_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10675 D_fake_loss= tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10675 D_tricked_loss= tensor(1.5742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10676 D_real_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10676 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10676 D_tricked_loss= tensor(1.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10677 D_real_loss= tensor(0.4534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10677 D_fake_loss= tensor(0.4134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10677 D_tricked_loss= tensor(1.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10678 D_real_loss= tensor(0.4481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10678 D_fake_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10678 D_tricked_loss= tensor(1.5834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10679 D_real_loss= tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10679 D_fake_loss= tensor(0.4121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10679 D_tricked_loss= tensor(1.6226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10680 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10680 D_fake_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10680 D_tricked_loss= tensor(1.5472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10681 D_real_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10681 D_fake_loss= tensor(0.4287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10681 D_tricked_loss= tensor(1.5300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10682 D_real_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10682 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10682 D_tricked_loss= tensor(1.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10683 D_real_loss= tensor(0.4723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10683 D_fake_loss= tensor(0.3933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10683 D_tricked_loss= tensor(1.5861, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10684 D_real_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10684 D_fake_loss= tensor(0.4322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10684 D_tricked_loss= tensor(1.5422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10685 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10685 D_fake_loss= tensor(0.4000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10685 D_tricked_loss= tensor(1.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10686 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10686 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10686 D_tricked_loss= tensor(1.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10687 D_real_loss= tensor(0.4702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10687 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10687 D_tricked_loss= tensor(1.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10688 D_real_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10688 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10688 D_tricked_loss= tensor(1.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10689 D_real_loss= tensor(0.4657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10689 D_fake_loss= tensor(0.4066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10689 D_tricked_loss= tensor(1.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10690 D_real_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10690 D_fake_loss= tensor(0.4101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10690 D_tricked_loss= tensor(1.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10691 D_real_loss= tensor(0.4606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10691 D_fake_loss= tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10691 D_tricked_loss= tensor(1.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10692 D_real_loss= tensor(0.4393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10692 D_fake_loss= tensor(0.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10692 D_tricked_loss= tensor(1.4958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10693 D_real_loss= tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10693 D_fake_loss= tensor(0.4040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10693 D_tricked_loss= tensor(1.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10694 D_real_loss= tensor(0.4490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10694 D_fake_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10694 D_tricked_loss= tensor(1.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10695 D_real_loss= tensor(0.4421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10695 D_fake_loss= tensor(0.4308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10695 D_tricked_loss= tensor(1.6141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10696 D_real_loss= tensor(0.4934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10696 D_fake_loss= tensor(0.4379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10696 D_tricked_loss= tensor(1.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10697 D_real_loss= tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10697 D_fake_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10697 D_tricked_loss= tensor(1.5133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10698 D_real_loss= tensor(0.4757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10698 D_fake_loss= tensor(0.4373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10698 D_tricked_loss= tensor(1.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10699 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10699 D_fake_loss= tensor(0.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10699 D_tricked_loss= tensor(1.5715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10700 D_real_loss= tensor(0.4638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10700 D_fake_loss= tensor(0.4086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10700 D_tricked_loss= tensor(1.5700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10701 D_real_loss= tensor(0.4434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10701 D_fake_loss= tensor(0.4256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10701 D_tricked_loss= tensor(1.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10702 D_real_loss= tensor(0.4640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10702 D_fake_loss= tensor(0.3959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10702 D_tricked_loss= tensor(1.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10703 D_real_loss= tensor(0.4570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10703 D_fake_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10703 D_tricked_loss= tensor(1.6486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10704 D_real_loss= tensor(0.4775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10704 D_fake_loss= tensor(0.4094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10704 D_tricked_loss= tensor(1.6770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10705 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10705 D_fake_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10705 D_tricked_loss= tensor(1.6041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10706 D_real_loss= tensor(0.4312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10706 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10706 D_tricked_loss= tensor(1.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10707 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10707 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10707 D_tricked_loss= tensor(1.6070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10708 D_real_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10708 D_fake_loss= tensor(0.4261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10708 D_tricked_loss= tensor(1.5756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10709 D_real_loss= tensor(0.4334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10709 D_fake_loss= tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10709 D_tricked_loss= tensor(1.5800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10710 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10710 D_fake_loss= tensor(0.4251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10710 D_tricked_loss= tensor(1.5763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10711 D_real_loss= tensor(0.4749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10711 D_fake_loss= tensor(0.4310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10711 D_tricked_loss= tensor(1.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10712 D_real_loss= tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10712 D_fake_loss= tensor(0.4137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10712 D_tricked_loss= tensor(1.6686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10713 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10713 D_fake_loss= tensor(0.4095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10713 D_tricked_loss= tensor(1.6182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10714 D_real_loss= tensor(0.4737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10714 D_fake_loss= tensor(0.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10714 D_tricked_loss= tensor(1.6223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10715 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10715 D_fake_loss= tensor(0.4242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10715 D_tricked_loss= tensor(1.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10716 D_real_loss= tensor(0.4314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10716 D_fake_loss= tensor(0.4129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10716 D_tricked_loss= tensor(1.6219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10717 D_real_loss= tensor(0.4274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10717 D_fake_loss= tensor(0.4588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10717 D_tricked_loss= tensor(1.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10718 D_real_loss= tensor(0.4542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10718 D_fake_loss= tensor(0.4222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10718 D_tricked_loss= tensor(1.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10719 D_real_loss= tensor(0.4687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10719 D_fake_loss= tensor(0.3977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10719 D_tricked_loss= tensor(1.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10720 D_real_loss= tensor(0.4540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10720 D_fake_loss= tensor(0.4452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10720 D_tricked_loss= tensor(1.5794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10721 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10721 D_fake_loss= tensor(0.4145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10721 D_tricked_loss= tensor(1.6478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10722 D_real_loss= tensor(0.4728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10722 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10722 D_tricked_loss= tensor(1.6093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10723 D_real_loss= tensor(0.4625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10723 D_fake_loss= tensor(0.4088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10723 D_tricked_loss= tensor(1.6034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10724 D_real_loss= tensor(0.4808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10724 D_fake_loss= tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10724 D_tricked_loss= tensor(1.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10725 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10725 D_fake_loss= tensor(0.4102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10725 D_tricked_loss= tensor(1.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10726 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10726 D_fake_loss= tensor(0.4374, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10726 D_tricked_loss= tensor(1.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10727 D_real_loss= tensor(0.4558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10727 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10727 D_tricked_loss= tensor(1.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10728 D_real_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10728 D_fake_loss= tensor(0.4222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10728 D_tricked_loss= tensor(1.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10729 D_real_loss= tensor(0.4501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10729 D_fake_loss= tensor(0.3978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10729 D_tricked_loss= tensor(1.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10730 D_real_loss= tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10730 D_fake_loss= tensor(0.4117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10730 D_tricked_loss= tensor(1.6105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10731 D_real_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10731 D_fake_loss= tensor(0.3938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10731 D_tricked_loss= tensor(1.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10732 D_real_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10732 D_fake_loss= tensor(0.4100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10732 D_tricked_loss= tensor(1.6233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10733 D_real_loss= tensor(0.4203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10733 D_fake_loss= tensor(0.4094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10733 D_tricked_loss= tensor(1.5933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10734 D_real_loss= tensor(0.4454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10734 D_fake_loss= tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10734 D_tricked_loss= tensor(1.6586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10735 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10735 D_fake_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10735 D_tricked_loss= tensor(1.6024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10736 D_real_loss= tensor(0.4677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10736 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10736 D_tricked_loss= tensor(1.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10737 D_real_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10737 D_fake_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10737 D_tricked_loss= tensor(1.5881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10738 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10738 D_fake_loss= tensor(0.4025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10738 D_tricked_loss= tensor(1.6252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10739 D_real_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10739 D_fake_loss= tensor(0.4372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10739 D_tricked_loss= tensor(1.5843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10740 D_real_loss= tensor(0.4722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10740 D_fake_loss= tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10740 D_tricked_loss= tensor(1.5785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10741 D_real_loss= tensor(0.4399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10741 D_fake_loss= tensor(0.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10741 D_tricked_loss= tensor(1.5280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10742 D_real_loss= tensor(0.4408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10742 D_fake_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10742 D_tricked_loss= tensor(1.5321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10743 D_real_loss= tensor(0.4479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10743 D_fake_loss= tensor(0.4199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10743 D_tricked_loss= tensor(1.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10744 D_real_loss= tensor(0.4375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10744 D_fake_loss= tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10744 D_tricked_loss= tensor(1.5515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10745 D_real_loss= tensor(0.4297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10745 D_fake_loss= tensor(0.4245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10745 D_tricked_loss= tensor(1.6196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10746 D_real_loss= tensor(0.4675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10746 D_fake_loss= tensor(0.4148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10746 D_tricked_loss= tensor(1.6295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10747 D_real_loss= tensor(0.4739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10747 D_fake_loss= tensor(0.4240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10747 D_tricked_loss= tensor(1.5936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10748 D_real_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10748 D_fake_loss= tensor(0.4210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10748 D_tricked_loss= tensor(1.5867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10749 D_real_loss= tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10749 D_fake_loss= tensor(0.4379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10749 D_tricked_loss= tensor(1.6507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10750 D_real_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10750 D_fake_loss= tensor(0.3948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10750 D_tricked_loss= tensor(1.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10751 D_real_loss= tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10751 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10751 D_tricked_loss= tensor(1.6061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10752 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10752 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10752 D_tricked_loss= tensor(1.6139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10753 D_real_loss= tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10753 D_fake_loss= tensor(0.4118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10753 D_tricked_loss= tensor(1.5713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10754 D_real_loss= tensor(0.4591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10754 D_fake_loss= tensor(0.4624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10754 D_tricked_loss= tensor(1.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10755 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10755 D_fake_loss= tensor(0.4036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10755 D_tricked_loss= tensor(1.6407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10756 D_real_loss= tensor(0.4853, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10756 D_fake_loss= tensor(0.4076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10756 D_tricked_loss= tensor(1.6708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10757 D_real_loss= tensor(0.4489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10757 D_fake_loss= tensor(0.4247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10757 D_tricked_loss= tensor(1.6302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10758 D_real_loss= tensor(0.4667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10758 D_fake_loss= tensor(0.4139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10758 D_tricked_loss= tensor(1.6575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10759 D_real_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10759 D_fake_loss= tensor(0.4080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10759 D_tricked_loss= tensor(1.5781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10760 D_real_loss= tensor(0.4529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10760 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10760 D_tricked_loss= tensor(1.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10761 D_real_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10761 D_fake_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10761 D_tricked_loss= tensor(1.5845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10762 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10762 D_fake_loss= tensor(0.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10762 D_tricked_loss= tensor(1.6366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10763 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10763 D_fake_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10763 D_tricked_loss= tensor(1.5698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10764 D_real_loss= tensor(0.4569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10764 D_fake_loss= tensor(0.4194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10764 D_tricked_loss= tensor(1.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10765 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10765 D_fake_loss= tensor(0.4063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10765 D_tricked_loss= tensor(1.5796, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10766 D_real_loss= tensor(0.4319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10766 D_fake_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10766 D_tricked_loss= tensor(1.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10767 D_real_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10767 D_fake_loss= tensor(0.4204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10767 D_tricked_loss= tensor(1.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10768 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10768 D_fake_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10768 D_tricked_loss= tensor(1.5008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10769 D_real_loss= tensor(0.4557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10769 D_fake_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10769 D_tricked_loss= tensor(1.6162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10770 D_real_loss= tensor(0.4817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10770 D_fake_loss= tensor(0.4189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10770 D_tricked_loss= tensor(1.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10771 D_real_loss= tensor(0.4440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10771 D_fake_loss= tensor(0.4087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10771 D_tricked_loss= tensor(1.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10772 D_real_loss= tensor(0.4642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10772 D_fake_loss= tensor(0.4126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10772 D_tricked_loss= tensor(1.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10773 D_real_loss= tensor(0.4705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10773 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10773 D_tricked_loss= tensor(1.6628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10774 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10774 D_fake_loss= tensor(0.4022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10774 D_tricked_loss= tensor(1.6038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10775 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10775 D_fake_loss= tensor(0.4140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10775 D_tricked_loss= tensor(1.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10776 D_real_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10776 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10776 D_tricked_loss= tensor(1.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10777 D_real_loss= tensor(0.4541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10777 D_fake_loss= tensor(0.4158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10777 D_tricked_loss= tensor(1.5417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10778 D_real_loss= tensor(0.4519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10778 D_fake_loss= tensor(0.4249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10778 D_tricked_loss= tensor(1.6157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10779 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10779 D_fake_loss= tensor(0.3953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10779 D_tricked_loss= tensor(1.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10780 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10780 D_fake_loss= tensor(0.4306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10780 D_tricked_loss= tensor(1.6145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10781 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10781 D_fake_loss= tensor(0.4271, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10781 D_tricked_loss= tensor(1.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10782 D_real_loss= tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10782 D_fake_loss= tensor(0.4111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10782 D_tricked_loss= tensor(1.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10783 D_real_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10783 D_fake_loss= tensor(0.4103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10783 D_tricked_loss= tensor(1.5893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10784 D_real_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10784 D_fake_loss= tensor(0.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10784 D_tricked_loss= tensor(1.5877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10785 D_real_loss= tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10785 D_fake_loss= tensor(0.4444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10785 D_tricked_loss= tensor(1.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10786 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10786 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10786 D_tricked_loss= tensor(1.6219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10787 D_real_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10787 D_fake_loss= tensor(0.3927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10787 D_tricked_loss= tensor(1.6063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10788 D_real_loss= tensor(0.4530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10788 D_fake_loss= tensor(0.4238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10788 D_tricked_loss= tensor(1.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10789 D_real_loss= tensor(0.4267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10789 D_fake_loss= tensor(0.4196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10789 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10790 D_real_loss= tensor(0.4580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10790 D_fake_loss= tensor(0.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10790 D_tricked_loss= tensor(1.6609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10791 D_real_loss= tensor(0.4658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10791 D_fake_loss= tensor(0.3975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10791 D_tricked_loss= tensor(1.6028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10792 D_real_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10792 D_fake_loss= tensor(0.4250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10792 D_tricked_loss= tensor(1.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10793 D_real_loss= tensor(0.4455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10793 D_fake_loss= tensor(0.4367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10793 D_tricked_loss= tensor(1.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10794 D_real_loss= tensor(0.4730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10794 D_fake_loss= tensor(0.4026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10794 D_tricked_loss= tensor(1.7162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10795 D_real_loss= tensor(0.4806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10795 D_fake_loss= tensor(0.4031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10795 D_tricked_loss= tensor(1.6043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10796 D_real_loss= tensor(0.4269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10796 D_fake_loss= tensor(0.4390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10796 D_tricked_loss= tensor(1.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10797 D_real_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10797 D_fake_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10797 D_tricked_loss= tensor(1.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10798 D_real_loss= tensor(0.4551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10798 D_fake_loss= tensor(0.3950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10798 D_tricked_loss= tensor(1.6468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10799 D_real_loss= tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10799 D_fake_loss= tensor(0.4252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10799 D_tricked_loss= tensor(1.6087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10800 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10800 D_fake_loss= tensor(0.4017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10800 D_tricked_loss= tensor(1.6377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10801 D_real_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10801 D_fake_loss= tensor(0.3996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10801 D_tricked_loss= tensor(1.6204, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10802 D_real_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10802 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10802 D_tricked_loss= tensor(1.6551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10803 D_real_loss= tensor(0.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10803 D_fake_loss= tensor(0.4191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10803 D_tricked_loss= tensor(1.6620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10804 D_real_loss= tensor(0.4446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10804 D_fake_loss= tensor(0.4364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10804 D_tricked_loss= tensor(1.6443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10805 D_real_loss= tensor(0.4491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10805 D_fake_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10805 D_tricked_loss= tensor(1.6391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10806 D_real_loss= tensor(0.4377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10806 D_fake_loss= tensor(0.4101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10806 D_tricked_loss= tensor(1.6305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10807 D_real_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10807 D_fake_loss= tensor(0.4109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10807 D_tricked_loss= tensor(1.6463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10808 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10808 D_fake_loss= tensor(0.4064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10808 D_tricked_loss= tensor(1.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10809 D_real_loss= tensor(0.4439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10809 D_fake_loss= tensor(0.4168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10809 D_tricked_loss= tensor(1.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10810 D_real_loss= tensor(0.4505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10810 D_fake_loss= tensor(0.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10810 D_tricked_loss= tensor(1.6142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10811 D_real_loss= tensor(0.4819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10811 D_fake_loss= tensor(0.4317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10811 D_tricked_loss= tensor(1.6276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10812 D_real_loss= tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10812 D_fake_loss= tensor(0.4075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10812 D_tricked_loss= tensor(1.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10813 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10813 D_fake_loss= tensor(0.4188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10813 D_tricked_loss= tensor(1.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10814 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10814 D_fake_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10814 D_tricked_loss= tensor(1.6192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10815 D_real_loss= tensor(0.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10815 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10815 D_tricked_loss= tensor(1.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10816 D_real_loss= tensor(0.4632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10816 D_fake_loss= tensor(0.3938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10816 D_tricked_loss= tensor(1.6180, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10817 D_real_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10817 D_fake_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10817 D_tricked_loss= tensor(1.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10818 D_real_loss= tensor(0.4733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10818 D_fake_loss= tensor(0.4008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10818 D_tricked_loss= tensor(1.6216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10819 D_real_loss= tensor(0.4391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10819 D_fake_loss= tensor(0.4483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10819 D_tricked_loss= tensor(1.6635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10820 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10820 D_fake_loss= tensor(0.4116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10820 D_tricked_loss= tensor(1.6146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10821 D_real_loss= tensor(0.4415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10821 D_fake_loss= tensor(0.4122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10821 D_tricked_loss= tensor(1.6720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10822 D_real_loss= tensor(0.4486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10822 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10822 D_tricked_loss= tensor(1.7051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10823 D_real_loss= tensor(0.4510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10823 D_fake_loss= tensor(0.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10823 D_tricked_loss= tensor(1.6681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10824 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10824 D_fake_loss= tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10824 D_tricked_loss= tensor(1.5779, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10825 D_real_loss= tensor(0.4713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10825 D_fake_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10825 D_tricked_loss= tensor(1.6438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10826 D_real_loss= tensor(0.4423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10826 D_fake_loss= tensor(0.4182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10826 D_tricked_loss= tensor(1.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10827 D_real_loss= tensor(0.4509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10827 D_fake_loss= tensor(0.4363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10827 D_tricked_loss= tensor(1.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10828 D_real_loss= tensor(0.4703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10828 D_fake_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10828 D_tricked_loss= tensor(1.6551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10829 D_real_loss= tensor(0.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10829 D_fake_loss= tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10829 D_tricked_loss= tensor(1.5828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10830 D_real_loss= tensor(0.4560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10830 D_fake_loss= tensor(0.4328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10830 D_tricked_loss= tensor(1.6511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10831 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10831 D_fake_loss= tensor(0.4236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10831 D_tricked_loss= tensor(1.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10832 D_real_loss= tensor(0.4442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10832 D_fake_loss= tensor(0.4046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10832 D_tricked_loss= tensor(1.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10833 D_real_loss= tensor(0.4445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10833 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10833 D_tricked_loss= tensor(1.5875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10834 D_real_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10834 D_fake_loss= tensor(0.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10834 D_tricked_loss= tensor(1.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10835 D_real_loss= tensor(0.4527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10835 D_fake_loss= tensor(0.4058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10835 D_tricked_loss= tensor(1.6215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10836 D_real_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10836 D_fake_loss= tensor(0.4338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10836 D_tricked_loss= tensor(1.5719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10837 D_real_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10837 D_fake_loss= tensor(0.4191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10837 D_tricked_loss= tensor(1.6129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10838 D_real_loss= tensor(0.4605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10838 D_fake_loss= tensor(0.4129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10838 D_tricked_loss= tensor(1.6260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10839 D_real_loss= tensor(0.4613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10839 D_fake_loss= tensor(0.4122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10839 D_tricked_loss= tensor(1.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10840 D_real_loss= tensor(0.4889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10840 D_fake_loss= tensor(0.4150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10840 D_tricked_loss= tensor(1.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10841 D_real_loss= tensor(0.4784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10841 D_fake_loss= tensor(0.4135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10841 D_tricked_loss= tensor(1.6174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10842 D_real_loss= tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10842 D_fake_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10842 D_tricked_loss= tensor(1.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10843 D_real_loss= tensor(0.4537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10843 D_fake_loss= tensor(0.4127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10843 D_tricked_loss= tensor(1.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10844 D_real_loss= tensor(0.4311, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10844 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10844 D_tricked_loss= tensor(1.5818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10845 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10845 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10845 D_tricked_loss= tensor(1.6231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10846 D_real_loss= tensor(0.4635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10846 D_fake_loss= tensor(0.4291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10846 D_tricked_loss= tensor(1.5429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10847 D_real_loss= tensor(0.4471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10847 D_fake_loss= tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10847 D_tricked_loss= tensor(1.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10848 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10848 D_fake_loss= tensor(0.4099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10848 D_tricked_loss= tensor(1.5857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10849 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10849 D_fake_loss= tensor(0.4350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10849 D_tricked_loss= tensor(1.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10850 D_real_loss= tensor(0.4700, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10850 D_fake_loss= tensor(0.4114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10850 D_tricked_loss= tensor(1.6467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10851 D_real_loss= tensor(0.4403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10851 D_fake_loss= tensor(0.4266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10851 D_tricked_loss= tensor(1.6315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10852 D_real_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10852 D_fake_loss= tensor(0.4144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10852 D_tricked_loss= tensor(1.6157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10853 D_real_loss= tensor(0.4484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10853 D_fake_loss= tensor(0.4207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10853 D_tricked_loss= tensor(1.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10854 D_real_loss= tensor(0.4096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10854 D_fake_loss= tensor(0.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10854 D_tricked_loss= tensor(1.5814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10855 D_real_loss= tensor(0.4383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10855 D_fake_loss= tensor(0.4046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10855 D_tricked_loss= tensor(1.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10856 D_real_loss= tensor(0.4343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10856 D_fake_loss= tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10856 D_tricked_loss= tensor(1.6434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10857 D_real_loss= tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10857 D_fake_loss= tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10857 D_tricked_loss= tensor(1.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10858 D_real_loss= tensor(0.4377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10858 D_fake_loss= tensor(0.4257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10858 D_tricked_loss= tensor(1.6092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10859 D_real_loss= tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10859 D_fake_loss= tensor(0.3985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10859 D_tricked_loss= tensor(1.6173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10860 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10860 D_fake_loss= tensor(0.3922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10860 D_tricked_loss= tensor(1.6200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10861 D_real_loss= tensor(0.4467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10861 D_fake_loss= tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10861 D_tricked_loss= tensor(1.6459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10862 D_real_loss= tensor(0.4328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10862 D_fake_loss= tensor(0.4219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10862 D_tricked_loss= tensor(1.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10863 D_real_loss= tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10863 D_fake_loss= tensor(0.4171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10863 D_tricked_loss= tensor(1.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10864 D_real_loss= tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10864 D_fake_loss= tensor(0.4233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10864 D_tricked_loss= tensor(1.6381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10865 D_real_loss= tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10865 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10865 D_tricked_loss= tensor(1.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10866 D_real_loss= tensor(0.4420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10866 D_fake_loss= tensor(0.4020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10866 D_tricked_loss= tensor(1.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10867 D_real_loss= tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10867 D_fake_loss= tensor(0.4003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10867 D_tricked_loss= tensor(1.6237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10868 D_real_loss= tensor(0.4468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10868 D_fake_loss= tensor(0.4193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10868 D_tricked_loss= tensor(1.6635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10869 D_real_loss= tensor(0.4666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10869 D_fake_loss= tensor(0.3940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10869 D_tricked_loss= tensor(1.6680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10870 D_real_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10870 D_fake_loss= tensor(0.4249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10870 D_tricked_loss= tensor(1.6227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10871 D_real_loss= tensor(0.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10871 D_fake_loss= tensor(0.4103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10871 D_tricked_loss= tensor(1.6762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10872 D_real_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10872 D_fake_loss= tensor(0.3782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10872 D_tricked_loss= tensor(1.6696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10873 D_real_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10873 D_fake_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10873 D_tricked_loss= tensor(1.5599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10874 D_real_loss= tensor(0.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10874 D_fake_loss= tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10874 D_tricked_loss= tensor(1.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10875 D_real_loss= tensor(0.4411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10875 D_fake_loss= tensor(0.4150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10875 D_tricked_loss= tensor(1.6072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10876 D_real_loss= tensor(0.4636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10876 D_fake_loss= tensor(0.4223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10876 D_tricked_loss= tensor(1.6024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10877 D_real_loss= tensor(0.4676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10877 D_fake_loss= tensor(0.4058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10877 D_tricked_loss= tensor(1.6360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10878 D_real_loss= tensor(0.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10878 D_fake_loss= tensor(0.4202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10878 D_tricked_loss= tensor(1.6234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10879 D_real_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10879 D_fake_loss= tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10879 D_tricked_loss= tensor(1.6466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10880 D_real_loss= tensor(0.4716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10880 D_fake_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10880 D_tricked_loss= tensor(1.6244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10881 D_real_loss= tensor(0.4464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10881 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10881 D_tricked_loss= tensor(1.5792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10882 D_real_loss= tensor(0.4318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10882 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10882 D_tricked_loss= tensor(1.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10883 D_real_loss= tensor(0.4416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10883 D_fake_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10883 D_tricked_loss= tensor(1.5873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10884 D_real_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10884 D_fake_loss= tensor(0.3980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10884 D_tricked_loss= tensor(1.6122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10885 D_real_loss= tensor(0.4480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10885 D_fake_loss= tensor(0.4063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10885 D_tricked_loss= tensor(1.5954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10886 D_real_loss= tensor(0.4586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10886 D_fake_loss= tensor(0.4285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10886 D_tricked_loss= tensor(1.5962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10887 D_real_loss= tensor(0.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10887 D_fake_loss= tensor(0.3876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10887 D_tricked_loss= tensor(1.6440, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10888 D_real_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10888 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10888 D_tricked_loss= tensor(1.6638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10889 D_real_loss= tensor(0.4289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10889 D_fake_loss= tensor(0.4010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10889 D_tricked_loss= tensor(1.6750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10890 D_real_loss= tensor(0.4356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10890 D_fake_loss= tensor(0.4228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10890 D_tricked_loss= tensor(1.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10891 D_real_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10891 D_fake_loss= tensor(0.4043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10891 D_tricked_loss= tensor(1.6551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10892 D_real_loss= tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10892 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10892 D_tricked_loss= tensor(1.6116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10893 D_real_loss= tensor(0.4532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10893 D_fake_loss= tensor(0.4114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10893 D_tricked_loss= tensor(1.6489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10894 D_real_loss= tensor(0.4627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10894 D_fake_loss= tensor(0.3791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10894 D_tricked_loss= tensor(1.6253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10895 D_real_loss= tensor(0.4282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10895 D_fake_loss= tensor(0.4351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10895 D_tricked_loss= tensor(1.6316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10896 D_real_loss= tensor(0.4435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10896 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10896 D_tricked_loss= tensor(1.6191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10897 D_real_loss= tensor(0.4549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10897 D_fake_loss= tensor(0.4090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10897 D_tricked_loss= tensor(1.6362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10898 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10898 D_fake_loss= tensor(0.4138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10898 D_tricked_loss= tensor(1.6373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10899 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10899 D_fake_loss= tensor(0.4132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10899 D_tricked_loss= tensor(1.6513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10900 D_real_loss= tensor(0.4515, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10900 D_fake_loss= tensor(0.4385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10900 D_tricked_loss= tensor(1.5584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10901 D_real_loss= tensor(0.4831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10901 D_fake_loss= tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10901 D_tricked_loss= tensor(1.5984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10902 D_real_loss= tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10902 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10902 D_tricked_loss= tensor(1.5619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10903 D_real_loss= tensor(0.4820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10903 D_fake_loss= tensor(0.3892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10903 D_tricked_loss= tensor(1.5672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10904 D_real_loss= tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10904 D_fake_loss= tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10904 D_tricked_loss= tensor(1.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10905 D_real_loss= tensor(0.4918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10905 D_fake_loss= tensor(0.4437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10905 D_tricked_loss= tensor(1.6417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10906 D_real_loss= tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10906 D_fake_loss= tensor(0.4035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10906 D_tricked_loss= tensor(1.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10907 D_real_loss= tensor(0.4689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10907 D_fake_loss= tensor(0.4168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10907 D_tricked_loss= tensor(1.6289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10908 D_real_loss= tensor(0.4610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10908 D_fake_loss= tensor(0.4057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10908 D_tricked_loss= tensor(1.6399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10909 D_real_loss= tensor(0.4431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10909 D_fake_loss= tensor(0.3990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10909 D_tricked_loss= tensor(1.6231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10910 D_real_loss= tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10910 D_fake_loss= tensor(0.4215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10910 D_tricked_loss= tensor(1.6019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10911 D_real_loss= tensor(0.4648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10911 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10911 D_tricked_loss= tensor(1.6492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10912 D_real_loss= tensor(0.4691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10912 D_fake_loss= tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10912 D_tricked_loss= tensor(1.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10913 D_real_loss= tensor(0.4521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10913 D_fake_loss= tensor(0.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10913 D_tricked_loss= tensor(1.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10914 D_real_loss= tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10914 D_fake_loss= tensor(0.4443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10914 D_tricked_loss= tensor(1.6237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10915 D_real_loss= tensor(0.4868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10915 D_fake_loss= tensor(0.4053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10915 D_tricked_loss= tensor(1.6544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10916 D_real_loss= tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10916 D_fake_loss= tensor(0.4277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10916 D_tricked_loss= tensor(1.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10917 D_real_loss= tensor(0.4717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10917 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10917 D_tricked_loss= tensor(1.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10918 D_real_loss= tensor(0.4459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10918 D_fake_loss= tensor(0.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10918 D_tricked_loss= tensor(1.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10919 D_real_loss= tensor(0.4461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10919 D_fake_loss= tensor(0.4227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10919 D_tricked_loss= tensor(1.6351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10920 D_real_loss= tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10920 D_fake_loss= tensor(0.4096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10920 D_tricked_loss= tensor(1.5156, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10921 D_real_loss= tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10921 D_fake_loss= tensor(0.4186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10921 D_tricked_loss= tensor(1.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10922 D_real_loss= tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10922 D_fake_loss= tensor(0.3877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10922 D_tricked_loss= tensor(1.6218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10923 D_real_loss= tensor(0.4630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10923 D_fake_loss= tensor(0.4164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10923 D_tricked_loss= tensor(1.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10924 D_real_loss= tensor(0.4668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10924 D_fake_loss= tensor(0.4126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10924 D_tricked_loss= tensor(1.6484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10925 D_real_loss= tensor(0.4347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10925 D_fake_loss= tensor(0.4030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10925 D_tricked_loss= tensor(1.6007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10926 D_real_loss= tensor(0.4456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10926 D_fake_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10926 D_tricked_loss= tensor(1.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10927 D_real_loss= tensor(0.4576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10927 D_fake_loss= tensor(0.4047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10927 D_tricked_loss= tensor(1.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10928 D_real_loss= tensor(0.4329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10928 D_fake_loss= tensor(0.4199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10928 D_tricked_loss= tensor(1.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10929 D_real_loss= tensor(0.4078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10929 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10929 D_tricked_loss= tensor(1.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10930 D_real_loss= tensor(0.4229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10930 D_fake_loss= tensor(0.4497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10930 D_tricked_loss= tensor(1.6288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10931 D_real_loss= tensor(0.4587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10931 D_fake_loss= tensor(0.4086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10931 D_tricked_loss= tensor(1.6238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10932 D_real_loss= tensor(0.4513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10932 D_fake_loss= tensor(0.4039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10932 D_tricked_loss= tensor(1.6234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10933 D_real_loss= tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10933 D_fake_loss= tensor(0.4282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10933 D_tricked_loss= tensor(1.6392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10934 D_real_loss= tensor(0.4354, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10934 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10934 D_tricked_loss= tensor(1.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10935 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10935 D_fake_loss= tensor(0.4004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10935 D_tricked_loss= tensor(1.6281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10936 D_real_loss= tensor(0.4516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10936 D_fake_loss= tensor(0.4248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10936 D_tricked_loss= tensor(1.6201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10937 D_real_loss= tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10937 D_fake_loss= tensor(0.4206, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10937 D_tricked_loss= tensor(1.6295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10938 D_real_loss= tensor(0.4240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10938 D_fake_loss= tensor(0.4566, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10938 D_tricked_loss= tensor(1.6406, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10939 D_real_loss= tensor(0.4910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10939 D_fake_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10939 D_tricked_loss= tensor(1.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10940 D_real_loss= tensor(0.4345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10940 D_fake_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10940 D_tricked_loss= tensor(1.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10941 D_real_loss= tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10941 D_fake_loss= tensor(0.4313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10941 D_tricked_loss= tensor(1.6615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10942 D_real_loss= tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10942 D_fake_loss= tensor(0.4265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10942 D_tricked_loss= tensor(1.5938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10943 D_real_loss= tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10943 D_fake_loss= tensor(0.4160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10943 D_tricked_loss= tensor(1.6495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10944 D_real_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10944 D_fake_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10944 D_tricked_loss= tensor(1.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10945 D_real_loss= tensor(0.4596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10945 D_fake_loss= tensor(0.4169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10945 D_tricked_loss= tensor(1.6280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10946 D_real_loss= tensor(0.4579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10946 D_fake_loss= tensor(0.4147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10946 D_tricked_loss= tensor(1.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10947 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10947 D_fake_loss= tensor(0.4135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10947 D_tricked_loss= tensor(1.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10948 D_real_loss= tensor(0.4599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10948 D_fake_loss= tensor(0.4268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10948 D_tricked_loss= tensor(1.6285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10949 D_real_loss= tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10949 D_fake_loss= tensor(0.4105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10949 D_tricked_loss= tensor(1.6030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10950 D_real_loss= tensor(0.4567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10950 D_fake_loss= tensor(0.4162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10950 D_tricked_loss= tensor(1.6164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10951 D_real_loss= tensor(0.4672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10951 D_fake_loss= tensor(0.4402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10951 D_tricked_loss= tensor(1.5976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10952 D_real_loss= tensor(0.4698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10952 D_fake_loss= tensor(0.4244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10952 D_tricked_loss= tensor(1.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10953 D_real_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10953 D_fake_loss= tensor(0.4058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10953 D_tricked_loss= tensor(1.5721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10954 D_real_loss= tensor(0.4298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10954 D_fake_loss= tensor(0.4324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10954 D_tricked_loss= tensor(1.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10955 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10955 D_fake_loss= tensor(0.4208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10955 D_tricked_loss= tensor(1.6270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10956 D_real_loss= tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10956 D_fake_loss= tensor(0.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10956 D_tricked_loss= tensor(1.5913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10957 D_real_loss= tensor(0.4346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10957 D_fake_loss= tensor(0.4409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10957 D_tricked_loss= tensor(1.5940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10958 D_real_loss= tensor(0.4869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10958 D_fake_loss= tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10958 D_tricked_loss= tensor(1.6358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10959 D_real_loss= tensor(0.4578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10959 D_fake_loss= tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10959 D_tricked_loss= tensor(1.6412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10960 D_real_loss= tensor(0.4376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10960 D_fake_loss= tensor(0.4088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10960 D_tricked_loss= tensor(1.6519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10961 D_real_loss= tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10961 D_fake_loss= tensor(0.4063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10961 D_tricked_loss= tensor(1.6364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10962 D_real_loss= tensor(0.4475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10962 D_fake_loss= tensor(0.4224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10962 D_tricked_loss= tensor(1.6695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10963 D_real_loss= tensor(0.4432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10963 D_fake_loss= tensor(0.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10963 D_tricked_loss= tensor(1.6272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10964 D_real_loss= tensor(0.4503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10964 D_fake_loss= tensor(0.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10964 D_tricked_loss= tensor(1.6150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10965 D_real_loss= tensor(0.4571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10965 D_fake_loss= tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10965 D_tricked_loss= tensor(1.6222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10966 D_real_loss= tensor(0.4811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10966 D_fake_loss= tensor(0.4326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10966 D_tricked_loss= tensor(1.6097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10967 D_real_loss= tensor(0.4771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10967 D_fake_loss= tensor(0.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10967 D_tricked_loss= tensor(1.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10968 D_real_loss= tensor(0.4507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10968 D_fake_loss= tensor(0.4382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10968 D_tricked_loss= tensor(1.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10969 D_real_loss= tensor(0.4583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10969 D_fake_loss= tensor(0.4126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10969 D_tricked_loss= tensor(1.6372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10970 D_real_loss= tensor(0.4574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10970 D_fake_loss= tensor(0.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10970 D_tricked_loss= tensor(1.6061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10971 D_real_loss= tensor(0.4682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10971 D_fake_loss= tensor(0.4187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10971 D_tricked_loss= tensor(1.6005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10972 D_real_loss= tensor(0.4577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10972 D_fake_loss= tensor(0.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10972 D_tricked_loss= tensor(1.6385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10973 D_real_loss= tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10973 D_fake_loss= tensor(0.4430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10973 D_tricked_loss= tensor(1.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10974 D_real_loss= tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10974 D_fake_loss= tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10974 D_tricked_loss= tensor(1.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10975 D_real_loss= tensor(0.4296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10975 D_fake_loss= tensor(0.4040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10975 D_tricked_loss= tensor(1.6218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10976 D_real_loss= tensor(0.4401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10976 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10976 D_tricked_loss= tensor(1.6241, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10977 D_real_loss= tensor(0.4500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10977 D_fake_loss= tensor(0.4565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10977 D_tricked_loss= tensor(1.5752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10978 D_real_loss= tensor(0.4693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10978 D_fake_loss= tensor(0.3931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10978 D_tricked_loss= tensor(1.6245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10979 D_real_loss= tensor(0.4562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10979 D_fake_loss= tensor(0.4349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10979 D_tricked_loss= tensor(1.6429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10980 D_real_loss= tensor(0.4740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10980 D_fake_loss= tensor(0.4094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10980 D_tricked_loss= tensor(1.6379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10981 D_real_loss= tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10981 D_fake_loss= tensor(0.4124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10981 D_tricked_loss= tensor(1.6687, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10982 D_real_loss= tensor(0.4696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10982 D_fake_loss= tensor(0.4013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10982 D_tricked_loss= tensor(1.6377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10983 D_real_loss= tensor(0.4611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10983 D_fake_loss= tensor(0.4273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10983 D_tricked_loss= tensor(1.6059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10984 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10984 D_fake_loss= tensor(0.4098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10984 D_tricked_loss= tensor(1.6443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10985 D_real_loss= tensor(0.4472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10985 D_fake_loss= tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10985 D_tricked_loss= tensor(1.6274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10986 D_real_loss= tensor(0.4473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10986 D_fake_loss= tensor(0.4119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10986 D_tricked_loss= tensor(1.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10987 D_real_loss= tensor(0.4800, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10987 D_fake_loss= tensor(0.3991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10987 D_tricked_loss= tensor(1.6081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10988 D_real_loss= tensor(0.4794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10988 D_fake_loss= tensor(0.4369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10988 D_tricked_loss= tensor(1.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10989 D_real_loss= tensor(0.4553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10989 D_fake_loss= tensor(0.4230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10989 D_tricked_loss= tensor(1.6344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10990 D_real_loss= tensor(0.4618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10990 D_fake_loss= tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10990 D_tricked_loss= tensor(1.6032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10991 D_real_loss= tensor(0.4589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10991 D_fake_loss= tensor(0.4221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10991 D_tricked_loss= tensor(1.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10992 D_real_loss= tensor(0.4612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10992 D_fake_loss= tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10992 D_tricked_loss= tensor(1.5919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10993 D_real_loss= tensor(0.4357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10993 D_fake_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10993 D_tricked_loss= tensor(1.5575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10994 D_real_loss= tensor(0.4575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10994 D_fake_loss= tensor(0.4235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10994 D_tricked_loss= tensor(1.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10995 D_real_loss= tensor(0.4572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10995 D_fake_loss= tensor(0.4358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10995 D_tricked_loss= tensor(1.5662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10996 D_real_loss= tensor(0.4681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10996 D_fake_loss= tensor(0.3958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10996 D_tricked_loss= tensor(1.5522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10997 D_real_loss= tensor(0.4841, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10997 D_fake_loss= tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10997 D_tricked_loss= tensor(1.6439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10998 D_real_loss= tensor(0.4359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10998 D_fake_loss= tensor(0.4143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10998 D_tricked_loss= tensor(1.6144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "******************************\n",
      "10999 D_real_loss= tensor(0.4305, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10999 D_fake_loss= tensor(0.4319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10999 D_tricked_loss= tensor(1.5865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Total Training Time: 40199.6660 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "G_model     = Generator_Net()\n",
    "\n",
    "D_model     = Discriminator_Net()\n",
    "\n",
    "D_loss_fn   = nn.BCELoss()\n",
    "\n",
    "G_opt       = torch.optim.Adam( G_model.parameters(), lr=g_learning_rate )\n",
    "D_opt       = torch.optim.Adam( D_model.parameters(), lr=d_learning_rate )\n",
    "\n",
    "training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt )\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Total Training Time: {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Time: 11 hrs 9 min 59 sec\n",
    "#### Time per epoch: ~4 seconds a epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_GAN_losses(list_losses_real, list_losses_fake, list_losses_tricked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test generating after training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = {\"Baked Potato\" : 0, \"Burger\" : 1, \"Crispy Chicken\" : 2, \"Donut\" : 3, \"Fries\" : 4, \"Hot Dog\" : 5, \"Pizza\" : 6, \"Sandwich\" : 7, \"Taco\" : 8, \"Taquito\" : 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Baked Potato\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Burger\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACRoAAATkCAYAAAAJ0C4xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACOfklEQVR4nOzc95Pf92Hf+e/2isU2LDqw6CBAEiTBChaRFMUikbQky5J1juPY58vN3cSZ2I4T36VcbnJ3iZOczpfm09lxTMmWZVuSJctqFEWKVawgCRIkiN6xCywW23u5/0DvzcxrJpzD4/Erd56L3W/ZT3nxW7W4uLhYAQAAAAAAAAAA+Cmq/2v/AwAAAAAAAAAAgA8/QyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAotqlfuFnfumT0W/8twZ3RXvN/c9Fe6+0jEZ79zVciPYq1y75oVuSP+pfE+0dP34+2tuw4/po7+GmtdHe/pYj0d7ygZlo7+sn+qK9/3WgIdo7/9HV0V7rty9Ge/9s4mi017KvPtq7eDH7+t3VNRztLUy0RXtHBrPvz6PvZHub9s5HexfeXoj2mlqyfz+GZ2uivcUVi9HepcNj0R7Ah9HoxA+jvYULc9Fe9URztPd+f/bYtuvVb0R7yx65OdqrG74r2lvY+qNor2X2/mhvsb412ps5fSDau3jyz6K9mr4bor3p7bPR3vnJ7mhvy55fiPYu1L0a7bWd6oz23pv+XrS34sTd0d7h5U9Ge+sOfyTa2/rAlmivc3322k3lylQ0N3Xia9Fez+wnor2RTceive69/0e0B/Bhde7tp6O92dcGo72BI+9He+d2rIz2rt1eF+21vJk9n5wYyd7LuXR/9lrw5IFN0d6W6f3R3vP7j0d7/2rd7mjvb3f8JNrbuJC9N3nd6uy1/kqlUpnftjPaq1+VvSbUOHVHtDfYUhXttQwfjvZmTkZzlYtnsj/vW53Z9/ybGg5Fe9+typ5DP7A++xk+o63Zv8G9rfuivR2r1//U/+4TjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoql3qF+768Uj0G3ft/Otob2zqUrR3YWIo2vv9ZauivYEf9UR7vcuORXu/Mr8j2rs41xDtPfnkU9HeY7u3RHvvLJ+I9j5xXzRXGXjyQrT35YEV0V79R1ZHe7cdGIz2rhycjvY6H86+//3cC9Fc5Wub+qO96ueX/KdrSZoas5vbs/sno73xDfXRXsNo9v10ZeNCtHd8fDHaA7gaXLhQFe01jWWPVUZWnY/2GhuzP++R2uzfsu0v/TDa696TPRevu9gV7U2t7Y726i69GO0NvPbVaK9q5YPR3sK9z0d7K4/tj/aqxv5xtDd3/Ei0t3rx7WjvnbmHor3mluzzZdmmU9FeS/9t0d767WPRXsvIyWiv4Y3GaG9wU/bkueX97LWRsbrstYyF6zuiPYCrRUtT9t7B2brstcfJm89EezV12WuZKzuui/beaovmKus7ZqO9rvq5aG9sxZPR3jP92Wu3Mzc3RXt/9+3RaG/Nx38m2hs9cznaG57Ino9XKpXKyoGt0V5VXfZF93xn9hrJroM10d6V5vCeYldftLdpMHs/rGt19hy1riF7DrNvMvv4ts/ujPZGx9dGe9WN2b1HpbL+p3+/8HcDAAAAAAAAAAD+f8jQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKapf6hfW3vRf9xvsPNUR7w+MT0d6Zix3R3tTKmmhvy67V0d6+i3PR3tsd49He5NCxaO/+msvR3v97Oft8fuuHzdHexz+W/fcdHcxuFEeG+qK9HT+3Ptq79Ez293fj9miucur4aLT3zwd3Rnu33TUU7e14ZG209+PXXo72KrPt0Vzv7PJob+XmoWjvwpForjI/WpUNAlwFXtz/RLT3yIpl0d7pQw9Ee9duyR6L1jY8Gu1dmvtOtNc8sSva65jInpvW1P7f0V7V97PXHi7NZo+VD3zn30R7Gze3RXvDyxajvaOLX4r2rhvOngxdvvHGaK++PntusHrwXLT3tWWt0d49N3402qufPRjtXXm9Ptrrf+svor1K68ZsbtUb0d6VA69GewvnVkZ7PV/4rWgP4MNqfih78Wz28Plob+XW4WivaU/2/OV4dfZ4b37dV6K9H3zx2WjvzgvZ472mXdlr6Q2NL0R7e1b8WrQ3tzb7fF7XczTae+a93mhv+PSb0V6lUqk0TmfvF0/Vd0d7101lz7EGRrL3izeN7on22ra2R3uTt2R704eejvaG12+I9hoGG6O9zs5V0V5X41C0VzuzKdor8YlGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABTVLvULNy40Rr/x6k9ne8f756K99c+uifbal81Ee7VvnIr2/u2DK6K9G996Jdo72NcW7a1YvxjtbXioM9q7ce1wtFc53RLNferzPdHeF14/G+3VvDgZ7c1VL0R7zxyYiPb+6c66aG+05kq01/X6+Wjv5SOj0V7vlqZob/r97PNvZDr796hhaCTaOzWTfT7PVmePDwCuBhtuGIj2Dle3Rnv3dWaPBfobron2Br/0QrS35VJ9tDe27Hi0V7duPtr74Nmnor3uV7PnulMtq6K9S4uz0V77s9ljs2WfyZ4bTL1/Lto7M5w9Vr6yP/v7u/1v3BTtLW/Nvt5+9cir0V7dzvXR3v757PvznasORnvD+26O9v7y8LFob+9Psue604PZa5GX7sm+3rZFawAfXuPN3dFe7c+PR3vVk5+P9noX74v2hi8/He21nKqJ9uYeG4v2uldkj+fPdWavtX5sbl+0N9lxJNobGs2+Phr+IHuv5ON3ZY/PBm7YGO1VKpVKTVf2NXLla09Ee9UXsvdLxh7ui/Ymzv4o2msa//fRXlVLe7TX2Zj9/dUezr7HvL0me/9qcvZwtPf0xew1pvVd2T3Ag5Wf/h7jE40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKpd6hde37wn+o37Rw9Ge99cVxftPb6+P9obapyM9p4baY72bh4Zj/Zuu/nGaK/p/ruivdvqnon2Tlb3RHuvDGUf34HlC9HeXavuifb2/uKlaO+NL74Y7Z1cuSLae3Tr2Wjv+NREtPfpy2PR3uRE9vn8UNVwtPe5Sw3RXs/Cymivvut4tDf/+ezGePOBvx3tnTn7J9EewNVg/K0bor2ts9dGe0MP1Ed7zX/5VLS3cdN3or3zNWuivTXXZY/lZ89lj1VaZmaivZE7a6K9Ez/Kntt/rKEq2mv+VFu0t/ytxmiv6+RgtDeyOXvsPTb/SrT373/ycrT395pvivamzo5Ge4vrvhft7T27Ntr7Su0d0d6a665Ee5V3nozm+t5tivZ2fPSWaG/n+ey1EYCrxcyK9dHe4uX5aK9mc/b4u3Yqe225fTR7fHF2+JvR3vabPhLt9R94NdprvfKlaO/Kp+6O9ubP/yDa6zyYPX95a3I22lt3Onu9oHF0e7RXqVQqr72TPYdu7Vkd7dVfOxXtXfp3Q9He8dGRaO/u2/8g2nthrDvaa3g3e3/3mrpV0V7T5QvR3tHN2T3Aiidbor3NNS9Ee5Ubf/o+yCcaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBUu+Qv7DgT/ca76pqivc+/3x/tXTg4GO397qaGaG/V56eivfGm1mivabg72lt8+d1o770HF6O9/S+ej/YOV12K9sZnl0V7/+yLfxbt3fHJ5mjvg1/bEu31/PMlv1UuyXPtx6O9mR9mH9+HNsxGe09syL7/zS4fj/ZufCH7fnpt745o79zW9dFe5ensz7tv9Ilo75vjC9EewNXg2NyhaG/f9uXR3uL0J6O9S9XfiPZ+cH4k2vv4Ddn/n2fqynS0V31pKNqr/0m2N11fF+3V1c1Fey9tyZ4bPNgbzVXOXvxstNf12b+O9nq6eqO9J/5lY7T3S41vR3uL6w5He10Pr432Bq5MRHuzlZPR3upVd0R7617NXou8uDL7eut59K1or7n7SLR38KE10d66aA3gw2th4US0t7w2e37QdLkn2ptoGY72FpZPRnsj+1qivfq5N6O9FVdORnv/+s3sz7tt8uVob3dP9lpwX3X49dFRH+0dH6uK9s4OHYv2KpVKpWVt9ppGXU/2/t+Jidujvd5PZ3/e1oGaaG/+Uvaa1X012cfjO5uye4p33vhytLeramW0t3b8b0V78788Fu2dm8w+/7YW/rtPNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgqHapX3j2zSvRb/wvqy5Ge80zS/5RlmSgUhPt1R+ejfYOnsj+++6sjEd7/7nqm9Fec/3qaO+GJy5Fe++0ron25rsGo73pltFob1X/QrT30kvT0d7WPz8X7f1V7WK0N/OH0Vzl8q110d4f1YR7r0Vzld9puTXa+/X7zkd737yQfb9/vSq7Ce7ZeTjae/DYqmhvsu1stAdwNVhYUR/tjbYfiPYuX7w22htqWxHtPX5oe7TX1pk9lho/lz22uNQ5EO2NProz2jtyYira+9jCzdHesXuOR3vnPhiO9jY++ONor7Uue+w92/fxaO9nf/dH0d7OsXujvblV2efz4VMHo71Lf5Q9N6i9dibau3v7LdHeyT37or0tx7LvB5duGYr2eo5sifY2Hb8j2qvsyeYAPqzmTmavpTcNdEd7Z8LHKxtH56K9ppHstdu53s5or2d6fbR38f7eaG/r4teivbPvT0R74+PZ892LL8xHeztuzd7729vWG+0NNx2J9iqVSmV79b3R3pUNe6O9aw4/F+3V3/lotNfYlD3IHZj442ivp2VDtPdI5VC0V1O3Odr7wvR70d4j1U9Geyvfvz3a61xsjfYqhX+eTzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKh2qV/4k46B6Dd+Y/98tDcyORPtbViW3WBdmsr2auuWRXuvj45Ge20NDdHe6PjFaO97s1XRXvv4YLQ3W7M82lvXsyvaW970UrR37sXFaO/txezrraYj+/5S37Xkt94laT45Ee19vJJ9/T4xOB7tdXT2R3tPTGbfD6auZP9e1h9eG+2dr8q+Pr6w6kS0t24g+3gAXA1uanon2jv28m9Fe9vX9ER7h2dui/Yu/uJ90d7k974S7VW3HY727li3Lto7XZ09lt+9ZTLaO7h8R7R34cXmaG+0aX+0d6TvQrT32tnssfd/tzv7/Fs1cCraG9ixN9qrfyP7+xv74blor/X0ULQ3P9IY7Z1Y+Hq01/LwndHe6dWfjfZ+MP14tFc9PxTtLbadjva2R2sAH179/W9He8eyh8uVtYdujPaq784er1RdnI72Wkey99YqCzdEc807j0V7j19aiPb6urPH802tddHeeG/2BdI4PRftzXxkfbT30Lrd0V6lUqlcCN9v2nrlO9FeZUf2nLzt8plob3J19ii3t/vj0d7Zd96P9sZGstdcWjaej/Z+vaEz2qvcuDGam5nM/vtePnso2ruu8N99ohEAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARbVL/cKTb3VEv/FCZ3+013m4Idob71iM9uYXqqK9Das7o72uO7dGe+vHRqK9Z949He2tWdsY7dVWXRPtdbVnn899l/dHe2cWJ6K96zc2R3szJxeivfnJ7Caze34m2rt5qivaa98WzVW+OjYX7c1ezP7+Wpuy7wf/9r+5Ntr76quj0d4zR7LP5+rB7PvV8bbs4wtwNfjm2L3R3s6dPdFeZ/tstNczOR7t9S/eEu1VOj4azdV1rI/2Lm7eEe11HHgv2jvw1Ilo72jliWhv4uY10d4vTGYf36/1rov2Hl1/Kdpr6hiI9tYsezzaq9RtjObm7tsU7Z1s6Iv2uj99Ntpb+dbBaK+hoT3a+0nfsWjv4aGmaK9v5Eq0t2XvQ9HeUNVt0R7A1WKgqSXaW7NsebTXPPJ70d74+8uivZN12d9f9+vnor2X5p+K9mr6hqK9y69lr80Pv5k9H3/00ezx99Dq7Oujuyt772++ui3ae+bYmWivUqlUVs5lH5PBN7LnME3rs+8J9R0bor3W5m9GeyOL10V7kxvHor2211qjvVPjD0R7u1e9EO1VjWb3FJWF7P21TWsvRnslPtEIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgKLapX5h9bbZ6DfuPrgY7R1dsSba27a8NdrrmT0U7X22dyHaO959Mto7e/pKtFc3MR/tVU3PRHsLqy9He2MXsr+/mom5aG/3DXdGex1HPoj2Ptia3VDeVZ3tXcq+fCuv3pINDn1vINrrbauP9qbq2qO9xuqpaO+P+rM/76+3N0d7/3BVtnep6aZo7181vhbtAVwNNnXsiPbuWTwe7bUP1UV7y9Yvj/bWVz0T7U11HIv23qjrjPZGX7oY7W3eti7am7ppfbT32gfZY72f6cgeSzVvvDba+62GFdFepeZPo7m6NRujvYWJXdHeYnX2WtXizKVo79G9D0Z7zYuPRHuL3X8v2hsdyr4fNB78RrS3f9s90d6Pj2f//g58dzTaa/509vXxkcpvR3sAH1Yd69dGez2t2ffjqvpPR3uv/d4Xo71tlaZo70uV56O9jfVLvs26JONvjER7Y+9l74WdaMrea1o3sSrau3VX9nxt4nz2esGBY9PRXlv4XkSlUqlc6tgQ7W3cmb2GMzecPcff/8qb0V7btoPR3pqVP4r2qgYfivY6Np6P9lZujuYqH0xkr6mtr++L9rrOdEV7xydPRXuVm3/6f/aJRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAU1S71Cy/MLvlLl2TthsZo77HxyWjvr/7m7mhvzcuHo73zb56L9i5u6Yz23n67JtqrqpmN9u66pyPa6z12Mdr7yuRwtNfQ0BTt/c6++6O9qd5N0V7PK38R7T17YSrau7M7+3469X57tHemqTnae+/SRLT3C+taor3bb3ss2tt+/YVo7/22ndHe6BtV0d6bk6uivb/zzJZoD+BqcGF4NNo7ORTNVRYHz0d76xpPR3sfrN8V7V2u+3G09/R/WBvtPfw/r4n2bti/Otq70p49lnr4o4eivS1ru6O9qv4V0V5N2/pob3Lz49Fe4/y6aO/o8UvRXs2RJ6K9/rUfifZ2TA1Gexcbsteq1tTdEu1VD2WvZWy99WC0997B7LnVDeOPRHtdY2ejvc53Nkd7leuyOYAPq7bR1mivbv1b0V7ja9l7GxObs/eu6qqz94bWH80+Hq89Nx3tLYTvxR7rm4n2Pr97Ptqrfz17veCvurP3dq+tyx5/D5+7K9q7/N7RaK9SqVROnPu30d7x9vZob2v3xmjv4tBr0V7bpez98XM3Ze/fr6z7crQ3+X728bh8f/b+eMeb2XOY5vnse0Jt93ejvZvOLkR7JT7RCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAICi2qV+4XVHx6Pf+N32VdHeiq6bo73f3fqTaG/49dXR3lfrhqK9rdNLfiosyZZfWxbt3XB8TbR3bvNstHd372K0d/HrI9HeUONctPf9gRPR3mPXjEV7k6/VR3v3zC9Ee8/O10V7c6snor2Np2uive0ruqK9o/VV0d6F4WejvV+dy/59u/767POv8s2d0dyaO7Pv9+/s3R3tfTxaA/hwumXNp6O9l596K9pbNxDNVXZ9ujXa2/rjK9Hes29eiPYeXJf923h766Zob27raLR33eHno72TE9lrBb3XZ/9/rdqWy9HecHVDtNczlT12vDD2VrQ33pU9Nz14Pvt+0D0+E+2dmc++3vrP/lq0NzHcGe2t7dkQ7V058EC0t9A1GO3VbP9ytNffuDna69n5WLQHcLU4Ovyb0V7t4b8T7VX/OHv8fW3d2mhvZEdftHfb8miu8u7YmWhvfq452lu+NXtv6L2h7LXgju6maG/Fsf3R3sLF7OPR2f5CtNe9Mnsvp1KpVI4ezt7vfGdF9n7nTW1vRnvNsyujvaHzvdFe58ThaO/7A23R3g3dx6O9qgs90d6KiaFo7/KjN0Z7y6qz59AnOrOvt9LdXZ9oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAEBR7VK/8Ojyueg33jnREO298vCFaO/+r3RGe/V7tkR7Ny4OR3sdJw9Ee6eeb4n2riyrifb2nW2N9tbfuRDt9Ry6HO1tPLYY7e0++o1o76vfy24eT1zMvj5a9i35rXJJbu2vivb2v5R9fz7UMBvt/Q892Z+35uZorvLQTPb313ldNFep7l4Z7bXc8SvR3onF34z2Nr5zMNoDuBo0nemL9p6tezva+58Wsr1zfdk/tu/tyh7Lf+5v7Yn2dp5YHe01ZQ/NKpPXno32Ltd+PtrbMP8H0d6V8Uejve7hqWivqfYH0d7Fl4aivcbmumivZcUL0d593bdFe5Xp/dHcsucOR3vbVmbPxYcWB6K92qmOaK+5/6+ivfau9dHem5tuiPYG/jx77fXxze9Ee5XKhnAP4MNpbvT6aO/5p09Fe9XLnoz2trfvi/amGrLHZw09r0V7627cGe0dnz8X7TVUN0V7M0eno71lK0eivbrq7L2cuuXZXs+KZdHe7PXZ6wWVSqVy7cKZaG9i3fZor6FyOtpbfcu6aK/+/Ey0N781uy/Y+XL2PWZsvj3aGx3OnqNObMmes103kr2GuNAdzVUGprP7ghKfaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAUe1Sv/CfzHZFv/GXqjujvX80ORLtrbj/sWhv9dGV0V7D7PejvYmWmWhv8vBUtHfycl20t/dnorlK64ZPR3uf2Xd7tLeq541or/qTN0R7NX/5drS38ObBaO/xK4vR3vGe7Mbz3mXZ19vgdFu0t+7uG6O9Xbe0R3vbBo9Ge3WzfzfaW5xojPYGHhmN9iY/uDPa2zhQFe0BXA1+9IWL0d6ZvbdGe0/syP6t/UfT2XOrB0ZXRHs9f/1CtHdp5fFor2nnb0d7M2cvRXv9b34p2qvZ0hPtne17KtpbeSF7bNY6lj137mlcFe0dbx+K9hbr7ov2Jmvfi/auHMoe21Zf3xftXdO55MuCS7LwzJpo792B7ONxsT17rvv6+Y9Ee7+xLfv36Pf2rY72Rj5YiPYqt2VzAB9WdW9nr51tang32ltYzN4LW9NwJNpbfKMp2nt1fDjam/joQLT30Kkd0V7/6ezf7+mq7L2IpiOno7139q2N9lZNZR+Pgen90V7jSPbfV6lUKq31c9Henb3d0d5UbfYaWHP/RLS3+ODuaG+qLXsOOPnmeLS3+9Zt0d7Bmew5W83sR6O9haaz0d6T381eQ2yaGIv2Kp/46f/ZJxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUFS71C/880pn9Bvfv3Uk2nv9byyL9laNPx3tDVz4e9HeusaL0V7/5rFor23rxmjvtp6paK+td3m0V9s9He1df//KaK/2oa9Ee4Mn/jDa+8RvNEd711z6B9HequGvRnu9r3ZFe219E9Fe88c/Hu1V37g12pvv+3K0N12/Jdqrav3daG+m5gvRXs/O9mjv4am7o7357T+M9gCuBoM3fCvau//4rdHe00Mno70/vid7LPVLbdujvb5Ds9He+cXsue7p7/6baK//2M5o7+iV7LHtvTcNRXstLfdGe8vPH4j2Rg9fivYuLyxGe4dWZ8+dN098P9o7OJi9llHVkr1282zVaLT3Tz6dPRc6294U7S0bqo/2ltdm369+rW1DtNfZlj23+s3bs+8Hl2qy1+YArhYbZrP3mk7OLER7W3pbo71LmzZHe+tWZ48H1p3NHg8s/OFb0d6l7uzxY3NT9l7YwuiVaO/Lndnjx/Y/H4/2nhl9Jtprf+TmaK/p5MFor1KpVFYszz7GH/SviPbWjd4Y7R1a2xftDR4fivb2Ds1Fe71d2feEE+9krxmMtr4a7b3YnX0+72jZHe1t6lryVGdJ/tOhM9He5wr/3ScaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBUu9QvvLL+WPQb3/LYDdHe0Zdqor32hezPu/3+fx/tja+4EO1du3ZPtDf9wzXR3uxHBqK9mfqxaK9q4CfR3omu5mivfaw92uvaVRXtzbX8q2hv88Yno73Buc9Ee5Ndz0R79TOj0V7VpezrtzLw5Wju9//P96K97R390d6ebYvRXs3f/F62d+7RaK8yejmaW2z+SLQHcDWYb+mN9p7q+CDaa+1vjPYGerLnanM1J6O9tbs3RXuzy9dHe22Xm6K9pp3T0d5cx+5ob2Am+/9XHXvlTLR391z2WOqV8YVo76GOmWjv0Nvj0d5/WJ19f+kaOxvt/cP27OOxceaeaG9Z1flo74bRkWived+D0d7hsez785UN2WtL0zXZx2PZQvZa6eyxF6O9yqbrsj2AD6ma+ez5y52P9UZ7cwezx/MTF2ejvcqJV6K5b34je7w3OJ0939g91B7t7azKHq80VbLHF03Hs8c/B3qy967O92Uf38/1n4723js3H+1VKpVK44+zr5GW+7LvMXUnVkd7VX2D0d5dE3XR3isN2ed0VfVktHfdrjujvUsj2fvtW753Jdr74/NvRHs3drVHexuvZK9BlPhEIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKapf6hZ031Ue/8ZXbRqO92ue2RXtnO9qivXWtd0V75w68EO0d+NGL0d66tsvR3jf+wVi091u/tjLaG9mUfX2c+mH299dz4/PRXqVubzR38OB90V73/C9Fe+dPfy/aW/NyZ7Q3M18T7X2r5t9Fe4Nzg9HeKwMz0d76tcPR3nO9Pxvt7dw/He0tzj4R7V3elf15N0/8jWgP4GpwTU322PbwvhujvYHxQ9Fe5/P90d784+Hf32T22Gz28E+ivYO1c9HewkK2t2GmN9rrnW+M9i6tyb4+Lv/4aLS39+bmaO/Nhey1kd7OW6O9/2ftS9HexhPXRnunTr0f7c2uy/68556oi/baZrPnaj85fz7aq+raFO3dUfNz0d6FlR3R3vkjx6K9ywPZa183RWsAH159PY9HeytXZO8d1Nbsj/bmT2XP115/L3u80r48e75WvXw+2jsynT1/2b7mSrR31+7ror2ZH1VFez+enIz23t+cvbdx8XxLtLerNXvvtFKpVL6z7+Fob+y17DnvL1ybfc292JB9zrz+2pFor7tnY7S39/rs/djm7WuivbaT/yDau+OR7HvgxTUHor0Lry9Ee8Pz66O9Ep9oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAEBR7VK/8MqTzdFvfOroYrQ3s/dj0d7bH/xhtLdm6GvR3gc1p6K9//317OPx6DUL0d5f9U1Hey9/dSTa+9gnsj/vPTPLo70zf/B2tHd401vR3oaX56O93+v842iv+nT28a09dSbaG9/bFu3tGW2I9rbtrY/2HtvaGu1VHt4QzY2+uSLaq9kxFO0Nvp59Pg/vPxrtDS6rifY6btkW7QF8GN1w77po7+4ja6K9/7z6s9HeQ43fiva+8B+PR3v//bbs37KBu6+N9iofnIvmmk9lj/XeWZM9Nx2tfifaW3s6+/s7WzUT7c18P9urOTUV7R3+lb3R3tz57PNlYv5CtPfq2eyx94ansz/v+Y7haG/1rdn3vw0z2XPTK0ey5wb/cfZstPd4Z7bXuip77nx+alW0B3C1aH/696O9yZO90d6lW0ejvfGT49Fe4/xQtPfYyqZor29uS7S35hez539rKsuivf6L2XtNy+/Ifh7Gz52+Eu2dGKyK9s5cyB7v9exuj/YqlUql48KJaG9De/Y94SsvZM/Jj89m709+ZiD7HnOlsy7au3tzV7TX3z8Z7e2oyT4ecy1j0d6V4dlob9nrF6O9zXdlH48Sn2gEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQFHtUr/w+js6ot+4afmaaG/9J3ZGe2fea4z2Gl5aiPaOt94T7X3j149Fe08NzkV7v795Nto7uXJVtLf/5fejveVt2effxO7FaK/qvZlo73cq2Z/3nz66NtprGVwd7b1+7INo7733ornKyfGmaO/RjzZEe+tu+mS0N/fsYLS3/qO3RXuzbU9Fe8ev3xLt9b//9WhvS9W2aK9SuT/cA/jw2XHNx6K90eGD0d4dveuivbkXa6K92sbhaO/Z0eyx7b3LxqK95Zdbor3vzJyJ9u6tbIz2aiezP+9UQ1W0t33tpmjveF/2+Tf8G9n/P+3xY6PR3h/+JPv6mLinK9qbWb4y2queOh/t/encdLT3Swey177W9Sz5suWSHG54Jdrb1fqpaK+tdyDaO/znO6K9nSP/LtqrfObj2R7Ah9RrNdlr8weeeTPaW7+mNdp7cDJ7vPxM+F7T5oWRaG/Pg9l7Jbt77oj2Ts5m7/3VtWXv7XYdfz7aG7u8LNq7bSKaq6ztzJ5f1XX1RHuVSqVyz5nsDz3Xmz0nr23M3i/+9G3Z3+Gqgew5zMZfzt4vWblwKNqrHcreH5+u/W+jvf2Xn432tpw+Ge0dvaY72luxIXtNqMQnGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVLvUL/zu4proN66beija6xpojvZu6t0X7T379rvR3qc2b472FhYORHvXVo9Ge13XVEV73z6RfTzGprL/vgOf+lS0d1ftULT39Mzz0V7n1Llo70+ONkV7v7yzLdprODkT7W1e2xDtLdyeff6tWb012jv3xH+K9g6uyj4ej7ReE+21TD0W7W08fDba6xvsj/b+9MXL0d5v/0o0B/ChNLmQPfbpXrU+2vtY60S0987dH4v2dvRdiPZuyZ4aVLqXfxDtvXvNvdHeJ/fUR3utV3ZHewdmHon2VjW/H+01vZw9lqrZMR3ttS3Pvh8cOJV9vxpf3xXtDVc2Rnsrejuiva9NZ/9/wdkPDkV7p2aWfJlxSVbUz0d7G7q3RXvbfvXBaK+u4fZor/OWH0R7Y+9k/30AV4sv1WaPz351b2u0t642+/fx/XPPRnuLNdnjx8aZ7PnL1qbstflzr/5ZtLesuTHaa9h2c7S3rO7WaO94a/b8+Ur3VLT3F2+MRXv7Trwc7VUqlUr7Ddn77ZvWLkZ7e3/u/mhv2fLt0d7J89n3/O2L2ftXfe9mr4HVZJ8uldnOL0d7rReORXuzl7Lvgavvzd6v2zaQvZ9Y4hONAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACiqXeoXrv7hweg3PvLzy6K9e775ZLRXdVt2gzU0vSLa+/3n3ov2blzZFu1dOT8U7d354Ppor+VUS7T3qe2ro71rGmajvcELrdHe5p3z0V7rgapob77tQrR39uKpaG/k5bFo74s7s4/vP5k+FO1dunw+2rtYNRnt3XDDg9He4sKj0V79+JFor3LfUDTX8PKeaG/917N/zwGuBstnpqK9xc7ssWjV+F9He7uyh46V/vGPRHvdTfujvfOvZo99bmvJHlus2PDJaO9Q80vRXu/lF6O9xsMPRXvN/QPR3p7pjdHeQm/2WHlhXfbawx29p6O9uyvXRntvHsiem35iOntuOlZfF+11/c2bo72LZ1ZGe+vu/aVor6fnmmivajT7fn9oflu017h9c7QHcNXYsyWaG5s/Hu3VvJu9Ftwy2B7tdV6YiPYudjVGe2P7L0d7c5uyx2dXTjREe3X1P4n2Oq/Jnh9cCF8v2HhkOtq7uzp7vWVkNvt8rlQqlafezr7mfntj9v7uheevRHs/nvpqtLd5vDPae+mz7dHeLXV7o70ry7PnROPjZ6K90fnsOXlN18lob0P7fdHe4EJXtFfiE40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKpd6hdONS9Ev/GvNs9Fe321XdHe4qUHor3nR//HaK/1THYj1jo8Fu09UlkZ7f3rP7sS7T2+qznaq93dEe3Nb/1UtNd+bUO0t/nYN6K9FX//pmivt/OhaO9b/+Jb0d7NW9uivf/lltujveaFV6K9xf6RaG/jg5+N9pZVXRftXZn4q2hv9q3j0V7dUF+017TvULT33u3Zvx8AV4OFyulo72TtdLS3YfI3or2JqTeivZ13PBXt9Z3MnuvekP3TXZkYOhrtjVe+He1tv3lztHdydsmXPZbkaNMH0d7mXceivYWh7LWC+ssvRHs37skee1cfGoj2pu84Eu0tW1cT7b1ybjba663URXtnvpV9w9qwuCbaW7En+/g+/c/WRnv7fjZ7LnTdhqlo78r0cLQHcLW4cTx7L+Liy/PR3jt79kR7v9iWvba8rjf79+zMc9njs/cnsucbVTXZ8/EVvU3R3sL2xmhvYGo82vvMuu5o74d92ePlketGo70VN+Svpf/qu9n7xUO12d4HB7O98c7t0d7wluwx8zV1Px/tNe7oj/Y6X3gn2mvak71/2tq9M9qbuZh9z6qd2RvtXa6cjfZKfKIRAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEW1S/3C5RcGot+47413o72239wS7f1fP/qn0d5HLrdEe5/53IZor25N9t/X/ydHo73qg+3R3hfPvhPt/czMpWivbVtdtFdd9Y1ob/HcfdHe+Qeqor3xsZXRXs3ejdHeq/P10d4NDYvR3le/WxPt3VV5M9q7cfT1aG/o9K3R3lv7s+8vt64YjPY679gV7fV9e1u091jfiWgP4Gowu5A9tlhWszraqwweiebOVY1Ge6u2DEd7dTuz51ajl+aiveH9/dFe/+R4tNdxNvv4joydj/aWnXg42ut79q1ob/rE96O9ueypRuU7zdlzjar65dHe3Ov7o72Ds2uivQcaW6O9AyPT0d6Woezr7a3W7LW+/X+cPdf4uTvej/ZGqh+K9tpqsn/fOs6tiPYqN2dzAB9WXfND0d5M055o75GT2fO17wzMR3ufWZe9V9L4mWXR3qW+7PnQ0LmuaK9/2US0d92JbK+6sjnam1qRvXe67p63o73tb/dEew3b9kV7lUql0rLz9mhvdCL7nKnr/GK0t7btlmhvZHJvtHdo4HC0N9eRfc/f/JHro72mxezjMTb1arTXfDF7//ncVPb1sXksew5Y4hONAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACiqXeoXPnrL7dFv/FzrQLTX/C9ORnsP1W+P9nY+eCraG78j21vV9wvRXn3rsWjvs1uyP+8PDi1Eeyt+uDHa699xNNq7cOhytHf9z3ZHe7e/ujvau1R3ONp7sjOaq6w52hHttb12Otqrbtof7b1yf3bTuv1i9gE5u7Y/2tu++bpo79vPPR/tffz7x6O9A9e9E+19643paO+r0RrAh9PsyFy097W+H0d727qWfNq5JA0HqqK99oYd0d76XY9Fe69943eivQ0b9kR7je2L0d5TR7PHtpsb5rO9Ddlz08ur6qK9p68JH3u/kH29ddZnj/XmZ0aiveG5tmivfij7/vxMa3O0d64u+/qYXF0T7a098W60d8Njn4v2On4+e6105JUvRHvn93462quqaYr21kZrAB9e901vjfYm7uqK9pZfyL6/37rwRrR34ujFaK9j3Wy0t3FF9vhsemYm2tvfsjrae/ep7PH8tZuy15avdGyI9rord0V7pz4Vvjf0wYVor1KpVOZueC3aq1/2y9He2u4V0V7D7JvR3tz3/3G09/yrk9HeyE3ror3GLZujvZ6uA9He4eyvr9KxMvv6WH5kWbT3zalz0d5vFP67TzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKh2qV94sv9s9BvfdvZMtPft2sVo7+mxw9Fe1wsL0d5Ma3Yj9tijX4n2zrw1G+0dPDEU7X2/rSra6xt6I9rbe+TvR3utfzkU7e1/vSbaqx/JPh6DO7ujvfk3L0d7L83XRXt/srEp2vv1lvFob/jViWhvpK0h2qs+PR/t/aeRI9He7Ez28R15eyTae/7l7PPlVKMNNMB/qZam7N+yz3dlz13G+nqivdMrs+d+ta1ro72jz70Q7e383L3R3ukPsucuq1fsi/bm51ZHexf7fhTtbRs7H+1V7sy+Pj72k8lo70B79li+u3F7tFfVeiLaW/529lz34PbGaK/j1MVob3x39uf9aFu29+YN/yba2/wrd0d7O+Zaor2Bm34r2pudGYj2jm7MnosDXC1W3bYs2jvzg+y15bo1D0R7m27M/rwfjB+I9t6dW/Jt0SVZWDYT7S27Jns89Uhr9t7Li5X6aG9iTfb4oqflpmhvfPpctLd15Zpob/9o9vpNpVKprBnaEu01HPt6tHfqpp3R3txi9n7OwuLPRHt7674d7a2bzb4ndE9kz8lna8eivfr27F7hwqkd0d6hN16P9lrvy15zKXE3DwAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAICiqsXFxcWlfOFrn709+o3X1/RHeyO9G6K9J989Ee3tO1kT7Z2ZG472KpWWaO3gz2c3bDV/MRftjc8MRnvv11dFe7+4Mvt8eW4x+/guLB+N9qbOLYv2tl9zc7T32vFz0d5tu7K9/kvd0V7N8flo75abx6O9kUpHtHfhdPbv0c4bso9H97ey71d/Otwb7a2cfj/a+1LdVLR36OJ0tAfwYTQxeDnauzyTPdarHRmJ9k6/8cfR3pnBi9HelZYlnWIv2fWNm6O9TbfvifYm3sieq1W3HI72amuPRnt1lxaivTcPnIr2nl5sj/YeGcq+Ps72ZM91V9TdEe2da6iN9irT9dHc2fMror2P1vdGe6P76qK97vbstb6uquy/b6RjebTXMzcU7c23ZM/F35jLXut7/KZroz2AD6tTf/71aK+uY1u0N1Cdvde0fHEi2uu78Ey09977R6K9H+3fEe21rv5etNfbfE20d+JM9vzvwt6+aO++ddnjlb2z2eOpk5Xs8U/LdGO0V6lUKqvXZt9jZs9nH+O+uew51shLH0R750bHor3xLdlrGtdM3RftbRrO/v7m9q6L9lp7sq+R46N3RXvXn5qM9o5/PPv7+5kHH/+p/90nGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVLW4uLi4lC9cnBvLfufquWxvbirbq2nI9iqt2dzMZLY31xjNjVbPRHuNF56P9hafORjtVd98b7RXtbk+2pseq4n2ahu6o72qxlPRXnXdlmhvYmx/tDc/sTPaG57JPp9Xdd0c7dXXt0V78zVL+rO1ZIs12b8ftQvz0V5lNPv6nWsI/7zVTdHewtxotFfbtjbaA/gw6hu+HO3Vz4xEew1HLkV7V6YuRHsNW9+M9l4/uBDt9Y51RXvn27K9awbfiPYqM9ljqcPVu6O9dzZPR3u3X6mL9hrOZY+V27ZvivbmawajvddaaqO93TXLor2WkZXR3thE9vXbNJO99nDuvey5fesDq6O9DU8divbOb86e20+vzV7r2z+bvbZ591T22vC1D18f7QF8WI29/1a0tziTfX+fasv2Lp8aiPZWXZc9/jn9ow+ivaGz2fPJt06fi/ZeWcye3699P3ut+ieXsufPy1Zn70W07s7eG7ru9Z5o79nG2WivUqlU7u/NngMeHl0V7d29M7svmOrLPqdnGrLvqX3rs9fUqsey1zSuWX5btLdzXfYaycj6jmiva0X2+Xxif/Ya2J627Dnllo/u+6n/3ScaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBUu9QvXJyvy37nqoVsrroj2qsszmd7NUv+VS+xtxjujUdzrfMj0V5Va3e0N7V5Ntqbrn072ps7czLaOzF2c7S3s+X9aK96zZpob+7SwWjv1MRYtHfsvSeivabZqmiv9a7JaK+9+6Zor6YSfn8eWx7NVTW3RHuLbdnHt7q/Idpb6BqI9qqblkV7AFeD+nffiPamlq+L9ubmTkR7bU07or3BwaZor2N1b7TXWTka7b0+nj23aq/Lntt/48mz0V7VhR9Ee2s6uqK9yfrssfKaBz4W7TVvbIz2pirZY+Xrm+qjvcbpqWjvnbHstZbTE+eivWXt0Vzl8ux70d6eC9lrS0N3b432NtRMRHtP1nVGe49PZa8d9uwNX9sEuEqMV2fPrxp7s/fqakeuRHutK7LXMmcns9cKex7I3iuZObk+2rt/Nnt+1flW9nh58M5T0d66//BctNfUkD2ebxm/L9ob/lxrtPe/rb422qtUKpWalVuivfs3Zp+D4wP90V7b8ew5R+P2jdHefN9wtDc0VBPtte/KnuN3ht/z109fivYunmqL9nq7s+f4lXezz5fKR3/6f/aJRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUVS0uLi7+1/5HAAAAAAAAAAAAH24+0QgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAD4/9q5sxhL08O87+85p07t1VVd3dU9va/Ts3L24XAnRVIUJUehKCmCbSW2ETmJJUQIkBsHuQmQGyOAgVxZsC5kATYECZJhiZJpU6S4DClS5HCbfeuZ3vfuqq6qrv1suQgSODfz0soz7Cb797tt4s/v1Nm+75xnDlBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUDf2o/8NGo/FuHgcAwLtiMBjc7kMAeFetrl6M9oZ6rWivsb4U7XU72WvTta35aG+0eynaW9p8Otqb2n862mtv7Yr2Gv2paG95YTHauzD+I3+M8iM5sXEj2tu6Gv7sZmox2yulTGzORXs3dmcf0wsb0VyZX1uJ9sav3Ir2Goeyz+ED7fuivY2p6WxvIfucWzr9crS3cfhotHdo6Gy0124fiPb2nfhktAdwJ1pfyJ4LNMO/HzBo9aO99vhwtFea2fPv/mr2c8LuoBvtbYxke0NnorkyOvJatPf9q+1o7/Nn1qO9j+47GO0dLZvRXuOe8WivlFJ2T2efw/OXr0R721eynxls3L8a7ZXuzmhu20T29jaHOtFeaY1Ec/1e9jVw0Au/Z7azn5k2e9FcaQ5nPxMaar3z388vGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQNXS7DwAAAIC/vV6vHe01Flaivd7ctmhvY3Mj2pue2BPtda5ORXtTY9n/Pmiwfija63c60V5rNHv/ju8YRHsPDaajvd7O4WhvceKlaG/v0NFor5RSuotz0d6uwUi0t7TxerS3dyF7fLfGtkd7zaHsa/Tg1FK0t+2B7N9v+9pitLe0dTDa235qV7T36o5T0d7j+++J9gDuBo2x0Whv86Xs9Vrn4a1ob6zbiPZGB9ne5q3s3689MxHtDa9lv7bt7M7+/bbW9kV7u9ur0d7IZjfaax/PPn+nOtlz+bXV7PO3lFL6G9nPINp7dkR7G0vZ+2RscTnaG9mbfc4129n7eFCy11eD0o/2mkPZz3BKaUVrjVb4PamZ/fuN9MK/MVT58/lFIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqhm73AQAAAPC3N7JxK9rrdxvRXmm0ormJ5ni0d6sTvr3bJ6K5oZub0V6vsxbt9WcWo71ufy7aG149HO2tnL4Z7W1uvR3t3Wq/Fu1dG5qM9kopZefuTrR3q7Mc7S1PbY/2Xjr5bLT34NpHor2DJ45He1NPrkd7q1dejPYu3GhHewuju6K9iW72NWHHjelo78rsYrS3J1oDuDP1trLn8yubi9He6NK1aO/q2d3R3vh0ttcp2dvbzl4elOZk9npoZno42tvobIv2dh3eEe19clf2XHR0Lft4ubawM9qbGO1Ge6WUsnwr+5p140o/2juxP3ub13ccjvZa4elFezCI9koz22t0l6K9rZI9vnZzJtor/exnnK1u9vORQasX7ZUy8o7/6heNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgaut0HAAAAwN/e1lg72muOj0V7w73haG+jMxLtrfU3o72ZXva/5zl/MHvZPnGjG+21rm6L9ppDr4d709HeoJ09vjPPL0R7Oz/xwWhv8C58bLS6mX3OnR6sRHtXnm9Ee5+553i0d/b630R7ran7or2zC9n7d7yffY2Zm8y+Z369PRHtPfPyc9He4ngn2nvr+/1o7/GHozmAO9Lmt69Fe+OtL0R7rc4vR3uzR6eivU7/ZLQ3fCV7LjBxaDza67cH0V6jvxTtDY/tiPaWe9lzx0fbW9Fe2Za9va2Z7Ocjg4ns5zellNLvZo9x2+Vb0d7ixGi0N93KfkYytBHNlcFm9jOm7sRytDc8lL0eapXs/Vu62fu3F/6IpNnPvic1BtnX1DL8zp/B+kUjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKqGbvcBAHAHaoR7g3APAPh/jbRnor3NzZVob30o+9+3tMeGo725Vvb4Bv1OtHd8kD2+1dmd0d5mL3t7m+3Hor3Gwny2tzuaK5NPfyjaG+71or1W+1K0V0opm0sz0d5480a0t6dsRHtf/dJ0tPfM7APR3vgr2dt7frAW7V1dzb5mHds1Gu39/Ej2Obf+0HuivZlu9vG3c+FMtAdwN1h75YfR3tnlM9HegxduRntjT2bPLXqtg9HexNqFaG8wMh7tlY3s9e7W8K1ob7P/drTXfPN8tLe2byzaaw7fH+2NjWSPr93Nfn5TSikbq9nXrKFd2b/hXLMf7V1ayr4G7hzeivaGt+2K9jqD9Wiv2ZuK9lrt7PXVoNmN9spa9v5tDWVfE3r97PVuq/LvftEIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgKqh230AAO+KRjbXHmR7nWyutMK9fvj2hu+O0g/3AOAn2eXBWrS3vZV9515d6kZ7s1Mr0d5G+Pamz3vajeyJ2Wgn+zHAWC97ZrsVPr4bI7PR3shy9vF3eNelaG9xfizae/NG9vhKKeXpXvY+Pn8q+xp4Y/NUtLfjoUPR3vRj90Z7g+3bo729f30u2ntzYSHaa29/JtqbnB6O9qZ3bYv2Fhe/E+0tjI1GewB3g+7Ws9HezVPZ97KhT2Tfu6++NB/ttcZvRHtnlrPnyye6H4/22uMj0d7Wxs1ob2Ly7Whv87UfRHsbc7ujvfFO9vHXent/tLfa/UK0V0opI9sPRnuDzcPR3tbe7Pn37vGT0V5jbUe099XT2W/Dji1+I9rbeM+BaO/46BPRXpmfjOYas9nroc3WhWiv2ZmK9kp558/U/KIRAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFVDt/sAAEbfhVeizVa219nM9tJ6jWxvKNzr9rPBVnMQ7fX60RwA/FjNboxlg62FaG54fCra6zez5xVjS6vR3vzgcrQ3tbY72utPbUV7vU72RGp080q0N9eYjPY2h9aivd7qYrRXXn47mjs+cn+0V0op1yayrzGbx05Gey9865Vo7327r0V7P2hPRHvP3MxePI9+ZH+0d6KxM9ob3cq+h3Q7b0R77eF90d5cM/uBy3RzJNoDuBtsn7g32tv78weivYu7l6K9qe8OR3vbH8+ej27r9aK9xj03or2tre3RXrv1bLS3MZ891zt18yvR3sQf3Iz2Jh/+QLTXP/ib0V5r81eivVJK6SycjvYaT3WivbFW9jONQf+eaK+MZl9TH53tRntXmtnX6I3N7JenK/NvRntL5VK0t6v30WivfyF7vdacHY32qv9/P9b/NwAAAAAAAAAA4CeSoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVA3d7gMAfgzSk8J+NtfsZXullDLo5pt3tEEjmusOBtFeKdneu/CQAYCfWI3WlWhv61T2ZG9i385ob3VkKdrbWs2eR402d0R7G80z0d7oxqVor3V9NNpb2r4Q7TWG2tFeq7Sivfn5G9HerXvfjPamv3Eq2iullNFHs8+Rzo2Xor3HH81ebQyuZV+jd7751WjvwtxktDeyPhPt9d+ajfbGjk5FeyvhD0hGpg5Ee8PDE9FeoxX+QAjgbnBrLJpbe/Gb2d5ffS3am3viiWjv9fNHo73jIx+P9oZnL0Z763/9r6O9M89tRnu7Pr4c7e3fcSLaG25+P9rbuvj1aK/XPBvtje/7zWivlFL6zZvRXuta9jOI7uEj0V7rSvb2ltn3RnPbx7OfQWwbbIv2OuE/X2/mXLS3uxOewjSz7+ntXdnrq97Ij/fbU79oBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAEDV0O0+AODHoH+7D+CdrQ3yzUa4N2iFg71wr7wLf8Q72R3+mAaAH6duezbaG30gmisr60vR3vjKSLR3s5k9jxoZWo72uovZM9vVyf3R3nArfP92Hon2Oss3or2l+R3R3qXXz0Z7o2svRHvzc/nrjIlTu6K9I42D0d6Va9nbPDWX/W/8ZmaPRHuD8bFo71vf+XfR3on2fxntdS9ORnu79mXvj+XRrWhvZvR4tLfaTX/aAvDT79rBdrS36/Cr0d6ObZ+N9rqtbdHefe3suePN2WvRXvfZb0V7z89lz1Xe+8hr0d7N17LXQ3O7Tkd7gyufjPbWJ78S7X3nD96I9p5+8g+jvVJKGX9yb7TXvJmdImzduBztlX0r2d7816O5fmc82mvs++Vo7+Z49jO63/397HPktx4Zjvbmnsl+5tfpZ78sfjt7eOU9Y1Pv+O9+0QgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAqqHbfQDAT55GeKI46Gd7pZQySAd76eAdrhHuxe8QAOD/MTy4Fe31+9nLxKnh6WhvaLQV7R0c/m60t/n9N6O97uzlaG9qbW+012ltj/aGV96K9havzkZ7pSxGa63OQrS3spZ9vu24cSHaK6WUiYefiPY218ejvRvjz0V7a/NHo71zb/1+tHd0x29Ge8/s/PvR3urYN6O9oZlfi/bKgdVobuT6VLQ3uDES7fX616K9sj+bA7gTjR86Eu1t7PntaG9lKnt881ez51L3n/l8tDc+/qFor3NkJtp779t/FO01br4e7bVbH4/2Bt2taK956Eq0130ue+5zfCx7vdacORvtlVLKzZX3RHv33H8x2rvx2ny0N7jcifY2Z1+M9maezV6TT382+5las4xGe//w4MvR3s3PZT9zeXV6ONp7+tIno70D+y5Fe2X3Pe/4z37RCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAICqodt9AMCPQSO7KRyN1krZKP1wsZRBoxEODrK9O91ddnMB4CfZ1vIXo732zK9me83suWi/83q01xhajvaau29EezfPdqO9paHs8a1vHIj2du9fj/YuXXw12vvh+HejvblzE9He1p6D0d73Jg9He6WUcmz5bLQ3uXQ42utc3BPtbd73RrQ30hyO9i53TkV7O9eznxhcXf1QtHet9WK097G1+6K9rUb2YnxsKvuaPz1Yi/YA7gbd8WPRXmftdLTXP3su2ttxPHu9ttT7frS3sHol2ht9czPa6+29Fe1denFvtHdw8gfR3vrobLT3Sq8V7a0sZO+PmQd/Ntrr73k82iullP7889HexOvhv+HkXLRXeuejucZGL9r74b5D0d6+7/15tNcZ++Vo79TOF6K9ziMnor37GtnXmMa9/y7aW1vNfoY4U554x3/3i0YAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVA3d7gMA3n3DjUG0t95oRXvNkezxlVLKYDPfTGqEe3f2rQUA3k2DkblscK0fzW31zmZ73ZVoryy8Gs1d/uaXo73VG/dFe6MfeTDaG9u/Ee1dee0H0V5j96PR3rHVr0V7146tR3vl2mw093PDV6K9UkpZGe5Ee4OjN6K9se2no70LjZ+J9j700ivR3q33rEZ72xcmor1vXfpStPfo2exjujO1Ge2d72V7/TIf7d1z6KloD+Bu8Jd//U+jvac+80+ivV3LL0V7Cy9kryf3Dmffe3atHo/2Rvqnor2N0ey51IH3DUd7V77ytWjvzHfHo73Nx7Kfj4x+8H+O9t4YzT5eHrj5fLRXSinj17KPwRd27I72nt79/mivf2BvtHflL7LXV/un/izaW1zNXm9snfmTaO/YPfdEe9cenIn2Dkx0o73+xM5ob+jmrWivxi8aAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFA1dLsPgDtEI9wbhHvpSVw/3LvD/4CD8B+wVdrRXn+rF+2VUuKPmZF+NriZfxACAHepxvzFaG9l4aVob/je70Z7my8/Gu2d7Z2J9n4wlj1vnDvwZrT32Ph/Fe1dOPflaG/98iPR3rEPbEV72zZ+Ltq7cfKvor3992Zv7/De+6O9Uko5culStHdq+UK0t2ske5sfbGSP79Lc9WhvbXlPtHdm161o776tc9Fec3Ek2lt5/WS0N73rSLS3MXI52ruyvhTtTUVrAHemDz/xD6K9pbPZ642r5Wa0N7q4EO2tz2Tfu2ce/kG011l6Mtrbtu1no73TU1eivZNbfxztXbw+Ge19/MPbor29S09Fe43x7OcZQ2PZc7NSSukdeD3au++hfdFed/RqtDfUezraG3ki+xhsvxX+vvjwSrR3z0eno73X1m9Ee5NXs5+RbM5lX7Na09mpzpnr3WhvrvLvftEIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgKqh230A3CEajWyvlc01m9nj62/1o71SHojWGq1Xo71eL3t7h5ob0V5/JJr7v22Gc43s37ARnnkOBtle+OaW8OEBAP+J3ttHo72Ve/ZEe1OLPxftre79brS3/q290d7sye9Ee1cOTkZ75z7/e9HepbPno71Dn/ilaG/hC1+N9q4/MBHtnXjsl6K9sue5aK61/Ei0V0opvdZitLd9bX+01906F+2129PR3uSHPxvtbbZ3R3vbznwj2jt031y09+r17HP4G8sHor2PHrse7Y1vfybaa/e60R7A3eDiRvaD6uPNC9HeizevRnv33dgV7Z3v3xPtXfjWH0V7xz6SPRddeeGNaO/8269He2Orj0V7H2tmz0XfePaxaG/00F9Ee7snO9HeYOR/ifZKKWXjUvYzjfXPfTHaG/zjp6O99uXsZ0y9rceivbPvWYv2Dt78H6K9y9e/Fu2dns/eH+MXPhPtXd3MPocPNdrR3mD2wWivxi8aAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFA1dLsPgDtDazCI9sK50t/KBhvRWimlvJHN9bK5fsn+/cJ3RymdcK+UEr7JpR1+1HTCT5Khfvb4uuk/IADwrlmdGon2diy1o73r96xHe61Tq9Hejp3L0d7xnbuivS8sZu/fb3wpe3sfOngg2uuu/5tob/Ijh7K9rWvR3nQ3e/G3rf1QtNeeuxTtlVLK6sK+aG/Q/vNo70pjT7TXGbsQ7Y2v9aO9I9uuRHv98mC098K156O96b3Hor2RG29Fe53z2des85M7or39jY1oD+BucOzsl6O9rQPZ87P3DZ+I9tZn/yTaWy7vjfZ2fv9otPfm//l/RHv9J7Jf256ZzJ7rTV8bi/Zem82emx3v/cto7+YPs8+3167sjvY+MPob0V4ppbzyw+xnBlc72d88ufj7e6O9mQe+Gu11ZmaivY/9cDja++byF6O9b72+GO29r5n9wvjq+78X7T2y45PR3rUXs68x931kW7RX4xeNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgaut0HwN9OI9zrhXv5YNYgXrzDb3BYo5XdKLb6/WivlFJ6Y61or9PNPmqa3ezLb7d0or249ItW/kkMAD+xrsx/LxvcsRXNzXTmo73WwUPR3vDid6K9FxaPRnu/+FD2/uhv+8Vo7/mVhWhv2/BItDfVfTPaW1k9Fe1N7v9itDc28lvRXn8ie3+UUsr4kZvR3nznSLS33j4f7Y3eOhbt9W5civY2ylS0d2llX7TXnD0Y7Y299Ea0t340e/+ujO+N9vZsdqO9uf61aA/gbnB+8+vR3sS17Gv7tW+uRnvL+4ajvQfuy56bPfv17PXz4U72fHliMfvdy8HuWrQ32sh+MH/v8R9Ee90PfSTaG38p+/crJXsu+icnx6O9Ukp59L3Z79bGp38m2rt/KXs9ed+LG9He55ZuRHvPfyB7f3z3a/8+2rv03k9He/+sXIz2/t6fjUZ7v/Rri9He2SeyX57Of+tfR3t7Pvvxd/x3v2gEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQNXQ7T6Au8WucG+h0Yj2uoNBtJfWCk/imv1sr5PN3fEag+wfcPJdmDwubvaywfBjpp8O3unu7JcYAPiJNrqZPa/o9M5Fe43LR6K9ifHlaK/x9fdEe0OLL0R7/YMPRXsXT7SivSM7VqO97vQD0d75m3uivT3bp6O9Xjf7+Ov0X4/2xrbGo71SStlsL0Z7vUsr0d6JjW3R3snuhWhvcurFaG/b6D+J9oYuvhTt7R5ai/ZeGZmI9j4xOhPtbTazn/ft2jYS7f31i8PR3mcej+YA7khn//BStHfPY9lvm+ZmzkZ7nSvZc7Pnf7gY7V3/aPZ7gweujkZ7Z5rtaG+2lX28HP8HO6K9K19/O9pb29we7d2/7x9Fe0dunYz22kN/Hu2VUsq3b/3X0d7W+ka0t/7Wl6O9Z7e2or35bd+K9torPx/tTTz5SLT3sSf2R3v7X/2VaO/jj2Y/A9vamZ3W7PwXC9He13vZ9+CHP/vO/+4XjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoGrrdB3DHamRzK+FJ10yzHe3d6GxFe2m9frjXyN4ho63sAbZ60VxZDz+epyZa0d5WZzraK6WU5vrNaC/8ECylDKK10dFornTDN7gbfokJP6TD94bjA+DHa24ue262Pj8c7XUPjUV7/cvZy9hvDF6M9mYPZd9p5zevRXv7Dt8T7bW7B6O9Wxe/HO1NzO2N9vrXvh/tvfzNq9He0M5j0d6DrezrQSmlLLWyrwnru49He68t/k20971nF6O9T49ui/ZWGmeivZI9vHLu3I1o797ZB6O9S2++EO3tGc9ejPemPxDtHdu+Hu0B3A2OfPypaO/ymy9He6eGt0d7Z763Fu09enAh2vvsnv892ms+eC7a2/vMB6O9XdvfH+2tbv1FtFdO/Vk0d+9C9ouI0adei/YWfy97PTmzmb0WKqWU7V9/I9q7OJq9zVub2S9QP/GZR6O9Z38nez157VPz0d5v3vuZaO/c9dejvXs2fjnaaz+Rfc1aOnMq2vvcxPVo78jJ7P1R4xeNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgaut0HcMcaZHNrveymq9FqZHuNVrRXSi9aG4TvjzLoR3Mb3WiuZO/dvJWV7B0yNFiI9koppZV+dQvfx+Pj2d7meraXnqE2wy8xjfCTpBe+f4fCf79O9iUr/RYXf9FqxA8Q4KfbyuRD0d7G8vlob3dnPto7tXQq2mvumYz2zs0vRXtzR/dHe1s3Xon2Fmd3RHvTex6L9nprL0d7S6tT0d6hPZvRXuksR3PnSvj4SilzczujvQtvXIn2zox8JNr71cdPRnsTL2UfgytPZy9O91/bHu2NT7wa7b12Nfuaf2om++HDtqHsa9byudlor310MdoDuBvsnng42ru+dizaO73wzWhvfH4i2ltYzL6Xfe3C70R7k/9N9vrvYy9mz+dPn3gu2vv86dejvQ9sz57rXXo+e3zNv9qI9tpz74v2XupdivZKKeXCUPYzl1dWPxDt/fwvvjfamxjLvsY8cGw12vvT156P9oaGPxbtlVvPRnMbt7L7gpeWsq+Bn5wcjfZOjE5He6f2PRnt1fhFIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqGoPBYPAj/Q8bjXf7WH66hf986fuj8aM9DH5k4VwJ57jDvBuvLo3JbK/VzR5lbzP7qB4fjubKSPhO+UAr2/v8WraXfhCONLI3eL3Xi/bS0s/h9Aq6m35TArjDPPtHvxvtdUey72OHjxyI9n6wshrtjbz83Whv53j2fXv7ifFo74XL2RPlh++bivbajQ9Gewsvfifae3P9fLS3Z3w22nvxpW9He8f756K9Ukp5efYT0d5693vR3s5du6K9QW97tHd45J5o757O5WhvbSH7mjr60IPR3uryVrTXmPyZaG9keSzaO7R9Pdobvjf7mrX32C9GewB3oj/6nX8W7Q2NfyHam178cLT3u//8X0V7x49nrzfmTy5Hey/sXIj29vf60d6hndkvDtbfkz0X/Y0fdKO9f7OV/eJgdP5WtPfcIHt9v+Pe7POjlFIeLQ9He4N9J6O9kVuPRXs7nsjeJ+V09hp6fXs72ls6NR3t3Wz/ZbS33Ho02nt8/a1o7+GHHoj2NpavRntXPtyJ9v7hr7zxjv/uF40AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqBq63QdwtxgJ9xqDQbQXzpWtbK60wr1BIx3M5vrZXEnf3OFwsJPNlVJKGVnN9tKP6anwg3p5M9t7YDjbe6E3Hu0daK9Fe+fDd/BWsxft3eEvWXHp2wvw0274Pe1ob3Jtf7S3/ua3o733P/ixaK/3zKeivY2Z7InUUutKtHd8e/bxMh4+U762dD3aO79jd7R3z8qD0V5r+8vR3qHFg9He2MyuaK+UUrqz+7K9jbFor3kj+9/kPf7k+6O93pv/Mdpbe+yBaO9A5zejvanRm9Heency2js5fzHaOzCbvdbdvjP7mtBrhj9sAbgLPLf1bLT3yQP/RbQ38e3fifaOTmTfay8Osh98j5y4P9o7+tL3or1XmuvR3v7V7BcR7bX5aO/16ez1xskrV6O9xxrZT6r3TGS//Xv7+kq0V0op9//z/y7a+4VLb0d7J/Zeiva++OKFaG/XR2eivbML2fPvtb98Pdobm81eT45+6ES094dnXoz29ryY/ft9vJv97nTQ3RPtlV9553/2i0YAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVA3d7gO4W2wObvcR/Hg1wxO24fDfb33QiPYajfAB3uGPl63w8Y1mc6WUUtbDvUYre6O74ZffRqMb7f1gK5orQ421aK+TfsplXxJKq5/tTWZzZTnc2x/unQ/3AH7azU0ci/YWu5vR3shTfz/am+5mLzZaO7Jv3Fud69HevuHs7V3uz0V7t9azZ/MnDmV70+vZE9uZ0Xa0N9T5SLS3duL90d7QyHi0V0opD3Znor3rC9+L9g48fW+0NzSxJ9prHrs/2hus9KK97nr2bL6xtjPaK2OdaG73/M1ob2TbA9He6f2Xo72Dp78f7ZUjn8j2AO5AH968L9r74h9+M9rbdyn7WvyzD56O9pqvZt97Xrg/e7022jgU7X2jlf37fWOzFe1dO5f9YP673ey549x49va+cWsj2ms2s9eTh8fz364d+b2/ifbeevRCtDe6ZyzaGx/KfvvyL/787Whv7+ls77XF7HeJR1eyn6ltfv6taK+190i0NzuavX7uz2ZfE2Y/mL2erPGLRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUDd3uA7hbpBdd/XAvrR8+wPVsrjTKINobZHNx8cMLP6DX34UHdCPca/ayvV4je680wq/m/U62txl+EDYa2Xu4mX6WTGRzuzayvaXw4/l8NgfAf6ap81PR3uTRh6O98bX5aG/tyg+jveFdu6K9sakD0V6/ZHvNxmK0N9NpR3u9wVK0t3t8LtrrNLK3d9DKnuh1SvZEb3J1IdorpZSNkewV/tzU49Fea6QV7bUH2ft4fi3bG7z5ZrQ3tPlytLft0MejvdIZjuYOPX0r2hvauhnttS9mX1OHR49HewB3g5G3su/dE6+ei/Ze33Y92rvnlex7bXs9e/79vR9cjvaGd49Ee50bo9HelV72/piezn6ZMzSTvX+fvJR9vp3pZ794eeHiZrQ3teNEtFdKKe3hfdHe6tJktPf8t/802rtwOfvd0Oa3zkR7f7y0HO09uWM82jvTyL5mlUvZx9/f+cRT0d4DvW3R3kOfDT/+1majvRq/aAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABA1dDtPoC7Rf92HwD/H4PSiPaGWlPRXre3HO3F/QQ8oAfhXvomN0ov2ut3orn43+9nh7PPuXNj2SO8uBLNle5qtrcv++crF8O99WyuDNIPQICfcuP3T0d7zaHNaG99tBXttQdPR3vl2jejucbe+6O9/q3sid7Yyky0N5hYiPa6nfCJVG82mpvati3aW10di/bGprNnZitnb0V7pZQytPN6tNdoZu/jjQvZv+Fg6Hy0d/HqUrRXVt6M5g6V7GtCp78R7Y0OvxLtdTaPRnvNW29He9ffvBTtfeXmjWjvt9/7a9EewJ2os3Q62hvfyp4LLJataO/a7uPR3qcf+HS09+1e9npj9BuvRnuHNi5Geydba9HeifftjPbGzmY/L2gdzn4+cmphPtrbs5E9t13duhrtlVJK97H/EO31Xu1Ge1eez35/uv+TR6K9+x65Ge1dOJj9TOj6i+Hn8OyeaG/0avbv13gx+/i7/HMno70v/8vs4/mxax+M9h74uXf+d79oBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAEDV0O0+ALgdGo1BtNfvr0Z7zTIW7fXLerR3N8o+YkpZTwfvcF/uZG/wPVvRXPwZ0g/3vhZ+vLRb2d6gl+0B8J9n0O1Ge71zV6K9xuj+aK81cSvaW+k/HO2119+K9nqD49He/NCZaG964Xq0t9W8EO2lnx+Nci3au3Xu7Whvo5M9MXvuja9Ee6WU8tiJ34j25pp/HO0tXlmL9vrL2dfUQX93tDd66NVo7wvzC9HeR7c60d7I/g9He6dvZq/+Jr97Jtp7sfW5aG/y2qPRHsDdoFWmo72Le56K9n7rUyvRXvPNkWjv3Gb2fHT4xgejvff+t0ejvev/ajna27nWjvZee24p2jvczH5N/Z73fzTa653PfhExOZS93v3S3LFor5RSllefjvZODv5DtPfa3/t0tPepje9GezuPPxjt3XdzPtqbGj8b7U0PZ99Ddn/qk9HeC09lr/+2ffF/jfYaX9iM9r75ZPY9+B9V/t0vGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQNXS7DwBuh8Eg3Cu9bLCsh3v8/9W4w4Ppx3T69vbDx3cpm7vrdNIvWQDcVs3BcLQ32JF9424M+tFefz37RjbT3Bvt9VcXo731W1+L9qZmstcaqxs7or322ki0d23yP0Z7k1+ZjPZePv9StHdp9nK0d+jcTLRXSinnh/402nvr7aVob/voVrS3dW062js9cjrae7x9K9r72NCnor2N1W3R3rbBaLR378zFaO/i4Y1ob/+NX432uo/cjPYA7gZP/N1fifYmTp2L9p7rbUZ7j/xM9nqt+2d7or3xN/5ttPd7b78/2ntiMnt93x2MRXuXl7O/X3FqeD7a+6df+nK0t28ke3vHnsye2x59/vvRXiml3Hjxb6K9v1pajPYaz74Q7f3JTPYaf3ohe7689OB4tPfJcm+098alC9He1q7nor0znYVor9nPfob4vseyU51tTz8U7dX4RSMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqgyNAAAAAAAAAACAKkMjAAAAAAAAAACgytAIAAAAAAAAAACoMjQCAAAAAAAAAACqDI0AAAAAAAAAAIAqQyMAAAAAAAAAAKDK0AgAAAAAAAAAAKgyNAIAAAAAAAAAAKoMjQAAAAAAAAAAgCpDIwAAAAAAAAAAoMrQCAAAAAAAAAAAqDI0AgAAAAAAAAAAqoZu9wEA/CQYNNLBcC/sDj88AOA/MdQYifZ6na1or7uR7a1d+Va0t+vhT0d7W9eWo73m9fFob9Cfi/a6k9kzx9GrX432Ft6O5srq4R3RXuPoz0R7T33uQrTXOnw92iullK3erWjvwtxj0d7DD7SjvTcvvxXtPbU+G+2d6RyO9ianbkZ7O9/7WLQ33N8b7fVGt0d7u6ayz49LXzke7T2x7aVoD+BuMNZZivZmhiejvV9/5gPR3rdXXo32Hv/vs9cb3b/4u9Fe82tfj/YGs49He9t/IfvFxq9fzfb+5sXz0d7qIPt8u9ZdjfY+9cX1aO/3t3WjvVJKuXejH+1tNLKfaTyzqxPtzSw/Ee199Ldnor2Xn1+L9rb/QnYa8utfy74mvHbf5Wjvf3rhZLR37bNj0d7Xzh6J9v7O2rVor8YvGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQ1RgMBoMf6X/YaLzbxwIAEPcjnuoA/MS68dor0d7a+Hq0N7Xy9WhvfeFQtLf9eLbXaE5He5uDC9Fe8/xQtLfZuh7t3RrL3t7h63uivbPttWjv4MRUtNfbyH52M1yuRHullDIYPhrtDe8+Eu1tvpZ9TG8ObkR7S1euRXtDk9lz5aFjw9He7okHo71OJ/uc614/F+0trt+K9q6Or0Z725dnor3HP/2ZaA/gTnT5S9nrtal7s++1zbFt0d7K9bPRXnM+ey7VO7I32ru88JVor/HN7dHeqdmNaG90rB3tfWftYLQ3+u//INp7uXcz2tt+eC7a65/cHe2VUsojz0xEe82N2Whv6Ons+e3cy51o70L7kWjvvke70d7smdPR3tmt89He+OGT0d7RsfuivctXl6K9+Wb2+H54JfuZ5P/2P/7jd/x3v2gEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABUGRoBAAAAAAAAAABVhkYAAAAAAAAAAECVoREAAAAAAAAAAFBlaAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQFVjMBgMbvdBAAAAAAAAAAAAdza/aAQAAAAAAAAAAFQZGgEAAAAAAAAAAFWGRgAAAAAAAAAAQJWhEQAAAAAAAAAAUGVoBAAAAAAAAAAAVBkaAQAAAAAAAAAAVYZGAAAAAAAAAABAlaERAAAAAAAAAABQZWgEAAAAAAAAAABU/V+4zC/+DeCZdwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Crispy Chicken\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Donut\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Fries\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACRoAAATkCAYAAAAJ0C4xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbB0lEQVR4nOzcZ5jdd2Hm/f/0Phr1bsmSrGq5d7BxBWJaIIEAgRACm7IkZEnIZlM2SzY9YZNNyJJsgGzCLh0HQjGmGBfc5IJtuciSJavX0WhG0/t5Xjzv+c1zXfez6730+bz1XN8ZzTlzzr/cPnW1Wq1WAQAAAAAAAAAA/Aj1/6d/AAAAAAAAAAAA4OXP0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgqHGuX3j98mui33h8/tFor6+2PNr7ubVviva+Pf6taO/GzduivbqN74z2bnzF2mhvzdKeaG/+0uZorzY6Gu0Nna5Fe031bdHeg/3Hor368Yejvcm+7M93xfabor3ekeeivYnqdLQ3vHxFtLdhb0+09+Lde6O9pw7/S7S347ns68Hgi/uivfahsWhvqLMu2lu2LLuB/srOkWgP4OVoYvWyaK/59nnR3qlb3xLtLTmc/fmqFTujudmndkV7M399PNqrtTVEe9/dlH3vvm0oe2zRtCx7blB3UWe0V3vTz0d7M2++O9qrLemO9upuPi/aq3/s6WivWpH9e6u/N3suXrtlONobX/aL0d6hI1+M9tY8lH09GJ08Fe21bJ+J9up2XxTtjbc+E+01vOJD0V7PFz4S7QG8XPWNz0Z7df3Zewdti7Pvt41T0Vw1NpX991b109HcbFNTtNcc/v21ZA9Hq9pM9vky05B9fLNnu1VVX5f991bhp3P6x/t/o9kfspZ9CaxmZ7LH4FO17GtC3Xj2/vNULfsgN7dmX2ROv5S9Xze+pCPa6+wfivYGjzwZ7Q3szV6TXLQge43p/J/Y+CP/u080AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCoca5fOL5xVfQbD41si/auHDkW7e0ZuSPa+8WrfzPa2/f8PdHeyPC/Znvnvyva+2HHZLR3Y+uiaK+1rSPaW7a4LtobG5yO9lZ1ZzeKo+svjvY2PN0d7fU2Zh+PhdPnRXv1DRujvaNj2efz1PJD0d7SNx6P9to/mX2+LJ7oi/b2tjdFew0N49Heq6p50d7+yeFoD+BcMNkyGO01PDvn08Q56W4K//8tP3ZTNDfzqb+L9uqXXBTtjV+zJNo79viOaO+W57PHUmc2fizaW9qT7Z35ieeivc7pbK/+1uZo76W7H4j2Ov5X9tzq2dn3RXuv2PjFaG/mE13R3rx7L4z2/ufDfxXtvfWmt0d7UzsWRnsjzdlraa2X9kd7vcfeGe2tOhPNVfUvrs4GAc4R86rZaO9Y9u2xmjqQ/flq3Wejvb6u7PHtojPZ3kT//mivvrMz2mvsWRDt9bRlz+/HprP3/joaW6K9ulo0V9XXssHx8OtLVVVV82j2Z5yuy/6MY+H7G00HJ6K9/pbs72+ooTXam/f4iWjvWydeiPaWf+tktPfH2x6L9tY+lv39PXLktmjv5352KNr7ncJ/94lGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1zvULx4aPRL/x1Mzj0d4Tjc3R3rvqb4j2Hl8xHu2d2Z3trX/Dlmhvzer50d4FK7ujvYbObG90airaa2jtj/Ym6tujvcaz0Vy188y+aK9x6HS0t7GhM9prOHkw2tv/2GC013btJdFex8U90V7P8MZo7/kLuqK9s5Ot0d7lddnXgx/cn30+n6nPvv61NmZ/PoBzwa5Ts9HethOT0V7rr2bP1Wq7H4v2quebornB2vnRXu9TX472uiayxz7Vvx2J5rrv/3a0N33dymiv9bk90d7Mouy5/fjJndHe8vrs68sn6nuivXf1/FO01/pA9lpG7fvZ3uT4k9HezyxuifYaZuZFe43rtkd7na9eG+1VU9+L5ha33B/t1d1+cbQ31T8a7bVUb4j2AF6u9teFg3v7orm6B7LnBwMbs//g+gXZ843DA9neyd0nor2zx5ZEexfckD3e67gke+32WFP259swOx3tVbNzvo0+J9N12fOr3pnwzbqqqlqHsz/jxET2ftiup4ajvRW7Ho72lr/6VdHeePepaO+ru74T7R24P/t47DszFO39ySXZ5/P7jm6O9lYvuSPa6x27Jtor8YlGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1zvULu/r2RL/x6sWror0t1fnRXu/y1mhvzQsd0d6rL7k52lsxdiLa27Bmzk+tOWlqaIv2piZ7o72mwclor/7UULQ3b/G3sr1jP4j2Jsevivb6mweivX/Ydyba23pmOtrbc8HqaO+281uivZ6xqWjv9NnmaO/a1vuivc8szz6+1x9ZGO2tWnA42nt66fxo76W9Z6M9gHPB+qnse890+7+J9p77+CejvU3XZ/9/mfo/XxHt9X74U9Hevx2eifZeW3d5tNf86aXR3jVLOqO9zfMWRHunpy6O9urnZY+luv/NR6K9ybuz14Jqz94d7dW/ciLaq7si+3x53zPPRnu/8anRaK9uuCnau+DTX4726t44EO3Ndm2I9sb/LnstrW559tph3Y4vRHtNjR+K9gDOFV07s8crD9Vn75WsvWUk2nvkrt3RXl/9smjvVcey93Keb8n+/pavOxTtbV6UvRfb1B7NVe11tWhvdjh7faTqzp6PTwxle4t3Zu/FVlVVHd86HO0NvpS937ny8sejvUWr10R74133Rntrl2bvn75z49ujvd6uz0V7zzyVvSbUdetror0vXHVPtLe8+u1or3F5di9T4hONAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAAChqnOsXDvTcEP3Gr1nbFe2t2Lkv2vunib5ob/uxlmive0s0Vy294aejvdrkdLQ3OX4o2qua6qK5+saD0V5v+wvRXuPeC6K99pbs8+Xy1u9He03L5/zSNidvOnss2vvGdFu099abNkR7tZkXs73mjdFeQ0NrtDe/dSzaO7VzT7T3UE97tPd8X/b9qHlsNNqrZrOvzwDnghcma9Fef9tL0V7D7I3R3vzHb4r2+vc9Ee2Nnnku2ttblz1WWdXwaLQ3W2Wff185nT22XX7nFdHeO7asjPaG/ukb0d6O35mJ9i5rzJ6rvbs7+/N1/uTPRXsNq/4g2vvE0D9He8tGs70/md0V7S2oBqO9+cPj0d7E7r/K9la9I9o7fOYz0d7m+uy1kYnb74v2FlXvifYAXq4ONExFe6sPnoz25tc6or1Xv7I52mufXRLt9XRHc9Xw9PJo78aF2Wu3M1X2+VdXn/35lk9lzw+eOjYc7W28J3tvqP367N/b0LKj0V5VVdXU089He5tWTEZ7o0deHe1NN+yI9jpPD0R7Q/0/iPaONGfvT3bPXBTtXdv6SLQ3ujC7V+g6dmu0NzO+Nto7Wz8b7S0u3N71iUYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFDXO9Qvfs3Yo+o2vfsfV0d6/djZEe2P7ZqK969/aHe29uPLRaK/nhx+P9rqvf3e0l17ETR/cF+3NjuyP9nof64v2vn/f30Z7o+tmo70rP3httHdR58Zob//UcLQ3tmx+tDd96Fi0d2ywK9obXXtXtPflz2b/fq8bekW09w8b5vzWOiffmToc7Y2OR3PVwYmJaK+x0QYa4P+rsa7sa+fVW2+N9p5Z/EK013VkT7T3kSe2R3uvueD90d63dmePHVcsezLam12ePXeeeer70d5Hn8xey/jGdxZGe9fevjja++Bj74n2Zu7Nngs9MZm9dnPhf7km2lv6hyeivd6WK6O9Bzdk/37Xvu9D0V7z378Y7dUaN0d7w0/9WbT301vOj/b+bm9LtDc+sSraW/jkw9EewLli44LstcIjQ9n3i5HWaK7qrl8f7bUuzV57rJ3IXhy9rCt7fHtwqinaW9AZzVXt09PRXm02e76xvnkw2vva1/4i2rt+96Jo79Gt4T/gqqpur7Ln+I9/+0vR3iVvzz5numuvjvbGHn4s2jvyzJlob6J/LNqrPXQk2mv8rbdEe0vr1kR7tZXZa5Ijs9n7uwtbs//eEnfzAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAAChqnOsXPrvmaPQbH/9SU7TXs+yCaO/Pfmcm2mt99ulo78aJRdHewa6Xor3xgeFor6G+I9tb8Vy0N733dLT39X3fjfYWd0xFe30LJqO91f90b7R3/CcWRnvrzvxitPfr5w9Ee7PLN0V7Q0c+Ee09sbM32rvtrduiveHHz0R7dfdn/z6u2LI12tv+3t3R3l9+bTba23/oULQHcC5on39dtDf/16+J9j5z50S0d+eD2XOXP7jmnmivc0P2/+fp/+110d6h7o9Ee0e/8UvR3qY7ssei938sfC704K9Fe3vWZ881hq74aLS39GeHor3t9/14tLdn61eivf96z/ujvb9c8Z1or3rzb0Zzo+vvj/Ya/nJttFc72hrtPd3xh9HeF7/ypmhv3me/Ge2Nve5wtDdxWfZaZFu0BvDyNVXXHO21NXVFe92j49Fey6aWaO9k355ob/4DY9HekS2Lo701a09Fe131F0Z7M7PZa99jR7P3nk/suCPaO7Yxey+7v25VtHfDkuzzr6qq6uvfPRjtbbjm56K94f4V0d5s3f5o797xndHeNbvnRXtPLxmN9rp/amW0t2hkINqr+qejuaa1l0d7Z/oHor227r5ob37V+SP/u080AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCoca5f2LZvQ/QbX3vh7mjvxPcejfaGlr4y2uu65TXR3tCZR6K94Ya2aG+67w+jvZbp66K9hrGLor2Z0W9Ee9ddOx7tfekL2U3hW3a1RHs/ONIb7W1o/W6013rjkWiv59SN0V53d0+01za/O9p7/UT2+Td2/nnRXm3N5mjv6Hj2/a1/4nS0NzU+Eu3VVYPR3qJoDeDccMW73hXt1e1rj/Z+7/h90d4/tE1Ge3s7xqK9LaveHe3VH/vLaO/X9zwY7b3tF9ZGe7eNn4r2dr3+T6O9r/xt9u/jQ39yd7TXO7wm2qvv2B7t3XfiI9HeyOenor2rnmqI9mYXvifam/qp0Wjv6x8YivZ+YmhJtFctXh3NXb/0RLRX7T8QzdXfNxvtdb77gmivel32+QxwrmhfNufbcHPSsDB7vDI52hTt1Y1kj1daTzwV7X28b1+0N+/e10V7Cy7P3nvpuD577bY2kv35JgeHo73B1eujvVuHs/fqFqzM3ms/8tkvRHtVVVXN2xdEe4vH3xjtze6I5qrGi/dHe11fz14zOPFk9pytescL0dzU1Kpo78w31kZ7yy/rjPZmTj8V7S05ekm0V791YbRX/H7/W78bAAAAAAAAAADwfyVDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoapzrFz4wel70G9/Sdyba+/arfiPa+40ndkd7Qy190d54/3eivS1vmxftNbfdEu3V9maffzP9n4n2Tk50RXubjr4u2vvoTz8Z7Z0eGor2Fj63MtprWNwS7bX+8GC0d2jtv0Z7TY8ORHvPde6L9m6tbo72lk6cjfYmOrOvfw9c1hTtTXxiONpbeuml0V5L433R3oqW7OMBcC4YaPjJaK/2/X8f7T327e9Ge0eWjER7bUeno73Zd/0g2lv55d+L9j5/6fPRXtN/vzvam3j/49Fe06ez5xqv/9zmaO/xv5mI9r581R3R3sTU+dHef5lYG+198ubsucvVrdlj+Y8/fSTa+4e/mIr2PtQWzVUDZ09Ge4s+cDTaa+jfEO1NHormqvH27LlQ44vZc+fGP8u+vtTd+uFoD+DlanA02+vI5qrZ+plo79jwWLTX9eTyaO+to9l7JZMLsucv89ddFO3VBqO5qmkse616rD/7+DY8MRvtrdnaHu01njge7R1qflu0V1VVtbnucLT39OLsa8LN67dGe+MT49Fe08rsNYNFbc9Ee6v2ZM+JqrcuiuYaf3p9tFd7Nvv8m73oDdFey+rs/fYzteZob0Hhv/tEIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKGuf6he941ZXRb7ztoqlo729bN0V73Vu6or264w9Ge88/szXae/aek9He7a86Fe01jU5He8frn4z2hh7OPl8aV0Vz1bHnBqO90/NWR3srWhZHewubd0V7p8azf29d2ZeDqtr+aDQX/vOt6m/pjvZmm5ZEe23150V7N05fEO3968bJaG9qz+For/OSFdHekfnZ13uAc8H0X7w92nuyJ3ts8T9rQ9Her52eifaWZ99qq8nPLI/2hhdkf3/tb/mlaO/F+p+K9ta+62C097Hjvxnt/fFAe7R32VD25O/I79ZFe2uu7I/2jv5p9ljvwXuaor3LPj8v2rv6g9lzydfd8VK090JtNtq78+Jj0d7C+7PnGtufzv58HxxZGO39Uvj98pbWddFe3eKV0R7AuaKlqkV7089k7+XMrM7e25hqyR7vPXLlmmiv66U3RHt7njsd7bU80xztrRjKPh51t2XPxzsOvBDtLaq/O9o78KULo73nFj8R7V138WuivaqqqkfP3hPtrXmwN9o7sTt7DaLjoqXR3ur67N/w/tdmXwNXjmXv17VNHYn2Bu/779He/PW/GO0178/eQJ26IHt/vLsre02oxCcaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFDUONcvbG+/MvqND3dnN06XrTke7fXVjkR79ce7or2mpYPR3vJPnYj2psbn/NSak7MXNkV7h55ZHu3NrpyI9g4eHo322p7viPZOb8/+vU2tG4v22lZn/94aOuZHexMz/dFe/Y4V0V7DyvOjvTODJ6O9rp7XRHvtp78X7TWcvija27p2TbT3lX3fifY2NIxEe4une6M9gHPBop+cifY2Xf5YtPfz/+vWaO9DB05He1/Ykj2WWr2tM9rrfcPKaK9Wnz3Wa9uZPXc+WL8j2hsYWBTtfeKig9He4Kefi/baJiejvf9045lo78N/82vR3pc/fFu019RbF+3VfuWOaK9vXvZay9gTz0R7227dHu2t3z0d7T2+583R3iffkD03bf76H0R7Dd3Z94+qe3G2B3COaGuvRXtT68+L9kbGstf2lndl33+W9B2I9o42ZY8vTlw+L9rrvjx7vlbtzR7fHjnZHu19/eYN0d4Ne+6N9n54+FS0t3nBgmhvz73fjPaqqqouWP5stHdi26po7+wzn472Vt+bfY1u25j9G9kw+OFob/z45mjvZNfPRnsjg++M9jq7s3uKR3uy78E31mX3D/+7P2LIJxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUNQ41y9se/5r0W/8+PYN0d61U33R3qlDm6O9eYv/Jdqr9V4X7VV1Z6O5E8+difa+NZ3tNR7cHu29YfNYtLdv5US0d7ZaFu29abg/2nviZF20d8XMq6K9mdmhaK/v6Lpo73NP3x/t9T71zWjvV/qvjfaWXtIW7c0suibaO3HxeLZ31z3R3rFtU9Fe62x3tLfvxLFoD+Bc0HBgabS3rvNotPdQz3S099/e/opob82OBdHeTPsD0d63H/1stPeewUuivUfv+JNo7+jGP4/2fuXgp6O9N/9e9tylbVNztPebt7872jv6P7LXgq77hTdHe08vXRHtXVL9a7R3/BfvjPaODWSvjZyqZc9dFt3dFe2dWfxfo73rW7PP5+mrHon22ndlr2XUtT8Y7T3zQvba5kXV30Z7AC9X9VPZ/99/rGsw2muZaYn2OqYno73Jq7LX0g+8sCjae1VL9vFdMDsQ7c2eV4v25rUvifZ+cjr7eDxRf1O0d/Wmg9Heiwcuj/Ya2n4Y7VVVVb3QnT3nfe2T2deE4U2z0d4j9+yP9q5rzP7+Ws9/Ktob294Q7TUezZ7jL3tl9ppf41D2nPfi/uw1nDPt2dfonrHs41sVDhF8ohEAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARY1z/cLhV7ZFv/G2ajbau//humiveV5vtLd2Tfb399L++6O9qcaRaK/pqpXR3sXProj2Hlo1GO29eHFDtLfnkdZob1vz7mhvdsVPRnsXLmyK9nbdvTPaO7pwONo7fPBMtNc7OueX8jmpTWZfrwa6s68Hh/ufiPZWLs6+HtRGl0R7fYuHor2hh7Pvb3uHtkR7K3smoj2Ac8EThx6M9toaro72vvv0gmjvyaOHor0Pbr472rv597PHZjubsscCD1Wvj/Ze23BltHfxjb8b7b1upCvaa7wle+3hn+Zlj30+duKlaO+vb1gU7S155R9Gew2jn4r2pnt+Ltr7p1O/Fu1NLM5eS/vwkezfx+zHW6K9//jLu6K9v1jxbLR36s690d7JG26K9i76Tvb/L908Hs0BnDOaGmeivfbp7L2I5p5sb2I422ucrkV7t7Vnj3/Gz8veW5tpWxPtTT11LNrrvqgj2mueHo32Rnqz1+b/5zf+Ktr78PvfH+3tnTg/2quqqnrpuzuivd3Hs68JrT2d0V7X9sujvXsPZc/xb38he41p/vbsOVHTTPaaZNM9zdFey+vfG+01Lo3mqra67DFCrTF7zaCqfvT9Yp9oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAEBR41y/8Bsv7Yp+45+uWxDtNXSMRnuXjj4Y7Q2ePi/aGzvVFO1VtfXR3OoFy6O9Eyv7or1bXtof7e18aFG097NHe6K9BwcORXsTQ9+P9rpWXR7tPbzgdLQ3O3Y22juwuiHae3GqLdqb6R+K9l5cmO21d30o2jv4+Fezvb5PRXuj4fePjueyG+ObFt0d7d13Ivz+BnAO2HB8PNo72jcW7b190ZFob+PoZLT3tv72aO/H62ejvfOvzB5LnXkgeyzwZFv2WGB975por2FkMNpb/I1ortqxMXvs884Ls+e6//3b2d/fr+0fiPYa/uJ3or3Zwy9Ee++7LPv31r65Jdpr2ZN9vR/504PR3gebfj3ae248/Psbrov2tn7xi9FeY/PWaG94amm0l70yDPAyVsseD0z1Z48fa3XZa9Wt87Pvj6MvzER7D4z0R3uXji2J9gZmsue73zqafXy3NoxEe9vbss+XC85k73Xe0/gz0d7O4dZob2T6TLRXVVX16MLmaO+hIzuivddevi3au+pN2XPKvX/5rWjvwOrD0d6WRddGezOnsn9zs/Unor2e3uz98cmO7B5gpiH799bY1hXtlfhEIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKGuf6hZu+uiL7jX9sPNob2X082pu8ciba2/fdumhvduBUtLftjUuivVWL1kZ7dS1j0d6Zk7Vo79KhyWjv1PlT0d6j92R7Jx87FO1deaon2vvC0uzz5Z1nu6O9t73tg9He3U/+INrbsPKRaG/b/AuivVUL/jHae+oLp6O9z720NNq7dNHRaG/vipuivctXPxvt3Xz8SLQHcC74/uxItPdk68Fo74rZ7LHy5Mgro72/emx+tDcz/o1o79bDC6O93RN90d6y1uy51YFHjkV7P7W4Ido7OZu9VvDO9vOivYF3vDfa+7E3fjnaa+w5Ge298M/fjvaevCN7reWdn4zmqqoze66x9z8fjvaW3TAY7U1ObYj2ttRnr3217n842hvpyl47bOzdGe31TLRHewDniqHs4W3V3NUc7R2bnfNtwjlZcTZ77+/TY9mfr/2H2fOhry4biPYadmbv5Ryd2BHtrRjaFu09M3NhtLflJ7PPl98/L3v94dFdw9HeshuviPaqqqouPnxjtLep7VeivevXXRvtjdSvifZ+5g3Zx2Sw50vR3qmJpmhvYs/z0d78rdnny3OnW6O9kePZa0zrO7PXTOefPx3ttVU/+pjDJxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUFRXq9Vqc/nCn//Ap6PfeFNDT7Q3tbIv2nvDsnuivdGpZ6O9B786E+3135TdnN22ZEG0N37nSLTXdcFQtDdw4Vi099Bd74v2Og7/dbTXNX022lu2uSPau29mRbS3+UhDtFdt6o7mJmpN0V5Dx2XR3ituviTaG9+9Jtrb/3z27+O3vpF9fK+dl/17G16zMtqbP3ws2ru3tjPaO3zPnmgP4OXoZP3qaO9D9W+N9i5q3xHt3XV99r1n5Y6j0d4PzkxHe+uao7nqlxdmjx33Xjcb7c3uuiDau7jqj/aGWrPnkjf+dPbxeH5gPNo7s6kr2rvx5o9Ge+N//ovR3sJVddFe3eu3R3vNHR+K9v5+23uivdauyWjvrRf1RHv1N1wU7TU9OS/aq9/7vWhvpjH7fG5a+5For/7zH472AF6ujh3PHi/XH8heK6yta4327hnOHo8uasueX008djza21+Xfb9tfmZvtLf69kujvUtWZu+9TA9k7601zGbPr6a75nQLfc5aR7L3dgeXZXtVVVX9L4XvP5/Nvmatm87ez168/ki0d/aFp6K9ppXZi0I9kzdGe+PNZ6K9g88ujfb2Pp7dj6xenn3PbL00e79u8yuy56htrT/6/rhPNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgqHGuX7jn2N9Ev/GazZdHex3Hbo72Hm0+P9r7/kP3RHu3Pzcd7XXffkO09+JTP4z2XvveS6O9sb6RaO+l6b5or+eSI9Fe797spnD4TEO0d3Y4+3i8/ap50d59lw5Ge9/8wZPRXldtJtq7+Zq6aO/AYFu017Dpm9FebaI52vuDXzoZ7e0+uTrau2d/d7R3etuL0V7z94ajPYBzwQt1J6K9IzP/Ldr7i9v/INp71e6OaO/Ymz4b7e393BPR3qkFV0d7Mzdlj33++PsPRntvO/9wtPfjC7PHtl/Z3xLt3du4Itrb+1D23LR3enm0949/+7PR3peOZM9NH/uj7LnV3hXZ5/PPPD8a7Q12ZP+9S4bnfJlxToaP90R7i9Zmz03Hv3hXtNc0fHG0V7/xpWivWpY93gA4V/T01KK9I9vao722/dnji5XPZq/tLV47Fu11TUZz1fyO7PHo082nor1tI9leU9viaK+3Kfv4bujP/r3NtGePb6v67Pnk8JGBaK+qqurkd74e7Z25ZGm0t+2BBdHe1NhEtLdwY3b/MLYgew1navC3or369j+O9rpuye4fZrZl74+vPdga7Z3ZGj7HH8leM21r/dHvcT7RCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAICixrl+YVPbTPQbHxy5INq76A0Lor19n2yL9obvORPt3bO4Pdqb//TT0d6Pn/eGaO/46Klob+/sqmhv8r6vRHs/duvj0d6D9dnny9To2Whv7LyOaO/I7Lpor27d3mjvLY8tj/aW9GQfjycefSzau2r6ZLT3w1Ubo71Lji+J9r763PnR3sFt2fffV45n/96efLg32mvYeGm0B3Au+JdqYbR3W9ucTxPn5I6v/na094F//r1o7+w/fiva69j+m9He6kP/HO1NfXMi2jv9h53RXu1Y9tjnwFAt2nty90C09yvTU9HePV3Z399f7T4d7f1gV/bx+N7K6Whv/n/K/v94r9gxFu0d+MXfj/bWb8leK/iNkcFo78GDB6K9vf+QPXfZMHpVtDe2bVe013nq+mivVv/z0R7AuaK/qS7aa5+ajfbmrWqK9tYeyZ5P1k9kz1+GL8je+7ugMXs+1H5mcbR3eOmiaG/e+FC013M6e7zcvCB7fjAznr33XGvM3uucau6L9qqqqhZteX20d/Tx34322i99U7TXeXn2ftOR7Cl0tXjsnmjvpaMbor3agf8U7U2MvzbaW7FpfbQ3ui7bm+ibjPbmnd8Q7ZX4RCMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAihrn+oVLq+noN67/4f+I9vZveX+0t+3V86O9/mpFtHfRzGy0t2ZiItpbcPbFaG/i2Y5ob+zhT0Z7S7f2RHtPHBiI9j5ffyzau3lp9vk3f3Y02psZ+0a013JiWbS38OrJaG/2aEu01zjZFe09+nz29aXvTPb59/SKwWhvdcNT0V5L443R3tmtu6O9i77UE+0duiT7eACcC7bVj0d7t870RHt3NDREe7UvHIn2Ws77s2jvipbsv7ejel+017D+bLTX2PtAtDc0OhDtHdwxL9p708XZ59/a86O56oNnsv/e923sj/bab8sey994pDnaO/HwVLT34b7sse0b//Qj0V41/hvR3H/ry/7/jI2/Wxftrfp4d7TX0HIm2mv7dvZcvFp8NJqrX5x9va+qjeEewMtT91Qt2jvdkL22PFmXff9uuGZhtncqe7w379BQtDe0Ift43LtpU7TX1rI32rvqpez55ON1A9HelvHWaK+p94Job+mmpmivYyZ7b6iqqmp47K5o79KWzmhvZtnqbG80e/9qSXNftDd9ZDjae2nPQLR36cbF0d7M2P5or3P+5miva/6paG/V9PJob2Y6ew5d4hONAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAAChqnOsXPnlqKvqNz3tuPNpb99X/HO0dvuSGaG/DTGe0N3DeTLR3dnpztPfdln3R3qUDh6O9Ne/81Whvy2Qt2rtn8ki0d+sr74r2Zu84He3tbm2P9i46kH292nnseLTXd6Qr2rt52ZxfyudkY0/29WDJsh9Ge3fdcHm0d/aby6K9rrEz0d765U9Eewvam6K9mf+YfT868tGj0R7AuaC9LntuVVuYPba9+Wz2WOXAjkPR3vJ3vD7a61q2J9o7/vSuaG/ppt+K9uq6+qK9mc/8h2hvZ9Mj0d7gHbPR3uIdF0d7V/+H1mhv7MzD0d7kZ7KvB50fWBntrb0z+/rye6PZc9OBN/27aG/Ft7KPR8toc7R39jMror0Fi7ZEe6d6n472FrRnr43UvfPfRXu1vQejvbpoDeDla7o/e35V680ej06sGYv2Jjumo71FC7LXMgdbsu+3Uyeei/auPPBQtLfgWPZa/8RV2Xudm188G+1VR7N/H20dw9FeQ+vWaG9Ba0e0V1VVNbb2mWivfyD7O5ypn8z2WtZEe8dPN0R7J45lz4nO2zwS7XW2jEZ7rauXRnvNXQujvdH67N9crcreT6ybzZ6TV9WPfj77RCMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAihrn+oVtI73Rb7y7uyna29JXF+1Nznss2tu06cJo7+5dg9Hezbf3RHsLnzwV7fUe6Yz2Lnvrl6O9fV+dF+1tXLU02muauTnam+zZFe01LT8b7X29ln08Fo/uj/auXrgg2rtw66XR3udfzP59zDvSFe29YumKaK914w+jvY8dqEV7N8xm3z/a6rMb4xf2r432Ni74drQHcC54+8xUtDdWjUZ7DZNLor26pRdEe9+evjPae1V1dbTX/DO/HO3NPpA99h5f9aFob2zkumjv56/4jWjv9PCvRHuL/yB77tc4tjza6/zEsWjvxHj2WsHJvx6J9ja/alG0t/5gX7Q3+bU3R3vzFmWvpf3hyAPR3q8ey14LqvXtjfaeaD4e7b2qYXW019jwuWivbuUHoj2Ac8VUlT1emV0y59t6c1I/kD0eWLO0Ndo7XRuO9hpmZ6K9I8Mt0V79ff3R3sD1j0Z7F3X+erQ3sGZDtNd1XvZ4b2BwXbTX3Nwd7Y03TER7VVVVHx+4Kdp7//zvRnudHdlj8KZ550V7y7uy55QLF8yP9k7tuSraq45/K5obu+TKaG9idGW0174i+55ZtaY/Eyh7jFDiE40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKGqc6xeeGc9+48np4WjvwYFatHfx/u5ob+/0zmjvDed3RHszn/1KtHemZTDa62xsjfb6/7492utqGIv29i09He01XnBhtHdiJvv3tmVwfbTXvn1XtLfw2ddHew239kR79a2PRHu37JiI9n6wIPv3O3bgrmjv/ivORHurhs6L9r5w5wPR3ttXXRrt1ZbcE+09dv5AtAdwLhhuqov2XjjbH+291Jjt9Tz7pWjvdSc3RHvjC7PHUu1XzPm0fU6a7pgX7f3cp7IXC6a7ornqV098MtpbfOnKaG/w203R3rL37Ij22sauivZOvu4z0d4Vl/5YtDf72ezv7+yDk9Fex4qvR3t1PSuivf883BvtTVwzHe1N3/kL0d41Sx+P9poWnor2Zr84EO1N9k5Fe+1/Fc0BvGztvn802lvU+UK019qXvdc0tv3iaK+7O3s+eawv+3525bPZa7dPb83ea1rf/t5or3Yye/43c+pYtHew8Wy0t7Qle6+ubzZ7ft8x0xLtVVVVXdm3L9rruOrGaK9xJHvRoGEq+5ksE7PRXFXfsTHaazs5FO3tXPG6aK/z+b+J9mbrL4/2ti9+W7TX2DI/2qursvfvS3yiEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFjXP9wlXrLo9+49nlO6O98zovjPYaTh2M9pafXBvtffO2I9HeiqHRaG/oeEu017xlNtq7ry/bq070R3P7j2Yfj+vW9EV7a+oXRXt7L5of7V06fF601/tTT0V7j+y8LNpb+sihaO9kU3u0d7pnS7S36Irno733zs++HuyfGo72erYuifbGV7832lve80K0t+zvjkV7AOeChobssfe66WXR3oensudW76nPHtv+Y2+299qxPdFe6zv/NdprqcaivdnJhdHeH7V9M9p79lRHtPfl57LHPusnt0Z7rzv+q9HeQP9Ho732xtdFe7Wj/zbamz3zZLTXtfDV0V7Loh9Ee1Pzfz3ae/hUtnf50x+I9lpv/C/RXnPn4miv+t6BaO70mUuivfltu6K9qnpDuAfw8rR4XV20t/CeedHewa0ror2NPdlro2e/NhXtzVx+Itrr335dtDezK3svtm9Z9tryzu8ORHvTffdFewMXjUd7zQtWRXvz6rKvB41tbdFeVVXV5quy57zHBwaiva6F2WtWrfuejvaGe6O5anDgdLQ3f/uZaO/aJ+6J9nb2ZV9TL9ySPWerG2yK9kbqR6K9upbsZwy1FKZEPtEIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgKLGuX7hgonh6Ddubbwg2mtYdCDaW9nQFe39r1O90d5le4aivfk3XRjtdWyf81NrToZHB6K9za2j0d7GfdnN3p1Ve7Q3s3VetDd/TVO09/aG5dHe1OmRaG/5qbXR3pOfuy/aO9QyG+1dvWRjtHfgWPb947mzLdFe/Q+7o70L33dztNewKft47Au/n3cfPi/am3/7iWgP4Fzwp5N10d4Ha9nevyzJHis/2zsT7e1oz577LR9tjvaatv9ytHfy2T+P9vpnsue63xzYEO0N1nZFe/eOtUZ7teqBaO/s/U9Fe3fVZX9/b/n42Wiv/h2D2d6i7dHezNGvRXu1hmXRXn3jH0V7l/dlz62ahjqjvZHzPxzttd31pWjvpZG/jPbWrcy+H9UvyR4fAJwrztvaE+0NZk+HqqUnTkZ7A31Ho72ZJdlrwZ0zA9Fex4rstfnOLdFcdezOx6K9tZcuiPY66rL3JuvmZX+BTT3Ze3UdzUujvbqGaK6qqqpa2/tj0V5D+6Fob2Zn9jHp7zke7T07MxbtLR14Mdpb3HJZtHes8f3R3po1K6O94ZXZPcDYVH+0V19ri/YWzfZEeyU+0QgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAosa5fuG2tlr0G5+ZWBrtTS5rjvbO61oS7Q127o/29r80Ee31bRmI9l771LJo75v39kZ7j21ZHu29+4bOaG/7BdnnX8fgpdHe5qHt0d7ZRXujver82Wiud+CFaK/hvIXR3rVXvD7aa933fLQ374Lsv/fFaiTau+StddHe46PZ98sbx8+P9k6OZ3++A1/bEe0dPP3NaK96929lewAvQ4tmxqO9v288FO11nMwe217Rk/3/Zd4/mj1WGVx6bbQ3OjEa7a2q+1C0d0fXl6K98dVbor2JfUejvYa6pmivvurL9mYGo71rqoZor9ZyfbR39t6D0d6zRz4f7d3QMS/am33xlmivsfWfo7269tujvSfP/H60d8l3so/HRM8Hor1V9f3RXt28C6K9mSc+Fu01Vu+N9gBerupb5nwbbk6617VGe48ePhPtLdg1E+3NTt0X7a2Yyt5bO73zrdFebXv23unTC78R7bU9fjzaa1+avZd41RWT0d7UePbe31hb9vVgXlP2XlhVVVW1KXu/vXF6W7R3qvdUtPeVZedFe++suqO92tbs/ezJwwuivZnaw9HeoePZay6Lx49Fe6cbN0V7rauz78HtdT3RXufNP/rx8IlGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1zvULOzrPRr9xQ9dotHe2vynau+/Jvmjv4tmLo70NyxdGe/29R6K9xpMD0d6bb7wi2qt/MZqrZk7sjPY6Fy+N9g48U4v2hrc9Hu2teuZ0tNe6eTjaW34q25u3fCraO3PwuWjvmq1bor1fuOGGaG/v95+K9k7WDkR7q/oXR3u7B7Ob4LYjX4r2/nrxTLTX8L3uaA/gXDBS1xDtvWYqe251Z/1QtHfJYPbf29K+Pdqbmtwd7bXvezDaG5qYjvbaetqivdYDR6O9jqbZaO9X6y6P9gZW3R7tLR7/WLR3dDB7rNc9k308jhz77Wjv8rrmaG98NPv31jL11WhvajT7+Na6e6O9VXWbor2jtf5ob/HZ7Otfw8wfRXvVwfXR3HTTYLQ354vSAP+3GxuI5kaOZq+lX/ma7PnQgbPZe02dh1ZGe4MPPh/tNb9tINrrPrg82nvFhbdEe8u2ZR+P6Z6BaG9iPHuEMTPWGu01L56M9qb/f/g8kfbm7DnM6dmOaK99Xfb+2htHsvdjx7J/ItWK9s3R3vHpg9HeQ7Vj0d6muuz+4fn510R7i3bvi/a+M3tZtPeOG/73fsaQTzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKhxrl+499SV0W+8rXVftDcw3B/tzR89Eu093joS7a1Z1xPtXXHwx6O9icvujvZOTZ+M9paPTUR7491bo71dd78U7d3Zmf17++izK6O9mcmZaG9wpjPae7BzNtpb3t0e7R35QXe094Oe7OvV5B8/n+1dOR7tbVq6NNqrHpqO5v7xy3dFe+O3XBztnd21I9obOJl9PgOcExraornV9dljgV+byR7rHazN+TR2TupG90R7myYGor2x+jdFe/tqX4321vW2Rnsd87O9wZHs/19Vm3og2usazj7/hlf+bLS3YNNnor3WR7PHjjNTC6O9xvbJaK+pqov2ajPZc43Z2s3ZXt8L0d5wbTDaW9u0LNobq/v30V5Vy77/VrXRaG6q4ZeiveyrPcDL15HR7LWunoXZ44G+U8eivVWL50d7E+uzx1OHLrw22ps3MRbtTcw/GO11L1ke7Y02NUR73Q3Za/Ot87PPl9O17PlBrT57ftrYkL0+UlVVNV4tivaasrfDqnkt66O9WvigtKc5e/959mj2HOH4TPYa4o0XvSva669l78eue/5AtNe7PPuefsniJ6K9xoHse1yJTzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKiuVqvV5vKFn37Lpug3bhtZFe399cwT0d70vp5o783LWqO9M6/O9jrXbIn2el84Hu2N9WX/vSe374r2bnlyQbTX23Ey2tu6fX20t6/vWLR3Zqo92rvt0GC09+j8FdHeZaNLor1vN2X/PvrHs4/vU/OujvZu2z8W7Y139EZ7LVevjvaeeW5+tNfXvy/aG29qiPbmP3I02tux51vRHsDL0ejm7Hvt0T0vRXs99UPZXm022ttRm4n2rqjqor3Jhjmdss/Z+MyGaO/Bhuyx40217LlBa11jtDfTkT0WbRocj/YaGrL/3n1d2effuqnror36JT8T7Y2N3BXttQwfifbqGl8R7U1P/TDaGxt/LNprq/qjveGO10R7XfXZa0tV63nRXO3U3mhvuJqI9hbOZs/FAV6uhsay5xsHs6dD1cKJqWivJ3upupqdzf7+JmrZ97OqcTKaqx8/G+11jGWvLU+0Zf+97a1Lo73p7KXqqr4xe35VF/77rVXZ87WqqqrhmWyzJXuJpGqayp5Dz9S3RHvTk9nf34nh7GvgvJnpaG+i1hTtzWvPvkaf6ctek9wx0B3trd84Eu11tnVGexsLPZ9oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAEBRXa1Wq/2f/iEAAAAAAAAAAICXN59oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAP9PO/f95fd90Pn+M72PZqRR712Wm2zL3Y6d4sTGTiedJBsSFsjCXjjLcnfJAucCu8tZNuSysHDJQpIlgSXJBgcn2ImdxHHvcpUlWb2X0UhTNL3d/4D33HNe51yd5PH41XOeM6NvmU95+QsAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFNXP9Qv7zo5Hv/GZ3uzGqXldNFe1j2Z7tbUT0d75EzXR3sIFjdHeaNNktDc9m32+LKypi/ZGpmejvYamaK6arcv+vtMzM9FefTUV7VVVVfVPn4n2ei8MRnsb9vRHew9etiHau6daEO2Nnc2+Rg5MnYr2RqqBaK+jZTraa2meF+119GXfEzrXdER7VUtnNlef/X0BLjY7f/gn0d5Ma/bY+7eGboj2qofvjeZ+5YU3or2NX/yX0d782exx3tj+7LH3/c/vjPZq72iN9rYf+V6017Ty3dHe5Pj3o726yU3Z3vbscWhVVVXN0auivTULssfyUy0Lo73j+7LX0+o2Za+3tE98Kdq798w90d6KJ05Ge+uuyL7nX9jfFe0tvSx7fe7B3d3R3ovzjkd7//fbfi3aA7gYbeq8OtobXXws2mscyd67WtPTHu0dXZn927jsUPZ8aGRF9rr30BPZ+xDzV2bP70+9/ZZo79/Nzvk29Zxc8+8/G+2NP5q9WTcyL/v6HR7622ivqqpq/MRd0d70js3R3uI190d7tR++JNq7788eivaGw/dKbmzJvscceOBgtPfd+X3RXtuh7L261W1d0d6Bid5or+dU9nrGP5595Z/97z7RCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAICi+rl+4d7hqeg37myri/bOHB+L9h47PxDtDU3N+Z96TjoXHI72mn8UzVWdW7K9TT1XR3unmrPP52og+3xpbGqL9tq7GqK9iZnJaK8m+/Ktqqqqhoe7o72G8XnR3n1ji6K9m/7obLQ39ZvZ5+DJzuxz8EcvZXtXdO6M9jrPz0Z7uycujfa2X9EV7Y3XdkR77bM10R7AT7rhFfOjvaMnNkV771o9E+2tues90d4b1z8e7S1uuDLaOzI/+/8HXTuVPRd/x5vujvZ27sqeWy1a0xztHW5tifae/W/7o73La5+I9p57LnzuXFXVse8ejfa67vlStPezTf8p2pv3kbdHe91PZ88lT2y5Pdr78JLLor26D0Rz1blXsu8Ju0//UbS3el72F7793IZor+PAvmivels2B3Ax6u84Hu0tPp+9mD421hTtvR6+lzivdnG0d+NM9t7at57NPh7Dddl7icNLpqO9jqOno72V778t2hs+NxTtLdjQGe1t6su+Pk7c+nvRXlVV1UR99tp8xztejPZGxi6J9hbX90Z797Rnj7+f2jAc7dW/mP2bNLmhNdrrPtMY7Y2czN47fa5jb7TXvbon2nt1fHm0V+ITjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoqp/rF+6uaqLfeOqRndFe69XD0d7xf9wf7d3Z2RrtDR5/MNo70bE32uudnIz2rtv8vWivflFDtHd4Kvv6uHAh+/pYda4/2ptadH20V3WPZHtVVc0fa4z2XmjK/ow9KxdEe+N3TkR7Q+dnor0FrePRXn3Xjmjvte8cjvYW3XAh2lu4fkO097XXzkR772s4H+21XLMl2qtvaIr2AC42L8/Oj/bW97VEe/euXR3tLejJHpe9azr7881rnhftVf1j0VzDgjlfBpiTmtPZx+OGz2d/36+u2xPtjc2ciPb2PP5ytLfh1tPR3t5TbdFeVVVV60hztPehjX8S7dUczl5f+uv3/W60N/rJ7GPyy08tjvb6P/WZaG9BX/ZcqGflZdHe1s7/Ee01Dp6L9nruyj5f7uz+ULQH8NOgbTT7//sfb84eL1cz2XtXVWv2uvLx8PnQ16ay1wnHG7PnQ+PN2efL9CvZ8/u67YPRXvXMoWjux333RXttl3482rtp+fpob+Z72XvFVVVV9eez1wxe3XJvtLf4WPbfcOSanmhv/T1Ho70nH87+vgtPHIn2vt++MNrrHz0Y7Z3tyL5Hz/ZFc9XMyuzfzN7+Y9FeiU80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofq5feOXg7ug3blw6Ee21zPRFe9u7X4/2Du38p2iv8erbo72ZFVdGe9e8/HS0N/XeY9He+Pml0d7QhR3R3tKqLtqbbZmK9s6ezj4ea6r10V5VVdXZjsFo7/T5pmivrW422hvcND/am19l36MnOoaivY/2XB3t7VqSfU4f2pf9+dafOhrt3Xxdc7R3vCn7N2Th5Gi019Scff0CXGyubF0T7f1gf0+0d+NtY9HeocnsccqdF94S7Y0cz/6+J3//N6K9eVf/22jvtZ33Rnufe6gm2mtYnD3uXjH9tWivtu94tNd+/Ppo7+qxjmivqqpq3aaF0d5Lj2Rfcz3Hz0R7Jw9krz+s2JU9d/n6sU3R3kce2RPtVT+zJZqracz+P5erxk9Ee9VA9vlc91z232/2hslor2rL5gAuRgM9w9HeRFv2fK3mwPlor6dmcbQ3uGBbtDdR90K0V9/XH+011LdGe9uXdEd759bM+bbynDz61tPRXsfz2fOhDWMbo72RPdlj5fsevS/aq6qqWr00e7/u2KHsv+HCkUXRXnvNpdHeyPlbo73Lr/hWtNc3+4Fob3r+N7K9g9l7u2s2bIj2To5l37NqmmeivbZ5vdFeiU80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofq5feKquOfqNl04eivZajp+K9mrfNBjtXb9qc7RXU7c32ru85e5or/ntq6O9N3a9HO31NJ2J9lbMjkd7zQ090d4Lk93R3g3V+WivZmpPtFdVVVVNTUZzN7bNRHuTC9dEe4tns+/Rs0dPRHtTswuivcaWlmiv7frror2lY89He1Mjy6O9Q99YGu29+SPT0d5YY0O01xGtAVx89i84Fu29/7Pror0VLU3RXm1d9rjs1bXZc78jj34u2mtbNhrtNS/5brR3/K+eivb6Fp+O9i6Zfzja61wbzVW/cdeqaG/mstuivffXZo/LqqqqxhvWR3tN8/dHe5978vFo7+692fPn176SPReat6It2htpyF6fG134v6O9lpXZc7+aQ9nrS9XTB6O52k/M+dLv3Jy/MdvLnpoCXJS2b/1MtDf6xo+jvdat2Xs5u6az98I2Hd8R7VXtZ6O5kU2d0d7o3nPRXt2Z7LHjVa2XRnu1r7wS7V2y/opo78kDr0d7q1/IHitva/mZaK+qqqq5IXuN5NnD2QO+T96zPdqb6H042rv/TPb+/b6n26O9u1dmrzE1PpjtjfZl7zV1dGWff/V12b8h549l36M7m7LXTEt8ohEAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARTWzs7Ozc/nC0b1PRr/xQENntDdZnYj2OvoXRXu19X8c7fWeH432Bi7cEu0NP/D5aG/furdFe/f0Xh3t9V2Rfb4suHxJtPfSE9+L9i407Y32+vdl3w+qqqpueM8vRXutDbujvZbhrmivffHmaG/6TPYxPj66NdprX7Q42muq64/2Xh59IdprP9ce7dWdjeaqmo3T0d6aZTdGez2L26I9gIvNJ/7zJ6O9dWvfH+1dd887or2ms4eiva/9xf5ob8PpM9Hee+58NNp76r7sufMXnjoa7Z06+0a0d23bTLR3+8evi/aWXDmnSzJztnLNO6O9dccPR3tVVVWNq7ZHe4+tuSfa2/jHL0V7nzv976K9wz/Ovmd9/6bs9aCuS7PP6Yna7LlB3WxNtHfs1i9He6M/WB/t9T63Jtrb9sst0d7yd//3aA/gYrT5ljuivdnpXdFe+77se/vZecPR3orxgWhvsD98b60x+3kOk0vqor2pzqZor7Ete6y3tXVetNc72hDtHRsZj/aWnBqK9ho+0hrtVVVVfWikO9qbbrom2jtbl72m0b20L9p7/G+z5xsfqcm+5v5iJJqrqtHs73uhJfv4TtRPRHuth8Kf4bO1K5o7ejB7v73/yMv/7H/3iUYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFNXP9QvPd22OfuOx8dlor/vscLTXNLk32puueW+013/829HexN4vR3vzb10d7V3b8JFo7+sTL0R73ef/c7Q3/N0t0V41k319TLw0Ge2tbLkh2quqqpp6+PFob/jqpdFef9OZaG9F09Zor3H0dLRXDbREcyOrsr2qbSSa2z5zWbT32NEfRns/fP1UtLflXPb5N+9dY9FeT9UW7QFcbB6+6sFob8fz10V7f/Pcj6O9Tz6wI9o7/tLuaO9DS7LnutWC7LnkrZfcH+198YFHor0r1jdFe58+1RHtXTfzRrR3dmB+tNf07b+O9vo+ene0V1VV1fbM2mhvy9jz0d7aD/1BtPeF35qJ9g5310V7r51/OdpbOp49lu+Y6o72xi75dLT3yJ9nr6ct+8BT0d7rXz8U7S0/8mvZXrQGcHE6fCx7vLymKXtd9Hxt9jph/0z2OlzvYPbYomU6mqumq+z5X8vJ7LHjyLGJbG8m+/s+2XE22tvUkn19bLswGu091d0V7b3jsfATuqqqL247Gu1teiyaqw5t3RbtrWvM/hs2LzkS7f3DshXR3tpXB6K9RZvmPDWZk32D2fesTdPLor29ndl7u0/3Z8+ItjTtj/ZKfKIRAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEX1c/3Ctob26Dfuqn0g2hsbeS3aG5j/zmiv47v/NdpbvOtH0d7Ly++K9jZON0d7syP/EO194NbGaK86eUs09+yB7OvtfP0Po70Vt2Z/34Wj+6O9qqqqodo90d7I0QvR3njt+mjvkmVro70nxndFez2TR6K9lmND0V7XxhuivafO9EV7o1sPRnsv/s/Ho73eBeuivefrsu/RfxWtAVx8PrJjY7T30rx/jPa2vvapaK9957Fo75rNL0R7NVe3RHsdZ26M9h7dejba++Vfyp77XTM6Fu3N1GSPK0Y+eG20t/TRwWjvpZrZaG/su/3RXlVV1cElfxPtfeCVnmjvtTMror0NG7PXv/qbsu8xbUezvVP/NBDtDa3Lnru8emhVtLfqwGi0t/VrV0Z7t3z85mhv9i3boz2Anwa15xqivbPLsp8fcE9D9nj+vumaaG+2oynam7l0ebR3aU9HtPfigez57tTx7PnBvJquaG/2wulo71BDW7R3rCX7+qg5Ox7tPdKbPRatqqpq3JN9zzq5qjPau2zgcLS3oeeSaO/p21ZGe//qqweivY4/uDvae/5s9j164d9+Odp7asmcpzBzsnA4ey/2ykPZa3RDg/3RXolPNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgqH6uXzg2Nh79xrMHT0R7VW9NNDde/61ob/RUU7T3as+KaG/9FSejvSefyj5fbr3s9mhv4qtfifYaLp+N9rYsb472Zvtvj/aebc7+vqs7fibaq6qqOtH0nWjv+PjyaO/dJ1+P9vprfxTtrTnVHu3tOvD1aO/S5RPR3mDNY9HewPTl0d6Wl1ZHe5uvy/Y2Nu6K9q5teVu0V1Ud4R7AxeWKq78Z7V39zaeivRemXon25m3N/v8yy0ey50JfeXZetPflX7gj2nv3n/12tPen4XPdv7hQF+399rXXRXsd/Z+N9k7e0Brt3Xvw96O9zyxdGe1VVVWt7X0w2nvlru5ob8MLd0Z7++99KNqbP5i93jKy8Fi01/7knC81zsnYhplo74dN90d71wxn3/PP3fafor01m9dGezcsyr5nAfw0WJA9vK0mh7L3Dr61anO013aqL9pbU9sV7W24MBLtPbEy2+tp7or2Bloao73JruwTevJI9tixZXFDtFe/NPv7tj8xFO011OU/T6SmOXsvrPbA7mjv0Nnsvav+HTujvaote37wpz03RXt337c32lt7efbx2Lkye7576MfHo73eybFo7+hU9j163Wj2+VfiE40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKqf8xd2TEW/8amh1dFexyULor3m/u9Fe89euzTaGxrcGu29PrAo2puZ93K0t2f2B9HesTN10V7tvYPR3u2Xd0V7R1sPRHvdzfuzvY0d0V5VVdX815qjvZGx7HN6/OySaK/l3vFo743+gWhv80g0V50/891ob8Xc/xzOybKhr0Z7C2/4cLT39vHLor1/2NUb7d0ynH2PrjqzOYCLze7dZ6O9Mw2PRnsTe78c7S1rzp5bnbnsxmjvl/ZeEe0NPfHn0d7USFO0977t2XPTzqFXor3W914d7Q1c1hrtrZlYGe19Ziz7eOx845For6qqamnDhWjve/+UfU+4LXuoXK39zc9He4s+/6Vo73z21K966J2vR3tvPnhJtNd8OntycN+87LWH+n1Ho71fuac92hs81RbtNS9cHO0BXIwGarLXuZoas3+863adjPYa6zdFe3vbJ6O9Y4PZ65j1j5+J9s4NZ//W3tZ9ZbTXck/2+sOi3e+M9l64cCLaO7kze298ZEH2RknnxPJor6qqqpo6Hs3N1o1Few0N2fvZK9qHor1tA+ejvcObnor2Bl7P/r5HdmXvTY6OZc+vmkayfzNXj9dEe5MzDdFe1T2c7RX4RCMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAiurn+oWzvdlvfKK3L9pbVTcY7bVNLYj2rrrQFe29eP32aK+1sSvaW3/2SLTXvHs42lv6obdGe9//8ZeivS+cz/6+H+3aFu1dv/2SaG+6833RXlVV1cTxL0R7LffPRHuvz3sj2hscHIv26i+/NNqrHfxktNc09Fy0d6Z1Z7T33T2Lor1/8dKqaG+m5kC096t3vy3aa2qui/YAftJt3fx4tPfA394f7Y13dUd71+zIHis/9NrWaK/pN7O98z/6m2hv6rb/GO2t+6fs829m+9lo78SL2f+/au1o9jzj7Klt0d78mr+I9j74riujvaqqqm++kj12fP/etdHevLEfRHubZ/9VtFfz77PXHyZ/95vR3rnBoWhv4jOLo71PN90R7Z2Z3RTtPXfv09Fe3Q+mor0Tx5dFe4vC1x4ALkazU+PR3thUT7RX1bREcyuvvy7aaz6dPT8d6sted5zun432lndPRHu/uL452ju9IPv8u/Wzd0d7A/d/P9r7242t0d7eH78Q7bXV7Yr2qqqq6lqz51c13Y3R3mRb9jl99ehbor19+7OPycTQZLT33tYN0d7fHXop2ttzMHsvdmv4T+aj2VxV1zQS7Q3NXxLtlfhEIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACK6uf6hVMTh6Pf+Jk37ov22h98I9rbt3xDtHftz94Q7V0+syLam3z+ZLTX2VYT7U0tHo/25k0ti/bu3Pg70V7fVa9Ge2f37Y72ukY/Fu01HXo02quqqup9IvueMNk+He1V3auiufaexdHeqmc7o71XV3w72tu26ZZo78Dh56K9y67MvkcP7Xsm2lt+2bxob/qK66O9Tc3N0R7AT7qVP7w52tvQ/vVo7z2XrY/2VryvP9p7049ujPbGzu+L9qbu3hTtvfji69HeX258Kdr7hcdmo73hqa9Ee0fGLo/23vy+H0V7XYveEu017ci+fquqqj6x8IPR3vAHxqK917+5Otr7j//xE9Heb364J9pbvKAu2vvQyNZor+Hp7Llp81VXR3tTK89He//2Z7PXX793IHsueXaqJdqrqrvCPYCLz8hY9m9t7XhftLewbiLa2/Ho30V7bcuy95rG1l+I9jpPZc8nb2jPXhc9c+Ol0d7B17LPv8tuzd4Le/rsmWjv3FhHtNc+b2G0N3hsMNqrqqp685KBaG9y3spo77Fdx6K9x0dPRHvDV2bv/V1/JPuaq245Hs3tPdoQ7Z2qy+4BTpzOXmNqbsr+TVpbl+3tOpy9PlLiE40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKqf6xdO13ZEv/Hi6fFo7zsnTkZ721rXRXuHXvmbaG9xzxXRXnVTdzS3b/8N0d5szZlob9n0vmjvtfrBaG/b0luivfknTkR7U8eejPaOzpvzW9GcTWzMNufvGY72BtqzP9/m6dFob/CtG6O9m8+0RHtnX/p+tLc8PLtteWBntPeNVdn3wM+svDHaW1U7Ge3N1tdFewA/6ZrecjTae1fTv472ehuyx1GLnzsU7e1Y/H9Ee0uWPR/t3TT1pWjvyaf+Itr79XM90d72698W7X3j8NeivUsXr4j2Dl/1L6O91p5T0d7K/buivaqqqpl1M9FeY032d14y9ofR3sZ9F6K9595oiPbWnM8ee09NZK8XPLhoZbT33HD28f30wN3R3svXDEV7N99yR7S3uqEt2gP4aTBbNx3t1Uxme2M12fO1mdlorpo51hztLRq4Ldq75tNro70NTQujvR37Tkd7H73pF6K9dVPLor2R9uz53492Ze/tfmph9vc91p89H6+qqlr+3CvR3v5f6Iz22vuy99Ye3pU9H9p+tj3aGz13KNr7/W9k//1am7I3106NZ3trZ7N/Mw9NZv/InZlsivZqquz+psQnGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVD/XL+xtbIl+4xV7j0R7M+u6or0FSyajvR8ePRft9Yy9GO3Nr3lXtDd78DvRXlNda7T3zLM7o727r7k22hv/s7+L9g7N9Ed7J88+Hu3deffHor2qqqrjl2+K9nbcdzTae+h4f7R329pF0d4dr/19tHfmriXR3sKfOR7tnXtqWbTXe0l/tLfqTG+013/uULS3fM3+aK9xOvt4VA0N2R7ARWbN4dlo76Fvfyvae7Yz+3eisyb7/8u89+c/E+01LN0T7b38wNeivbuvWxHtHVj9u9HekZEvR3sX7u2P9h5s/G60t/Dd34/2Pvz4vGhv4sVj0V5VVVXthYPR3tHreqK95t6z0d7BFe3RXuPuBdHeooHxaO/YtcPR3k273oj2Lll0Jtqr2Z699rB+70y019L2TLR3bMXHo731y6M5gItSbfZWU1XbnD3e6x/rj/aquuz56ey8ddFe6+Ybor2Ofdne+Zns+catSw5Fe2smstcL5rd8Ntq79sbs+e5HXh2L9ur3Zs+FnlvZF+1VVVUd7JrzdGBOFuzInh8sqM/ea9rSnr1/f+ZC9vxlXmP23kbrbE20t+vISLSXvuZ3pDbbq2lpjPZWX7cm2hs+n319lPhEIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACK6uf6hY2vDES/8eT8oWhv9OkL0d63L30t2nv7WPbfr2F8SbT31Y7/EO2dG+6M9m6Zqon2mlpHor0f7H4q2lt37dZor+8bL0V7eyY3RHs3zmYfj6qqqr7d7dHeioZ10d5n2qK56t7zp6K9ayeyj0njwGC0Vzv1tmivtX1ntNc+b1G0V3PsSLS3omd5tFdXPy/aq2mc8+EJAFVV/Z8XHo72Rhb9KNp7y7lLor2XRxuivWv/+43R3vLu7HHF5XesivZGf3BrtHfiweeivRdHdkd7h7u2RHstx3qjvef/KHvc/e41h6O9odH50V5VVdXkhpejvTWDTdHe4aHsc2b1v7gl2ru59/PR3le+EM1V77oi+5wZ+8ivRXu3tT8S7R3547+L9qpfXR3NTffuifY61l8b7VXV7eEewMWnpi57rDI7Mx7tVbPZXN1U9uermc0e344eeSHa6/ls9rpo9fU3orne8b5o7+Xj56K9Pc/sivbuacyenx5Z+55o7+Tw30d7S/pWRntVVVXDb26M9nb+bfbe1cGVh6K9j7ZnrzFNz8/em3z88Fi09/po9jU8MJ69fz9ZOx3tNdRmf76R2Wxv+FD2+XJJd3YvU+ITjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoqp/rF766uy/6jff1j0d7g82D0d73eieivS0NNdHeddPZ33dp42y0Nz54JNqbv3letLd5dmW0d3xyINobOPJ6tLfqgx+O9i47nn2+jC3LPl+qqqpOvbww2rvyxm3R3rn27HvCZ07viPYGWuuivdOPnI/2Njyffc7UXHom2qs7e2m0t3tP9vd9oyb7HrNtNLtbbpnOvsfUmVUDP+F++/gno73/61RvtLer54Vo751d2eO8v973J9He7+y6Mtp7bPGhaO/I/SeivdG2tmjv3HD2OLn12uzrY/PWx6K9BStei/Z2tG6K9t50xbpor6qqqnfJxmzwzNPR3OrLDkR789+cvf7wgz+5Mdr7F5/YH+2NTf1ptHfZkuzfkKmZj0d7HTecivZO956N9r6xJ3s993dezD6+1R/9UrYHcBFqbGqP9sYns9dZq5rshbPZxmiumj6f/X1Ha1qjvUf/6f+J9lY/kT0/+PF0S7T3cx9bFe2NPPRb0V7Tst+O9m7u/2a09/DmqWhvsvdctFdVVTX0yO3RXlPP6Wjv99qWRHunx7L3wu47Nh3ttWzIvgcunF0c7S3dPRrtjQ1m9yN9E9m9R1t99m9644YN0V7f0LPRXolbbwAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAU1c/1C2++tCP6jUdfuz7au6rxmWivaWYi2ls8PB7tHegbjPY6u2qivQ8taor2akeiuaq2Oft83jk7Fe2tPpzt3XLL+Wivaf1/iPZmFv9VtFdVVXXd7ux7wvk3vS/aW38y+xquW3pTtLeu+3S093TTZLR3YPb5aO/a5UuivaMzL0R7m8ez76mrX+2P9oaafxjt7Vy6Jdq7qWqI9gAuNi9NfSPa6+68Ldq7/MST0d5j849Ee1fdHM1V3z57NNv7LzPR3uyx49HeRFv2OK+ttjna+9CpHdHe5tHsceMPbsw+nzc2b4r2Dr3jX0V7VVVVm1/JPiZnzz8e7Z3ceiHaW7TkXLT31g17o72672SPlSc+9Ea0Nzm0IdqbWHgq2vtm/UC017N3XbT36aZl0d7sL3442gP4aTBdm73XVFs/59t6c+tVPdFec0v2eL5pNHts1j7vQLS3YTT7t7t7W1209+uXtkZ7R4YWRHtvum5etFetyj5fDp3O3px86Mns+8GW62ejvaqqquWN2dfIG1PZc+jf2Jl9TG7ZfDLaO9aXfUy29GyL9m676kS0V9feGO0dOZB9T3hiYiza6zs+Gu11Vtnn3+KpK6K9Ep9oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAEBR/Zy/8upV0W+89sjN0d6u556J9m5sGIr2dl+Y+z/1XEwumB/t3fCuyWhvdl9NtLeppyXaa17YHu1t3LEy2muozf77zRy4Kto7NvKH0V5764Vor6qqqq/nF6K9the/HO01dX4m2hsefDza233y4Whv0arsc3qgrTnaO7cz+57/4ye6o73l9Wejve/1Zv8mrbnw/Wjv8rXvj/aqhg3ZHsBFZl3Hxmjvwtt/GO390+nbor1fbH8o2vvLg1dGex9+8Y1o7/N3rY72Fm9aGO1dOJ49Vzs+0x/tPbble9Fec99Ho703t2avjdQfPhLtTQwfivaqqqqqrgXR3PjBFdHeufnHo72Zzz8W7S3rzb5nHajLXk97afB/Rnvv2rQ92js1ln2NfOfLL0V7N3c3Rnunl26L9u64si/a2569nAZwUWpqyh77TA2di/am67OfRzA79ZFob8m87LHK0ODhaG9J17+O9npuyj4ev3f8r6O9X7rxpmjvtdey9+qW9H0+2jtbmz0fv7sn+34wXZ89Vq6qqlrQl/0Zf3D+uWhvvDl7vtbx2ky019SdfQ3PO9Yf7R06PBztffC66Wjv1Tdvivbm33si2uvu6Ij2Zme2RXs9i94S7ZX4RCMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAiurn+oWLx+b8pXNyomFHtDf2jvZob8+ujmiv9/Uz0d5buy5Eex1nlkV7o6fHor2h+nnR3lTTeLQ3uTz7+qibPBLttZ9dF+0tvGQ02ht8vTXaq6qqev3h34v2Tl0Yifa2bfp8tPf4xLlor3vhVLT3kQu3RXv7ul+I9o6/vS/ae/PhiWjvx7PN0V53dzRXbay5IdobaVga7QH8pGvpyf4dWz+U7X1w88Job+GaJdHeB577YbS35mPzo70F9YujvZnj2d/33l0D0d7a2tlob3796mjv0Oh3or3xVxqjvfsODkV7P7d+Z7RXVVXVdLYl2ptafT7au/RY9vpI/Xuz1wvO/vavR3s1n/pqtLdq389Gez03XhrtNZ7ZH+19bsPPRXs/WJy9XrVy3/PRXkeVvb5ZVdnnM8DFaGose912ospep54ZG4z2Gtr+R7TXV10Z7V133R9Fe3292WO9kZGXo71fPLEq2ltz1Y3R3kM3PhDtDb++NtprXLcn2qs90BDtTTxzX7RXVVX1xd7s/dh5DdnzvwuN2XPoXSPZaxDDU9nj+R+3nor2JuqiuaprV/b+c8todv8wVpu9RneuK/t8XrQr+3xZvnp3tFdVP/PP/lefaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAUf1cv3Cyti/6jXfW3R7tXXfX7mjvK+3N0d7qmYFor290Mtq78Fj256vf2hDtLT59Otrb984T0d78B7Ovj9qjw9HeyY17or3L2jdGewOnDkR7VVVVL5+ZifZqjoxGeztWZV9zlz8fzVWNnY3R3vNbdkR7y3vmR3v157Lv+U1vvybau2v9yWjv9ddmo72WdYujvRUz2Z8P4CfdAwe+E+0133NDtHftM9+O9n73v5yL9rYMzvm0eE5GXsoeV7TUvhTtLV11RbT3wflPRntv1F4Z7b3wicFor/u3s+d+iz7QGe19/MUz0d43T49Fe1VVVT83eFu09+wDZ6O9K27ojvZuuuvfRHsr/2o62ut8aku0t+SyDdHebH/28eidOBLtHfo3V0V7t/3XndHe8n+5Otrra/ydaA/gp0HPvHXRXvPQsWivtzV7L2Jiui7aG2vMHs+/9PrBaK+t8RvRXvu+7L2S7sYbo72XPvFStHfdnuz5fcON10V7gz/K3us81PBYtHe+oSXaq6qq6pqXfU841dwa7S2azd67erEze877i91N0V7PxsujvZdfeD3au3c0e3614Fh2/3C0OXvvauuS7PO5ZujZaO8fDvdGe79f+O8+0QgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAovq5fuHIzJy/dE6+dvDRaO/fnOyI9n5l61uivZfWHo/2hn743Wivu3FhtHfu2Olo7/iZ89Heph9tifYaVkZz1eEXZ6K9BUeyj8fQExPRXufSJ6O9qqqq969cEe0N3lIT7a24fmO0d299Z7TXfvjFaG9531i0N2//DdFe/ckHo71nu1qivR2t2X+/reevjvbOHJrK9nqmo73Vq6M5gIvOe9//3mjv1LON0V7fs13RXlfHkmjvlWp3tHfbK3XR3uMbR6O9DSf6o73O5c3R3oO9L0d7k4+0R3vdl10b7TV29EV7S1svRHu/cPyOaK+qqmrynb8b7S0d//Nor331wWhverQ32muad3O0N3tsZ7T30u1t0d47Hs9eP5w+ciTau/M92XPxVxa/Ldpru+7no70VS5dFewA/DQZqssfLUws3RXsTA9ljlfbm8WhvaGQg2hsd+3y019Z0abQ3Nj4U7T3W9Vi097s/OBbtfeuh7L2rRXcsiPY612Xv1W2+piHaO/lfs6+3qqqqoYnsvYiO5aeivV/uyh5/P9I7L9q75v3Z99TXvvNGtNd3NPueem32JVI9MT/bW3gye34/dfbyaG+ma1W019OyP9or8YlGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABTVz/ULa5uao9/4c2/+WLS364u/Hu0t3jIY7b1161XR3sn63mhv8v5ro70v9f51tHf9meFor3/HoWhvUfOCaG+2cSraO1H/YrTXULM02tu8Ifv6qKqqahzJPqcXXXEo2qtr6In23nnp96K9gUUt0d7pN7ZEe0eaF0Z7By5dFu29euCRaO+V72Zfc9suPx7trbrqc9FeU9NMtAfwk+7k3jeivfGld0R7/235kmjvlonHo733NF4X7Z08nf19t182Ge3teWU62ms51xbttV+Z/X1Pj4xGe+/61AejvcETK6K9rju/Fe317nh3tFdVVVXT8JvR3ppb/m20t+fFP4z2LjmcPbeaavthtNe/bCTau7Ir+x49ddWcL13Oyfy7tkd7wy9ti/aWfir7ePScOR/tHavqor1Fndn3QICL0RXjB6K956YHor1l4/OivfMrsvc2Vr+WPX+p25T9+TZP7Iz2ji3OPh6zfdm/3eePXRntrX1H9t5fw9rXo71rurL3IR74n+PR3vLWpmivqqrqE2PZ85c778jee2k7vCjaOzz7crT3rfvWRHszK+ZHe71nso/vmeOno736kxPR3uhsTbS3fnZ3tDdWZfcFd13WHu2V+EQjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIrq5/qFdS0t0W98/aLuaG/gY5+K9p4YvCnaW//q/mjvyqveHe2dW9ET7f3Gk38W7f3puVeivdGDT0d7B8dORntV63A0t6RrfbR3yZWt0d7JBbdEe1VVVV01I9Fex6WfjfYGZpdGewvXXBrtLRvMPmfWfbAz2ju2b360t3rp+6O92bq/jPZu27kv2uuY3RTtdc8cj/bqWrJ/kwB+0j23+HC0d2XdhWjvwwvfHu31zq6N9iYXHIr2tt75ULTXc8m/i/YW33Es2hvqzl4r6P6rR6O91145G+298p/+W7T3Uvi8YNHbPxLtvWfRV6K9qqqqHzw7Ge21Lb0/2tvScCjam9w8E+01nDoQ7b14ejTaW/TIrmive8Vbo73p17L/fgdOfy/aW/v0c9He4Z/7+Wiv59iqaK/afE22B3AROjO/KdqracmeD41MD0V7zQcmor3J7tlob9n8ddHexMD2aG9x9XC0d3Ase6/pa88+Fe21PJN9/tV1nYn2as/1RnvNd2XPhV7d0xjtVVVVbQx/RMm+o9l/w8ba7HvMeJV9THq3ZH++j27KXnPpb87eW+t9Pfses//UnKcrc9Ldnf0bPLliKtqbXjIe7Z1vzd4bL/GJRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAU1c/1CydGa6Lf+Hy1MNpb3bgh2lvYMhztzRtYFe1Njs6P9lo3ZX++p7eej/Y+3L812pt49PZob+TaZ6K9k4Pzor1b56+J9rraroz2Grr7or2qqqrZmuxrZGZ6MtrrHm2M9np73hfttbQ1R3v9/dPR3v41u6K9wYMN0d6+I9nX8DPzu6O9O584F+1d+o62aK++Ifv6APhJ1/bEHdHe5I5j0d7Vf7E32ht49fpo78Wx7HHFyL7V0d6Th/4g2lvfMxPtLWxZGe11Pbsi2qt540S098CiiWhvQW/2uOypmb+L9o7XnIr2qqqqLnRn/w3v/JnWaK9n1a9Eezv/rjfaOzx/Ktr7X/cfiva2185Ge+tnsuemu94550uhc3PJb0dz4+uy19OOnMg+HkNXjUd72auRABenoZns8d6bGo5He8dasucHfUuz10Xrj2SP9VqGX4n2Vi7OXvc+eWJRtPerd2bvrT00nT2/P/vU4WhvoDZ77Li/sT/aW7Y7e51/+7L2aK+qqqp3KHtN6Oz5S6O9h5tORnuH9mX3AG89kP2Ml/MHs9eselasj/Y6Fy2J9mq2Za+pXbX0bLT3jz3Z6xnTPeuivWWPPx/tlfhEIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACK6uf6ha2dc/7SORlva4/2Rqv+aG9BtSram9fZEe1Nty6L9tqqM9HeJQPLo72WxdPRXtu7so/Hjpo10d7d6zqjvYnpmWhvdHoy2ptsyD5fqqqq5tXPRntDNW3R3jOjY9HeovGmaG9fXV2019VdE+017pkf7c2saIn2Vp+/K9o7v6Er2rtp/bFor6tzc7TXMGsHDfD/xYn+wWhv6NbT0d7A156P9rrv/I1o75PD66K9r1/2o2hv+/7s38VNjw5Fe6emsj/fg8uOR3sralqjvaULzkZ7rR9bGe1t/5PsecvvN2V/36qqqtvqfy3aGx3LPsb/+49PRns9Hd+O9l5evjXa+0jnc9Heid1T0d79y5ZEexvastdH2mYXRntNs9mfb/327Ln4yB9/NdqrvnhbtgdwEZo6m70OvLC9O9rb2ZO91j+0bzjba8ge650/nL2OPtnaHO0tXrsi2hs49Gy0t23BQLS3tzN7r3iiLvt82bQie2w7f2I82lt5Jnsvsaqqanom+2+4dd7+aO/pl7P3i9vPZ/cP+9+Uvdd0cHX2mtWOV3ZHe7efzp6fLnj9XLT3JwM7o72R7uz56c9f/1K017DoymivxJ08AAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIrq5/qFDXUz0W/cNdkZ7fU3vSXau1DfHO0tnJyI9s71ZzdiF+qXRHtTx/qjvSfDz7/rz3REe/O3ZJ8vE6emor3Rs3XR3sk1TdHexFD29VFVVTU+PRvtNU+MRXuPjl+I9noGs8/py5Zl32NWtjRGe83bFkd7kwfOR3t7x4ejvTWX10R7q6evj/bOzWZ/vqVN2R7AT7pzW7ZGe22P3BztDazOnvs9+Pt/GO19d9M90d5Ix6For6vv6WjvC/+QPdeY7cyeG9y89ZJo76a3ror2duxti/YG//61aO9Pt8yP9t7ele1VVVXVvumhbG/RR6O9t//71dHe97+YPVc7diR7rnF4V/Y5faoz+/N9+v0PR3srj3wh2huvzZ5LLl4/GO29MrMj2juydG20lz0zBbg4dc3PXue6//xAtHddTfbeyytNC6O94emT0V5P+Pxl7NS+aO/EVPbYcbzlpmhv9Zlno70FK7Kvj8412fO/3buPRnub+s5Ge2Mnz0R7VVVVxzsmo70/ejV7b2jNi9n7nefmNUR7txy6KtrrnR2P9m5vy95bu/ZN2fPJV59vjfa2r9sS7V1x/dJo78+XjEZ77xvaFu2V+EQjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIrq5/qFfVVD9BtPnxmO9lqqxmhv6fhotHewvjXam5odj/baW5ujvTXLx6K9rprZaG+2sTPaW3Us+3yZ6sq+3gYn+6O9usm6aG/VaPb5UlVVtedw9jFeNnQ22tswFc1VPWuzj0nPaHu0Nzg5He0NN2XfsxrnjUR7HW+6NtpbeOxUtNe0Lvue+nh/9j1wS+NMtHd1+G8wwMVmdtsb0d6Ct9ZEe60PPBvtLTreFe19aeTvo71FLzwW7d1024Zob2rlsWjvwsHsccWqc0eivUcX/mq0d/Lg69HeDZcsi/Z+ZfmBaK9my1ujvaqqquPju6K9F599Mdpb2ftqtLf0juy5Wue57LnQwD2T0d6CR26L9rZdviDaW750ebT38urF0d7hmZ5ob7ZuY7TXemf++g3AT7ptvdl7Vz+qzV43e7Ime120afpEtFezoCXaO9MzEe1NHsw+vpdUO6O9E8uy5wfTk23RXs8Nl0R7285krwOvWZ49Hxpf8nC0N3vkdLRXVVW1f093tNdwafYaU+em7DWI0XPZ94SZ2oFor/pe9jXSeF32/G9gNPsePXnhtWjvsb7s49HUnX19fKDplmhv0f3ror2qcEnNJxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUFQzOzs7O5cvPDsxFf3G48PRXDWv5kK0NzPRHO0Nt9VEe4MN2V7HzEy01zXUEO1V87I/34WZ7MaubTT78422ZX++qSr7881WY9Fe7XBTtFdVVXWyKfs7tw1kX3Mt/SejvcmF2fesl0c7o701NdnHY15dfbR3on402rusNfs3aXS6Ndp7cST777ekLfv8m63Nvgde3Rb+mwRwkdn72F9Gez88UhftHftfP4j2hsd7or3R609Ee8uv3RDt3bHvaLQ3VtMf7U01bIr2xk6uiPYe3ftgtPe21sZo79n63mhv0fyl0d75lruivaqqqr592cfkwolD0d7IyQXR3p43n472Vt12Z7T3yzPviva+c3hXtDd86+XR3m+tWRLtNc9m/2Y+X5c9t7qyPXsto7Yve266dF22B3AxumRJ9r39wlA0V/XPTkZ70zXZ63rLFmSPv1vb53RLdM7qVmfPX+bvPhPtXd92SbTX25899vnw27LXqWd6sveuTk/dFu3Nzt8Z7e154Mlor6qq6pXh7Gt4bcPaaG9mY/bnW9qwLdo7eW4i2uvtGYj2LtnbHe3VX5a9pja8641o79DlG6O9m664Ltr7XsviaO9Dtdn36I9//Jf+2f/uE40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKqZnZ2d/f/7hwAAAAAAAAAAAC5uPtEIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKPp/AQhMcIRcqo36AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Hot Dog\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Pizza\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Sandwich\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACRoAAATkCAYAAAAJ0C4xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACZ2klEQVR4nOzcZ5Sc92Hf+2d2ZvtiURa9E4UgCfbexCJKFJuqLcmyLbkqVpxrybEdxznOkcuNT1xviuXIsmPLtuQiy7IqZYoiJYqkSIoN7CBAACzodbEAtu/M3Bd5z//ec345wbn4fN5iz3enPjvPzA9Ta7fb7QoAAAAAAAAAAOBNdPyfvgAAAAAAAAAAAMDpz9AIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKgx2x/86m//VPQXf+7vd0Z752/eFu0NXFKP9r7+tcXR3tDrx6K9w4NT0V7PmoXRXkdvb7R3zotvRHtfme6J9kbnLYj2Ng53RnszGwaivdsvuCTae6P2vWhvweCmaO+v780+XhYuezTaO/rUWLQ3f2Iw2ludzVWvdpyK9hauPRHt7dm2MtqbPDgc7S2+fCjam3fLT0R7j/72J6I9gNPRjT99a7S39dE90V67nT3XqC6dE81N3fN6tDc9uT7am3/JdLQ3fV4t2ms8kX1xdnJsS7Q31ZU9t+rsWRLt1bdm38uYXNAV7b19U/bcfuu27mjvrPmHor3jHcujvbVT7Wjv6bdk36sa+8L2aG+qMRrtrZjTH+194qxorvqlR2f9tuqsdE9kz9V6OlvRXn89e323joVfHwCcptqt7PG4mX15UY1V2WBfLXu+0W5ne7V29vpmL11VVTPZv4+1Rvb8YDz7cqWqD2Vvwc7w8yP+bR217PGgqp3+3yfSCh+0WuGr3Ag/iVvhY0z6GNjRET9qRU2Fb7+OVvigUM8+AHeHXyOsDP9V6i5c39P/CAQAAAAAAAAAAPwfZ2gEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWN2f7g5E190V989MWRaO+C99wQ7b3x1K5ob9O6VrR3+C0bor3Vj+6L9lrXdEZ7c5/dH+0dvmJutHf1WDPaG3hiJtq78d1ro71vLt4U7R1buCTau2P/2dHeE+3j0V5n89lor/fh1dHezOX1aK/3ZDRX7Tw8Fu2975p50d621Suivfkjl0V7W3sfi/aONA9Geze98Y/RXlV9ItwDOP2sWb452ttwVva1VG3OJdHe4M21aO9b234v2lu++dxor/8dC6O9pR1Ho71vHv2XaK+xJftadOmS7Lnp6I7suWnndPbc/lTXj0V7T+z7UrR3qv50tNe7+B3R3mW3Zh9/1ZcujuZGatnX8it+dnG0d+W92feWblg3Fe01FmZ7K4ez740cfHFLtHdoJnuudnMt+94XwJmiXWtHe+lvDxhoZc+vah3Z61vVspev1c72qir7WU67kb39mtmLV3XOyV6+U9PZ3mAje/+2w4+/qgpfvmjtf0lf447wMSF9n7TTh6xWNlgLX99a/FGTvXzd6fu3nu3Fz4jCT7jx9P1R+HffaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAUWO2P3jOxPujv/i21YejvQc/ty/au2b9yWjv0qEbor0jY6PR3n85lr39rn1uONr7wMruaG9m49po79EvLoj2Vt2wMNpbv3lDtDdvMPv463zoyWhveP5EtFcbvCbaGxqcjvZeXZp9vr3j5ezxeeSa7PNj06qbor1Tm45Hex/suzba27HpxWjv6q7s/fsX37k42tv1oezzA+BM0H3qgWhv8uRbor3a3gejvfF3vyPau/iH50d7fQvmRnujU4uivTuf2hPtLZu/Ltobvvzt0d7zo49Fey/efHm09+7+nmivfnwk2rv85deivWMLs//fbc3lm6O9tRvfFu395oWPRnuf2z4e7bVuzr7XMu9TvxftHfij7LnL/EtfjvbqX+yP9j41MBXt/VzrwmivMfhQtAdwpqiF/79/q9WO9mqtZrRX1Wf9sePsZK9uVWtmr2+7I3v/zrSyr8+yn3RWVX+Vfb0yUMs+Xprp51s1E+2dmMr25nVlHy9VVVUdteyTrhl+EjfHs5+H1ToHor2qnf18cnwy+5g51p39vG5FoxbtVbVsbzp8zKpX2efculr2mJX99L7MNxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUNSY7Q/Waz3RX3zDD/18tLet/ZVob8HcK6K9U2vOjvZ6Wn8R7f3ExV3R3sJt50V71Q2vRHNDc1ZHezesfke098LBz0d7q6bXRHv7vt0Z7V32E78c7e07djjaG5rIPv4uWHNttPcP878Z7Q3sn4z2tr50ebS34pZHor03dp4V7b0wNh3tHa5WRnsXvZy9vvNWZZ8fC784EO1Vn8jmAE5HqzZ+KtqbN/+r0d6DR34o2rvryUXR3gu1P4z23rr20WjvGy8+G+39wbIXo70j35uK9ka//wfR3gULhqK9fzW4PNr76I+/P9rbsePuaO+1TbdHe+/6yex7BU9/7/vRXvfBm6K9pXO+He31XvRgtPenW7LH55/YmD033briyWhvzutXRXtLPnAq2vv+330v2lsxkH0vcrDz3GgP4EzRjgdb4V4tm2tlr3Grln2vtaOe/Wyjo529vl317P0xVG9Ge7Vad7TXrmVvv1r48TzdzH5fR8+perTXHszev1VVVe36TLTXUct+3tSaPhbtNavsa/qOzvForz51PNtrXxztTXVljwndndnncGeV3T+0atnnXCv8nUCNKnv7lXK+0QgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAosZsf7Br6cLoL55+/kS01/meNdHe1Ov7or31F9ajvZemxqO9sx7uifYa27OX79jMudHeyctGo70rnn0i2ltzyUS099qx+6K9c+78YLTXtXJ5tLfhSG+019M3FO3NffufRHt/8tiGaO9fms1ob9Ed2d5zU9m/R+sWXh7tDXxxRbR30cV7or3vrJ0f7V16T/Z4tXb69WgP4EzwvjvmRHsvfu9Xor3Lmk9Ge7f/ymXR3l1dS6K9XxuZivZ+ZPGRaO+iX21He092bY32nt2wINr7lfN+LtpbfMveaK/zrL5ob0X93dHeFUMro73J17uivav2vDfau2fmp6K9/3Dwumjv1csujvZ+dGA62nujeVe097NXHI72nrr/pmjvyMP/JtqrLZr127Sz6x09Fe2Nzlwc7QGcKZrtVrTXbmV7zWb2+wg6Wtn3CqtGLZprV9n3qlu1cK+dfT3QWc/efrVm9ny3Cl++djt7vvvS6P3R3uJ29rOmyWpetFdVVTV/aiDa66rvj/Z6atnL1zyZfczU5nwj2utonRftDTRfifba9ew+ozmT/Xw3fYyp17J7jyr7J73qCl+8Et9oBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAEBRY7Y/uOsv/yD6ix8f6o72rnr+uWhv9coN0V777ieivd0DQ9He3Ha2t2TNgWhv+1Q0Vw0dvDPaa64+FO2Nhe/fBasvifaa67N3SGvbWLTXdWX2+LKhsTTaaw7+p2jv+BU7or3bj70Y7Z0cvTLam7OqGe3tPNAX7XX9/N5or3Z8QbT3zvFbor2Zy5+N9va88LfRHsCZYP7dW6K90eHror13L3o52uvcviLam+nqj/aWHjwW7X35wexr7+MLfhDtdS66Itr7w5PZ11Kd878U7b20bSDau3pZ9v6dec+PRntPP/Q30d4z87OvbX/yZ98X7S3r/dlob/z47mhv8vXs8ersjbVor+OC7Lnpc93Zy3fPf/9YtHds3juyvfE90d47r8nefodGsufOAGeKmXb2eFwPf3/AdDUZ7fV3dkZ7463s7deoZT+LaI5n36tuhs9PO5rh13ud2cdfc+Z4tFc/8Ua0N2/6smivvz/7/kj/TFe0V1VV1btnW7TXHng82pvatz/b23s82nvywJPR3uae7GOw78Z10d7Y8+dEe7vOXRLtre2fF+21a9n9yGAt+zekURuM9jrq9Tf/9+hvAwAAAAAAAAAA/n/J0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAihqz/cEND836R2dlav13or2zTq2K9o5O7oj2urrOj/YuuG5TtLdu675o7+Ha9dHekre+Gu3VF78S7Y00Z6K9mZns42VmrDPaG/znqWjvxPLs42/wkuz1rXUtjvZOzRyO9gYnlkd7CzacF+0dn3g02mtXF0R7q/omo73O8WXR3s6OPdHeVWctifY6ahdGe9/YMhTtAZwJXhzJHjtvev/WaG/B/U9Ee/tfyL4WfeWeQ9HeFb+aPXf5vZHBaO+dP/zH0d7DS7KvRWubfi7b+9t/jvaW/MVno72v7n092jv3tW3R3qPtLdHeqSPZ18rdb30k2ptY/Hi0N/rAdLR3zx1vi/am73kh2vuNd78/2vvulePR3s3v/2i09+g3vh7tPbizHe196uLV0d7+65rRHsCZoqudPX62w18f0F3LBmvt7N+zrlor2jt0Ins+2d8+Fe11twaivemJo9Fea/pEtHeylX29N9CZ/WxoXvUv0d6pnQuivTnLX472qqqqDhx5LNob7Hgx2mvVV0Z7J+vZ58jqI9nP73vP7472Tg6fFe0NbR6L9haPDUd7R449E+01V/VHe4MT2WN+rZbtVfX6m/6zbzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKgx2x/cde5U9Bfvfn0g2ltx8y3R3rp3DUZ7Lx09Fe2ddaov2uuq/0a0d9svZq/vnFNfjvYOHm5Hez39t0V749PPRnsLn3sy2pvYsDLaW3b2xmiv1nNdtDd9cG+0d6r+SLTXW50d7c3Ussf7quuiaK69bzra69s3Fu319w1He5eefX201710Itp77Uj2eLr65nOiPYAzwaK+x6K9J//0YLT37g//UbQ3PnQ42utZ8P9Ee2N/Nzfa+8wFvxftHVs3Hu1dsGxntFffkn1tNjA/2/vBbd3R3m1PHon2/mRJPdrrO1yL9hZd1Yr2/u/nvhvtffmZ7LnG8Ez2+j5xw0vR3sGPvyXa+9pTPdFe92fXRntLrro62vvi72Tfi/zkoYejvT/9pezrg9+Yyv79ADhTnJzIvp7qr09Ge43Ormgv/f0GrbHs9R0YXJDtjUZzVVXP/r3dOX4o2nvs5ZPR3vt6s+fPU+u2R3u9Pc9Ee92tZdFefezt0V5VVdXigRuivXrXhmhvav5T0V6jmT2HPvncnGivPfN6tNfd0xntNV/Kft7UcX/289jVZ2ffE6omrormRhYdj/b6RrKf1w2uffM9gG80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCoMdsfHF0+Gv3F29dEc9WC+vejvblP/3y0d3RwItrr2lGL9lZumvVDYVaa7clob3rRHdHe0gXtaK9ZH4v2ehqbo736/BXR3ry5zWhvsrMv2muN/CDbe/5for1lK98X7bW7s8eX2rF90V73ZPZ4tW3RS9Fe3+SF0V77UPb4V1+cPT7PabeivRUdZ0d7xxbviPYAzgSD1/50tDd0yz9Ge9ubfxbtNV66Odo7ePzyaK/v3Cujve47uqO9DZMHo73XDxyL9vqWrIv2hh6bH+2977rLor324exrxzuPTUV7r12TPdfo/Hb28fe1o9nb7+cWDER7yy/Jnjvv7zwa7fU8+FC0d3z13dHet+7PnrtsuH1PtPfr09m/vxu+kH38vfqRjdHeZ5ZnL99V0RrA6as1Mx3t1brq0V6rmX392K66or2pWvb69k4fjvZao9nrO1plz/9aE9nXU7fMmRPtPT/4erS36Dv90d5QPfvZ2tyea6K91vyhaK+qqqqxMvsY7DhyItpr7V8Z7TXa2XOiIyePR3unPvtqtFdd+kQ01x7MPl7Wvu3t0d6J15+O9voXfz7a66lnPz/tnvxgtFdVb/58841GAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1ZvuD/zx4VvQXL9p6Ito7eOSRaO/XThyL9m7cWIv2Lr9jebTXe/57o72Jrd+J9saWnx/tVRP7o7la56Fob7z/bdHeTPfz0d68w+ujvc6e70d7M3tuj/bqZ98V7bXGvh7tzbw+Ee3tri2K9np3bYn2Wj3Zx9+WW7PH08uGLor2FrT2RntT7a5or3Msu1k+sfWxaK+64IpsD+A0NOes3mhv5dELor3nXvzVaO/lux+N9pb+xC3R3vKjfxztHTz4iWhv8RO/G+2telv2tejMS49HexPn3hbtbd+Zfe1z3kcPR3uXvzIe7W17cSja+96RkWjv165fGe1ddOvCaO9gXz3a+6UTk9Hef7k/ey706InseyM//esHo70jSz4c7Q1/PXs8uORHF0R712wZjfbuGzkZ7QGcKQaa2dcDzfF2tNdqdWZ7vc1or1GfyfZODUR7zb5orqr3ZT9LnDf5dLQ3Obkp2lt8cle0N3zRrD/2npWBA9nre3z5D6K9eYNzor2qqqpTVfbzxDlzT0V7HXufjPZGH4jmqsP9L0V7uzZnzwEXDWWPMV8M7z0+dc2D0V5j9Zps73D2HLWx9p3ZXmf2GFjiG40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKGrM9gdv+NoPor946tqj0d70qwuivavHspfvhvX90d6Sns3R3kt/dn+0t3R6V7S3Y9Ur0d6yXXuivb7L1kV7b8x/Itpb1Lsk2js69lC0N/3iRLQ3dN7z0V79tQuivZfuOR7tvfL8X0V771jcHe3tvHFjtFfbnz0eXPXV5dFe49IXor2OqRXRXmPB1dHexMB90d7M6Hejvar6hXAP4PRTPzg32vut53832rvwr6+J9o49tjPa63jmt6K969Zk/z/P4OCOaG/s+yeivdFPZs/9Vly/LNqbuupgtLf+kWejvR3/lH2vYEVP9lz3yERvtPdH/35etNe9ZkO0d2LP26K9vnkPRHt/eyR7/27PvpVWfXj9gWjvyI7s/fvOeX8e7U2d//5o74rOrdHeqXXtaG/sgVa0B3CmqHdPRXszVU+016yNR3vV8Fg01zk0J9qrBruiuY7qeLTXe2Ik2uvs2BTt/ePof472bp2/JtpbcmhxtDe+7sZor7lnfrT37Wo62quqqrqokf285LXnPhntDTyRfc+lfsWpaG/N49nPc666cjTaG308e8w/vPpItDfy1HC0N3dx9vId7b8w2hs4mX0PbKQn+xqhdET1jUYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFDVm+4NPdT0X/cU/9Gx24/TkiVXR3js/vDnaW3n5xmhvYsmeaO/VP/t6tDe6eDDaO7p3Jto70h6N9i57dlu0t+nd2etba9SivR07Xo722hPro71nH69HexMTW6K9JS/fH+197/npaG90eVe0d96pndHeo/W+aK9/7LejvVfuvjHau2LjeLRX+8g50d7139ga7XX1nhftAZwJ+mtHor1b/u7j0d7hDQ9He+tfnYz21o5kX3sf3NqK9qaqp6O9+XedFe1VtSuiuZcvPxTtrflu9vEyPNqM9ubPjER7AyuiueqdY93R3tNfzp67HFq+K9qbPJE9N+jfnT23uuLjc6O9lQuHo70TuzdFewuWZ9976Pj+ULQ3ePH3or035r4r2uvd9li0t348e7wHOFNMd2U/C6t3Zl/fjo1mL1/fwKw/dpyVVmsq22uHL9/JL0d7r977xWhv5fXZ94Jvfi37+nbX/uz7BZO9A9He0tbuaO/o4XnR3nP/9Ea0V1VVdd1Hs8+RI89n9wXbns2+57J+99Jor3njyWjvlS9ne1OXnoj2Dj3cjvbm1rPH/KN3Zj9/XnvqqmhvamP2+s6Zejbaq6rL3vRffaMRAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWNWf/g4nXRX3zvi29Ee89seD3aO//e8Whv8Yq3R3uTr49Fe+d+cF60t3DNkmjvvicei/Za3+qN9roWr472ZvYdivYaJ6ajveOj2efH2IvNaO/JIy9EeyfXzI/2Fk9kH393nTsQ7V2waDTa2zFnJtr73P0j0V671RPt/czybdHegebGaG/993ZGeyevODva+8x9+6O926M1gNPTtnt+M9pbO/ZMtDf40HC0NzGQ/f8yuzqWRnsXfzD72mzJM7uivb6bJqK9Zj17Ln7k0yujvVbPjmivo/9ktDfnzsujvenrb4r2Fn3x5WhveiT7eNmz+hPR3jlbfjHaW9iVPbdqHM2+V9C54ES01//I4mjvxIa10d70x6eivQVzd0d7Zx1eGO2dvKgW7f3Q0JpoD+DM0ZXNjWffax2qZ9+bb9fnRnu16ezf78Pbsu89zsypR3vzV2c/Wzvxcvb+7d2cffzNf2BBtHds955or3Vl9rOchTuORXu3Tmevb1VV1e6/m4z2Diw5K9pbvTT8+Wkze85Wfyz7ntB3N2c/j937z33R3tWd3dHeltuz71mtu+i8aG98+Z3RXtcL2fc4X1pzWbR3aeHffaMRAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWN2f7gBdM3RH/xW27aFu0NVq1o78v1XdFeffTT0V71Ym80d/k7m9HenHVXR3s3T/dEe5O7j0d71cj+aG54Zjzam5i/JNp77uHJaG/XvNFob/PJ90R75980EO3NP/xMtDf17P3RXvvtb4n2Fu0/EO399Lrs34/1t/1YtPfqI3dHe18+/LVo786HvxLtPbRwKNpbs3cw2gM4E6x+/cFor+vc66O9DVuzr1VG7piJ9jpvyv7/m/5PvxHt7Qj/aVz30ES0N75vONpbtP5otPf1h6aivVMXt6O9d916V7Q3f+wr0d7fjWffK3jfhnq09/4PrIr2phdeHu19+88fivaq3k3R3K2L50V7e694Mdqbc+6t0d4r33o+2vvy09nj3+S7fyjam1qaPVf7meufifaqKnuuC3C6qlfZ16NVI/t6tFnLvj5rNLPnawensrff4W/vjfaWvTf7WWL7VPb2a0xmP3sZWHFztNf/wbFob8/Of4r2qr/cGc0d+1B/tPfan56K9qqqqtbcMT/aWznnWLR3opa9ziPjtWhvwVu6or23vdQZ7e08nL39PjfnZLR38bcXRXvDo9m9wuIPZK/v5q7l0d7Grr5or8Q3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQ1JjtD2649KzoL27XO6O9he+7ONo7/5Xd0d7c7vuivTkrfizae+rxT0Z7l8w8G+3t2T8c7a1dOBDtTa5pRnuHtszN9l44Fu3tbi2K9jZdsCHbe/83o73uDf8z2vv6zFeivZGB6Wiv/8nHor0rF86L9i5sZ5+/p+57NNobyz59q5eaPdHeu8+ejPZe/tL6aO+ZbVuivf8WrQGcno4svyTamxzui/aW/UH2XHJp11uivb2j2XO1yTuXRHv9L22P9mpbDkd7u7oHo72u57PnVit6s68dh5/qj/a6v/21aK/62M3R3M3v3xrtTR3NPp5PLvp6tDeyYFe01/2T7Wiv45qZaO/1B16M9nZW49Heha2/jvZO3Js9Pn9lVyva+5NNC6K9bzwQvr5/+DPR3r+J1gBOX62JWX8MNyv1mex7e+3u8PcR1MeyvfEHornea+dHe636tdFeZ++50V5z/R9Ee8eOZF//DLyxNtpb0bEp2nviwgPRXs99tWjv/nl7or2qqqp/vW9FtDd39ES01//h7OdhXa9lP9DZ82z2Pj51cfY5d3RLV7R38YLsOe/BS9dFe13XPRDtnb3+HdHei6eWRnvzDp2M9i5c+Ob/7huNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAAChqzPYH9598LvqLr/3E9dFee/fCaG9F47PRXnfnv432ThxrRntL5p4f7Z2sXRnt9WxeHe1NTtwb7T39wlS0d9OcN6K935msRXs9/Qeivae2PRDt7X6kHu3d9pvfifZ+YqA/2vvzPUuivVuWTER7Y12ror3dPzIc7S3Ze3m0d/G+L0V7P7J7MNprPDUZ7a1atSXamxrN/n0DOBOsXTAT7Q2vfDDaq49vjvampp+M9pYv/Mtob+LVr0R7C8/K/v+g7rf/UrS36dXPRXtf+G+vRHszfYujvVVHdkR7rz2aPbc6Z8nr0d6KXRdGe8OPHIz2Tnb9fbQ3/5GuaO+rL01Hex/esivaqzXmRXsXLMqe6y7a2o723nX54Wjv+k/8crQ3sCj73tLH5t4f7dXu//1or3rvu7M9gNNV56w/hpuVdlf29WOtlf17Oz06FO0t6M++9917zvFor/1iX7TXN/xstPfY0KZob/8XH472LmneF+3tnMp+lvjoTHe0t+27j0Z759Sy5y9VVVX1jmPR3q7+7Dll9/O7o73JkT3R3hsns5+v1Q70Rnu7r1gb7S04565o7/aN2XOY+Z3zor2ek9m/mWcNZD8PmzM3u5cp8Y1GAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1ZvuDA3uviv7i3e0Xor3B7ulsb/g90d6plcujvUU3PhbtTbx2fbTXt+DWaG/JxGejveqyJdHcpX2XRHv79u+P9s6bn328vDSSfb79VKMz2vv7zRdHe4sOjEZ7zy67Otrb0P9ktPf4YPbx8v6Fb4v2zmmMRHvj61dFe5984Jlor29qT7T3mUOT0d6vX559ffDVJS9HewBngoee3xDtrXpL9ljcN/mWaG/qvOy5xkz4tW3ziqeivVceuT3au7grey6+6Jb50d4lf5Z9rdK152S0N/Sz2eu78wvd0d7+/5k9lxxZm308D2zI/n+35Uc+Fu3tOOfPo72fGlsb7d0ffq9gsDt7rnvdzLJor3/JVLT36Kqzo72LRtrR3o6z3xntDbWz55LjE49Ge3OjNYDTV2dPLRtsrYzmms2ZaG9qTvb61g9ujvb6j2avb7Vu1h+zzsrUkoPR3vpdPxLtfb37c9HeH79+d7T3My+8GO091ZV9vbcy/f0f52Q/a6qqqvqHY49Ee/3zornq3DnZ69zxnqFob+0/nYj2Oi79oWjv0vfcEO09Nbko2jtw7MJob+llV0R7e+rZY/7i7oFob26rK9or8Y1GAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1ZvuDHbc/HP3FHSNvi/ZG9m+N9o5OT0V7569dFu21mhdGez29L0Z7r4x/J9pbdnTWD9VZGegcivYGL9wU7Y1f0Iz2rluyLtpb+mL2/hhfvDDau21HPdpr922O9kaf/f1o79Gxg9Heeff0RntbL34l2tu06EPR3vb7Px3tnXdu9v74wXPtaK9xbDza+6t/uCfaW31t9vgMcCa4sNoR7XV29UR7E+vXRntz+7OvlTs6vhntNU9eH+1ddOMF0d5EI3t9O0fmRnvX/k53tNeYfl+016rdH+2tuXBetDf52bFo79VlG6O9BVdkz007b/vxaG/rlx6M9q5Zdizau+5Ef7T3X3dn3/u6ZM10tPfs3oFob/P8Z6K93nn7o71TD2TPnR+e/H60d9MDN0V7VfbUHuC01a6y7+1Nt7K9Wq0V7XXUatFe52BXtPdSlX290nh+Z7S366GXor2O294a7R25cHW0d/bu7PnBP3Zmz4dO7Dke7XVevDLa+/CywWivqqpq26KfyvaOZj+/v+Su7Od1zUb287Dq352d7S2+Jpo7a0H2nLKvI3vM7zk3e4wZ6Mxevq7WaLS3upF9D3Z8JvsaocQ3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVGu32+3Z/OA3f/0T0V/8nbE10d4Pd85Ee/PPmRvtLb6qP9qbqX8v2jv0QPbyrb/kI9Heqa6haK9vqBHt1eovR3sndz4V7Z06NBztTTV6or15HSejvVeaT0d7A11XRHtTe6ajvb7qYLT3UjO7Qe1avTja2/j8VLT3H776N9Hexa1zor2p65vR3kuPZY8HB8cGor39h7PHg917d0V7AKejB3/ld6O9uVdnXyufvfL6aK/j7IXRXn3gaLRXTe+I5iYPXBrt1fd9K9qrRl6N5hr1wWivY9PaaG/smezzbXx5d7Q39vnd0d7g+vdFe0cOXR3tzb/kcLTX1bov2jvRvyzaa3S8Ee1Nrbwk2vvvv/iNaG/n9AXR3m+954ejvRN7s+/d3LP6kWjv4lXZ917/8dHxbO+PvhntAZyu2q1WuBfNVc3J7HuPYyPZC9g7rxbtvdrKvvc4cWAk2nvf8/ujvU8uWBLtPTaxMtq7s2tftFef/nq09517s4+/qRuvjfbevT77/K2qqhpasCLaq/XNifbmtbLX+fW90Vx1vHcs2rt54aJor7e3M9qbCH+lTfesViuzN17LBida2WPC3Ho0V9Wa2b/BnZ1v/h6xbzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKgx2x/8nwf2RX/xBXMeifa+2nhntPfTJ1rR3u5/uT/aO94YifZWzdsd7W3dsTraGxi9Mto7tf7haO/Yl78X7XUtnxPtTa8ZiPaOHRiK9gbq26O9Vw4vjfbOv+S5aO/EojujvRcPz/pQPitrO/ZGe0uXnhXtffPErmivb+2KaO8rz+2M9q7duSHa65/MPn/3TUxGe/Wf+ni0B3AmOOcX+6K9+VPd0d43tz8V7b395Vq0d2ph9txqonN+tLdg4IVob/zkt7K9X3022pv5wKpor++N7GuVyVPj0V77jXOivTn/16XRXm/P7dFe7b/dE+1NTm+N9g73/adob8kN7Whv7lT28XK8NhbtrftI9tzvPdsPRnt/v/Ub0d7wfWuivRvWvTfaO/o72dcHN679aLQHcMaYzp6/VF3ZXK0n+30EXZ2j0V57qjfaW1NlPyvZNZ49//v8edn3+ucvXRTtva2WfTx3tbKf5Yx1vj/aW3n+3Ghv1fzsE7i3Yyraq6qqmm70RHtT2Y/bq7529jE4vimaq7qa2WNC+Oar2h3Zc9Se8P1xIvyQ7u0MH7PCt99E+Pbr7Aj3Cv/uG40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKq12+32bH5w/SfujP7iDz99MNpbPDEd7U0uXRXtrW8sjvZ2738+2rvy8gPR3lO7+qO9jt1Ho72udd3R3rHq8mhvZEP28XzXuiXRXv38k9HeUNfN0d6rd98d7c2/bkO0t+0bk9Hefc/viPZuefvmaO/xq26N9s69bzjam5n8H9He3sHs7ffUxPFob9549vhyXj37/O29tSfa++U7fy7aAzgdDU8cifa6t/1CtLfz/l3R3gvh1z43b/jtaG9wzbxob7z3D6O917aMRntP/82+aG9oRfa1wHBv9tz0++ccj/b+4/pro73+9dlzv7mXfizaGx9bGO311P822ht/Lftafu78jdHezMql0d6J8Ua0t/fTp6K9R2/6bLR302O3RHvDXbujvXsnfhDt3TD40Wiv9sHs8fnmNdn3WgBOV9OtWX0EN2v1aK2qsu8UVlXHTPb6dpyaiPaajWa0t3+mFe11dnVGe33d4V49e/+ONrPfhzE5lb1/u7MfhVXdi7LXt/t/w/eJtFvZ27BZzx61DoUPWguyuaqrK3ufdGSfclWtlu1NhC9fI/03M3uIrqrsIbWqwtd3ppl9gnR3vfk5oG80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCoMdsfvODc1dFfvGf/ULT3xuD6aG/JzrujvfrUG9HehRs2R3uT114S7d16x7ejvf9y78Zob/HUkWhveuhotPevF66J9k5Mvhbt7em8NNrrG8s+Pxp3fDjaa/WtiPaevvTFaG+6d3e0d/f0VLR3zeMz0d5Ax2i0V6vOjvYWdy+M9trh++P42v3R3tUbatHelv0roz2AM8FLk/uivYlXs+d+9WXZ18qLt41Ee3u/8lvR3px/e2W013HuHdHevh3/EO3dvaIr2rv6yla09/1jzWjvI8PZ9zKOfuPxaO/Qv/vLaO+8PVujvZnudrT3+e3fi/baL5wf7V2/6bvR3vPPR3PVxrFbor39F/5VtPeuH/x4tNf/nuzftxNborlq4VD2eLXoO89Ee1/51vxo7+Z/tSHaAzhd1ars65/sq+WqOpG9eNVgM/tecMdgZ7TXnsj+vV3am71HGvXuaK9Zj+aqRpV9L3iwI9tr9WQf0O2u7A1Yr4UvX/j+qKqq6ugIP+eitapaVss+50bCB9XGdPg+zh5Sq1Zn9vIdjNaqamX4Id2qTUd7HZOzntbMTvj61uvZ9+hKfKMRAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEW1drvdns0P3nDLTdFfPO9gZ7T3/rsuj/Z2Htwf7V14zgvR3s1XXhjtHV/5gWhv+uCWaG/v0aeive5Hx6K9eW/5+Wxvz5eivdZMPdqrrxmI9joWbYj2Ts1ZEe11TmSfb/vG/jHau/9Tj0Z7//zyS9HexrXZTeu5C26O9l55/v5ob3zp6mhv4JLs38uVB26L9vZe+Z1ob+XOE9Hef/rP34v2AE5Hf7Pjj6O9dfuGor2ee/5HtPfX1YFo72OLpqO9xjkz0d6J5o3R3oKnsudCA+dkz9X+7Jl3R3tXDbw12lt48z3RXtefvRLt9b6xO9prXjIv2htYuTna+/WHs6+99z+WPZ7e0bUo2jt+wY9Ge88+uz3aW3l9d7T3rh95T7S3vL0q2usd2hXt/eC+7O33VyM90d55T3wm2vujh7LvfQGcrsabs/oIbta6018fkL14Vas1Ge0NTzejvcZUI9qrd01Ee3317B3c7sh+llPPftQU12yFe7XsE6SrVov2whevqqqqmggfs9oz2V4zfBsebmUvX62RvXwrZjfjmLV2+PbrGMseo9uD2cs32cweU2vN7OXr7crefunvGKp3vHnPNxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUFRrt9vt2fzgjf/6rdFfPFSbjPZur+ZFe8eGuqK9m+cOR3vji6+M9jbOqUd7/YtWRHutvXuivW8e2R7trdj2aLTX39gc7e2a3BXtNUffFu197eD3o71/ddeSaK9vzb+N9r5Tyz5envvN/dFeo35PtDfSOivaq05mj1enVkVz1XuXr4v2/n7x8Whv3cBAtLfkO49Hey9U2efvvQ88HO0BnI4OntgZ7Q1vzb62mBl5Idr7weePRHvz3vdctDd131PR3onttWhvYrQ/2vvQT2bP/XZ27Ij27nnyULS3Ybgv2us99Y5ob8kT2cfLF+t/F+1turoR7V2x4FeivZHrvxjtdfyPi6K9h4eORnvNiQXR3s03/3S017nw3mjvwrW/HO2NdI9Fe0dr2cffp38r+3i54V3Zk+cf++VfiPYATlet5qw+gpu1mfDXBzRm9xHhrDWrbK/eiuaqVvj6ttvNaK/Wyl7hqUb2vfTuqjPa68hevCr88Kums7mqkT1d+9+i2creiFPh61yrssH0MTD9IGyEr2+rlu3NVNljYL2d/SPXEb57mx3Z268z/Pxohf+G1OtvfpD2jUYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFDVm+4PvfW1x9Bf/4Mi2aG/n0o3R3qHXOqO9+rlHor0liyajvee/tjfam//+g9HexRtui/Y29K+I9t545pVo72v7d0V7E89m74/XL7g72tt7cira2/5IX7TX87mPRXv7GyujvVeOvRDtbZy3INobPXQg2qsvGo723jM8L9prXb422rvy6TnR3q512efHnpUT0V73SPbxB3AmaOzInlvdt3fWp4mzsuTI9mjv0ts/FO0NtaajvYeP7Y/2vv5cd7R3/kdejva+Xy2L9nY9eFG09+zzT0R7T3dmX/usOfWlaO8nN2afv/u2t6K9tz6efW+pt/Hn0d7AxruivaWXn4r2uh6+KtobvTh7/9Y3PR7tjez9YLQ3s/Qvor1Tx3882ju8c1W0N3zu8WjvQMdMtAdwpmjXwr12tjcT7k3PZD+76qpnX9921OvZXpX9LHE6+/KsOhV+wDQ6sr2ZVvYJ0khf33r28qVfTWUfff9LoyN7nevhY0z4IVO1q2ww3Zupsjdg9ghYVV219PXNHgSb4T/C6VOimVoz2ptuZ+/hvkLONxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUFRrt9vt2fzgFz7+G9Ff3HPdd6O9J3eMR3s3v94T7b3+4KFo78VFrWjvu9190d6P3j6rh9WsXTM9GO29MHlttNe17pVo77U/fDra2354b7S3f8miaO/sZj3a61naiPYm952M9nbszx6vnpmbvb4rT2afbyPLpqO92uF50d7g9HC0d2TjULR39uHRaG9XO3v/Dh/fF+2tXZLdQD/70pFoD+B09DO/8PvR3tVvXB3tda35TLR34XlvjfaGdh+N9r656MFob96hm6K9ay7Pnps2Vn0o2js2fyrae+3wF6K94aPhc/vP7Ir2Hm6dHe19/JLN0d6KRva12alX90R78yaORXtbf+WqaO+CT2WPz5+/5dejvblfmIz2tpy8Odob/9CyaO9nth+P9r51/epo78Af/2m091z38Whv77eyz1+A09VMK/tZSThXTdaynzXVmtFc1ZquRXv9PdkbsFnLvpdZm91HtrM2HH68DNay90f46lbZT0qqqnEGfl1H+C6pskeYfHC6lr3GJ6K1qlpQZZ9zedmDfvpvyMxo9j2m6fB3+HTM6Yz2suuWqqrX3/zz+zPwEAkAAAAAAAAAAPx/ZWgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEW1drvdns0P/trvvDf6i1dU/dHerm1ror17n3ww2rttsDPae/r1Z6O9V6fHor359Ua011wxFO1NNkeivcWHu6O9fdMz0d7R0ez1Xd09N9rbeXI42uvvqUd7vdNd0d7ynuz9u2s8mqtGa4ujvWbHwWivu9GM9uZ1ZY/PJ8azj7/pednHSzXciubatez90d2Tfb4dPRZ+ggCchs66/tJo7/af/dNor737ULR39pLsa9sXnvtKtNc4uCDaW3T20mhvTzUZ7f3+j7wj2ntyInv59v7FaLR3+K6eaG/xV5+I9u5/5kC0d6B7V7T3S2fPifZqWz4Q7U3VPx3tvbz5rGhvuHFNtHfPD3452hvrvy7au2Dx6mhv5uXN0V7j2rXR3sjb/inaG/3kq9FefXx7tPfogezrA4DTVWt2H8HNWrOV7dVq0Vy8V7XTwazJ7N1RdVfhx0tH9vbLfvJXha9tVdXCwfTjOX59w72qqqrsu/1Vlf20JC99fdvhY3RH+EGYfkyHr241Gf6b2Rl+1rXCz7rO8N+4Wvj26+h88+8s8o1GAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQ1ZvuDu7f3RX/xy/sGo71TPSeivbEFw9HeP209Fe01WvVob2o6uznb3zkR7U1sOxDtDbWjueqFZvb+HW+1or05ndFctf3UsWivVatFeyOt7ON5omM62jvazF6+mSr7eFnQPRLtnRzP3r9T4Y3scPj2m2xnr2/t6FS019UO//3o7432Jkazlw/gTPCRiz8a7X3x1Fejvavvzb62+O/rH4r2pp7LvtZb0GhGewMjN0d7t25aEu3du3VBtPfCrt+N9u594vVo78OPjEZ7w10z0V41+Vo09+rJa6K9/1i9EO2NXfJGtPeh4eybBfc/uSXa+69rsu9VbW1cG+0NXNcV7R0fzj7f7rzkymhveuqZaO/4y9ujvca/vz7au+xvlkZ7AGeK7DuPVdXREX7vMVrL99LBVvizoc5aOBj+rKQKX7zp8MXrDF++8XCvEb4BO8L37/+Od9LT31CSfcclf53TvZnwQSt9TA0/ReKXrzf8N64ZvsJd6b9J4SdIrZG+h9+cbzQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoKjWbrfb/6cvBAAAAAAAAAAAcHrzjUYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEA/L/t3GeQZfdh3unTOffknHNCGgwGORCJIAEiSMykRMuSJVtZdLZqrfXK9pblIFuSJVqWvDJpURSoQBIgSIJEBoEZ5AmYhMnTk2N3z3RO+2G/899b9dYuCnyer7j16+m+6ZxzX1wAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAovrJ3vDsYFf0B9dc/J/RXkfzY9He9svRXLV96M+ivZ3/7VK0990zn4z2lnzoP0d7G585HO1daJ4T7b328r5o78jl3mivbii7KWxtnhbtLWirifaqqqoWL7wS7b3+sU3R3j979DPR3rznfhjtnXhiPNrb2nEq2uvadzrae/Tnb432Fg5l3zN3nB+I9m6tXxDtTZt3W7TXc/JQtPfwv/3daA/g/WZofCTaqx2biPbqw/9/y/DocLTXfXI02hud9Fn25HSF/31ta6K5asbLY9He5e5nor3/suvJaK9qyR6nXDl3V7T3M7dkz9VePpk9L6iqqlo99oNo7+3H7o/2fmbaQ9He/vNHor05o1OivTeypxrVVcc7o70l98yI9mady56rDZ45EO1NjG2I9poWLoz2hmYMRntzZy6L9gDej/7db/1etPfVS/ujvSlN2fO1u+dujPb++MyFaG/OluxnLxObX4v2Pnch+znEzI3ZY583n2uK9vYuyh47zv32E9He2G3ZY59PNjdHe3+9Ykm0V1VVtWF+9hrE7p2PRXtb3vlutDdnLPv5bv2Bn4n2rvtsX7S3fEX2s8n6dx+P9tYsPx/tLTmXfY/b9VOfiPaur5sV7XWfyb6m3njP6h/5332jEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABF9ZO94fGLZ6M/eHr/x6O9nvbGaK92z3i0t/rqn4n2Fl3bEu2dePmNaK9l92ejvcd7H4/2Nk85E+393Ors/fEXu5ujvWM12d+39frL0V7vqezvW1VV9U7To9Hen06dH+3t/+9PR3vbX52I9s7OWB/tnRhtiPbWt6yL9tr2XYn2ptVfFe3dsrQ92tt58LVob90bX4723rlmZrT3cLQG8P5zeCh77rJkrC7aG2rKHqecHm2K9qbNz/ZGTvZEe5092X/f1OFJXwaYlKNLuqO9upHsv2/ztKnR3uPblkZ7i3/2WLS3vWZ7tDfQvyDaq6qq+urJX472PrutO9rb3/CdaO/dRcujvd7XWqO9NYtGor3e+fOivZHT2f9H8qWj4dfozpXR3r4956K9jr490d6mG26N9uZGawDvT5cOLYz2Hus+Ee11r50d7V0cGYz27mhbEe0dvy57frrwB9nPhp6+K3vde/Gs7OPl8F1t0d49z3w72nvmzuz98bGZndHemxP90V7zmeyxY1VV1d2HZkV7W7r+Y7TXcvhStNfXnD1fu9j8F9Fe49ezr6m7Fv1NtHfn9EXR3v/23Olor65/NNp7YHb2fLLl0d+M9rbOyP6+Nxb+u280AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofrI33N7zTvQH39/ZGO0NHhiP9qZemB/tzZlYEu2dv7872nv04aXR3tWX9kR7v/HNw9Fe+3BTtLfr1p+M9h588Ui0N740+/fbXDcW7fXPuynaq6qqWlWT3VHu6IrmqrmjM6K9bw19P9rr3nM62rvnmmujvcfuHo72ml+b9NvhpPT2Zx9/J1/5TrQ3deSWaO+/Xcw+/jreG4j2qv+QzQG838zor4v2Jtqyr8M9wy3RXmP3ULR3oS37vj11Vmu0N2P+SLQ3dr4/2mutOxHtDU70RHtrlnw82nto+VPR3ujJa6K9xsYXor36GZuivaqqql/tG432xo8sj/Z2Xdsd7b22+/lob7Q+ey5Uc+buaO9jKxZEew1Ts4+XU99tj/YGphyJ9sYOro72Gt9+NdobPdgZ7VVfXJntAbwPbbgtex3u9G3Z94p5J2ZGey+1vxbt1RzOHvuMX5c9/5s2L3s+fvdV2c8may9vjvYWLD0X7b0zM3td/q7u7Pn4WOt10d4XNqyK9rY+8/Vor6qq6q9mZj8bOnUs+xy5Mivbq52Z/bxz5sx50d7IO4ujvZuHD0Z7Zz62Itq79feyz5Gam74R7Q3u3xftjV/I9hb0ZM93q2vX/8j/7BuNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACiqn+wNO45ORH9w27w3o71Lez8f7c2csjPaO3NpRrR31cIl0d7MxqZo7/yUPdFe79Ls71vz6ivR3rtbz0V7/Wvbor22+xZEe/Xt2fvj4Gg09//48+x9fO6ZS9He0Kbp0V7HquxrdNPC4Whv2rGuaK9l8/5ob97ihdFe3TsvR3tT3uuN9kZvOBnt/eP35kR72z5yMdoD+KA7czl7nDJvbCDamzjRHO2dbB6M9iYasgej02pbor1jQ9lztaa2SV8GmJSJb2fPXWZtyj7+9p2ZH+0tWjo12ntiMHvcePOeRdHesraD0V5VVdU7J1+I9k61jUd7G8/eEO3dc+7WaO+vlzRGeysuj0R7f/jS70d7v/DQz0d7M2+9EO217j8c7a36ZPbceXz4zmivY/n5aA/gx0H7PXXRXv9E9rrytNXHo735zy2P9l5+Pfve3bD81Whv+c9ljx1vPJw9tm06mD3Wu3NV9nxy2mP3Rnv/ek/2/t2we0u099UXX4j2Prw2mquqqqq2fmdltHfnxjuivcbO70Z7x7dlr2mc7Mleg6j75JRor2dPQ7TX2JR9EH7mJ7KfDe0+d3e098NL2e/weePIH0R7F7dn9zLVAz/6P/tGIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACK6id7w02NG6I/+PT5OdHeixe+GO2tWjjpP82kzJp+bbTXXY1Ge3WjO6K95lf+Ktr7q517o71jr9dEe4vXjUd713SMRHs3/WBPtDe6Ovv8+NVF2cdfVVXV3pEl0d74tHPR3pdPXYz2HtmUvU9uunQ+2vvjtQ3R3m/+m8XR3r9a2BrtnT+bfc3fdtOL0d7n9twb7dXdOj3aW/72C9EewAdd98Er0d67q9qivXmD2WP5V3oGo70NDdOiveUdHdHe4trsuUbL4ES097V726O96eezxxUtVw9Fe0/uORbtPbLn1WhvWcdt0d5I8w+ivaqqqprrl0d7z01dGe0dPdgb7TW1zo/2/vlLp6K9LSuy10f+rxfC16uOPhXtrb6wP9rb+1NXRXv3vD4v2lt6fzRXTZyblQ0uyOYA3o+uCv///ouP90V752ZkP6ubMud70d60q7Pnp5+4Lnt/nO66EO1N6Tsc7XVcmz2fHOw6Hu1teSJ7bLakYUa013DxdLT3dvPlaO97/z2aq6qqqlYty94nC667Ptr7QvON0d6Ll2ZHe//z3a9Hexufa4n25o1Mifa+vTV7zeC9aizaa7znE9He9a9nz0+7h++L9nYefzfaK/GNRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAU1U/2hlOufSX6g+cO3xPtPTL94WivpuvlaK+ttj/aG7gyFu299mpXtLfz2f3R3hfm9UZ7F6/J/v2+e2Eg2hsfbYz2zk/NPv5+/6ns/bu2ZTzaq6qq+ui07L9xR+dItPfP18+M9uofWBDtTTudfc5t/trxaG/jiuFo75+MXx/t/eLS96K9dV3/Jtob/Nmno72GF7K9kzf1RHurojWA958l1YFob07rddFe8/o50V5tf/bcZU7N6Wive2xhtDdzMHus/PW92XODdePfj/aWd5+J9rb0H472bt816csokzL9QHe0d6zh9Wiv/chotFdVVbVqTvY5/MkzN0d7DTdujPb2tDdHeysfXRztnX9mS7T3d8fPRXtT6jqivaYlNdHehm3Zf9+iO9dFex0NfxHt9XRnr2VU1f3hHsD7z5HXs9f62x8cjPaaj7dEe31LNkR7H5n5lWiv8Wz2fGjh9dkrjxNLPxntvXfm2Wjvye1PRXsdd02P9ta+1RftzW3JPj/Wt9dFe10N2c9xqqqqBi9k/4azX/hatPfq2Nlo78jsB6K9f7n29mzvaHavcH3HwWjv429lr1lN/PKt0V5nS/aa0OtLGqK9H7y3K9pr23sq2ivxjUYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFNVP9oYth5qiP3ho4DvR3p5nn472hm+bHe11vrY92rvQ/sfR3ltvvBbt9U2cjPYa1i+I9t451Bvt3fLwWLS34vgN0d4rl96J9qodp6K5G65MRHtVVVUnfrk52vvZ47OivZmrHo72BuZfifYunno22nvm/Nlor3Vj9v79wtNvRHvzu+ZHe99c8S+ivVf+8dpo7+4N2fv3SEf2Pfgj0RrA+0/dsg3R3vTu7LHt1t4z0d7M6dnjgJqh7Pt257ED0d73z2TPxbec+/1ob/Gyu6K9K6t3Rnszhy9Eeytvyz6eVy7ujPYuN/dFex3PtUV7VVVVw7ffEu3VLFwX7TXVrI/2NrfVRHsDg8ejvY9vXBHt7ZvbEO21f29atFfT90q0d/yqt6O9sfbs9aBqx0g0V3/1mmgP4MfBqupQtPf289OjvTV3X4r23us9Gu0tGV4Y7e1acHu0d91AR7R34eR70V7NvOz57s833hHtNX38/miv/7Z3o73RPduivXsPPhDt9XZ/P9qrqqp65N7sOe+Jk5+O9gbPZ895u2aciPZqb70p2vv2gpnR3r4D2Wskh58bjfbq+rPX1DrnZ9/jVjdnHy99N/xmtNfend3flPhGIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACK6id7w5O1r0d/8M5/uTjau7y0Kdr7r63Hor1H25+K9r534HK0t+uvu6K9u+sfjPZqTyyI9n7lzmejvb1Lr4/2pi+/EO09vL0z2huedzza+6OTE9FeVVXVV3vbor2J5X3RXs3T+6K9gYtj0d7Mmdnf9+6RaK6a9/JAtPelU/3RXltT9u+3r6Ex2utv2RXtff/czGjvK9OyPYAPuomzb0Z7u7tao7192/ZHe/996Ei099lPfyHaW9LREe093f+H0d6vH//JaG/qzpPR3swZ2XOXtqnZ47yp53ZHezVLs8c9HYevRHsHFmb/flVVVetHz0R7E8Nbor365pujvZq+o9FeXWN3tDd0/mK0t3yoJ9o717sn2rvSPxTtHZ/IPodb0/9P6Nx7o7npNdnXaIAfB1PHlkZ7K68djPbODl2K9m5+bXu0t+iaO6O95qYZ0d7sqYuivZbWJ6O93uquaO/EF3412ms5Px7tLT2ZPTbbt3JTtDdjNHt95F8tyX+2dqr16mivqTv7+X3Lkuz5y5sdN0R73+7qjfbaV9wX7a29IXs8P3XVaLR39m//R7T3S413R3uPzX4s2ptyeGe09/z57HtwiW80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofrI3/OnfHI3+4CvdT0R7X7rhw9HevzyyOdr717XZ33do2dJo7zMf7o721j/ySLTXvnB3tFdf94+ivfXTTkZ7lwbORnsz67LP3xObTkV7/2B4MNqrqqp66+REtPfg4vZo79ziH0Z70xtuifb2ti+N9j523fFo76lnL0V7p6rxaO/4YPY599hIdhd86FJHtHdV08xo79+/tSza+1a0BvD+881d2eOUvrHscco9mz8d7XVcjOaq1670RntLVi6N9j5V+/Fob+GqWdHeRE93tFc3JXtcO7uuJ9qr618f7U3MfjHaO9f8ZrQ3vakp2quqqhodOh/tNY9nnyMTNS9He/UTn4j2amr3Rnt1K5ujvctbnoz2vtLWF+0d33ZttPf556ZHe+umZs+d62ZnzyUP7pof7W1cEc0BvC+9vHxHtHfxcmu0N7V+abTXPn53tDcyK3u+u759WrQ3OnIi2hu8vDTaa53VEO3d2DAc7b3YGM1V/WtGor0fNNVFe792sj/a29J+R7RXVVX1Tk32s5LPzfgf0V7/koejvf/YeWu094eXfzva+1b24/Hq2rsmPQ2ZlFV110R7Mx+bEu11fin7+X3Vlr1m+vLg6miv663/b79jyDcaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBUP9kbzhs6H/3BH/3cF6K9avmSaK65bmu09897jkZ75269I9o7vPh/Rnsf3XAh2rvQ89Vob1lN9vFyZUt3tDd75apor2/Bvmjvd5Z+Ito7N/XNaK+qqqq9riXam7jnV6O9zn1/E+3Vnnsn2ls996por3Xz2mhvevOL0d7Df3022vv6pfFob+LszGhv+7y6aO/E5a5ob6KrJ9oD+KBb3NcU7c258+5or33O3Gjv5qbRaG/druyxaF1PQ7Q3o3lNtNfQsDPaq50Yi/ZqaieivbEjp6K92utuiPbGhz4S7U294fvRXu3An0d7VVVVo9OmZ4N1C6K5oZNvRHu1Hd+M9saHh6O9S7Wbo73RDb8Y7Y19/clor+Hc09HeyZZfi/ae3Jp9Tb2wO3utYNant0d7G6vfjvYA3o82XLsi2jt7LnsdbsGb2euYO1bVRHsrxpujveH+7LHUSM3j0d7UhfdGew2XO6K94dpJf6w8Kbc3ZI993uk7Ee21H5kf7f3lgo3R3pzdu6K9qqqqOYuz1zQGOxZFe68+n/1sbc7PdEd7M5pvjfYaJrLXNO7Zlf18vPfCmWhvVue6aO/fr8w+Xl6dmt0/3LFzZbT38790T7RX4huNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACiqn+wNFzaejf7gV/Y8E+1dfXl9tPd7F/dEe7OmjkR7877VFe0teuiFaK+xvynam9a2Itob3Hs02us7siPaO9D6eLS36PIXo73DL/VFe8fPXI72qqqq7vqHN0d7Ez3XRXvjdb8X7b1ysifaW37gO9He/rnTor3H7pr029ek3FA3Jdp7/W+zj+nBBYPR3lUNs6K909VAtPdrJxZEewAfdFsH/zbau6rnV7K99uy50ImmE9Hewqb50d7Bd2qivb5l56K9Jc1zor22hY3RXm1f9lzjwpGt0V5T96For2Heqmivtu6j0d7u7X8Y7VVVVa1t2xjt9XcNRXsjo6eyvanZc6H2VTOjvYnR7dHe8MCN0d59H10U7X33wjXR3olpb0V7N1/996K9KfdmXwMX/nb22kP1WDYH8H60t8oeq1xbl/0sbGzj4Wjv7qnZ65h1w8PR3pHd26K92tXZ85fm4d5o7+Kx16O9C9+ti/Zmhc9Pe65kj73HFh+M9oZ3NUR7zXMWR3tVVVXL67N/w6PnWqO9wY3Zz5+/vO1KtHf33Ow1sGO9J6O9b+24J9prejB7zWpZ/dpo7/Q72WtWNy29P9qbff3maO+p7iejvRLfaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAUf1kb7i2bUr0Bx85ejLa+5Vjc6K9+7vqor13r5oW7b1xdGu0949v+Mlor/ba66K9pT0bor3Bs9ujved2b4v2lsxaHe2NLH0t2uvcnL0/njtwc7RXVVW17GR/tPfDV/5FtDey63y0d2DRcLTXvD37Gnj9nIvR3tFD2dfUprPZv9+q1RPR3rNv9kR7w9V4tHeppTXaa57XFe0BfNAtmntVtLdyWk20t7sm+z5x5+Gl0d6V6e3R3unh7HHUzR0zor3aluxxQPPo9Ghv8PwfRHv7mjdFe0vmZe+PBfOuRHsj5/qivbk/8Wi0V1VV1X3mWLT39v4Xo73la+6I9ibmNUR7e05lr8+tmNYZ7V08/3q0d2ooey508fahaK/pYEu0N7Ipe71q3pZF0V7LLY3RHsCPg99+5YVo7xenrYr2Hli9NNobvLI72ts5+vVo78r4ndFe7eN/L9r72/X/Idrr3bcu2rv62L5or2X58mjv4Ws/Gu2tHDkb7X11ONvbe/HuaK+qqurUaPbz5797c/Y161zXI9HeyMbL0d6eU/ujvTeyp/jVHSu3RHsjexZGe/92Tvaz3Q/Pyn7+PGtx9vP7i6dHor07p98f7ZX4RiMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAiuone8PXZizO/uCaNdHeb85vjPYG/v7GaO9k7f5o78Q3DkV7g6//VrQ31P7paO+pSxejvTV7xqK9u9b2RXu118yN9prqPhHtjbV1RHu/fs3yaK+qqmrw6KJor2HP/x7tvTtvXrR3d2v2MThcVxftzbluabTXdvBctHeofiDau/Ht7I73m32j0d5Yy3i0137mcrT3O2ND0d4/iNYA3n+uuu1j0d7MKdljvXmt2WPv/pamaO9QbU201zWrJ9rb0Dsc7a2YMT3a6+49HO31Dr8Z7W2c2xntvdWTPS6rzm2K5mbO64/2mmbeHe1VVVVNZC/fVBunvhLtHerKvia0912J9lo6Jn0pb1IG6luivbH+S9HewnkHo732r2UfgGeHzkR731t0a7Q3ty57PbJtz+lob0O0BvD+9InDb0R7w+9mr5t1rFwY7R3p2hftHb2YfbfYOOPRaG//9ceivYe3/0K0d2ywK9pb9GD2/GpK073R3nj98Wjvr585G+21dg5Ge29tzT7fqqqqFj6U/fz5f7y4INobHMj+zve81hrtvblofrTXOPpStNe0MntNaMWS7DWr/2NLb7Q3eGJatHekN/sa+M0L2d93ZNtz0d5ThWvOvtEIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgKL6yd5wR+O90R/8qUfWR3s3LDsa7R2eOj/a2/X8wWjvuq6maO/oY1+M9mp6/yDaO/WNA9He3roV0d7n7/tEtDd49rpob3TkeLR3+tnfifYGFvxWtFdVVdXX+hvR3smZ56K91S2ror1LZ8ajvVmNI9HemesvRXsT32uM9o6MjkV7J6dme7dcaYn21rT1RXu7OhdEe3vO1EV7AB90tROt0d6Mxuz/jzLcXxPt1bVMRHu7+6ZFe00Xzkd75+d2RnujNQPR3tjwkWiv782l0V7V2RvN9W4ZjfaGal/I9h7sifYmerLnBVVVVe9eOBbtnR7YG+0tbZsd7e17c9KX3iZl4/W3RXv161ZGe00zs9f7jnStifam3/50tHf0BzdFez+/Inv9cHjFomjv4okL0R7Aj4Ntndnzq/YTW6K9jx7IfvbyYs3haG9G7e3RXlfjqWhvypns+d/im7PHorc13BntnZ/oj/YOdn012jtzOft42dDybrRXe9UN0d7ozdnz06qqqsE9M6O9bYNvR3tzpt0S7fVs3hXtnfxfX4v29s2ZHu2tu3lGtLdy+7xor/HO7O97pTP72enlNy5He3c8MjXae7Uz+9lziW80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofrI3bOjfG/3BN5x6MNr700M7o73Nm6O56tGLq6K9+3+jLdo7/tr5aK/uI5+J9m79tVejve/92Y5o7/GXvhLt3fzhl6O98foZ0d6Uus5ob0/bP4z2qqqqfvCH2efIhqWj0d6RiT3R3ok3x6K9ofE50d4//Xr2MXN8RvY5fPm97P37E/PXR3uHx/ZHeycuZu/fI+0t0d59HddFewAfdMtmNER79SOTPk2clK+duBTtffRK9n3nkezbYnXiYmu0d2zHt6K9nQ8uivYWnumK9l68kj3Ou3mgP9pbujR7nnFyazRXfe/3Ho/2VjcORntVVVU/OD4Q7a1ZPxztfXGiN9pb+NapaK/3Yvbc6oHr50d7p7uzz+ETZyeivds/+tPR3vpPZ9+Daw4sjPa6jvdFe9Maso8/gB8HV2/JvhZf+xPt0d6BvmnR3oNbsp9F/Jtrj0Z7n9yXPRZ9Y/P2aG/u8eyx7fBY9thi3qzs36+jLntC3nht9rPOvut+I9qrO5X97K/l3O5or6qq6rWdH4r2Zoz+SbR3oSt7jr9oIPsa0zkn+5r/yZaRaG/r949He/d8dna0V9vaGO31rVoX7e34k/8W7R26sjjamz9yKNqrHvnR/9k3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVD/ZG65fdnv0Bw8+0hnt/dyUR6O91156L9pb8wvTor1Lf3V9tNf+id+J9mo7Hon25g5fFe09+MiiaG/8zJVo7+TQULS3tjb7eB5a/Ilo71PX/lG0V1VVtfLjPdHeM0dnR3sPr54b7dXsOx3ttdyWfY4cmzgS7Z3pbo/2vnxpONp7aqA72vvIrOx7yNjg+WivbvhitLez5kS0B/BBV9tcE+2drCaivXvmT4n23jjQHe0tmzUe7bW/cynaq1v1XLTXMvp3or2z7ZO+rDApD6zP9ma2ZY+7D7WvifbWLf2baK/uvexx44YbG6O9qqqqNa13RHt/te9UtPe5ddlj20f+14Zo79QNM6K9mgP7o70pby2L9ra1r4r22i4viPbuaci+Zy5amn0NbDh7MNp7auJ70d5d1b+L9gDej7ZU56K9vX+wOtr7/N9ZHu2du/apaG/dtpuivfpHDkV79xy9Otob7N0d7e07tSvau37DwmhvtHZPtDer9nPR3pUL2cdLf0P4/t05GO1VVVU9tfdPo721982J9m7oejfaOzU7ezz/mauy98nTp7Ln+Hdfl30OH7uY/SxxxYUj0d76hYujvV96LPua/8U//5No740l+deEH8U3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVD/ZG742NiP6g2sW1ER7b7x1MdpbM+PVaO+rXzof7X328UnfdZMy7dLmaK/nzrPR3vJrFkV7TfXZx8velXOjvdePvhLtbfhub7S3a/YfR3st387++6qqqhruaYv27lv3iWhv+Ilt0d7h2s5ob+WHZkV7+0/0R3s7nzwT7XV2jkZ7Oy5lX/PHRrKv+R++b120t+z5Q9HeKwNj0R7AB91I70i0VzejOdrbXj8c7dXWjEd7O765K9r7yycORHuf/fwXor1Tr2+L9ja1ZM/9Do3URXvvjXVEe1sWr432fml8U7TXXJf9+9Xuey/aq6qq6r/uZLT3uTnt0d7FV6dGeztu2h7tXbN8KNqrqbK93jVPRHuru7PPkbNdLdFeb0/2PWngoQ3R3pSJ+dHepWXZaw8APw5O7d0b7TVvmhntHRzKXrdt+mb2OuaZiex11he2Zo8d/96Jt6O9yzdkr8svmHlttNfYnP3cZfbUKdHe2OXj0d7XquznEC89dyTa++LpU9FeVVXVlDX3RXsL512I9kZ3Xhft9Xz7a9HemU88EO3dtXl5tLdx7oJob//5Y9He77/0jWjv84ezrzE/bHo62nvskdujva6e/DWcH8U3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVD/ZGy7bNOmbTsqGvdFc9aHG7Gbq+JuLo73FP/hytLe3YUa09403aqK93xkZjvbmji2K9vraRqK9FW8/E+39Yvjft3uwN9pr3toU7b2zJpqrqqqqznxtdbTXcftfRnszlrZGe61Dn472nnn529Fe0xP7o70TA1eivQuD0Vy1oj77Gl03FN4FP3k6mtteZV/ze8ez70kAH3QXJ8ajvTlDE9HeVbV10d7Jkey/79Th7LH8ok3ZY/mBpjnR3pVX3o72Lm9sifaG2rLnGk1vvhft/WzP7mhv7+ns87dhJPv329tyJNqrqqpa+EL2BPC9uZeivb6nj0Z7Y6PN0d7353w32msfnR3tHZu1LtpbtvyFaK/pxEPR3tZbeqK9ZW9l30MaZ2ffM2/rcK4G8P9Wz+Hs8d6rTQeivbWd2df2F44ej/Y+vzn797tx3Y5or/HOX4/23n43fL52IPvZ5E11vxbt1V87M9obnntTtLfoxez1ghvmL432/qJ9erRXVVX1aN+SaO8j0x+N9s7+6sFo79T2hdFe62vPR3tT59wW7Y03bY32Ro88Ee2dOJG9hvPeRPaz4u79H4r2Oh7Kfn5/b9/UaK/ENxoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUFQ/2RvOr6mL/uDnv/FetLd+zUS099KJA9HesqU3R3vf2b0z2ptxfnO096UnvxPt7XrxULT30P3N0d7E2mnRXv203mhv4JYZ0d78nS3R3ty/81S0V1VVNdr/p9HemVNvRXtDH86+Jky95kK0t+f3e6K9bzRmd621fR3R3tHe7O97oS57fyxpbY/2pjRm3zPf6m+L9jbUXYr2AD7oRhtHo73BS+PR3uXWmmhv13j2fWLtjOy50O5n/ybaG53/QrQ3rXNutDe479Vob8aC1dHe/I9lnx8jI1dHexf3Z88zbrxqSbRXv+Q/R3tVVVXN05+I9oaePx7tdd+Rfcwc6Zke7Q2+dSTaO7TmYLR3b8/MaG/rf8qeWx1Z9ni09/CGz0Z7l5dnr39dPp+9nju6+5VoD+DHwcDHV0V71/QPRXtHz2avs55vbor23u04He1N2XpbtHf2w9n3xultXdFe7/6L0d6hjuejvWVD26K9Jweyx7Y1rZejvWunNUZ7AyPZzyarqqrOjWc/Ozg3cSbamzG4KdobH34x2qv56Q3R3sVX/220N2PuT0Z7Nd+5Ptq7bzR7DXHhxs9He5fnnYv2pr+Uvf7Qeib7/K0+86P/s280AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofrI3vO3WldEf/EzPsWhv0cyRaO/Tyz8Z7e3buzXa++3ls6O9rx9+PtpbVi2O9qaOHYr23jldE+0tvC272ZszvCjam3ngcrQ3dMu10d7JkWeivaqqqqa/2BDt/Zdp26O9ectPRnt39rdEe8uv/slob9YL/zHa29kxFO1NHZmI9gbqx6O98absa8yLs1dEe3dd6Yr2/rYve38AfNAdGJn0ad2kTGscjfZWNWTfx2atXxrtDbY3Rnvr+/qjvT/flr0/Fk1pjfY+vCh7brV4//5o7/LpGdHe2dZt0d6SzoZo77X3jkZ7dVP+Otqrqqpac+GaaO9393wr2lt1PpqrPt57Ltr7zw3Zc43Bp7O9r7dlr391Lp0W7W340Lxo767p2euRV061RXttO5+I9v5wV/bayMeiNYD3p08OfiHaW3qsN9o79FD2+PGLV6+K9k4Mb4n2Du/MXpef0jUn2ttzeW60t/vW5mjvpuvWRnv7nx2I9s60T4n2Rt+YGu09O/hitPfoqvnRXlVV1ZEV2Wsk3z2XPacc+87r0d7FvcPR3sDXBqO9B3/hn0Z7Yw0PRXvdnz0d7W08VxftDa3M9pZdyD6HR+bfFu1dvHZmtFfiG40AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKKqf7A2PPf6D6A++ZcOcaK/56PRob8a81mjv6psei/auHH4l2vu5e09Ee8defT3aG1icvT+OLzwd7Z35o4Zo79Ly7AbwUzsuRnujs5ZHe1u3/Kdor6qq6tSWG6K9D/36eLT30Oz10d5f/OWFaG/mmd+N9obPDUR74/3RXNVTVxftLWiYiPZmzuqM9oa6j0d7V8Zbor2OvrZoD+CDbvPzXdHeyIPLor2qNvu+OCv8vn1l8cxo76ZPbIr2Vhy/FO1deu3VaG+0vznaG2i5HO39+fcPRntrp1wd7U3/8GC0N3bygWjv0ttfifaqqqoWdi+O9hbN6on2Hl2SPd/9R49nz8fn9/RFe+PD2XPdqi57vW/GT10V7V1/y3XR3vDSNdFe26nsa8LeVdn7t/mFFdEewI+DlnMvRntP/MpN0V7Hn52J9j4Wvo55x40bor0Dn74n2jtzMvvZZMf3n4j2fnJZ9rOm+zb3RntfaT0S7bVvHon2dnRmzycXX85el788nP1ssqqq6sED/yva+/7Yh6O91kPd0V5fR/Y5csdV2WtCtTOzj5n9Z09Ge7esG4v2htb9ZLT32i9nr5ku/tRPR3vjH8peY9o1/q1or8Q3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVD/ZG46t7Y7+4ONTO6K94aVnor3anjuivdHd+6O95k/NivYWvPXJaO+772TvjyMTe6K9pVPnRnuzrpkW7X3r3UPR3qfuqYn2hlY/G+3dfCy/edz68DeivSXfaYn2XruxLtpb1ZJ9jpw/NhHt3VOTfQxeDj9kLtaNR3sTfdFcNdCdDdYt/lS0d/zg30R7jdNGoz2AD7qJqxujvS1HD0d7H160MNprq88eCIz0R3PVkmpKtLd8wa3R3p90/zDam9W3Mto7e2B7tHflyqQve0zK33Tvjvb2PZ897h4f/t1or3Nf9vlbVVX1g8H/PdobPjwS7b30ofeivV9e2hnt7TrSGu098NGmaK9qvSmaO3DTL0R7Dcez5861K69EexMLF0R7l3a/E+09eG/2ehrAj4POe6+O9v7+U93R3tK2n4/2hn7qSLR3aHQo2ls6dX20t2Fgb7TX+guLor2JZy9He1uezx5b7NmR/fvN2zs72rtuaW+09/zlI9He/tOXor2qqqrO3uznnXWdJ6K9y+tvj/Y2rVgS7d3ZmL1PTnd+IdprGZ0a7Y1eyJ6PH7mSvSbUdmv2NWvinew1ydOrs7/vDe3Z95AS32gEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQFH9ZG84Z+uJ6A/eeKIx2ntxWTRX/cT1NdHe4Izs73usfjzaq5uX/ffN/eKxaG/tlolor65tSbS3fMnKaO/EpmnR3pFnn4v2fvDdl6O9+2o6o72qqqrlC7LP4f9z55Vob+KFZ6O9/onWaG9V81i091b2Jat6pC17/z7eFs1Vl05n/32fae+I9gZ7n4n2ltT2RHsTNbOiPYAPuoYqeyz10Fj2fezkcPZAoD37z6tGuvuivctD2f+fZ7y5O9rrfHh9tLf/Ky9Eex03fDram71gf7Y30BvtNex9M9p7KXtYVs3pP5MNVlW1qDN7fv/mWPY51/dOf7S3fzT7Gr2pPXvut3sge+z94E3Zv9/55uxzZOeM2dHe1B3Z58ja9uFo795p2ZPdrtrboj2AHwfTlt4S7b098l60N/+qOdHeirG10V7n/OzvW43Pj+YGW7J/v5Gp10Z7DQ99Pdp74/ns5wZN0xZHe7f3XIz2dnWdjPY+9sDCaG/OxeyxbVVVVc3K7DWcO/qzx4+L1qyK9uqPz4z2pracjfYWtmWvaVyemX2Nnnj1hWjv0GD2/mi5/sPR3sT68Gvg+ex70qEre6K9DxX+u280AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofrI3XLnpF6I/+JWl3dFe35mT0d5z3cejvdtb50Z77T3Z3/fo7t3R3kfX/XS098RnmqO9NWMXo73+9nnR3mdPXIr2/uj0mmjv/PDRaO/N2oFor6qqquadxmjv8umhaO9c/ZRo78brR6O96kx2h7pyfkO0V13IvqZuuph9TV29YVa0t6b1lmjvXO9T0d7c+e3R3sVl90V7AB90TSumRntdPRPR3plz49Fe88zsccqZjsFor74x+744uiN7rvGp638i2vvSZ++J9jbNOhTtXd+7LtqbeTJ7XHugJ9s7tf1ytHdly5For6qqqr8t+5yrq8n+Dac1ZI/l59yZPb8fvzIt2ruwoCfaO/rGh6K9q4+uivaWXNcX7S3orYv2Bvr2RHs1K1ZEe7XHr4n2AH4cTL0m+9r+60tWRns9V7LvjdXK1mjuwivZ89Pxac+He9nztWkD2b/fWO/Ho73bb/patNfV8mi0N9C+P9rb9523or1F3xmL9s5PzX7WWVVVdd/07GN6YunSaG+g57Vor6VtcbR3fqwr2mtr/mS0V3v6lWhv3/TsZ7HL92+J9r67YnW0N3d/9vx0+6Xs73vvxf8a7VWbf/RrtG80AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKCofrI3vOHms9EffPvlpmivd+y6aK/uXFe01zNvarRX0/V0tHeoZWu0t/dPX472TqxaFu29ef8/iva+cDr7/GhtfSjaa/jcxmhv8A+y9+/F4TeivaqqqneGh6K92bPnRnt3TbkY7dUOtkZ7286PRHsTYzXR3gsTJ6O9kQXZ3e2e/ivR3tb9b0V7j9zaFu29+dZgtLfl7LejvZ+P1gDef9rHR6O9DQ0T0d68RY3R3vCp7PvO5Y7OaK/l4Jlob3hhQ7T35F+9He2tb3kv2nv1mlnR3md6s8eh5w/ujvbqhrLnulcNnYj2FqzJvr5UVVXtn5u93nJpb/Y5cmz/hWjvjTez5wY3TA8/pjeuifaGlz0V7S0e64j2rup5ONrbUT892mtc0B7tzT+ZvT8GmqdEewA/DjpeaY72Bi9kewcWH4j2Fp0ciPY6mrOfvVx+fjzaa7n5VLS3bW9PtDd34ofR3pz5H4/2Fkw5Hu39sDod7d0x4/Zor/ZjR6K9BU3Zz3GqqqqWLVkX7TWMXIr2DvaPRXu7e74c7S1u+blob6w6HO01tF0V7dV//9eivb+Zcne0d/qN7Gv0xA+zn2cP3dof7Y3N/9lor8Q3GgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQVD/ZG148fyH6g2ePd0d7rVM3RXs72pqiveub3o32Ts1rj/Yuzt0Y7b32SF+093B3Q7TX/7U90d5f3bgw2vvs+K5o7+Br2efv9vFT0d76puzjuaqq6mOL+6O9b9f2RntbTkZz1fLmy9HeqdHxaO+ekbpo79jF1mjvvVND0d7UddneY3Ozz+Gx89n743Bn9j3z9Pj5aA/gg+78pez79qzG4WhvoH8i2mtr7Y72bu3Pvo8dbswe6L14/r1or31TV7T39W9lz/0++sOWaG/fZ2uivaWdK6K9772+I9rrmr8+2ltxW3O0V1VV9TP9q6O9p2YsifYmpm6N9p5ZmT22nXooe/58++mPRHvz6tZGexfrL0V7bVcfj/Yuz1gU7a2suybamzi3Idp7Y+lYtHdntAbw/rT4/PXR3s7rvxXtbT6bPV6+3Lk52jvbl73uXXvTwWivY9totFdz05Zo77VvZd+7j095PNob3jk72ptz5JVob2DT/dHehobssXzj7Oy5VVVV1fCF7GdrDY3Zz0qmXByJ9ha1/lS0d6F7brR3pXXSU45JaTrzXLT3ZuPt0V7/uWiuur89+xp48OHse1zt+exrwtBL2fPd6rEf/Z99oxEAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARfWTveHbhzujP3jd0Ilor7b/dLQ37eSb0d7xe6ZHexMdV0d7j8xaEe1dP9IS7dXVzoj23l7VE+21/Pn3or3ffqw72jvx9oFob9GVsWjv+NQr0V5VVdXQmdFo73z/RLQ3ND4S7XUOdUR7H5+3KNqbsjb7mjDzSPY1/95rN0R7HYezO96Li7L377kL+6O9nRPHo72VEw3RHsAH3Xjf2Wjv7d2Xo725Q1OivWpNXzQ3MD17nFIzcibau3tPY7TXs3pztNdyV120t7LrXLQ39HZbtLdnc/Zc6HTL+WjvziPZawXjdeujvaqqqoNT90V7A4ffi/bGJ45Eeze/Oi/a61h5VbQ3um5VtFczFM1VH3rg5mhvrH5mtLewIXtuv/9ATbT3Rl/2esua9/482qtW/JdsD+B9aLQje+zTVJO9jrl7ffZ4+WRH9r3s0cEl0d6Z7SejvS91Ph7t3fdm9vx024XD0d5nT2ePbbs/kr3uPeOpOdFe79Et0d6+CzdFe0MN70Z7VVVVYyuy98mpxdnf+WcWZI9v93xjd7RXv6w12ps4+Fy0N+Vs9hrTzEXZ+7fmruw1v5bj2c/Clp5aF+2NndgZ7e2a2BbtVdU//ZH/1TcaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBkaAQAAAAAAAAAABQZGgEAAAAAAAAAAEWGRgAAAAAAAAAAQJGhEQAAAAAAAAAAUGRoBAAAAAAAAAAAFBkaAQAAAAAAAAAARYZGAAAAAAAAAABAkaERAAAAAAAAAABQZGgEAAAAAAAAAAAUGRoBAAAAAAAAAABFhkYAAAAAAAAAAECRoREAAAAAAAAAAFBUP9kbPrB4QfQHD25riPYOP/2daK9rbmO01/ely9He7EcnfddNysnRumjv0pYl0V79+v5ob1tPNFd1fezeaO+m/r3RXucD3dHe29/NbhRbzu+L9qqqqt4aG4v21ozMj/YG5gxGey1XWqO9av5ANPfKnrPR3vrm7GvqxDNvRXtDy7P3x4qe7Gv01w8ei/Zur18e7XWuzh4jAHzQnTp2JdprfbE72vty84lo77b6KdHerAtbor2enuujvS2Xs+cG1V+cieamLs4eV3ylK3vuN7ppYbTXdD77eJ7Smj23f+tg9lrGmr6L0V5VVdXO0T3RXteMu6K9WX3Z5/Are85Fe7X7Dkd7Awe+Hu2tnpq9XjBy+JZo79ScFdHeqtqhaO982+5ob8eOtdHewblTo72f+Gg0B/C+tKtrWrR3pa0t2nvxyp9Fe/+k85Fo740334v2eru7o737l2aPRb93/svR3tZ3N0V79/dnj23bp4xEe791Q/b++Ogfj0Z7XTPfjvaGDr0R7VVVVXXMvCnam73uyWjvny3NnvNO7c+ek988nH2OfOvsVdHeF5Z9KtpbOnYw2ju+Z2e0t2PtbdHesldfjPb6PtUS7R1/MvseXOIbjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoMjQCAAAAAAAAAACKDI0AAAAAAAAAAIAiQyMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACgyNAIAAAAAAAAAAAoqpmYmJj4//sfAQAAAAAAAAAAvL/5RiMAAAAAAAAAAKDI0AgAAAAAAAAAACgyNAIAAAAAAAAAAIoMjQAAAAAAAAAAgCJDIwAAAAAAAAAAoMjQCAAAAAAAAAAAKDI0AgAAAAAAAAAAigyNAAAAAAAAAACAIkMjAAAAAAAAAACg6P8Gm2gjFHjUvxYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Taco\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Taquito\"\n",
    "\n",
    "label_dex = label_index[label]\n",
    "        \n",
    "label_tensor = torch.zeros((10))\n",
    "label_tensor[label_dex] = 1.0\n",
    "\n",
    "        \n",
    "label_tensor = label_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n",
      "Output shape: torch.Size([1, 2352])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(32,16))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Generate a random input vector and get model output\n",
    "        output = G_model.forward(random_G_vector_input().unsqueeze(0), label_tensor)\n",
    "\n",
    "        # Print the output shape for debugging\n",
    "        print(\"Output shape:\", output.shape)\n",
    "\n",
    "        img = output.detach().numpy().reshape(3, 28, 28).transpose(1, 2, 0)  # For RGB\n",
    "        img = (img + 1) / 2\n",
    "\n",
    "        # Display the image\n",
    "        axarr[i, j].imshow(img, interpolation='none')\n",
    "        axarr[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "py38_its530"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
