{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9644b5fe",
   "metadata": {},
   "source": [
    "\n",
    "## American History GPT\n",
    "\n",
    "* Goal: Learn more about American history\n",
    "* Subgoal: Replace history teachers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10298ff7-88f3-4fdd-bbde-3f3050f90b29",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd998537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "import os \n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea3e61-1c48-4b35-b3df-d8618c2c44d0",
   "metadata": {},
   "source": [
    "## Check that cuda is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f15de0c4-2d21-405b-8031-0c6669aa599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2034d17-00ce-4251-a77b-7d7090d23a83",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5ef4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(256)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "block_size        = 40      ## N tokens in sequence\n",
    "batch_size        = 64 \n",
    "max_iters         = 300000\n",
    "eval_interval     = 10000     \n",
    "learning_rate     = 0.0003\n",
    "eval_iters        = 300\n",
    "vocab_size        = 168  ## 65\n",
    "\n",
    "## every id for a given token is embedded to vector of this size\n",
    "n_embd            = 512                  \n",
    "n_head            = 8         ## 8 attention heads\n",
    "n_layer           = 6         ## 6 eoncoder layers\n",
    "dropout           = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83ba7a-1b9a-4e12-a49d-3d44d51df474",
   "metadata": {},
   "source": [
    "## Data\n",
    "* 102 United States History Books from Project Gutenburg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75320194-12be-41bc-8c3f-855e208318a8",
   "metadata": {},
   "source": [
    "## Merge the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d745f9f3-d954-4c66-9624-70153c94e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"E:/ITS 530/datasets/Books/Seperate/American_History/*.txt\")  # or \"file*.txt\"\n",
    "with open(\"output_file.txt\", \"wb\") as outfile:\n",
    "    for filename in filenames:\n",
    "        with open(filename, \"rb\") as infile:\n",
    "            shutil.copyfileobj(infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2849b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = ''\n",
    "\n",
    "input_file2 = 'output_file.txt'\n",
    "\n",
    "with open(input_file2, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ee15f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data in letter or characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53531405"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"length of data in letter or characters\")\n",
    "len(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b283be76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ç',\n",
       " '?',\n",
       " 'H',\n",
       " '#',\n",
       " '\\xad',\n",
       " '”',\n",
       " 'E',\n",
       " '{',\n",
       " '%',\n",
       " 'ë',\n",
       " 'W',\n",
       " '3',\n",
       " '\\t',\n",
       " 'í',\n",
       " 'Ñ',\n",
       " '0',\n",
       " 'î',\n",
       " ']',\n",
       " 'Y',\n",
       " '(',\n",
       " 'r',\n",
       " '5',\n",
       " '9',\n",
       " '´',\n",
       " 'P',\n",
       " 'è',\n",
       " '4',\n",
       " '}',\n",
       " '\\n',\n",
       " 'h',\n",
       " '|',\n",
       " '2',\n",
       " 'ú',\n",
       " '\\ufeff',\n",
       " 'f',\n",
       " '6',\n",
       " '³',\n",
       " 'F',\n",
       " 'Æ',\n",
       " 'Ê',\n",
       " 'ß',\n",
       " 'T',\n",
       " 'D',\n",
       " 'Ü',\n",
       " 'Z',\n",
       " 'i',\n",
       " 'J',\n",
       " 'ñ',\n",
       " 'ê',\n",
       " '[',\n",
       " 'Ë',\n",
       " 'È',\n",
       " '`',\n",
       " 'u',\n",
       " '·',\n",
       " 'z',\n",
       " 'A',\n",
       " '^',\n",
       " '!',\n",
       " 'ä',\n",
       " 'B',\n",
       " 'à',\n",
       " 'X',\n",
       " 'ö',\n",
       " '×',\n",
       " 'É',\n",
       " 'M',\n",
       " '§',\n",
       " 'á',\n",
       " 'x',\n",
       " '*',\n",
       " 'I',\n",
       " '•',\n",
       " 's',\n",
       " '+',\n",
       " '=',\n",
       " 'y',\n",
       " 'k',\n",
       " '.',\n",
       " 'Î',\n",
       " 'n',\n",
       " 'ô',\n",
       " '$',\n",
       " 'p',\n",
       " 'N',\n",
       " 'Ò',\n",
       " '—',\n",
       " '’',\n",
       " '\\xa0',\n",
       " 'm',\n",
       " 'b',\n",
       " 'v',\n",
       " '1',\n",
       " 'Â',\n",
       " '>',\n",
       " '\\x8a',\n",
       " 'Ô',\n",
       " '¹',\n",
       " 'œ',\n",
       " 'K',\n",
       " 'À',\n",
       " 'ù',\n",
       " '\"',\n",
       " 'e',\n",
       " '∴',\n",
       " 'U',\n",
       " 'd',\n",
       " '8',\n",
       " 'ï',\n",
       " '£',\n",
       " '…',\n",
       " 'c',\n",
       " 'V',\n",
       " '¢',\n",
       " 'O',\n",
       " ',',\n",
       " '&',\n",
       " '<',\n",
       " 'Å',\n",
       " 'R',\n",
       " '‘',\n",
       " 'é',\n",
       " ':',\n",
       " ')',\n",
       " '¨',\n",
       " 'º',\n",
       " 'L',\n",
       " 'w',\n",
       " '\\\\',\n",
       " 'Ú',\n",
       " 'l',\n",
       " '°',\n",
       " '»',\n",
       " 'ˆ',\n",
       " '²',\n",
       " 'ü',\n",
       " '@',\n",
       " \"'\",\n",
       " '“',\n",
       " 'ç',\n",
       " 'Ö',\n",
       " '™',\n",
       " '-',\n",
       " 'q',\n",
       " 'a',\n",
       " '_',\n",
       " ';',\n",
       " 'æ',\n",
       " '½',\n",
       " 'G',\n",
       " 'û',\n",
       " 'S',\n",
       " 'o',\n",
       " 'Í',\n",
       " '/',\n",
       " '\\x9c',\n",
       " 'Œ',\n",
       " 'ó',\n",
       " 't',\n",
       " '7',\n",
       " 'Ä',\n",
       " 'â',\n",
       " 'g',\n",
       " 'å',\n",
       " 'j',\n",
       " ' ',\n",
       " 'Q',\n",
       " 'C']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(set(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1fbd2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|} ¢£§¨­°²³´·¹º»½ÀÂÄÅÆÇÈÉÊËÍÎÑÒÔÖ×ÚÜßàáâäåæçèéêëíîïñóôöùúûüŒœˆ—‘’“”•…™∴﻿\n"
     ]
    }
   ],
   "source": [
    "\n",
    "the_chars  = sorted(     list(set(text))     )\n",
    "\n",
    "vocab_size = len( the_chars )      ## 65\n",
    "\n",
    "print(  len(the_chars)  )\n",
    "\n",
    "print(  ''.join(the_chars)  )\n",
    "\n",
    "## The printed oputput\n",
    "## !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbd6792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stoi = { ch:i for i, ch in enumerate(the_chars) }\n",
    "itos = { i:ch for i, ch in enumerate(the_chars) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c6f5989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '#': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, '*': 12, '+': 13, ',': 14, '-': 15, '.': 16, '/': 17, '0': 18, '1': 19, '2': 20, '3': 21, '4': 22, '5': 23, '6': 24, '7': 25, '8': 26, '9': 27, ':': 28, ';': 29, '<': 30, '=': 31, '>': 32, '?': 33, '@': 34, 'A': 35, 'B': 36, 'C': 37, 'D': 38, 'E': 39, 'F': 40, 'G': 41, 'H': 42, 'I': 43, 'J': 44, 'K': 45, 'L': 46, 'M': 47, 'N': 48, 'O': 49, 'P': 50, 'Q': 51, 'R': 52, 'S': 53, 'T': 54, 'U': 55, 'V': 56, 'W': 57, 'X': 58, 'Y': 59, 'Z': 60, '[': 61, '\\\\': 62, ']': 63, '^': 64, '_': 65, '`': 66, 'a': 67, 'b': 68, 'c': 69, 'd': 70, 'e': 71, 'f': 72, 'g': 73, 'h': 74, 'i': 75, 'j': 76, 'k': 77, 'l': 78, 'm': 79, 'n': 80, 'o': 81, 'p': 82, 'q': 83, 'r': 84, 's': 85, 't': 86, 'u': 87, 'v': 88, 'w': 89, 'x': 90, 'y': 91, 'z': 92, '{': 93, '|': 94, '}': 95, '\\x8a': 96, '\\x9c': 97, '\\xa0': 98, '¢': 99, '£': 100, '§': 101, '¨': 102, '\\xad': 103, '°': 104, '²': 105, '³': 106, '´': 107, '·': 108, '¹': 109, 'º': 110, '»': 111, '½': 112, 'À': 113, 'Â': 114, 'Ä': 115, 'Å': 116, 'Æ': 117, 'Ç': 118, 'È': 119, 'É': 120, 'Ê': 121, 'Ë': 122, 'Í': 123, 'Î': 124, 'Ñ': 125, 'Ò': 126, 'Ô': 127, 'Ö': 128, '×': 129, 'Ú': 130, 'Ü': 131, 'ß': 132, 'à': 133, 'á': 134, 'â': 135, 'ä': 136, 'å': 137, 'æ': 138, 'ç': 139, 'è': 140, 'é': 141, 'ê': 142, 'ë': 143, 'í': 144, 'î': 145, 'ï': 146, 'ñ': 147, 'ó': 148, 'ô': 149, 'ö': 150, 'ù': 151, 'ú': 152, 'û': 153, 'ü': 154, 'Œ': 155, 'œ': 156, 'ˆ': 157, '—': 158, '‘': 159, '’': 160, '“': 161, '”': 162, '•': 163, '…': 164, '™': 165, '∴': 166, '\\ufeff': 167}\n",
      "{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: '#', 6: '$', 7: '%', 8: '&', 9: \"'\", 10: '(', 11: ')', 12: '*', 13: '+', 14: ',', 15: '-', 16: '.', 17: '/', 18: '0', 19: '1', 20: '2', 21: '3', 22: '4', 23: '5', 24: '6', 25: '7', 26: '8', 27: '9', 28: ':', 29: ';', 30: '<', 31: '=', 32: '>', 33: '?', 34: '@', 35: 'A', 36: 'B', 37: 'C', 38: 'D', 39: 'E', 40: 'F', 41: 'G', 42: 'H', 43: 'I', 44: 'J', 45: 'K', 46: 'L', 47: 'M', 48: 'N', 49: 'O', 50: 'P', 51: 'Q', 52: 'R', 53: 'S', 54: 'T', 55: 'U', 56: 'V', 57: 'W', 58: 'X', 59: 'Y', 60: 'Z', 61: '[', 62: '\\\\', 63: ']', 64: '^', 65: '_', 66: '`', 67: 'a', 68: 'b', 69: 'c', 70: 'd', 71: 'e', 72: 'f', 73: 'g', 74: 'h', 75: 'i', 76: 'j', 77: 'k', 78: 'l', 79: 'm', 80: 'n', 81: 'o', 82: 'p', 83: 'q', 84: 'r', 85: 's', 86: 't', 87: 'u', 88: 'v', 89: 'w', 90: 'x', 91: 'y', 92: 'z', 93: '{', 94: '|', 95: '}', 96: '\\x8a', 97: '\\x9c', 98: '\\xa0', 99: '¢', 100: '£', 101: '§', 102: '¨', 103: '\\xad', 104: '°', 105: '²', 106: '³', 107: '´', 108: '·', 109: '¹', 110: 'º', 111: '»', 112: '½', 113: 'À', 114: 'Â', 115: 'Ä', 116: 'Å', 117: 'Æ', 118: 'Ç', 119: 'È', 120: 'É', 121: 'Ê', 122: 'Ë', 123: 'Í', 124: 'Î', 125: 'Ñ', 126: 'Ò', 127: 'Ô', 128: 'Ö', 129: '×', 130: 'Ú', 131: 'Ü', 132: 'ß', 133: 'à', 134: 'á', 135: 'â', 136: 'ä', 137: 'å', 138: 'æ', 139: 'ç', 140: 'è', 141: 'é', 142: 'ê', 143: 'ë', 144: 'í', 145: 'î', 146: 'ï', 147: 'ñ', 148: 'ó', 149: 'ô', 150: 'ö', 151: 'ù', 152: 'ú', 153: 'û', 154: 'ü', 155: 'Œ', 156: 'œ', 157: 'ˆ', 158: '—', 159: '‘', 160: '’', 161: '“', 162: '”', 163: '•', 164: '…', 165: '™', 166: '∴', 167: '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( stoi )\n",
    "print( itos )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4e0a86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68, 67, 74, 74]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encode = lambda s: [ stoi[c]          for c in s   ] \n",
    "\n",
    "encode(\"bahh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec4f776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UT[['"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "decode = lambda l: ''.join(   itos[i] for i in l   )    \n",
    "\n",
    "decode([55, 54, 61, 61])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14091bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([167,  54,  74,  ...,   1,   1,   1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = torch.tensor(   encode(text), dtype=torch.long   )\n",
    "\n",
    "print( data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15111645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n          = int(   0.9*len(data)   )\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data   = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bff7ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(split):\n",
    "    if split == \"train\":\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = val_data\n",
    "        \n",
    "    ix = torch.randint(   len(data) - block_size, (batch_size,)   )\n",
    "    \n",
    "    x  = torch.stack(    [  data[   i : i+block_size ]     for i in ix ]    ) \n",
    "    y  = torch.stack(    [  data[ i+1 : i+1+block_size ]   for i in ix ]    )\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb11fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36045809, 50637744,  1395100, 24036015])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_batch_size = 4\n",
    "temp_block_size = 16\n",
    "\n",
    "## select random starting points for the 4 sentences\n",
    "ix = torch.randint(   \n",
    "            len(data) - block_size, \n",
    "            (temp_batch_size,)   \n",
    ")\n",
    "\n",
    "print( ix )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18713538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(71)\n",
      "tensor(86)\n",
      "tensor(2)\n",
      "tensor(67)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index_temp in ix:\n",
    "    print(  data[index_temp]  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c67d3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[71, 79, 81, 88, 71, 70,  2, 85, 87, 69, 74,  2, 81, 72,  2, 86],\n",
      "        [86, 75, 81, 80,  2, 81, 72,  2, 82, 81, 89, 71, 84, 16,  1,  1],\n",
      "        [ 2, 68, 87, 86,  2, 67, 86,  2, 86, 74, 75, 85,  2, 82, 81, 75],\n",
      "        [67, 85, 71, 70,  2, 75, 80,  2, 86, 74, 75, 85,  2, 85, 81, 70]])\n",
      "tensor([[79, 81, 88, 71, 70,  2, 85, 87, 69, 74,  2, 81, 72,  2, 86, 74],\n",
      "        [75, 81, 80,  2, 81, 72,  2, 82, 81, 89, 71, 84, 16,  1,  1, 54],\n",
      "        [68, 87, 86,  2, 67, 86,  2, 86, 74, 75, 85,  2, 82, 81, 75, 80],\n",
      "        [85, 71, 70,  2, 75, 80,  2, 86, 74, 75, 85,  2, 85, 81, 70, 70]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x  = torch.stack(    \n",
    "    [ data[   i : i+  temp_block_size ]   for i in ix ] \n",
    "    \n",
    ") \n",
    "\n",
    "y  = torch.stack(    \n",
    "    [ data[ i+1 : i+1+ temp_block_size ]  for i in ix ]    \n",
    ")\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c58677ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()    ## for efficient processing\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()   ## set to no training\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()  ## back to training\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01742ea3",
   "metadata": {},
   "source": [
    "\n",
    "## NN Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01cc1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "\n",
    "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
    "        \n",
    "        self.register_buffer(\n",
    "                  'tril', \n",
    "                  tril_def\n",
    "               )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
    "        \n",
    "        k = self.key(   x )            ## k = (B, T, 64)\n",
    "        q = self.query( x )            ## q = (B, T, 64)\n",
    "\n",
    "        E2 = 64     ## I think this is 64 and not 512\n",
    "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
    "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        \n",
    "        \n",
    "        wei = wei.masked_fill(\n",
    "                      self.tril[:T, :T] == 0, \n",
    "                      float('-inf')\n",
    "        )   \n",
    "        \n",
    "        ## (B, T, T)\n",
    "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
    "        wei = self.dropout(   wei   )\n",
    "        \n",
    "        ## perform weighted aggregation of values\n",
    "        \n",
    "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
    "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
    "        \n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76ae3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd):         ## 512\n",
    "        \n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe67e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):    ## (8, 64)\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )\n",
    "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
    "        out = self.proj(  out   )\n",
    "        out = self.dropout(   out   )\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a52f09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):     ## (512, 8)\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head        ## 64\n",
    "        self.sa   = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward( n_embd)    ## 512\n",
    "        self.ln1  = nn.LayerNorm(n_embd)\n",
    "        self.ln2  = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(     self.ln1(x)      )\n",
    "        x = x + self.ffwd(   self.ln2(x)      )\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2727b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]\n",
    "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]\n",
    "        )\n",
    "        \n",
    "        self.ln_f    = nn.LayerNorm(  n_embd    )        \n",
    "        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape     ## (Batch, 40)\n",
    "        ## ids and targets are both (B, T) tensors of integers\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx)      \n",
    "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  \n",
    "        \n",
    "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
    "\n",
    "        ## This is the architecture\n",
    "        x = self.blocks(  x  )   ## (B, T, E)        \n",
    "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
    "        logits = self.lm_ffw_head(x)         ## [B, 40, 65] \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, E  = logits.shape\n",
    "            logits  = logits.view( B*T, E)\n",
    "            targets = targets.view(B*T)\n",
    "            loss    = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
    "        for _ in range(max_new_tokens):\n",
    "            ## crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)    ## ## get preds\n",
    "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
    "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
    "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
    "        return idx\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b674c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model   = GPTModel()\n",
    "\n",
    "m       = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(  m.parameters(), lr=learning_rate   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13fac071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.3366, val loss 1.4400\n",
      "step 10000: train loss 1.2785, val loss 1.3796\n",
      "step 20000: train loss 1.2421, val loss 1.3471\n",
      "step 30000: train loss 1.2170, val loss 1.3299\n",
      "step 40000: train loss 1.1968, val loss 1.3118\n",
      "step 50000: train loss 1.1873, val loss 1.3021\n",
      "step 60000: train loss 1.1783, val loss 1.2899\n",
      "step 70000: train loss 1.1672, val loss 1.2888\n",
      "step 80000: train loss 1.1635, val loss 1.2777\n",
      "step 90000: train loss 1.1523, val loss 1.2764\n",
      "step 100000: train loss 1.1460, val loss 1.2667\n",
      "step 110000: train loss 1.1416, val loss 1.2636\n",
      "step 120000: train loss 1.1414, val loss 1.2581\n",
      "step 130000: train loss 1.1363, val loss 1.2566\n",
      "step 140000: train loss 1.1351, val loss 1.2579\n",
      "step 150000: train loss 1.1304, val loss 1.2597\n",
      "step 160000: train loss 1.1248, val loss 1.2436\n",
      "step 170000: train loss 1.1198, val loss 1.2475\n",
      "step 180000: train loss 1.1197, val loss 1.2433\n",
      "step 190000: train loss 1.1197, val loss 1.2439\n",
      "step 200000: train loss 1.1161, val loss 1.2456\n",
      "step 210000: train loss 1.1109, val loss 1.2411\n",
      "step 220000: train loss 1.1118, val loss 1.2321\n",
      "step 230000: train loss 1.1092, val loss 1.2384\n",
      "step 240000: train loss 1.1093, val loss 1.2347\n",
      "step 250000: train loss 1.1047, val loss 1.2353\n",
      "step 260000: train loss 1.0984, val loss 1.2386\n",
      "step 270000: train loss 1.1021, val loss 1.2315\n",
      "step 280000: train loss 1.1021, val loss 1.2338\n",
      "step 290000: train loss 1.0919, val loss 1.2201\n",
      "Total Training Time: 13221.3996 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "for iter in range(max_iters):\n",
    "    \n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    ## eval the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)   ## zero out\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Total Training Time: {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66262e50-a697-47ac-a7f3-e83fa3fc0e56",
   "metadata": {},
   "source": [
    "##### Total Training Time in hours: 3 hrs 40 min 21 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8be5cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t _Face of\n",
      "Perkins'—war    Business.—Senator of Perry.—Elliot Root in 1842.—The Allies.%--The Napoleonic\n",
      "   Basin.\n",
      "\n",
      "_Why was Mexico_ the matter endowed in resolution that the same being practically\n",
      "phrased to a means rising out of data with five\n",
      "months. He was consecrated, Webster, who & N.H.\n",
      "Roberts reviewes demand a receival of the increase of meeting in individual seas. These\n",
      "defeated laws have published, it must be well\n",
      "placed in cipheral comfort, and the keen range have\n",
      "maintained wheat agai\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Starting token  id_sos = 0\n",
    "sos_context = torch.zeros(  (1, 1),  dtype=torch.long, device=device   )   \n",
    "\n",
    "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0992ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Western South Carolina was not won in practice than he was of this object in connection. He was admitted to the day of unity as therefits was\n",
      "confined upon a majority of those who have\n",
      "separated jurisdiction.'\n",
      "\n",
      "The Westerns under George Penn in the United States of America._]\n",
      "\n",
      "The Great Lakes that exploded the Bower Sturdill. To Nashville, in whatever\n",
      "manners, Superintendence and theirs\", being \"Christians.\") The son therefore might stir more men averse yells into the gun, wore cattel\n",
      "about Pout\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sos_context = torch.ones(  (1, 1),  dtype=torch.long, device=device   )   \n",
    "\n",
    "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf899e-5fa3-4364-8bd1-1359accabd03",
   "metadata": {},
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1452a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_lst = encode(\"What is America?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b581fdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 74, 67, 86,  2, 75, 85,  2, 35, 79, 71, 84, 75, 69, 67, 33])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_np = np.array(  new_lst   )\n",
    "new_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58105edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[57, 74, 67, 86,  2, 75, 85,  2, 35, 79, 71, 84, 75, 69, 67, 33]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "new_context \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd205697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is America? How is this order, and very combine now had proved\n",
      "him a raking baron, but it was lie to its morally in\n",
      "due view; but some court is good interest in the\n",
      "Government for the present. Congress's removal to Canada, he would \"get out the first addition of the fifty Years. It was not very significant to go any better chances, when their year later\n",
      "foreigners, threatened their screams of resiin, consequently picturesqueness, and his\n",
      "warriors of deep tudy. The snow springs trees are\n",
      "bitterly supersediness.\n",
      "\n",
      "I please, think, there resorted to an army as specifically\n",
      "equal; but they are very much, at least to give\n",
      "the former Debs and Generals \"making their\n",
      "Benedicts,\" to lay them in arms and the modern forests in the confiscatory night. From\n",
      "1660 to the more President Hampshire. The strength of the\n",
      "Dutchester, who, of the Marque Act, now met at\n",
      "them, and half the (repel with half the children's earth, was thought\n",
      "worn-out of a prize. French of Britain wrote of the improvement of supremacy that \n"
     ]
    }
   ],
   "source": [
    "\n",
    "generated_text = m.generate(new_context, max_new_tokens=1000)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a90c44f-3d9a-4143-88e9-2234fd985fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When was America founded?\n",
      "\n",
      "C. H. Supply of 1824-37-1820. Conspicuo and Whigan. Some men\n",
      "reared as follows:\n",
      "\n",
      "    The amendment of the House on Mr. Hutchinson as a complete needen\n",
      "fear. There has Beecher beguiled his readiness into nine one-half. There were not less local elections than the league, and flouted another at accomplishment now, the right to all\n",
      "American citizens of the class. Though the business of the\n",
      "Pies, the Court discussed the literature; and what parts for\n",
      "From this public of lay an acre of rural negro\n",
      "question the people.\n",
      "\n",
      "Mr. R. W. Keller delegations advocated the temporary\n",
      "loan of five votes, because they may see them to\n",
      "have put such language. Happily were put by everybody\n",
      "of napoly. While the capital lay, and fresh the other, cloth o'clock, were importunately digested into about a\n",
      "          branch used for their salvation without terminal protection systems. It was consequent to the militia regiment.\n",
      "\n",
      "2. Coming into a proclamation and unabandondden army call them. It on a circumstance cle\n"
     ]
    }
   ],
   "source": [
    "new_lst = encode(\"When was America founded?\")\n",
    "\n",
    "new_np = np.array(  new_lst   )\n",
    "\n",
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "\n",
    "generated_text = m.generate(new_context, max_new_tokens=1000)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31a772fe-510f-4e60-a6c7-93fa52a7e8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who won the civil war?\n",
      "\n",
      "§§§ 422, 432.--_a_. Why was the wildest execution in pursuance of the minors. This was the\n",
      "Junction, and advised an electronic workman\n",
      "\n",
      "Pursuant to the Project Gutenberg™ collection will\n",
      "remain freely available, and should be enjoined, in the action, one of a new\n",
      "indignation, usage, did the right to reflections in\n",
      "him, he could abandon the first, turns the master killed the tenth century. He was appointed accordingly elected a Union and\n",
      "Commander-in-chief of General Bragg.\n",
      "\n",
      "Completing the controversy.\n",
      "\n",
      "[Illustration: The Cohons and the Koyukuk Islanders]\n",
      "\n",
      "A Few Marmont--16.\n",
      "\n",
      "At best, suhtered brother on the newspaper.\n",
      "\n",
      "We went to bed the chief companion. Marshal Granger was\n",
      "deciding to invent a tax on railroad payments on bankruptcy by getting the rear of the editor of\n",
      "\"Three Duties,\" not on a most menacing kind\n",
      "of genius you will be a verge of observation, or impracticable, it was considered as embraced if Pocahontas became\n",
      "dwelling upon the King, in Virginia he directs a firm not a\n"
     ]
    }
   ],
   "source": [
    "new_lst = encode(\"Who won the civil war?\")\n",
    "\n",
    "new_np = np.array(  new_lst   )\n",
    "\n",
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "\n",
    "generated_text = m.generate(new_context, max_new_tokens=1000)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25788a36-19b8-4404-9a64-800e61594f4f",
   "metadata": {},
   "source": [
    "## Fill in the Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97ed853f-34c6-4e6d-8511-495325e3a0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America is walking out of first inviolated laws of\n",
      "the Confederation, and the next year Wilson, which he\n",
      "disciplined leads below the comforts of Christopher were now changing to _all_.\n",
      "\n",
      "\"The name of expression as also =Skagames is ended by centre. A gross inceremonization of industry, interesting person than priieves, it could be lifted again, and art commended for it.\n",
      "\n",
      "     Finding that he interposes on the experience of General Sheridan's\n",
      "eloquence is hard to dispose, the right to renew the power\n",
      "of government in two States and another barrel of rigges_     |     1  |     2  |\n",
      "--------------------------------------------------------------\n",
      "Total  |   |    | 11 |   | 3 | |o--| 14 | -- |  -- |   | | |20 ||  | 2 |  --\n",
      " Between                 | 3,791,882|14,861|29,175|16.9| 3,288|  182.75.3\n",
      "District of       3.10. Holghland. 1850.\n",
      "  Fowles..............................................Sdartine.\n",
      "  Sailor, Sherman, Edward R., Charles W., nominated forty years by\n",
      "Fenton's reply and robustitude.\n",
      "\n",
      "\"Now,\n"
     ]
    }
   ],
   "source": [
    "new_lst = encode(\"America is\")\n",
    "\n",
    "new_np = np.array(  new_lst   )\n",
    "\n",
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "\n",
    "generated_text = m.generate(new_context, max_new_tokens=1000)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "551e8030-7ba3-4305-adc7-58818ba80f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe is, but was largely impossible as its\n",
      "aristocratic and mutual prospects. The parties, in\n",
      "Canada, while the waving of the Indians\n",
      "were issued in Lincoln's House. The intent of training might therefore continue so vastly, and he is best one of the\n",
      "greatest favourites, and gradually trim to as they attributed the people.\n",
      "\n",
      "\n",
      "[Illustration: Portrait.]\n",
      "Goosevesee looking forth a \"preliminary\"--in\n",
      "cases which have so matched breath a reality, however, was due to a lamp that\n",
      "these men should come from Blanch's House.\n",
      "\n",
      "Seven years later Franklin WICCOTT, two words in detachment\n",
      "on the one hand, under the Democratic Jury, and the Department of Federal Office, the Court rules, held that the confusion in\n",
      "Jacob Brown in 1848 five-year-note. In 1858 opposition William\n",
      "Kearsley, a free and his territory, it was property or discovery of a just quota region, excluding believe, without\n",
      "enrolling such evils, similar and personal execution, II.\n",
      "  proportions of the States, IV.\n",
      "  memorial and elaborate revolt\n"
     ]
    }
   ],
   "source": [
    "new_lst = encode(\"Europe is\")\n",
    "\n",
    "new_np = np.array(  new_lst   )\n",
    "\n",
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "\n",
    "generated_text = m.generate(new_context, max_new_tokens=1000)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f88240f-2ca2-4635-9de7-59fdea489ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada is short of Coloradose which later complains Capt. John Price, a Tory\n",
      "   scene which rushed into despotillato widely and chucklebering; against the\n",
      "connection of Indians. After that obligation has appeared for more money repealed by public goods which shall be sued functioned as very\n",
      "ill. But a defective speecher left the breaking out of the\n",
      "     machines of the ruffled horns oak to land stone, sold,\n",
      "numbers of cotton on both sides, and pointed four hundred vanquis gener gute in\n",
      "] love of a single quorum\"                            51\n",
      "\n",
      "\n",
      "\n",
      "Kentucky and South                                    583\n",
      "      Status of the sufferings of discussion showed that Greely situate is gifted with that of\n",
      "the judicial conciliation), or to the institution and in favor of a virtue\n",
      "of practical disciousness abuse of the buyers of that State. Soon the\n",
      "neighboring wheel was limely uplifted by international progress, Reynal, and John Morris arrived.\n",
      "\n",
      "\n",
      "This accomplishment touches, as if they had beheld five\n",
      "thou\n"
     ]
    }
   ],
   "source": [
    "new_lst = encode(\"Canada is\")\n",
    "\n",
    "new_np = np.array(  new_lst   )\n",
    "\n",
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "\n",
    "generated_text = m.generate(new_context, max_new_tokens=1000)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e764b1-492a-4d33-bd81-07a3a288324b",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "* More Data\n",
    "* Longer Train Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16989b7",
   "metadata": {},
   "source": [
    "\n",
    "## Figuring out dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c883349f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_context.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0df7379e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sos_context_tmp = torch.ones(  (1, 1),  dtype=torch.long, device=device   ) \n",
    "sos_context_tmp.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
